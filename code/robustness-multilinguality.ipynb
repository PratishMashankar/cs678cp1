{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7a6BWc7yY2rF"
      },
      "source": [
        "# Checkpoint 2\n",
        "Project Name: **Once More! An iterative text revision model**\n",
        "\n",
        "\n",
        "Robustness and Multilinguality checks for Author's models and those of \"Understanding Iterative Revision from Human-Written Text\" by Wanyu Du et al.\n",
        "\n",
        "\n",
        "Team\n",
        "* Pratish Mashankar G#: G01354094\n",
        "* William J David G#: G01129185\n",
        "* Sai Likhitha Allanki G#: G01336091\n",
        "\n",
        "Git Repo: https://github.com/PratishMashankar/cs678cp1.git"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "daVLPuPEZMKb"
      },
      "source": [
        "## README\n",
        "The following code perfroms Multilinguality and Robustness tests on Authors and the Wanyu Du et al's code. The work flow entitles as below:\n",
        "\n",
        "1. Cloning Git repo\n",
        "2. Using requirements.txt to download the necessary libraries\n",
        "3. Robustness Checks for Intent CLassfication and Text Generation\n",
        "4. Multilinguality Checks for Intent CLassfication and Text Generation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NkZUpl6LZ5Po"
      },
      "source": [
        "## Processing code\n",
        "\n",
        "The following code blocks import the required files and datasets from Authors and Wanyu Du et al git repositories. They also install the requirements"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ljk4vop9Z-MH"
      },
      "source": [
        "Cloning Git Repo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "48SjRUaRYdiD",
        "outputId": "78b4ba1e-0bb0-4d3d-ec94-5c769dcef48c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "git-lfs is already the newest version (2.9.2-1).\n",
            "git is already the newest version (1:2.25.1-1ubuntu3.11).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 24 not upgraded.\n",
            "Cloning into 'cs678-cp1-cp2'...\n",
            "remote: Enumerating objects: 73, done.\u001b[K\n",
            "remote: Counting objects: 100% (73/73), done.\u001b[K\n",
            "remote: Compressing objects: 100% (63/63), done.\u001b[K\n",
            "remote: Total 73 (delta 34), reused 31 (delta 7), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (73/73), 1.07 MiB | 2.77 MiB/s, done.\n",
            "Cloning into 'iterater'...\n",
            "remote: Enumerating objects: 243, done.\u001b[K\n",
            "remote: Counting objects: 100% (56/56), done.\u001b[K\n",
            "remote: Compressing objects: 100% (44/44), done.\u001b[K\n",
            "remote: Total 243 (delta 21), reused 40 (delta 12), pack-reused 187\u001b[K\n",
            "Receiving objects: 100% (243/243), 121.33 MiB | 18.07 MiB/s, done.\n",
            "Resolving deltas: 100% (108/108), done.\n",
            "Downloading dataset/IteraTeR_plus.zip (257 MB)\n",
            "Error downloading object: dataset/IteraTeR_plus.zip (082f3d5): Smudge error: Error downloading dataset/IteraTeR_plus.zip (082f3d5516b4f8d180b95f0a1ac36237409d217ef21ed08c52b60c1492364c2f): batch response: This repository is over its data quota. Account responsible for LFS bandwidth should purchase more data packs to restore access.\n",
            "\n",
            "Errors logged to /content/iterater/.git/lfs/logs/20230507T212653.769644456.log\n",
            "Use `git lfs logs last` to view the log.\n",
            "error: external filter 'git-lfs filter-process' failed\n",
            "fatal: dataset/IteraTeR_plus.zip: smudge filter lfs failed\n",
            "warning: Clone succeeded, but checkout failed.\n",
            "You can inspect what was checked out with 'git status'\n",
            "and retry with 'git restore --source=HEAD :/'\n",
            "\n"
          ]
        }
      ],
      "source": [
        "%cd /content\n",
        "!apt-get install git-lfs git\n",
        "!git clone https://github.com/PratishMashankar/cs678-cp1-cp2.git #dont change this\n",
        "!git clone https://github.com/vipulraheja/iterater.git\n",
        "!git config --global user.email \"sailikhitha22@gmail.com\" #change this with your email\n",
        "!git config --global user.name \"Sai Likhitha Allanki\" #change this with your name"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B21YQK1DaHBD"
      },
      "source": [
        "Downloading Requirements"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IWEORASyaKGn",
        "outputId": "0d2095a0-61c0-48ef-9d9e-530a5ace0a67"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from -r /content/iterater/requirements.txt (line 1)) (0.15.1+cu118)\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.28.1-py3-none-any.whl (7.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m65.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting datasets==1.18.3\n",
            "  Downloading datasets-1.18.3-py3-none-any.whl (311 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m311.7/311.7 kB\u001b[0m \u001b[31m36.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from -r /content/iterater/requirements.txt (line 4)) (3.8.1)\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.10/dist-packages (from -r /content/iterater/requirements.txt (line 5)) (3.5.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from -r /content/iterater/requirements.txt (line 6)) (1.22.4)\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m66.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: google in /usr/local/lib/python3.10/dist-packages (from -r /content/iterater/requirements.txt (line 8)) (2.0.3)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from -r /content/iterater/requirements.txt (line 9)) (3.20.3)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from -r /content/iterater/requirements.txt (line 10)) (1.4.0)\n",
            "Collecting rouge_score\n",
            "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting wandb\n",
            "  Downloading wandb-0.15.2-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m84.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sacrebleu==1.5.1\n",
            "  Downloading sacrebleu-1.5.1-py3-none-any.whl (54 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sacremoses\n",
            "  Downloading sacremoses-0.0.53.tar.gz (880 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m880.6/880.6 kB\u001b[0m \u001b[31m58.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets==1.18.3->-r /content/iterater/requirements.txt (line 3)) (23.1)\n",
            "Collecting aiohttp\n",
            "  Downloading aiohttp-3.8.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m59.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets==1.18.3->-r /content/iterater/requirements.txt (line 3)) (2.27.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets==1.18.3->-r /content/iterater/requirements.txt (line 3)) (1.5.3)\n",
            "Collecting dill\n",
            "  Downloading dill-0.3.6-py3-none-any.whl (110 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.5/110.5 kB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multiprocess\n",
            "  Downloading multiprocess-0.70.14-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.3/134.3 kB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets==1.18.3->-r /content/iterater/requirements.txt (line 3)) (4.65.0)\n",
            "Collecting xxhash\n",
            "  Downloading xxhash-3.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.5/212.5 kB\u001b[0m \u001b[31m22.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting huggingface-hub<1.0.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.14.1-py3-none-any.whl (224 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m26.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]>=2021.05.0 in /usr/local/lib/python3.10/dist-packages (from datasets==1.18.3->-r /content/iterater/requirements.txt (line 3)) (2023.4.0)\n",
            "Requirement already satisfied: pyarrow!=4.0.0,>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets==1.18.3->-r /content/iterater/requirements.txt (line 3)) (9.0.0)\n",
            "Collecting portalocker==2.0.0\n",
            "  Downloading portalocker-2.0.0-py2.py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->-r /content/iterater/requirements.txt (line 1)) (8.4.0)\n",
            "Requirement already satisfied: torch==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->-r /content/iterater/requirements.txt (line 1)) (2.0.0+cu118)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0->torchvision->-r /content/iterater/requirements.txt (line 1)) (4.5.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0->torchvision->-r /content/iterater/requirements.txt (line 1)) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0->torchvision->-r /content/iterater/requirements.txt (line 1)) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0->torchvision->-r /content/iterater/requirements.txt (line 1)) (2.0.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0->torchvision->-r /content/iterater/requirements.txt (line 1)) (3.12.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0->torchvision->-r /content/iterater/requirements.txt (line 1)) (1.11.1)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch==2.0.0->torchvision->-r /content/iterater/requirements.txt (line 1)) (16.0.2)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch==2.0.0->torchvision->-r /content/iterater/requirements.txt (line 1)) (3.25.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers->-r /content/iterater/requirements.txt (line 2)) (2022.10.31)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m108.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers->-r /content/iterater/requirements.txt (line 2)) (6.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->-r /content/iterater/requirements.txt (line 4)) (1.2.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->-r /content/iterater/requirements.txt (line 4)) (8.1.3)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy->-r /content/iterater/requirements.txt (line 5)) (2.0.8)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy->-r /content/iterater/requirements.txt (line 5)) (1.1.1)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy->-r /content/iterater/requirements.txt (line 5)) (3.0.12)\n",
            "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy->-r /content/iterater/requirements.txt (line 5)) (0.7.0)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.10/dist-packages (from spacy->-r /content/iterater/requirements.txt (line 5)) (8.1.9)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy->-r /content/iterater/requirements.txt (line 5)) (1.0.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy->-r /content/iterater/requirements.txt (line 5)) (67.7.2)\n",
            "Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from spacy->-r /content/iterater/requirements.txt (line 5)) (0.10.1)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy->-r /content/iterater/requirements.txt (line 5)) (6.3.0)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy->-r /content/iterater/requirements.txt (line 5)) (2.4.6)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy->-r /content/iterater/requirements.txt (line 5)) (1.10.7)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy->-r /content/iterater/requirements.txt (line 5)) (3.3.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy->-r /content/iterater/requirements.txt (line 5)) (1.0.9)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy->-r /content/iterater/requirements.txt (line 5)) (3.0.8)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy->-r /content/iterater/requirements.txt (line 5)) (2.0.7)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from google->-r /content/iterater/requirements.txt (line 8)) (4.11.2)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from rouge_score->-r /content/iterater/requirements.txt (line 11)) (1.16.0)\n",
            "Collecting sentry-sdk>=1.0.0\n",
            "  Downloading sentry_sdk-1.22.1-py2.py3-none-any.whl (203 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m203.1/203.1 kB\u001b[0m \u001b[31m27.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb->-r /content/iterater/requirements.txt (line 12)) (5.9.5)\n",
            "Collecting pathtools\n",
            "  Downloading pathtools-0.1.2.tar.gz (11 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting docker-pycreds>=0.4.0\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Requirement already satisfied: appdirs>=1.4.3 in /usr/local/lib/python3.10/dist-packages (from wandb->-r /content/iterater/requirements.txt (line 12)) (1.4.4)\n",
            "Collecting setproctitle\n",
            "  Downloading setproctitle-1.3.2-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
            "Collecting GitPython!=3.1.29,>=1.0.0\n",
            "  Downloading GitPython-3.1.31-py3-none-any.whl (184 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m184.3/184.3 kB\u001b[0m \u001b[31m23.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiosignal>=1.1.2\n",
            "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
            "Collecting multidict<7.0,>=4.5\n",
            "  Downloading multidict-6.0.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.5/114.5 kB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==1.18.3->-r /content/iterater/requirements.txt (line 3)) (23.1.0)\n",
            "Collecting yarl<2.0,>=1.0\n",
            "  Downloading yarl-1.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (268 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m30.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==1.18.3->-r /content/iterater/requirements.txt (line 3)) (2.0.12)\n",
            "Collecting frozenlist>=1.1.1\n",
            "  Downloading frozenlist-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (149 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.6/149.6 kB\u001b[0m \u001b[31m19.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting async-timeout<5.0,>=4.0.0a3\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Collecting gitdb<5,>=4.0.1\n",
            "  Downloading gitdb-4.0.10-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets==1.18.3->-r /content/iterater/requirements.txt (line 3)) (3.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets==1.18.3->-r /content/iterater/requirements.txt (line 3)) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets==1.18.3->-r /content/iterater/requirements.txt (line 3)) (1.26.15)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy->-r /content/iterater/requirements.txt (line 5)) (0.0.4)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy->-r /content/iterater/requirements.txt (line 5)) (0.7.9)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->google->-r /content/iterater/requirements.txt (line 8)) (2.4.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.0.0->torchvision->-r /content/iterater/requirements.txt (line 1)) (2.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets==1.18.3->-r /content/iterater/requirements.txt (line 3)) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets==1.18.3->-r /content/iterater/requirements.txt (line 3)) (2022.7.1)\n",
            "Collecting smmap<6,>=3.0.1\n",
            "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.0.0->torchvision->-r /content/iterater/requirements.txt (line 1)) (1.3.0)\n",
            "Building wheels for collected packages: rouge_score, sacremoses, pathtools\n",
            "  Building wheel for rouge_score (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for rouge_score: filename=rouge_score-0.1.2-py3-none-any.whl size=24954 sha256=5155a027573eb3db1d5aff110361342758c58d0202561585920a20d011d8223e\n",
            "  Stored in directory: /root/.cache/pip/wheels/5f/dd/89/461065a73be61a532ff8599a28e9beef17985c9e9c31e541b4\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895259 sha256=43494fb2229485b25bb339385842a922f9f383b071237c12573a5797974c9aaa\n",
            "  Stored in directory: /root/.cache/pip/wheels/00/24/97/a2ea5324f36bc626e1ea0267f33db6aa80d157ee977e9e42fb\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8807 sha256=e18553c977d4bfba7db6ba631e27db9ebe310c14794e8b1d1a1f00bcb7d1738e\n",
            "  Stored in directory: /root/.cache/pip/wheels/e7/f3/22/152153d6eb222ee7a56ff8617d80ee5207207a8c00a7aab794\n",
            "Successfully built rouge_score sacremoses pathtools\n",
            "Installing collected packages: tokenizers, sentencepiece, portalocker, pathtools, xxhash, smmap, setproctitle, sentry-sdk, sacremoses, sacrebleu, multidict, frozenlist, docker-pycreds, dill, async-timeout, yarl, rouge_score, multiprocess, huggingface-hub, gitdb, aiosignal, transformers, GitPython, aiohttp, wandb, datasets\n",
            "Successfully installed GitPython-3.1.31 aiohttp-3.8.4 aiosignal-1.3.1 async-timeout-4.0.2 datasets-1.18.3 dill-0.3.6 docker-pycreds-0.4.0 frozenlist-1.3.3 gitdb-4.0.10 huggingface-hub-0.14.1 multidict-6.0.4 multiprocess-0.70.14 pathtools-0.1.2 portalocker-2.0.0 rouge_score-0.1.2 sacrebleu-1.5.1 sacremoses-0.0.53 sentencepiece-0.1.99 sentry-sdk-1.22.1 setproctitle-1.3.2 smmap-5.0.0 tokenizers-0.13.3 transformers-4.28.1 wandb-0.15.2 xxhash-3.2.0 yarl-1.9.2\n"
          ]
        }
      ],
      "source": [
        "# Change 1: Updating the requirements.txt of Wanyu Du et al. to match the latest versions\n",
        "import re\n",
        "\n",
        "requirements_path = '/content/iterater/requirements.txt'\n",
        "\n",
        "# Open the input file\n",
        "with open(requirements_path, \"r\") as f:\n",
        "    # Read the contents of the file and split on newlines\n",
        "    contents = f.read().splitlines()\n",
        "\n",
        "# Clean the package names by removing whitespace and version numbers\n",
        "cleaned = [re.sub(r\"\\s*\\d+\\.\\d+(\\.\\d+)*$\", \"\", package) for package in contents]\n",
        "\n",
        "# Write the cleaned package names to a new file in the desired format\n",
        "with open(requirements_path, \"w\") as f:\n",
        "    f.write(\"torchvision\\n\")\n",
        "    f.write(\"transformers\\n\")\n",
        "    f.write(\"datasets==1.18.3\\n\")\n",
        "    f.write(\"nltk\\n\")\n",
        "    f.write(\"spacy\\n\")\n",
        "    f.write(\"numpy\\n\")\n",
        "    f.write(\"sentencepiece\\n\")\n",
        "    f.write(\"google\\n\")\n",
        "    f.write(\"protobuf\\n\")\n",
        "    f.write(\"absl-py\\n\")\n",
        "    f.write(\"rouge_score\\n\")\n",
        "    f.write(\"wandb\\n\")\n",
        "    f.write(\"sacrebleu==1.5.1\\n\")\n",
        "    f.write(\"sacremoses\\n\")\n",
        "\n",
        "!pip install -r /content/iterater/requirements.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W0HLu91baJsN"
      },
      "source": [
        "Unzipping Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F_gr-0M7aQkL",
        "outputId": "1ae6aa5a-ffd6-4e65-e550-28b2112608c0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/iterater/dataset/IteraTeR.zip\n",
            "   creating: IteraTeR/\n",
            "   creating: IteraTeR/full_sent_level/\n",
            "  inflating: __MACOSX/IteraTeR/._full_sent_level  \n",
            "   creating: IteraTeR/human_sent_level/\n",
            "  inflating: __MACOSX/IteraTeR/._human_sent_level  \n",
            "   creating: IteraTeR/full_doc_level/\n",
            "  inflating: __MACOSX/IteraTeR/._full_doc_level  \n",
            "   creating: IteraTeR/human_doc_level/\n",
            "  inflating: __MACOSX/IteraTeR/._human_doc_level  \n",
            "  inflating: IteraTeR/full_sent_level/test.json  \n",
            "  inflating: __MACOSX/IteraTeR/full_sent_level/._test.json  \n",
            "  inflating: IteraTeR/full_sent_level/dev.json  \n",
            "  inflating: __MACOSX/IteraTeR/full_sent_level/._dev.json  \n",
            "  inflating: IteraTeR/full_sent_level/train.json  \n",
            "  inflating: __MACOSX/IteraTeR/full_sent_level/._train.json  \n",
            "  inflating: IteraTeR/human_sent_level/test.json  \n",
            "  inflating: __MACOSX/IteraTeR/human_sent_level/._test.json  \n",
            "  inflating: IteraTeR/human_sent_level/dev.json  \n",
            "  inflating: __MACOSX/IteraTeR/human_sent_level/._dev.json  \n",
            "  inflating: IteraTeR/human_sent_level/train.json  \n",
            "  inflating: __MACOSX/IteraTeR/human_sent_level/._train.json  \n",
            "  inflating: IteraTeR/full_doc_level/test.json  \n",
            "  inflating: __MACOSX/IteraTeR/full_doc_level/._test.json  \n",
            "  inflating: IteraTeR/full_doc_level/dev.json  \n",
            "  inflating: __MACOSX/IteraTeR/full_doc_level/._dev.json  \n",
            "  inflating: IteraTeR/full_doc_level/train.json  \n",
            "  inflating: __MACOSX/IteraTeR/full_doc_level/._train.json  \n",
            "  inflating: IteraTeR/human_doc_level/test.json  \n",
            "  inflating: __MACOSX/IteraTeR/human_doc_level/._test.json  \n",
            "  inflating: IteraTeR/human_doc_level/dev.json  \n",
            "  inflating: __MACOSX/IteraTeR/human_doc_level/._dev.json  \n",
            "  inflating: IteraTeR/human_doc_level/train.json  \n",
            "  inflating: __MACOSX/IteraTeR/human_doc_level/._train.json  \n"
          ]
        }
      ],
      "source": [
        "# dataset_path = '/content/iterater/dataset/IteraTeR'\n",
        "!unzip '/content/iterater/dataset/IteraTeR.zip'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NtS_yS0IaSuL"
      },
      "source": [
        "## Part 1: Robustness Test\n",
        "\n",
        "We test the robustness on best models obtained from Checkpoint 1 for the two tasks of Intent Classification and Iterative Edit Generation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WrnApHTF1Dyk"
      },
      "source": [
        "### Generating Robustness Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QHFd0qWA1ILy"
      },
      "source": [
        "#### Installs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jNRykkn21Qae",
        "outputId": "e2ffc035-4120-46c9-b532-27f7d50c2658"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting checklist\n",
            "  Downloading checklist-0.0.11.tar.gz (12.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.1/12.1 MB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.18 in /usr/local/lib/python3.10/dist-packages (from checklist) (1.22.4)\n",
            "Requirement already satisfied: spacy>=2.2 in /usr/local/lib/python3.10/dist-packages (from checklist) (3.5.2)\n",
            "Collecting munch>=2.5\n",
            "  Downloading munch-2.5.0-py2.py3-none-any.whl (10 kB)\n",
            "Collecting dill>=0.3.1\n",
            "  Downloading dill-0.3.6-py3-none-any.whl (110 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.5/110.5 kB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jupyter>=1.0\n",
            "  Using cached jupyter-1.0.0-py2.py3-none-any.whl (2.7 kB)\n",
            "Requirement already satisfied: ipywidgets>=7.5 in /usr/local/lib/python3.10/dist-packages (from checklist) (7.7.1)\n",
            "Collecting transformers>=2.8\n",
            "  Downloading transformers-4.28.1-py3-none-any.whl (7.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m30.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting patternfork-nosql\n",
            "  Downloading patternfork_nosql-3.6.tar.gz (22.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m22.3/22.3 MB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting iso-639\n",
            "  Downloading iso-639-0.4.5.tar.gz (167 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m167.4/167.4 kB\u001b[0m \u001b[31m22.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets>=7.5->checklist) (0.2.0)\n",
            "Requirement already satisfied: widgetsnbextension~=3.6.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets>=7.5->checklist) (3.6.4)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets>=7.5->checklist) (3.0.7)\n",
            "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.10/dist-packages (from ipywidgets>=7.5->checklist) (5.7.1)\n",
            "Requirement already satisfied: ipython>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets>=7.5->checklist) (7.34.0)\n",
            "Requirement already satisfied: ipykernel>=4.5.1 in /usr/local/lib/python3.10/dist-packages (from ipywidgets>=7.5->checklist) (5.5.6)\n",
            "Requirement already satisfied: jupyter-console in /usr/local/lib/python3.10/dist-packages (from jupyter>=1.0->checklist) (6.1.0)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.10/dist-packages (from jupyter>=1.0->checklist) (6.5.4)\n",
            "Requirement already satisfied: notebook in /usr/local/lib/python3.10/dist-packages (from jupyter>=1.0->checklist) (6.4.8)\n",
            "Collecting qtconsole\n",
            "  Using cached qtconsole-5.4.3-py3-none-any.whl (121 kB)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from munch>=2.5->checklist) (1.16.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy>=2.2->checklist) (23.1)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy>=2.2->checklist) (2.4.6)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy>=2.2->checklist) (1.10.7)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy>=2.2->checklist) (2.0.8)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy>=2.2->checklist) (1.1.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy>=2.2->checklist) (2.27.1)\n",
            "Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from spacy>=2.2->checklist) (0.10.1)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy>=2.2->checklist) (6.3.0)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy>=2.2->checklist) (3.0.8)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy>=2.2->checklist) (2.0.7)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.10/dist-packages (from spacy>=2.2->checklist) (8.1.9)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy>=2.2->checklist) (3.0.12)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy>=2.2->checklist) (3.3.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy>=2.2->checklist) (67.7.2)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy>=2.2->checklist) (1.0.4)\n",
            "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy>=2.2->checklist) (0.7.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy>=2.2->checklist) (4.65.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy>=2.2->checklist) (1.0.9)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy>=2.2->checklist) (3.1.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=2.8->checklist) (6.0)\n",
            "Collecting huggingface-hub<1.0,>=0.11.0\n",
            "  Downloading huggingface_hub-0.14.1-py3-none-any.whl (224 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m32.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=2.8->checklist) (2022.10.31)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m118.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers>=2.8->checklist) (3.12.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from patternfork-nosql->checklist) (0.18.3)\n",
            "Collecting backports.csv\n",
            "  Downloading backports.csv-1.0.7-py2.py3-none-any.whl (12 kB)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from patternfork-nosql->checklist) (4.11.2)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from patternfork-nosql->checklist) (4.9.2)\n",
            "Collecting feedparser\n",
            "  Downloading feedparser-6.0.10-py3-none-any.whl (81 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.1/81.1 kB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pdfminer.six\n",
            "  Downloading pdfminer.six-20221105-py3-none-any.whl (5.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m116.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from patternfork-nosql->checklist) (1.10.1)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from patternfork-nosql->checklist) (3.8.1)\n",
            "Collecting python-docx\n",
            "  Downloading python-docx-0.8.11.tar.gz (5.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m123.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting cherrypy\n",
            "  Downloading CherryPy-18.8.0-py2.py3-none-any.whl (348 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m348.4/348.4 kB\u001b[0m \u001b[31m46.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers>=2.8->checklist) (4.5.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers>=2.8->checklist) (2023.4.0)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.10/dist-packages (from ipykernel>=4.5.1->ipywidgets>=7.5->checklist) (6.1.12)\n",
            "Requirement already satisfied: tornado>=4.2 in /usr/local/lib/python3.10/dist-packages (from ipykernel>=4.5.1->ipywidgets>=7.5->checklist) (6.2)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets>=7.5->checklist) (2.14.0)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets>=7.5->checklist) (0.7.5)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets>=7.5->checklist) (0.2.0)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets>=7.5->checklist) (3.0.38)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets>=7.5->checklist) (0.1.6)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets>=7.5->checklist) (4.4.2)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets>=7.5->checklist) (4.8.0)\n",
            "Collecting jedi>=0.16\n",
            "  Using cached jedi-0.18.2-py2.py3-none-any.whl (1.6 MB)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2->checklist) (2.0.12)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2->checklist) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2->checklist) (2022.12.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2->checklist) (3.4)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy>=2.2->checklist) (0.7.9)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy>=2.2->checklist) (0.0.4)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.8.0,>=0.3.0->spacy>=2.2->checklist) (8.1.3)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.10/dist-packages (from notebook->jupyter>=1.0->checklist) (0.16.0)\n",
            "Requirement already satisfied: Send2Trash>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from notebook->jupyter>=1.0->checklist) (1.8.0)\n",
            "Requirement already satisfied: pyzmq>=17 in /usr/local/lib/python3.10/dist-packages (from notebook->jupyter>=1.0->checklist) (23.2.1)\n",
            "Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.10/dist-packages (from notebook->jupyter>=1.0->checklist) (21.3.0)\n",
            "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from notebook->jupyter>=1.0->checklist) (0.17.1)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.10/dist-packages (from notebook->jupyter>=1.0->checklist) (5.8.0)\n",
            "Requirement already satisfied: jupyter-core>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from notebook->jupyter>=1.0->checklist) (5.3.0)\n",
            "Requirement already satisfied: nest-asyncio>=1.5 in /usr/local/lib/python3.10/dist-packages (from notebook->jupyter>=1.0->checklist) (1.5.6)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->patternfork-nosql->checklist) (2.4.1)\n",
            "Collecting zc.lockfile\n",
            "  Downloading zc.lockfile-3.0.post1-py3-none-any.whl (9.8 kB)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.10/dist-packages (from cherrypy->patternfork-nosql->checklist) (9.1.0)\n",
            "Collecting portend>=2.1.1\n",
            "  Downloading portend-3.1.0-py3-none-any.whl (5.3 kB)\n",
            "Collecting jaraco.collections\n",
            "  Downloading jaraco.collections-4.1.0-py3-none-any.whl (11 kB)\n",
            "Collecting cheroot>=8.2.1\n",
            "  Downloading cheroot-9.0.0-py2.py3-none-any.whl (100 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m100.6/100.6 kB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sgmllib3k\n",
            "  Downloading sgmllib3k-1.0.0.tar.gz (5.8 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy>=2.2->checklist) (2.1.2)\n",
            "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter>=1.0->checklist) (0.2.2)\n",
            "Requirement already satisfied: tinycss2 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter>=1.0->checklist) (1.2.1)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter>=1.0->checklist) (0.7.1)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter>=1.0->checklist) (0.8.4)\n",
            "Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter>=1.0->checklist) (0.7.4)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter>=1.0->checklist) (1.5.0)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter>=1.0->checklist) (0.4)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter>=1.0->checklist) (6.0.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->patternfork-nosql->checklist) (1.2.0)\n",
            "Requirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.10/dist-packages (from pdfminer.six->patternfork-nosql->checklist) (40.0.2)\n",
            "Collecting qtpy>=2.0.1\n",
            "  Using cached QtPy-2.3.1-py3-none-any.whl (84 kB)\n",
            "Collecting jaraco.functools\n",
            "  Downloading jaraco.functools-3.6.0-py3-none-any.whl (7.9 kB)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography>=36.0.0->pdfminer.six->patternfork-nosql->checklist) (1.15.1)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython>=4.0.0->ipywidgets>=7.5->checklist) (0.8.3)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.10/dist-packages (from jupyter-client->ipykernel>=4.5.1->ipywidgets>=7.5->checklist) (2.8.2)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.10/dist-packages (from jupyter-core>=4.6.1->notebook->jupyter>=1.0->checklist) (3.3.0)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.10/dist-packages (from nbformat->notebook->jupyter>=1.0->checklist) (4.3.3)\n",
            "Requirement already satisfied: fastjsonschema in /usr/local/lib/python3.10/dist-packages (from nbformat->notebook->jupyter>=1.0->checklist) (2.16.3)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython>=4.0.0->ipywidgets>=7.5->checklist) (0.7.0)\n",
            "Collecting tempora>=1.8\n",
            "  Downloading tempora-5.2.2-py3-none-any.whl (13 kB)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=4.0.0->ipywidgets>=7.5->checklist) (0.2.6)\n",
            "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.10/dist-packages (from argon2-cffi->notebook->jupyter>=1.0->checklist) (21.2.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->nbconvert->jupyter>=1.0->checklist) (0.5.1)\n",
            "Collecting jaraco.text\n",
            "  Downloading jaraco.text-3.11.1-py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six->patternfork-nosql->checklist) (2.21)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->notebook->jupyter>=1.0->checklist) (23.1.0)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->notebook->jupyter>=1.0->checklist) (0.19.3)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.10/dist-packages (from tempora>=1.8->portend>=2.1.1->cherrypy->patternfork-nosql->checklist) (2022.7.1)\n",
            "Requirement already satisfied: inflect in /usr/local/lib/python3.10/dist-packages (from jaraco.text->jaraco.collections->cherrypy->patternfork-nosql->checklist) (6.0.4)\n",
            "Collecting jaraco.context>=4.1\n",
            "  Downloading jaraco.context-4.3.0-py3-none-any.whl (5.3 kB)\n",
            "Collecting autocommand\n",
            "  Downloading autocommand-2.2.2-py3-none-any.whl (19 kB)\n",
            "Building wheels for collected packages: checklist, iso-639, patternfork-nosql, python-docx, sgmllib3k\n",
            "  Building wheel for checklist (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for checklist: filename=checklist-0.0.11-py3-none-any.whl size=12165634 sha256=72f15e858baa2bf321ec0b270d30cfe869b4767e27e89f2452c2997e70c6ad01\n",
            "  Stored in directory: /root/.cache/pip/wheels/69/8c/8d/ee02f2800af2cc27b01018a46d7c1c5c5a7cfe31b9fde273a8\n",
            "  Building wheel for iso-639 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for iso-639: filename=iso_639-0.4.5-py3-none-any.whl size=168853 sha256=8fbb4544eaa6ad106134641bcbce1bfb09740adc58cbd24f34b70dbb75709d4b\n",
            "  Stored in directory: /root/.cache/pip/wheels/d8/78/cc/5478ca3b1c3f602eae6f8cdbd78f909c0a0bfa0bbcb5c7771f\n",
            "  Building wheel for patternfork-nosql (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for patternfork-nosql: filename=patternfork_nosql-3.6-py3-none-any.whl size=22332801 sha256=ab38c0ce55d4fcc728115671f28e1f69a95c84e5822f13c53b6dbbaa920d59f4\n",
            "  Stored in directory: /root/.cache/pip/wheels/a1/4c/b6/9d3a6963fe490043b4ff4c9699411a11a9946542dcaa79e24c\n",
            "  Building wheel for python-docx (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for python-docx: filename=python_docx-0.8.11-py3-none-any.whl size=184505 sha256=aea49a920f2d1ebfcf90383eb3e29263ef87a00e949a223ce3b25ed3215eb5fa\n",
            "  Stored in directory: /root/.cache/pip/wheels/80/27/06/837436d4c3bd989b957a91679966f207bfd71d358d63a8194d\n",
            "  Building wheel for sgmllib3k (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sgmllib3k: filename=sgmllib3k-1.0.0-py3-none-any.whl size=6065 sha256=0c99cef409a0f7aba3dd2eaf6d501e1f6532b268bd9e2ff734456014fa251599\n",
            "  Stored in directory: /root/.cache/pip/wheels/f0/69/93/a47e9d621be168e9e33c7ce60524393c0b92ae83cf6c6e89c5\n",
            "Successfully built checklist iso-639 patternfork-nosql python-docx sgmllib3k\n",
            "Installing collected packages: tokenizers, sgmllib3k, iso-639, backports.csv, zc.lockfile, qtpy, python-docx, munch, jedi, jaraco.functools, jaraco.context, feedparser, dill, autocommand, tempora, huggingface-hub, cheroot, transformers, portend, pdfminer.six, jaraco.text, qtconsole, jaraco.collections, cherrypy, patternfork-nosql, jupyter, checklist\n",
            "Successfully installed autocommand-2.2.2 backports.csv-1.0.7 checklist-0.0.11 cheroot-9.0.0 cherrypy-18.8.0 dill-0.3.6 feedparser-6.0.10 huggingface-hub-0.14.1 iso-639-0.4.5 jaraco.collections-4.1.0 jaraco.context-4.3.0 jaraco.functools-3.6.0 jaraco.text-3.11.1 jedi-0.18.2 jupyter-1.0.0 munch-2.5.0 patternfork-nosql-3.6 pdfminer.six-20221105 portend-3.1.0 python-docx-0.8.11 qtconsole-5.4.3 qtpy-2.3.1 sgmllib3k-1.0.0 tempora-5.2.2 tokenizers-0.13.3 transformers-4.28.1 zc.lockfile-3.0.post1\n",
            "Installing /usr/local/lib/python3.10/dist-packages/checklist/viewer/static -> viewer\n",
            "Making directory: /usr/share/jupyter/nbextensions/viewer/\n",
            "Copying: /usr/local/lib/python3.10/dist-packages/checklist/viewer/static/index.js.map -> /usr/share/jupyter/nbextensions/viewer/index.js.map\n",
            "Copying: /usr/local/lib/python3.10/dist-packages/checklist/viewer/static/__init__.py -> /usr/share/jupyter/nbextensions/viewer/__init__.py\n",
            "Copying: /usr/local/lib/python3.10/dist-packages/checklist/viewer/static/bundle.js.map -> /usr/share/jupyter/nbextensions/viewer/bundle.js.map\n",
            "Copying: /usr/local/lib/python3.10/dist-packages/checklist/viewer/static/index.js -> /usr/share/jupyter/nbextensions/viewer/index.js\n",
            "Copying: /usr/local/lib/python3.10/dist-packages/checklist/viewer/static/custom.js -> /usr/share/jupyter/nbextensions/viewer/custom.js\n",
            "Copying: /usr/local/lib/python3.10/dist-packages/checklist/viewer/static/extension.js -> /usr/share/jupyter/nbextensions/viewer/extension.js\n",
            "Copying: /usr/local/lib/python3.10/dist-packages/checklist/viewer/static/bundle.js -> /usr/share/jupyter/nbextensions/viewer/bundle.js\n",
            "Making directory: /usr/share/jupyter/nbextensions/viewer/__pycache__\n",
            "Copying: /usr/local/lib/python3.10/dist-packages/checklist/viewer/static/__pycache__/__init__.cpython-310.pyc -> /usr/share/jupyter/nbextensions/viewer/__pycache__/__init__.cpython-310.pyc\n",
            "- Validating: \u001b[32mOK\u001b[0m\n",
            "\n",
            "    To initialize this nbextension in the browser every time the notebook (or other app) loads:\n",
            "    \n",
            "          jupyter nbextension enable checklist.viewer --py --sys-prefix\n",
            "    \n",
            "Enabling notebook extension viewer/extension...\n",
            "Paths used for configuration of notebook: \n",
            "    \t/usr/etc/jupyter/nbconfig/notebook.json\n",
            "Paths used for configuration of notebook: \n",
            "    \t\n",
            "      - Validating: \u001b[32mOK\u001b[0m\n",
            "Paths used for configuration of notebook: \n",
            "    \t/usr/etc/jupyter/nbconfig/notebook.json\n"
          ]
        }
      ],
      "source": [
        "!pip install checklist\n",
        "!jupyter nbextension install --py --sys-prefix checklist.viewer\n",
        "!jupyter nbextension enable --py --sys-prefix checklist.viewer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YPfRGnsS1Htc"
      },
      "outputs": [],
      "source": [
        "import checklist\n",
        "from checklist.test_suite import TestSuite\n",
        "from checklist.editor import Editor\n",
        "from checklist.perturb import Perturb\n",
        "from google.colab import output\n",
        "import spacy\n",
        "import numpy as np\n",
        "\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "\n",
        "output.enable_custom_widget_manager()\n",
        "editor = Editor()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cHeKfc6g1WzL"
      },
      "source": [
        "#### Editor Set up"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mX0CjoS11cIl"
      },
      "source": [
        "DATA:\n",
        "\n",
        "- urls\n",
        "- misspelling(minimal and catastophic)\n",
        "- grammar errors\n",
        "- Taxonomy(simple word changes)\n",
        "- names with ethnicitys\n",
        "- mismatching pronouns\n",
        "  - ie she w/ john\n",
        "- refrencing different times\n",
        "  - ie talking in the present then last week\n",
        "- negation, double negation and triple negation\n",
        "- refrenceing a noun multiple times with some sort of possesion\n",
        "- combinations of the above\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Sm53BrR1ezT"
      },
      "outputs": [],
      "source": [
        "data = ['John is a very smart person, he lives in Ireland.',\n",
        "        'Mark Stewart was born and raised in Chicago',\n",
        "        'Luke Smith has 3 sisters.',\n",
        "        'Mary is not a nurse.',\n",
        "        'Julianne is an engineer.',\n",
        "        'My brother Andrew used to be a lawyer.']\n",
        "sample_urls = [\"https://colab.research.google.com/drive/1pOVdpSaZSFcjFEW_5nYb0vD62vl6YB7W#scrollTo=nQtrjhZo9S87\",\n",
        "               \"https://github.com/marcotcr/checklist\",\n",
        "               \"https://nlp.cs.gmu.edu/course/cs678-spring23/project/\",\n",
        "               \"https://arxiv.org/pdf/2005.04118v1.pdf\",\n",
        "               \"https://chat.openai.com/\",\n",
        "               \"https://www.netflix.com/search?q=cyber&jbv=81054853\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3z36jFCv1lPg"
      },
      "outputs": [],
      "source": [
        "# Personal pronouns\n",
        "personal_pronouns = ['I', 'you', 'he', 'she', 'it', 'we', 'they', 'me', 'him', 'her', 'us', 'them']\n",
        "\n",
        "# Possessive pronouns\n",
        "possessive_pronouns = ['mine', 'yours', 'his', 'hers', 'its', 'ours', 'theirs']\n",
        "\n",
        "# Reflexive pronouns\n",
        "reflexive_pronouns = ['myself', 'yourself', 'himself', 'herself', 'itself', 'ourselves', 'yourselves', 'themselves']\n",
        "\n",
        "# Demonstrative pronouns\n",
        "demonstrative_pronouns = ['this', 'that', 'these', 'those']\n",
        "editor.add_lexicon(\"personal_pronouns\", personal_pronouns)\n",
        "editor.add_lexicon(\"possessive_pronouns\", possessive_pronouns)\n",
        "editor.add_lexicon(\"reflexive_pronouns\", reflexive_pronouns)\n",
        "editor.add_lexicon(\"demonstrative_pronouns\", demonstrative_pronouns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q-8Fj4Bo1nj0"
      },
      "outputs": [],
      "source": [
        "verbs = ['run', 'eat', 'sleep', 'masticate', 'gargle', 'defenestrate', \"runed\"]\n",
        "editor.add_lexicon(\"verb\", verbs)\n",
        "nouns = ['dog', 'cat', 'car', 'bus', 'book', 'phone', 'quagmire', 'mellifluousness', 'gobbledygook']\n",
        "editor.add_lexicon(\"noun\", nouns)\n",
        "not_ = [\" not\", \"\"]\n",
        "editor.add_lexicon(\"not\", not_)\n",
        "editor.add_lexicon(\"url\", sample_urls)\n",
        "editor.add_lexicon(\"adj\", [\"happy\", \"stupid\", \"serendipitous\", \"ebullient\", \"execrable\", \"strong\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E56ULbMp1u6w"
      },
      "outputs": [],
      "source": [
        "urls = [\"I've linked this {adj} website, {url}, to {first_name}'s resume\",\n",
        "        \"This link {url}, is really {adj1} as well its {adj2}\"]\n",
        "grammar = [\"{personal_pronouns} was {verb} with {mask} {mask}.\",\n",
        "           \"{noun}, was {mask} {verb} upsidedown {personal_pronouns}\"]\n",
        "names = [\"{first_name1} and {first_name2} met {first_name3} at {city}, but {personal_pronouns1} couldn't stay long because {personal_pronouns2} had to meet up with {personal_pronouns3} friend. Later, they all went to {first_name2}'s house for dinner, and {personal_pronouns2} {verb} {personal_pronouns3} a {verb} meal while {personal_pronouns1} {verb}.\",\n",
        "         \"{first_name1} is from {country1}, {first_name2} is from {country2}, {personal_pronouns1} doesnt know {personal_pronouns2}\"]\n",
        "temporal = [\"After {personal_pronouns} finish this task tomorrow, {personal_pronouns} will have already submitted it yesterday, but {personal_pronouns} need to revise it next week before the deadline that was two days ago.\"]\n",
        "nega = [\"I love{not1}{not2}{not3}{not4}{not5}{not6} going to {country}\",\n",
        "        \"please do{not1}{not2}{not3}{not4} {verb}\"]\n",
        "pos = [\"{first_name1} owns ten cars {personal_pronouns} loves them {personal_pronouns} cheerishes them {personal_pronouns} hates them and {personal_pronouns} always washes them\"]\n",
        "#print(list(editor.lexicons.keys()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-D7ak9Ip10kP"
      },
      "source": [
        "#### Data Generation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "referenced_widgets": [
            "89292e82c5eb4101a48c1be2698fc232",
            "0b0b1dfaf8d6409fb46ff879593d939d",
            "98f1a00eb6f7419a8d783315a608517f",
            "cd122485192847598f7bd960063985bc",
            "23a77decbb454962ba7cfb38bc621394",
            "2f1ed22774fe471dab11ec6230ed4d99",
            "a5e3b4d38e884b50804cd46af7a01e37",
            "e703a6953b4644aa9adecc07ac2fc6ad",
            "2885fcfaf6e641fcb1630ef870cda141",
            "1635b1aac34148759856d748ca4b228a",
            "4b41cbcc6b7f4dd487068ef982959e3c",
            "66014c512c5b4dcd8c6cb7c81a061b32",
            "0e70110beb2e4d97b0304e6d129d2ab1",
            "31d1bd51aded40b7a923e4ad7a1482e8",
            "9edd3f1765514c058b1782fc02d4c6db",
            "e9f2eef57c1e46fab74b07b6bd20695e",
            "85295745d4f84dd6a18508b55afd7839",
            "ec9df7f736174bed9d144a7f1e16fb21",
            "24d52bcd0364477f80b96ddbdc4c5413",
            "e39f665eae444b078180cec12c983f9b",
            "542bc26609f44040b2dbcafaaac6891c",
            "ecd209b0dd5d400bbb651e8f16e26f26",
            "e681b04b211e4d8594d074e10568870e",
            "2c9951ab4b87430fa29cf3ce8f5b199e",
            "9f1d4f779f2c45f9bed86941339c21ef",
            "f1428e0451a448f9aa4d8a4c5761589c",
            "90fee9af1d9945abb2b622713e3ae262",
            "ae9664db0c8b4d74b7a7c8c442e1c272",
            "c8af097b721c4870b1b7436342e56e72",
            "779d908a6fb3466db707f31fd479dbb6",
            "f40514e63d1e4959a7cbcfac70dc784e",
            "6691fc2e31e24a12b63b6b78c7331dad",
            "26975757cbc0431bab72b5b13e65b5c9",
            "a5d1611b270949a397c3a6e7316722f2",
            "cd2dd45d36d744309c53a6e1e93a7a45",
            "d2860eb1ad024fa9b35de9e256825166",
            "71b517cae9304d629857cc4a2edc8b62",
            "db86c1b6a8bc46949fb54d577cfdf81c",
            "be38747e0c5a4219872a133c893eab3b",
            "b593d756d7644f8a9de3de24a7b00556",
            "8e42c7909a1c43268049dee9d35a6770",
            "8829a3508767430784c5e6e9f520b171",
            "b14c5873d3a94193a1b29962a26a8ef2",
            "e30fe1a315b743c9907dbaf068c320c5",
            "b0d08b981b044ce083501049bae9921a",
            "a4da6cb97eea4110bb6c739965fb641e",
            "0f354d1326104642bb13f857639dafc2",
            "c656f7d20b624664b70d6a5406a413ce",
            "d2d86a62c3c6486fab5a44efb20e229b",
            "4da3f72e742a4f62bd8c211c6406841b",
            "c7e7e80c59ce499da47672585d383c8b",
            "7e6008d278de4bb7bf25401b4c69778d",
            "6cda7705f34641cd80e92af87742e555",
            "5792bfc1a1b740578335e717c413fbc3",
            "7dafdbc7acb14490add81f4e23aae744"
          ]
        },
        "id": "TsMpKdu4125q",
        "outputId": "beeaefec-5486-4dd1-b46f-7b0c816b09c4"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "89292e82c5eb4101a48c1be2698fc232",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)lve/main/config.json:   0%|          | 0.00/481 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {
            "application/vnd.jupyter.widget-view+json": {
              "colab": {
                "custom_widget_manager": {
                  "url": "https://ssl.gstatic.com/colaboratory-static/widgets/colab-cdn-widget-manager/b3e629b1971e1542/manager.min.js"
                }
              }
            }
          },
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "66014c512c5b4dcd8c6cb7c81a061b32",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)olve/main/vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {
            "application/vnd.jupyter.widget-view+json": {
              "colab": {
                "custom_widget_manager": {
                  "url": "https://ssl.gstatic.com/colaboratory-static/widgets/colab-cdn-widget-manager/b3e629b1971e1542/manager.min.js"
                }
              }
            }
          },
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e681b04b211e4d8594d074e10568870e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)olve/main/merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {
            "application/vnd.jupyter.widget-view+json": {
              "colab": {
                "custom_widget_manager": {
                  "url": "https://ssl.gstatic.com/colaboratory-static/widgets/colab-cdn-widget-manager/b3e629b1971e1542/manager.min.js"
                }
              }
            }
          },
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a5d1611b270949a397c3a6e7316722f2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {
            "application/vnd.jupyter.widget-view+json": {
              "colab": {
                "custom_widget_manager": {
                  "url": "https://ssl.gstatic.com/colaboratory-static/widgets/colab-cdn-widget-manager/b3e629b1971e1542/manager.min.js"
                }
              }
            }
          },
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b0d08b981b044ce083501049bae9921a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading pytorch_model.bin:   0%|          | 0.00/501M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {
            "application/vnd.jupyter.widget-view+json": {
              "colab": {
                "custom_widget_manager": {
                  "url": "https://ssl.gstatic.com/colaboratory-static/widgets/colab-cdn-widget-manager/b3e629b1971e1542/manager.min.js"
                }
              }
            }
          },
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/checklist/text_generation.py:171: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:245.)\n",
            "  to_pred = torch.tensor(to_pred, device=self.device).to(torch.int64)\n"
          ]
        }
      ],
      "source": [
        "url_data = editor.template(urls, remove_duplicates=True)\n",
        "grammar_data = editor.template(grammar, remove_duplicates=True)\n",
        "names_data = editor.template(names,nsamples =200000 ,remove_duplicates=True)\n",
        "tempor_data = editor.template(temporal, remove_duplicates=True)\n",
        "nega_data = editor.template(nega)\n",
        "pos_data = editor.template(pos, remove_duplicates=True, meta = True, save=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fee5607g15k0"
      },
      "outputs": [],
      "source": [
        "# change the size values for different distributions of the data\n",
        "pos_points = np.random.choice(len(pos_data.data), size= 5, replace=False, )\n",
        "url_points = np.random.choice(len(url_data.data), size= 6, replace=False, )\n",
        "grammar_points = np.random.choice(len(grammar_data.data), size= 6, replace=False, )\n",
        "names_points = np.random.choice(len(names_data.data), size= 5, replace=False, )\n",
        "tempor_points = np.random.choice(len(tempor_data.data), size= 5, replace=False, )\n",
        "nega_points = np.random.choice(len(nega_data.data), size= 5, replace=False, )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xe5bvLuD18ux"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "misspelling = []\n",
        "\n",
        "for i in range(1,50):\n",
        "  temp = Perturb.perturb(data, Perturb.add_typos, typos=i).data\n",
        "  for x in temp:\n",
        "    misspelling.append(x[1])\n",
        "\n",
        "#print(misspelling[0])\n",
        "mis_points = np.random.choice(len(misspelling), size=5, replace=False)\n",
        "points = (url_points, grammar_points, names_points, tempor_points, nega_points, pos_points, mis_points)\n",
        "data_built = (url_data, grammar_data, names_data, tempor_data, nega_data, pos_data, misspelling)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z0NtNT5B2CzL"
      },
      "source": [
        "#### Making the JSON"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KeZRs8ps2G_7"
      },
      "outputs": [],
      "source": [
        "labels = ['clarity', 'fluency', 'coherence', 'style', 'meaning-changed']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "21k72vqr2J58"
      },
      "outputs": [],
      "source": [
        "final_data = []\n",
        "labelcnt = -1\n",
        "for d in data:\n",
        "  labelcnt+=1\n",
        "  final_data.append({\"before_sent\" : d,\n",
        "                     \"after_sent\" : d,\n",
        "                    \"before_sent_with_intent\": \"<\"+ labels[labelcnt%len(labels)] +\"> \"+ d,\n",
        "                    \"labels\": labels[labelcnt%len(labels)],\n",
        "                    \"doc_id\":'0',\n",
        "                    \"revision_depth\": \"3\"})\n",
        "for point in range(len(points)):\n",
        "  for p in points[point]:\n",
        "    labelcnt +=1\n",
        "    #print(data_built[point].data[p])\n",
        "    #final_data.append(data_built[point].data[p][0])\n",
        "    try:\n",
        "      try:\n",
        "        final_data.append({\"before_sent\" : data_built[point].data[p][0],\n",
        "                           \"after_sent\" : data_built[point].data[p][0],\n",
        "                           \"before_sent_with_intent\": \"<\"+ labels[labelcnt%len(labels)] +\"> \"+ data_built[point].data[p][0],\n",
        "                           \"labels\": labels[labelcnt%len(labels)],\n",
        "                           \"doc_id\":'0',\n",
        "                           \"revision_depth\": \"3\"})\n",
        "      except:\n",
        "        final_data.append({\"before_sent\" : data_built[point][p],\n",
        "                          \"after_sent\" : data_built[point][p],\n",
        "                          \"before_sent_with_intent\": \"<\"+ labels[labelcnt%len(labels)] +\"> \"+ data_built[point][p],\n",
        "                          \"labels\": labels[labelcnt%len(labels)],\n",
        "                          \"doc_id\":'0',\n",
        "                          \"revision_depth\": \"3\"})\n",
        "        continue\n",
        "      labelcnt +=1\n",
        "      final_data.append({\"before_sent\" : data_built[point].data[p][1],\n",
        "                         \"after_sent\" : data_built[point].data[p][1],\n",
        "                           \"before_sent_with_intent\": \"<\"+ labels[labelcnt%len(labels)] +\"> \"+ data_built[point].data[p][1],\n",
        "                           \"labels\": labels[labelcnt%len(labels)],\n",
        "                           \"doc_id\":'0',\n",
        "                           \"revision_depth\": \"3\"})\n",
        "    except:\n",
        "      #print(data_built[point].data[0][0])\n",
        "      final_data.append({\"before_sent\" : data_built[point].data[0][0],\n",
        "                         \"after_sent\" : data_built[point].data[0][0],\n",
        "                           \"before_sent_with_intent\": \"<\"+ labels[labelcnt%len(labels)] +\"> \"+ data_built[point].data[0][0],\n",
        "                           \"labels\": labels[labelcnt%len(labels)],\n",
        "                           \"doc_id\":'0',\n",
        "                           \"revision_depth\": \"3\"})\n",
        "      continue"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "igL6ZBpA2MSx"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "#j = json.dumps(final_data)\n",
        "#print(j[0])\n",
        "with open(\"robust_test.json\", \"w\") as outfile:\n",
        "  j = json.dumps(final_data)\n",
        "  for i in final_data:\n",
        "    j = json.dumps(i)\n",
        "    #print(j)\n",
        "    outfile.write(j + \"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Do these two commands if you want to generate a new test set for robustness testing"
      ],
      "metadata": {
        "id": "PCOZgvNnmX0w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!rm /content/cs678-cp1-cp2/robust_data/test.json"
      ],
      "metadata": {
        "id": "OvLtKs_umG6J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!mv /content/robust_test.json /content/cs678-cp1-cp2/robust_data/test.json"
      ],
      "metadata": {
        "id": "HHeGDojhmJo9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Pertubing exitsing data"
      ],
      "metadata": {
        "id": "3Cc3hr3VnVLf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#temp = Perturb.perturb(data, Perturb.add_typos, typos=i).data\n",
        "%cd /content/\n",
        "\n",
        "file = '/content/IteraTeR/human_sent_level/test.json'\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "c = 0\n",
        "\n",
        "with open(file) as f:\n",
        "  json_data = json.loads('[' + f.read().replace('}\\n{', '},\\n{') + ']')\n",
        "\n",
        "for x in range(len(json_data)):\n",
        "  #print(before_sent)\n",
        "  before_sent = json_data[x]['before_sent']\n",
        "  after_sent = json_data[x]['after_sent']\n",
        "\n",
        "  if isinstance(before_sent, list):\n",
        "      before_sent = ' '.join(filter(None, before_sent))\n",
        "\n",
        "  if before_sent is None:\n",
        "    continue\n",
        "  #print(before_sent)\n",
        "  if c%5 == 0:\n",
        "    before_sent = Perturb.add_typos(before_sent, 50)\n",
        "    after_sent = Perturb.add_typos(after_sent, 50)\n",
        "  elif c%5 == 1:\n",
        "    try:\n",
        "      before_sent = Perturb.perturb(list(nlp.pipe([before_sent])),  Perturb.add_negation).data[0][0]\n",
        "      after_sent = Perturb.perturb(list(nlp.pipe([after_sent])),  Perturb.add_negation).data[0][0]\n",
        "    except:\n",
        "      try:\n",
        "        before_sent = Perturb.add_typos(before_sent, 100)\n",
        "        after_sent = Perturb.add_typos(after_sent, 100)\n",
        "      except:\n",
        "        before_sent = Perturb.contract(before_sent)\n",
        "        after_sent = Perturb.contract(after_sent)\n",
        "  elif c%5 == 2:\n",
        "    before_sent = Perturb.contract(before_sent)\n",
        "    after_sent = Perturb.contract(after_sent)\n",
        "  elif c%5 == 3:\n",
        "    before_sent = Perturb.expand_contractions(before_sent)\n",
        "    after_sent = Perturb.expand_contractions(after_sent)\n",
        "  elif c%5 == 4:\n",
        "    before_sent = Perturb.perturb(list(nlp.pipe([after_sent])), Perturb.punctuation).data[0][0]\n",
        "    after_sent = Perturb.perturb(list(nlp.pipe([after_sent])), Perturb.punctuation).data[0][0]\n",
        "\n",
        "\n",
        "  json_data[x]['before_sent'] = before_sent\n",
        "\n",
        "  json_data[x]['before_sent_with_intent'] = \"<\" + json_data[x]['labels'] + \">  \" + before_sent\n",
        "\n",
        "  json_data[x]['after_sent'] = after_sent\n",
        "  c+=1\n",
        "\n",
        "with open('test_pertub_robust.json', 'w') as f:\n",
        "  j = json.dumps(json_data)\n",
        "  for i in json_data:\n",
        "    j = json.dumps(i)\n",
        "    #print(j)\n",
        "    f.write(j + \"\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kUsw0kLInbw6",
        "outputId": "1adb498b-d967-4239-d107-7b7621778d5a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -r /content/cs678-cp1-cp2/robust_data /content/cs678-cp1-cp2/robust2_data\n",
        "!rm /content/cs678-cp1-cp2/robust2_data/test.json\n",
        "!mv /content/test_pertub_robust.json /content/cs678-cp1-cp2/robust2_data/test.json"
      ],
      "metadata": {
        "id": "BuUSLTOfBmZz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/cs678-cp1-cp2/robust2_data/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2NaiowEdE4oj",
        "outputId": "5b63c8fe-a65a-4b48-a6a1-96f16f372c0d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/cs678-cp1-cp2/robust2_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tm6aVcu6bHhd"
      },
      "source": [
        "### Task 1.1: Robustness Test on Intent Classfication Model - RoBERTa 10 epochs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rD9qJ0YAaRPY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bdefcaf7-9b31-4c07-edbb-225bfa3d7ffe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-05-09 01:52:20.598664: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Using custom data configuration robust2_data-11869534e8520c46\n",
            "Downloading and preparing dataset json/robust2_data to /root/.cache/huggingface/datasets/json/robust2_data-11869534e8520c46/0.0.0/ac0ca5f5289a6cf108e706efcf040422dbbfa8e658dee6a819f20d76bb84d26b...\n",
            "100% 3/3 [00:00<00:00, 10932.16it/s]\n",
            "100% 3/3 [00:00<00:00, 1798.33it/s]\n",
            "Dataset json downloaded and prepared to /root/.cache/huggingface/datasets/json/robust2_data-11869534e8520c46/0.0.0/ac0ca5f5289a6cf108e706efcf040422dbbfa8e658dee6a819f20d76bb84d26b. Subsequent calls will reuse this data.\n",
            "100% 3/3 [00:00<00:00, 866.00it/s]\n",
            "[1258, 739, 311, 100, 807]\n",
            "[157, 115, 46, 13, 54]\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
            "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.decoder.weight']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "{'loss': 1.4312, 'learning_rate': 9.502487562189056e-06, 'epoch': 0.5}\n",
            "{'loss': 1.2792, 'learning_rate': 9.00497512437811e-06, 'epoch': 1.0}\n",
            " 12% 250/2010 [05:02<35:29,  1.21s/it]\n",
            "  0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            " 29% 2/7 [00:00<00:01,  2.66it/s]\u001b[A\n",
            " 43% 3/7 [00:01<00:02,  1.87it/s]\u001b[A\n",
            " 57% 4/7 [00:02<00:01,  1.63it/s]\u001b[A\n",
            " 71% 5/7 [00:03<00:01,  1.51it/s]\u001b[A\n",
            " 86% 6/7 [00:03<00:00,  1.44it/s]\u001b[A/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "                                      \n",
            "\u001b[A{'eval_loss': 1.0934988260269165, 'eval_accuracy': 0.5896103896103896, 'eval_P_Clarity': 0.5888888888888889, 'eval_R_Clarity': 0.6751592356687898, 'eval_f1_Clarity': 0.6290801186943621, 'eval_P_Fluency': 0.6235955056179775, 'eval_R_Fluency': 0.9652173913043478, 'eval_f1_Fluency': 0.7576791808873721, 'eval_P_Coherence': 0.0, 'eval_R_Coherence': 0.0, 'eval_f1_Coherence': 0.0, 'eval_P_Style': 0.0, 'eval_R_Style': 0.0, 'eval_f1_Style': 0.0, 'eval_P_Meaning-Changed': 0.37037037037037035, 'eval_R_Meaning-Changed': 0.18518518518518517, 'eval_f1_Meaning-Changed': 0.24691358024691354, 'eval_runtime': 4.5677, 'eval_samples_per_second': 84.287, 'eval_steps_per_second': 1.532, 'epoch': 1.24}\n",
            " 12% 250/2010 [05:07<35:29,  1.21s/it]\n",
            "100% 7/7 [00:03<00:00,  1.44it/s]\u001b[A\n",
            "{'loss': 1.0794, 'learning_rate': 8.507462686567165e-06, 'epoch': 1.49}\n",
            "{'loss': 0.9762, 'learning_rate': 8.00995024875622e-06, 'epoch': 1.99}\n",
            "{'loss': 0.8331, 'learning_rate': 7.512437810945274e-06, 'epoch': 2.49}\n",
            " 25% 500/2010 [10:22<30:27,  1.21s/it]\n",
            "  0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            " 29% 2/7 [00:00<00:01,  2.66it/s]\u001b[A\n",
            " 43% 3/7 [00:01<00:02,  1.87it/s]\u001b[A\n",
            " 57% 4/7 [00:02<00:01,  1.62it/s]\u001b[A\n",
            " 71% 5/7 [00:03<00:01,  1.51it/s]\u001b[A\n",
            "                                      \n",
            "\u001b[A{'eval_loss': 1.1957775354385376, 'eval_accuracy': 0.6103896103896104, 'eval_P_Clarity': 0.6556291390728477, 'eval_R_Clarity': 0.6305732484076433, 'eval_f1_Clarity': 0.6428571428571428, 'eval_P_Fluency': 0.734375, 'eval_R_Fluency': 0.8173913043478261, 'eval_f1_Fluency': 0.7736625514403292, 'eval_P_Coherence': 1.0, 'eval_R_Coherence': 0.021739130434782608, 'eval_f1_Coherence': 0.042553191489361694, 'eval_P_Style': 0.0, 'eval_R_Style': 0.0, 'eval_f1_Style': 0.0, 'eval_P_Meaning-Changed': 0.39805825242718446, 'eval_R_Meaning-Changed': 0.7592592592592593, 'eval_f1_Meaning-Changed': 0.5222929936305732, 'eval_runtime': 4.5489, 'eval_samples_per_second': 84.637, 'eval_steps_per_second': 1.539, 'epoch': 2.49}\n",
            " 25% 500/2010 [10:26<30:27,  1.21s/it]\n",
            "100% 7/7 [00:03<00:00,  1.44it/s]\u001b[A\n",
            "{'loss': 0.8179, 'learning_rate': 7.014925373134329e-06, 'epoch': 2.99}\n",
            "{'loss': 0.635, 'learning_rate': 6.517412935323384e-06, 'epoch': 3.48}\n",
            " 37% 750/2010 [15:39<25:23,  1.21s/it]\n",
            "  0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            " 29% 2/7 [00:00<00:01,  2.66it/s]\u001b[A\n",
            " 43% 3/7 [00:01<00:02,  1.87it/s]\u001b[A\n",
            " 57% 4/7 [00:02<00:01,  1.62it/s]\u001b[A\n",
            " 71% 5/7 [00:03<00:01,  1.51it/s]\u001b[A\n",
            " 86% 6/7 [00:03<00:00,  1.44it/s]\u001b[A/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "                                      \n",
            "\u001b[A{'eval_loss': 1.0188910961151123, 'eval_accuracy': 0.6597402597402597, 'eval_P_Clarity': 0.650887573964497, 'eval_R_Clarity': 0.7006369426751592, 'eval_f1_Clarity': 0.674846625766871, 'eval_P_Fluency': 0.7661290322580645, 'eval_R_Fluency': 0.8260869565217391, 'eval_f1_Fluency': 0.7949790794979079, 'eval_P_Coherence': 0.37142857142857144, 'eval_R_Coherence': 0.2826086956521739, 'eval_f1_Coherence': 0.32098765432098764, 'eval_P_Style': 0.0, 'eval_R_Style': 0.0, 'eval_f1_Style': 0.0, 'eval_P_Meaning-Changed': 0.631578947368421, 'eval_R_Meaning-Changed': 0.6666666666666666, 'eval_f1_Meaning-Changed': 0.6486486486486486, 'eval_runtime': 4.5467, 'eval_samples_per_second': 84.676, 'eval_steps_per_second': 1.54, 'epoch': 3.73}\n",
            " 37% 750/2010 [15:44<25:23,  1.21s/it]\n",
            "100% 7/7 [00:03<00:00,  1.44it/s]\u001b[A\n",
            "{'loss': 0.6299, 'learning_rate': 6.019900497512439e-06, 'epoch': 3.98}\n",
            "{'loss': 0.4871, 'learning_rate': 5.522388059701493e-06, 'epoch': 4.48}\n",
            "{'loss': 0.5169, 'learning_rate': 5.024875621890548e-06, 'epoch': 4.98}\n",
            " 50% 1000/2010 [20:58<20:21,  1.21s/it]\n",
            "  0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            " 29% 2/7 [00:00<00:01,  2.66it/s]\u001b[A\n",
            " 43% 3/7 [00:01<00:02,  1.88it/s]\u001b[A\n",
            " 57% 4/7 [00:02<00:01,  1.63it/s]\u001b[A\n",
            " 71% 5/7 [00:03<00:01,  1.51it/s]\u001b[A\n",
            " 86% 6/7 [00:03<00:00,  1.44it/s]\u001b[A/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "                                       \n",
            "\u001b[A{'eval_loss': 1.15871262550354, 'eval_accuracy': 0.6649350649350649, 'eval_P_Clarity': 0.6440677966101694, 'eval_R_Clarity': 0.7261146496815286, 'eval_f1_Clarity': 0.6826347305389221, 'eval_P_Fluency': 0.8070175438596491, 'eval_R_Fluency': 0.8, 'eval_f1_Fluency': 0.8034934497816594, 'eval_P_Coherence': 0.4166666666666667, 'eval_R_Coherence': 0.32608695652173914, 'eval_f1_Coherence': 0.3658536585365854, 'eval_P_Style': 0.0, 'eval_R_Style': 0.0, 'eval_f1_Style': 0.0, 'eval_P_Meaning-Changed': 0.603448275862069, 'eval_R_Meaning-Changed': 0.6481481481481481, 'eval_f1_Meaning-Changed': 0.625, 'eval_runtime': 4.547, 'eval_samples_per_second': 84.672, 'eval_steps_per_second': 1.539, 'epoch': 4.98}\n",
            " 50% 1000/2010 [21:03<20:21,  1.21s/it]\n",
            "100% 7/7 [00:03<00:00,  1.44it/s]\u001b[A\n",
            "{'loss': 0.3562, 'learning_rate': 4.527363184079602e-06, 'epoch': 5.47}\n",
            "{'loss': 0.4245, 'learning_rate': 4.029850746268657e-06, 'epoch': 5.97}\n",
            " 62% 1250/2010 [26:15<15:19,  1.21s/it]\n",
            "  0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            " 29% 2/7 [00:00<00:01,  2.66it/s]\u001b[A\n",
            " 43% 3/7 [00:01<00:02,  1.88it/s]\u001b[A\n",
            " 57% 4/7 [00:02<00:01,  1.62it/s]\u001b[A\n",
            " 71% 5/7 [00:03<00:01,  1.51it/s]\u001b[A\n",
            "                                       \n",
            "\u001b[A{'eval_loss': 1.2484772205352783, 'eval_accuracy': 0.6857142857142857, 'eval_P_Clarity': 0.7074829931972789, 'eval_R_Clarity': 0.6624203821656051, 'eval_f1_Clarity': 0.6842105263157895, 'eval_P_Fluency': 0.7698412698412699, 'eval_R_Fluency': 0.8434782608695652, 'eval_f1_Fluency': 0.8049792531120332, 'eval_P_Coherence': 0.44680851063829785, 'eval_R_Coherence': 0.45652173913043476, 'eval_f1_Coherence': 0.45161290322580644, 'eval_P_Style': 0.3333333333333333, 'eval_R_Style': 0.07692307692307693, 'eval_f1_Style': 0.125, 'eval_P_Meaning-Changed': 0.6612903225806451, 'eval_R_Meaning-Changed': 0.7592592592592593, 'eval_f1_Meaning-Changed': 0.7068965517241378, 'eval_runtime': 4.5465, 'eval_samples_per_second': 84.68, 'eval_steps_per_second': 1.54, 'epoch': 6.22}\n",
            " 62% 1250/2010 [26:20<15:19,  1.21s/it]\n",
            "100% 7/7 [00:03<00:00,  1.44it/s]\u001b[A\n",
            "{'loss': 0.3413, 'learning_rate': 3.5323383084577117e-06, 'epoch': 6.47}\n",
            "{'loss': 0.2999, 'learning_rate': 3.0348258706467666e-06, 'epoch': 6.97}\n",
            "{'loss': 0.2683, 'learning_rate': 2.537313432835821e-06, 'epoch': 7.46}\n",
            " 75% 1500/2010 [31:35<10:16,  1.21s/it]\n",
            "  0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            " 29% 2/7 [00:00<00:01,  2.66it/s]\u001b[A\n",
            " 43% 3/7 [00:01<00:02,  1.87it/s]\u001b[A\n",
            " 57% 4/7 [00:02<00:01,  1.63it/s]\u001b[A\n",
            " 71% 5/7 [00:03<00:01,  1.51it/s]\u001b[A\n",
            "                                       \n",
            "\u001b[A{'eval_loss': 1.414730191230774, 'eval_accuracy': 0.6623376623376623, 'eval_P_Clarity': 0.6776315789473685, 'eval_R_Clarity': 0.6560509554140127, 'eval_f1_Clarity': 0.6666666666666666, 'eval_P_Fluency': 0.75, 'eval_R_Fluency': 0.8347826086956521, 'eval_f1_Fluency': 0.7901234567901233, 'eval_P_Coherence': 0.4634146341463415, 'eval_R_Coherence': 0.41304347826086957, 'eval_f1_Coherence': 0.4367816091954023, 'eval_P_Style': 0.25, 'eval_R_Style': 0.07692307692307693, 'eval_f1_Style': 0.11764705882352941, 'eval_P_Meaning-Changed': 0.6, 'eval_R_Meaning-Changed': 0.6666666666666666, 'eval_f1_Meaning-Changed': 0.631578947368421, 'eval_runtime': 4.5465, 'eval_samples_per_second': 84.68, 'eval_steps_per_second': 1.54, 'epoch': 7.46}\n",
            " 75% 1500/2010 [31:40<10:16,  1.21s/it]\n",
            "100% 7/7 [00:03<00:00,  1.44it/s]\u001b[A\n",
            "{'loss': 0.2303, 'learning_rate': 2.0398009950248755e-06, 'epoch': 7.96}\n",
            "{'loss': 0.2014, 'learning_rate': 1.5422885572139304e-06, 'epoch': 8.46}\n",
            " 87% 1750/2010 [36:55<05:14,  1.21s/it]\n",
            "  0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            " 29% 2/7 [00:00<00:01,  2.66it/s]\u001b[A\n",
            " 43% 3/7 [00:01<00:02,  1.87it/s]\u001b[A\n",
            " 57% 4/7 [00:02<00:01,  1.63it/s]\u001b[A\n",
            " 71% 5/7 [00:03<00:01,  1.51it/s]\u001b[A\n",
            "                                       \n",
            "\u001b[A{'eval_loss': 1.5317634344100952, 'eval_accuracy': 0.6779220779220779, 'eval_P_Clarity': 0.6855345911949685, 'eval_R_Clarity': 0.6942675159235668, 'eval_f1_Clarity': 0.689873417721519, 'eval_P_Fluency': 0.7698412698412699, 'eval_R_Fluency': 0.8434782608695652, 'eval_f1_Fluency': 0.8049792531120332, 'eval_P_Coherence': 0.4358974358974359, 'eval_R_Coherence': 0.3695652173913043, 'eval_f1_Coherence': 0.39999999999999997, 'eval_P_Style': 0.2, 'eval_R_Style': 0.07692307692307693, 'eval_f1_Style': 0.1111111111111111, 'eval_P_Meaning-Changed': 0.6607142857142857, 'eval_R_Meaning-Changed': 0.6851851851851852, 'eval_f1_Meaning-Changed': 0.6727272727272727, 'eval_runtime': 4.5467, 'eval_samples_per_second': 84.678, 'eval_steps_per_second': 1.54, 'epoch': 8.71}\n",
            " 87% 1750/2010 [37:00<05:14,  1.21s/it]\n",
            "100% 7/7 [00:03<00:00,  1.44it/s]\u001b[A\n",
            "{'loss': 0.1843, 'learning_rate': 1.044776119402985e-06, 'epoch': 8.96}\n",
            "{'loss': 0.1668, 'learning_rate': 5.472636815920398e-07, 'epoch': 9.45}\n",
            "{'loss': 0.1591, 'learning_rate': 4.975124378109453e-08, 'epoch': 9.95}\n",
            "100% 2000/2010 [42:15<00:12,  1.21s/it]\n",
            "  0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            " 29% 2/7 [00:00<00:01,  2.65it/s]\u001b[A\n",
            " 43% 3/7 [00:01<00:02,  1.87it/s]\u001b[A\n",
            " 57% 4/7 [00:02<00:01,  1.62it/s]\u001b[A\n",
            " 71% 5/7 [00:03<00:01,  1.51it/s]\u001b[A\n",
            "                                       \n",
            "\u001b[A{'eval_loss': 1.6045029163360596, 'eval_accuracy': 0.6909090909090909, 'eval_P_Clarity': 0.6962025316455697, 'eval_R_Clarity': 0.7006369426751592, 'eval_f1_Clarity': 0.6984126984126984, 'eval_P_Fluency': 0.7716535433070866, 'eval_R_Fluency': 0.8521739130434782, 'eval_f1_Fluency': 0.8099173553719009, 'eval_P_Coherence': 0.47368421052631576, 'eval_R_Coherence': 0.391304347826087, 'eval_f1_Coherence': 0.42857142857142855, 'eval_P_Style': 0.2, 'eval_R_Style': 0.07692307692307693, 'eval_f1_Style': 0.1111111111111111, 'eval_P_Meaning-Changed': 0.6842105263157895, 'eval_R_Meaning-Changed': 0.7222222222222222, 'eval_f1_Meaning-Changed': 0.7027027027027027, 'eval_runtime': 4.5478, 'eval_samples_per_second': 84.657, 'eval_steps_per_second': 1.539, 'epoch': 9.95}\n",
            "100% 2000/2010 [42:19<00:12,  1.21s/it]\n",
            "100% 7/7 [00:03<00:00,  1.44it/s]\u001b[A\n",
            "{'train_runtime': 2562.2925, 'train_samples_per_second': 12.547, 'train_steps_per_second': 0.784, 'train_loss': 0.564526048584364, 'epoch': 10.0}\n",
            "100% 2010/2010 [42:42<00:00,  1.27s/it]\n",
            "100% 7/7 [00:03<00:00,  1.84it/s]\n",
            "{'eval_loss': 1.604159951210022, 'eval_accuracy': 0.6883116883116883, 'eval_P_Clarity': 0.6918238993710691, 'eval_R_Clarity': 0.7006369426751592, 'eval_f1_Clarity': 0.6962025316455696, 'eval_P_Fluency': 0.7698412698412699, 'eval_R_Fluency': 0.8434782608695652, 'eval_f1_Fluency': 0.8049792531120332, 'eval_P_Coherence': 0.47368421052631576, 'eval_R_Coherence': 0.391304347826087, 'eval_f1_Coherence': 0.42857142857142855, 'eval_P_Style': 0.2, 'eval_R_Style': 0.07692307692307693, 'eval_f1_Style': 0.1111111111111111, 'eval_P_Meaning-Changed': 0.6842105263157895, 'eval_R_Meaning-Changed': 0.7222222222222222, 'eval_f1_Meaning-Changed': 0.7027027027027027, 'eval_runtime': 4.5459, 'eval_samples_per_second': 84.691, 'eval_steps_per_second': 1.54, 'epoch': 10.0}\n",
            "CPU times: user 16.5 s, sys: 3.23 s, total: 19.7 s\n",
            "Wall time: 43min\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "!python 'train_intent_classifier.py' --upsample_values 1 1 1 1 1 --weights 1. 1. 1. 1. 1. -e 10  -s roberta-large-ten -d /content/cs678-cp1-cp2/robust2_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "61593067-020b-45d5-af25-29026b38b4d7",
        "id": "LUk6TgpbCqeo"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-05-08 18:22:05.497026: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Using custom data configuration robust_data-70aec4dfca20afa6\n",
            "Downloading and preparing dataset json/robust_data to /root/.cache/huggingface/datasets/json/robust_data-70aec4dfca20afa6/0.0.0/ac0ca5f5289a6cf108e706efcf040422dbbfa8e658dee6a819f20d76bb84d26b...\n",
            "100% 3/3 [00:00<00:00, 11057.04it/s]\n",
            "100% 3/3 [00:00<00:00, 1708.94it/s]\n",
            "Dataset json downloaded and prepared to /root/.cache/huggingface/datasets/json/robust_data-70aec4dfca20afa6/0.0.0/ac0ca5f5289a6cf108e706efcf040422dbbfa8e658dee6a819f20d76bb84d26b. Subsequent calls will reuse this data.\n",
            "100% 3/3 [00:00<00:00, 847.96it/s]\n",
            "[1258, 739, 311, 100, 807]\n",
            "[157, 115, 46, 13, 54]\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
            "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.dense.weight', 'lm_head.decoder.weight', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.bias']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "{'loss': 1.4016, 'learning_rate': 9.502487562189056e-06, 'epoch': 0.5}\n",
            "{'loss': 1.2823, 'learning_rate': 9.00497512437811e-06, 'epoch': 1.0}\n",
            " 12% 250/2010 [05:02<35:29,  1.21s/it]\n",
            "  0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            " 29% 2/7 [00:00<00:01,  2.66it/s]\u001b[A\n",
            " 43% 3/7 [00:01<00:02,  1.88it/s]\u001b[A\n",
            " 57% 4/7 [00:02<00:01,  1.63it/s]\u001b[A\n",
            " 71% 5/7 [00:03<00:01,  1.51it/s]\u001b[A\n",
            " 86% 6/7 [00:03<00:00,  1.44it/s]\u001b[A/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "                                      \n",
            "\u001b[A{'eval_loss': 1.1861869096755981, 'eval_accuracy': 0.5584415584415584, 'eval_P_Clarity': 0.6090225563909775, 'eval_R_Clarity': 0.5159235668789809, 'eval_f1_Clarity': 0.5586206896551725, 'eval_P_Fluency': 0.5069767441860465, 'eval_R_Fluency': 0.9478260869565217, 'eval_f1_Fluency': 0.6606060606060606, 'eval_P_Coherence': 1.0, 'eval_R_Coherence': 0.06521739130434782, 'eval_f1_Coherence': 0.12244897959183672, 'eval_P_Style': 0.0, 'eval_R_Style': 0.0, 'eval_f1_Style': 0.0, 'eval_P_Meaning-Changed': 0.6470588235294118, 'eval_R_Meaning-Changed': 0.4074074074074074, 'eval_f1_Meaning-Changed': 0.5, 'eval_runtime': 4.5693, 'eval_samples_per_second': 84.257, 'eval_steps_per_second': 1.532, 'epoch': 1.24}\n",
            " 12% 250/2010 [05:07<35:29,  1.21s/it]\n",
            "100% 7/7 [00:03<00:00,  1.44it/s]\u001b[A\n",
            "{'loss': 1.0646, 'learning_rate': 8.507462686567165e-06, 'epoch': 1.49}\n",
            "{'loss': 0.9568, 'learning_rate': 8.00995024875622e-06, 'epoch': 1.99}\n",
            "{'loss': 0.8327, 'learning_rate': 7.512437810945274e-06, 'epoch': 2.49}\n",
            " 25% 500/2010 [10:19<30:26,  1.21s/it]\n",
            "  0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            " 29% 2/7 [00:00<00:01,  2.66it/s]\u001b[A\n",
            " 43% 3/7 [00:01<00:02,  1.87it/s]\u001b[A\n",
            " 57% 4/7 [00:02<00:01,  1.63it/s]\u001b[A\n",
            " 71% 5/7 [00:03<00:01,  1.51it/s]\u001b[A\n",
            " 86% 6/7 [00:03<00:00,  1.44it/s]\u001b[A/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "                                      \n",
            "\u001b[A{'eval_loss': 0.9950829148292542, 'eval_accuracy': 0.6701298701298701, 'eval_P_Clarity': 0.6705882352941176, 'eval_R_Clarity': 0.7261146496815286, 'eval_f1_Clarity': 0.6972477064220183, 'eval_P_Fluency': 0.6896551724137931, 'eval_R_Fluency': 0.8695652173913043, 'eval_f1_Fluency': 0.7692307692307693, 'eval_P_Coherence': 0.7272727272727273, 'eval_R_Coherence': 0.17391304347826086, 'eval_f1_Coherence': 0.2807017543859649, 'eval_P_Style': 0.0, 'eval_R_Style': 0.0, 'eval_f1_Style': 0.0, 'eval_P_Meaning-Changed': 0.6101694915254238, 'eval_R_Meaning-Changed': 0.6666666666666666, 'eval_f1_Meaning-Changed': 0.6371681415929203, 'eval_runtime': 4.5442, 'eval_samples_per_second': 84.723, 'eval_steps_per_second': 1.54, 'epoch': 2.49}\n",
            " 25% 500/2010 [10:23<30:26,  1.21s/it]\n",
            "100% 7/7 [00:03<00:00,  1.44it/s]\u001b[A\n",
            "{'loss': 0.8196, 'learning_rate': 7.014925373134329e-06, 'epoch': 2.99}\n",
            "{'loss': 0.6534, 'learning_rate': 6.517412935323384e-06, 'epoch': 3.48}\n",
            " 37% 750/2010 [15:36<25:23,  1.21s/it]\n",
            "  0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            " 29% 2/7 [00:00<00:01,  2.66it/s]\u001b[A\n",
            " 43% 3/7 [00:01<00:02,  1.88it/s]\u001b[A\n",
            " 57% 4/7 [00:02<00:01,  1.63it/s]\u001b[A\n",
            " 71% 5/7 [00:03<00:01,  1.51it/s]\u001b[A\n",
            " 86% 6/7 [00:03<00:00,  1.44it/s]\u001b[A/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "                                      \n",
            "\u001b[A{'eval_loss': 0.8935842514038086, 'eval_accuracy': 0.6935064935064935, 'eval_P_Clarity': 0.7133757961783439, 'eval_R_Clarity': 0.7133757961783439, 'eval_f1_Clarity': 0.713375796178344, 'eval_P_Fluency': 0.7333333333333333, 'eval_R_Fluency': 0.8608695652173913, 'eval_f1_Fluency': 0.7919999999999999, 'eval_P_Coherence': 0.5428571428571428, 'eval_R_Coherence': 0.41304347826086957, 'eval_f1_Coherence': 0.46913580246913583, 'eval_P_Style': 0.0, 'eval_R_Style': 0.0, 'eval_f1_Style': 0.0, 'eval_P_Meaning-Changed': 0.6379310344827587, 'eval_R_Meaning-Changed': 0.6851851851851852, 'eval_f1_Meaning-Changed': 0.6607142857142857, 'eval_runtime': 4.5446, 'eval_samples_per_second': 84.716, 'eval_steps_per_second': 1.54, 'epoch': 3.73}\n",
            " 37% 750/2010 [15:40<25:23,  1.21s/it]\n",
            "100% 7/7 [00:03<00:00,  1.44it/s]\u001b[A\n",
            "{'loss': 0.6629, 'learning_rate': 6.019900497512439e-06, 'epoch': 3.98}\n",
            "{'loss': 0.5021, 'learning_rate': 5.522388059701493e-06, 'epoch': 4.48}\n",
            "{'loss': 0.5772, 'learning_rate': 5.024875621890548e-06, 'epoch': 4.98}\n",
            " 50% 1000/2010 [20:52<20:21,  1.21s/it]\n",
            "  0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            " 29% 2/7 [00:00<00:01,  2.66it/s]\u001b[A\n",
            " 43% 3/7 [00:01<00:02,  1.88it/s]\u001b[A\n",
            " 57% 4/7 [00:02<00:01,  1.63it/s]\u001b[A\n",
            " 71% 5/7 [00:03<00:01,  1.51it/s]\u001b[A\n",
            " 86% 6/7 [00:03<00:00,  1.44it/s]\u001b[A/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "                                       \n",
            "\u001b[A{'eval_loss': 1.058254361152649, 'eval_accuracy': 0.6831168831168831, 'eval_P_Clarity': 0.7123287671232876, 'eval_R_Clarity': 0.6624203821656051, 'eval_f1_Clarity': 0.6864686468646863, 'eval_P_Fluency': 0.7122302158273381, 'eval_R_Fluency': 0.8608695652173913, 'eval_f1_Fluency': 0.7795275590551182, 'eval_P_Coherence': 0.5666666666666667, 'eval_R_Coherence': 0.3695652173913043, 'eval_f1_Coherence': 0.4473684210526315, 'eval_P_Style': 0.0, 'eval_R_Style': 0.0, 'eval_f1_Style': 0.0, 'eval_P_Meaning-Changed': 0.6142857142857143, 'eval_R_Meaning-Changed': 0.7962962962962963, 'eval_f1_Meaning-Changed': 0.6935483870967742, 'eval_runtime': 4.5455, 'eval_samples_per_second': 84.7, 'eval_steps_per_second': 1.54, 'epoch': 4.98}\n",
            " 50% 1000/2010 [20:57<20:21,  1.21s/it]\n",
            "100% 7/7 [00:03<00:00,  1.44it/s]\u001b[A\n",
            "{'loss': 0.4356, 'learning_rate': 4.527363184079602e-06, 'epoch': 5.47}\n",
            "{'loss': 0.4651, 'learning_rate': 4.029850746268657e-06, 'epoch': 5.97}\n",
            " 62% 1250/2010 [26:09<15:18,  1.21s/it]\n",
            "  0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            " 29% 2/7 [00:00<00:01,  2.66it/s]\u001b[A\n",
            " 43% 3/7 [00:01<00:02,  1.88it/s]\u001b[A\n",
            " 57% 4/7 [00:02<00:01,  1.63it/s]\u001b[A\n",
            " 71% 5/7 [00:03<00:01,  1.51it/s]\u001b[A\n",
            " 86% 6/7 [00:03<00:00,  1.44it/s]\u001b[A/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "                                       \n",
            "\u001b[A{'eval_loss': 1.1763594150543213, 'eval_accuracy': 0.6831168831168831, 'eval_P_Clarity': 0.7253521126760564, 'eval_R_Clarity': 0.6560509554140127, 'eval_f1_Clarity': 0.6889632107023411, 'eval_P_Fluency': 0.7163120567375887, 'eval_R_Fluency': 0.8782608695652174, 'eval_f1_Fluency': 0.7890625000000001, 'eval_P_Coherence': 0.4888888888888889, 'eval_R_Coherence': 0.4782608695652174, 'eval_f1_Coherence': 0.4835164835164835, 'eval_P_Style': 0.0, 'eval_R_Style': 0.0, 'eval_f1_Style': 0.0, 'eval_P_Meaning-Changed': 0.6491228070175439, 'eval_R_Meaning-Changed': 0.6851851851851852, 'eval_f1_Meaning-Changed': 0.6666666666666666, 'eval_runtime': 4.5449, 'eval_samples_per_second': 84.71, 'eval_steps_per_second': 1.54, 'epoch': 6.22}\n",
            " 62% 1250/2010 [26:13<15:18,  1.21s/it]\n",
            "100% 7/7 [00:03<00:00,  1.44it/s]\u001b[A\n",
            "{'loss': 0.3789, 'learning_rate': 3.5323383084577117e-06, 'epoch': 6.47}\n",
            "{'loss': 0.3688, 'learning_rate': 3.0348258706467666e-06, 'epoch': 6.97}\n",
            "{'loss': 0.301, 'learning_rate': 2.537313432835821e-06, 'epoch': 7.46}\n",
            " 75% 1500/2010 [31:25<10:16,  1.21s/it]\n",
            "  0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            " 29% 2/7 [00:00<00:01,  2.66it/s]\u001b[A\n",
            " 43% 3/7 [00:01<00:02,  1.88it/s]\u001b[A\n",
            " 57% 4/7 [00:02<00:01,  1.63it/s]\u001b[A\n",
            " 71% 5/7 [00:03<00:01,  1.51it/s]\u001b[A\n",
            " 86% 6/7 [00:03<00:00,  1.44it/s]\u001b[A/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "                                       \n",
            "\u001b[A{'eval_loss': 1.1779909133911133, 'eval_accuracy': 0.6753246753246753, 'eval_P_Clarity': 0.723404255319149, 'eval_R_Clarity': 0.6496815286624203, 'eval_f1_Clarity': 0.6845637583892618, 'eval_P_Fluency': 0.7194244604316546, 'eval_R_Fluency': 0.8695652173913043, 'eval_f1_Fluency': 0.7874015748031497, 'eval_P_Coherence': 0.475, 'eval_R_Coherence': 0.41304347826086957, 'eval_f1_Coherence': 0.44186046511627913, 'eval_P_Style': 0.0, 'eval_R_Style': 0.0, 'eval_f1_Style': 0.0, 'eval_P_Meaning-Changed': 0.6, 'eval_R_Meaning-Changed': 0.7222222222222222, 'eval_f1_Meaning-Changed': 0.6554621848739496, 'eval_runtime': 4.5459, 'eval_samples_per_second': 84.692, 'eval_steps_per_second': 1.54, 'epoch': 7.46}\n",
            " 75% 1500/2010 [31:30<10:16,  1.21s/it]\n",
            "100% 7/7 [00:03<00:00,  1.44it/s]\u001b[A\n",
            "{'loss': 0.2878, 'learning_rate': 2.0398009950248755e-06, 'epoch': 7.96}\n",
            "{'loss': 0.2421, 'learning_rate': 1.5422885572139304e-06, 'epoch': 8.46}\n",
            " 87% 1750/2010 [36:42<05:14,  1.21s/it]\n",
            "  0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            " 29% 2/7 [00:00<00:01,  2.66it/s]\u001b[A\n",
            " 43% 3/7 [00:01<00:02,  1.87it/s]\u001b[A\n",
            " 57% 4/7 [00:02<00:01,  1.62it/s]\u001b[A\n",
            " 71% 5/7 [00:03<00:01,  1.51it/s]\u001b[A\n",
            " 86% 6/7 [00:03<00:00,  1.44it/s]\u001b[A/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "                                       \n",
            "\u001b[A{'eval_loss': 1.2597830295562744, 'eval_accuracy': 0.6883116883116883, 'eval_P_Clarity': 0.7593984962406015, 'eval_R_Clarity': 0.643312101910828, 'eval_f1_Clarity': 0.696551724137931, 'eval_P_Fluency': 0.7266187050359713, 'eval_R_Fluency': 0.8782608695652174, 'eval_f1_Fluency': 0.7952755905511811, 'eval_P_Coherence': 0.5, 'eval_R_Coherence': 0.5, 'eval_f1_Coherence': 0.5, 'eval_P_Style': 0.0, 'eval_R_Style': 0.0, 'eval_f1_Style': 0.0, 'eval_P_Meaning-Changed': 0.5970149253731343, 'eval_R_Meaning-Changed': 0.7407407407407407, 'eval_f1_Meaning-Changed': 0.6611570247933883, 'eval_runtime': 4.5456, 'eval_samples_per_second': 84.697, 'eval_steps_per_second': 1.54, 'epoch': 8.71}\n",
            " 87% 1750/2010 [36:47<05:14,  1.21s/it]\n",
            "100% 7/7 [00:03<00:00,  1.44it/s]\u001b[A\n",
            "{'loss': 0.2632, 'learning_rate': 1.044776119402985e-06, 'epoch': 8.96}\n",
            "{'loss': 0.2161, 'learning_rate': 5.472636815920398e-07, 'epoch': 9.45}\n",
            "{'loss': 0.2323, 'learning_rate': 4.975124378109453e-08, 'epoch': 9.95}\n",
            "100% 2000/2010 [41:59<00:12,  1.21s/it]\n",
            "  0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            " 29% 2/7 [00:00<00:01,  2.66it/s]\u001b[A\n",
            " 43% 3/7 [00:01<00:02,  1.88it/s]\u001b[A\n",
            " 57% 4/7 [00:02<00:01,  1.63it/s]\u001b[A\n",
            " 71% 5/7 [00:03<00:01,  1.51it/s]\u001b[A\n",
            " 86% 6/7 [00:03<00:00,  1.44it/s]\u001b[A/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "                                       \n",
            "\u001b[A{'eval_loss': 1.2706228494644165, 'eval_accuracy': 0.6909090909090909, 'eval_P_Clarity': 0.7278911564625851, 'eval_R_Clarity': 0.6815286624203821, 'eval_f1_Clarity': 0.7039473684210527, 'eval_P_Fluency': 0.7318840579710145, 'eval_R_Fluency': 0.8782608695652174, 'eval_f1_Fluency': 0.7984189723320159, 'eval_P_Coherence': 0.48717948717948717, 'eval_R_Coherence': 0.41304347826086957, 'eval_f1_Coherence': 0.44705882352941173, 'eval_P_Style': 0.0, 'eval_R_Style': 0.0, 'eval_f1_Style': 0.0, 'eval_P_Meaning-Changed': 0.639344262295082, 'eval_R_Meaning-Changed': 0.7222222222222222, 'eval_f1_Meaning-Changed': 0.6782608695652174, 'eval_runtime': 4.5449, 'eval_samples_per_second': 84.71, 'eval_steps_per_second': 1.54, 'epoch': 9.95}\n",
            "100% 2000/2010 [42:03<00:12,  1.21s/it]\n",
            "100% 7/7 [00:03<00:00,  1.44it/s]\u001b[A\n",
            "{'train_runtime': 2545.2474, 'train_samples_per_second': 12.631, 'train_steps_per_second': 0.79, 'train_loss': 0.5954136028811706, 'epoch': 10.0}\n",
            "100% 2010/2010 [42:25<00:00,  1.27s/it]\n",
            " 86% 6/7 [00:03<00:00,  1.44it/s]/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "100% 7/7 [00:03<00:00,  1.85it/s]\n",
            "{'eval_loss': 1.270631194114685, 'eval_accuracy': 0.6883116883116883, 'eval_P_Clarity': 0.7278911564625851, 'eval_R_Clarity': 0.6815286624203821, 'eval_f1_Clarity': 0.7039473684210527, 'eval_P_Fluency': 0.7299270072992701, 'eval_R_Fluency': 0.8695652173913043, 'eval_f1_Fluency': 0.7936507936507937, 'eval_P_Coherence': 0.475, 'eval_R_Coherence': 0.41304347826086957, 'eval_f1_Coherence': 0.44186046511627913, 'eval_P_Style': 0.0, 'eval_R_Style': 0.0, 'eval_f1_Style': 0.0, 'eval_P_Meaning-Changed': 0.639344262295082, 'eval_R_Meaning-Changed': 0.7222222222222222, 'eval_f1_Meaning-Changed': 0.6782608695652174, 'eval_runtime': 4.5441, 'eval_samples_per_second': 84.725, 'eval_steps_per_second': 1.54, 'epoch': 10.0}\n",
            "CPU times: user 17 s, sys: 3.44 s, total: 20.4 s\n",
            "Wall time: 42min 44s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "!python 'train_intent_classifier.py' --upsample_values 1 1 1 1 1 --weights 1. 1. 1. 1. 1. -e 10  -s roberta-large-ten -d /content/cs678-cp1-cp2/robust_data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3c7LyW2yc7FX"
      },
      "source": [
        "### Task 1.2: Robustness Test on Iterative Edit Generation Model - PEGASUS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "992bbcbe-4b6a-423b-a336-7980c15fa2f4",
        "id": "tgtdxkd2C2HK"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mv: cannot stat '/content/cs678-cp1-cp2/cp1files/train_sent_pegasus.sh': No such file or directory\n",
            "/content/iterater/code/IteraTeR_ACL2022/model/generation\n",
            "+ export TOKENIZERS_PARALLELISM=false\n",
            "+ PYTHON=python3\n",
            "+ git clone https://github.com/huggingface/transformers\n",
            "fatal: destination path 'transformers' already exists and is not an empty directory.\n",
            "+ cp run_summarization.py ./transformers/examples/pytorch/summarization/\n",
            "+ TRAIN_SCRIPT=./transformers/examples/pytorch/summarization/run_summarization.py\n",
            "+ TRAIN=/content/IteraTeR/human_sent_level/train.json\n",
            "+ VALID=/content/IteraTeR/human_sent_level/dev.json\n",
            "+ OUTPUT=pegasus_sent_model/\n",
            "+ sha1sum ./transformers/examples/pytorch/summarization/run_summarization.py\n",
            "1a98b8a4f2cf13523ec0e86d2094d61c4c53c7c1  ./transformers/examples/pytorch/summarization/run_summarization.py\n",
            "+ python3 ./transformers/examples/pytorch/summarization/run_summarization.py --model_name_or_path google/pegasus-large --do_train --do_eval --train_file /content/IteraTeR/human_sent_level/train.json --validation_file /content/IteraTeR/human_sent_level/dev.json --per_device_train_batch_size=4 --per_device_eval_batch_size=4 --num_train_epochs 5 --gradient_accumulation_steps 4 --evaluation_strategy steps --eval_steps 200 --save_steps 100 --predict_with_generate --logging_steps 50 --output_dir pegasus_sent_model/ --overwrite_output_dir --text_column before_sent_with_intent --summary_column after_sent --learning_rate 3e-5\n",
            "2023-05-08 19:10:23.181139: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "05/08/2023 19:10:27 - WARNING - __main__ -   Process rank: -1, device: cuda:0, n_gpu: 1distributed training: False, 16-bits training: False\n",
            "05/08/2023 19:10:27 - INFO - __main__ -   Training/evaluation parameters Seq2SeqTrainingArguments(\n",
            "_n_gpu=1,\n",
            "adafactor=False,\n",
            "adam_beta1=0.9,\n",
            "adam_beta2=0.999,\n",
            "adam_epsilon=1e-08,\n",
            "auto_find_batch_size=False,\n",
            "bf16=False,\n",
            "bf16_full_eval=False,\n",
            "data_seed=None,\n",
            "dataloader_drop_last=False,\n",
            "dataloader_num_workers=0,\n",
            "dataloader_pin_memory=True,\n",
            "ddp_bucket_cap_mb=None,\n",
            "ddp_find_unused_parameters=None,\n",
            "ddp_timeout=1800,\n",
            "debug=[],\n",
            "deepspeed=None,\n",
            "disable_tqdm=False,\n",
            "do_eval=True,\n",
            "do_predict=False,\n",
            "do_train=True,\n",
            "eval_accumulation_steps=None,\n",
            "eval_delay=0,\n",
            "eval_steps=200,\n",
            "evaluation_strategy=steps,\n",
            "fp16=False,\n",
            "fp16_backend=auto,\n",
            "fp16_full_eval=False,\n",
            "fp16_opt_level=O1,\n",
            "fsdp=[],\n",
            "fsdp_config={'fsdp_min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},\n",
            "fsdp_min_num_params=0,\n",
            "fsdp_transformer_layer_cls_to_wrap=None,\n",
            "full_determinism=False,\n",
            "generation_config=None,\n",
            "generation_max_length=None,\n",
            "generation_num_beams=None,\n",
            "gradient_accumulation_steps=4,\n",
            "gradient_checkpointing=False,\n",
            "greater_is_better=None,\n",
            "group_by_length=False,\n",
            "half_precision_backend=auto,\n",
            "hub_model_id=None,\n",
            "hub_private_repo=False,\n",
            "hub_strategy=every_save,\n",
            "hub_token=<HUB_TOKEN>,\n",
            "ignore_data_skip=False,\n",
            "include_inputs_for_metrics=False,\n",
            "jit_mode_eval=False,\n",
            "label_names=None,\n",
            "label_smoothing_factor=0.0,\n",
            "learning_rate=3e-05,\n",
            "length_column_name=length,\n",
            "load_best_model_at_end=False,\n",
            "local_rank=-1,\n",
            "log_level=passive,\n",
            "log_level_replica=warning,\n",
            "log_on_each_node=True,\n",
            "logging_dir=pegasus_sent_model/runs/May08_19-10-27_532485e9ca09,\n",
            "logging_first_step=False,\n",
            "logging_nan_inf_filter=True,\n",
            "logging_steps=50,\n",
            "logging_strategy=steps,\n",
            "lr_scheduler_type=linear,\n",
            "max_grad_norm=1.0,\n",
            "max_steps=-1,\n",
            "metric_for_best_model=None,\n",
            "mp_parameters=,\n",
            "no_cuda=False,\n",
            "num_train_epochs=5.0,\n",
            "optim=adamw_hf,\n",
            "optim_args=None,\n",
            "output_dir=pegasus_sent_model/,\n",
            "overwrite_output_dir=True,\n",
            "past_index=-1,\n",
            "per_device_eval_batch_size=4,\n",
            "per_device_train_batch_size=4,\n",
            "predict_with_generate=True,\n",
            "prediction_loss_only=False,\n",
            "push_to_hub=False,\n",
            "push_to_hub_model_id=None,\n",
            "push_to_hub_organization=None,\n",
            "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
            "ray_scope=last,\n",
            "remove_unused_columns=True,\n",
            "report_to=['tensorboard', 'wandb'],\n",
            "resume_from_checkpoint=None,\n",
            "run_name=pegasus_sent_model/,\n",
            "save_on_each_node=False,\n",
            "save_safetensors=False,\n",
            "save_steps=100,\n",
            "save_strategy=steps,\n",
            "save_total_limit=None,\n",
            "seed=42,\n",
            "sharded_ddp=[],\n",
            "skip_memory_metrics=True,\n",
            "sortish_sampler=False,\n",
            "tf32=None,\n",
            "torch_compile=False,\n",
            "torch_compile_backend=None,\n",
            "torch_compile_mode=None,\n",
            "torchdynamo=None,\n",
            "tpu_metrics_debug=False,\n",
            "tpu_num_cores=None,\n",
            "use_ipex=False,\n",
            "use_legacy_prediction_loop=False,\n",
            "use_mps_device=False,\n",
            "warmup_ratio=0.0,\n",
            "warmup_steps=0,\n",
            "weight_decay=0.0,\n",
            "xpu_backend=None,\n",
            ")\n",
            "05/08/2023 19:10:27 - INFO - __main__ -   Seq2SeqTrainingArguments(\n",
            "_n_gpu=1,\n",
            "adafactor=False,\n",
            "adam_beta1=0.9,\n",
            "adam_beta2=0.999,\n",
            "adam_epsilon=1e-08,\n",
            "auto_find_batch_size=False,\n",
            "bf16=False,\n",
            "bf16_full_eval=False,\n",
            "data_seed=None,\n",
            "dataloader_drop_last=False,\n",
            "dataloader_num_workers=0,\n",
            "dataloader_pin_memory=True,\n",
            "ddp_bucket_cap_mb=None,\n",
            "ddp_find_unused_parameters=None,\n",
            "ddp_timeout=1800,\n",
            "debug=[],\n",
            "deepspeed=None,\n",
            "disable_tqdm=False,\n",
            "do_eval=True,\n",
            "do_predict=False,\n",
            "do_train=True,\n",
            "eval_accumulation_steps=None,\n",
            "eval_delay=0,\n",
            "eval_steps=200,\n",
            "evaluation_strategy=steps,\n",
            "fp16=False,\n",
            "fp16_backend=auto,\n",
            "fp16_full_eval=False,\n",
            "fp16_opt_level=O1,\n",
            "fsdp=[],\n",
            "fsdp_config={'fsdp_min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},\n",
            "fsdp_min_num_params=0,\n",
            "fsdp_transformer_layer_cls_to_wrap=None,\n",
            "full_determinism=False,\n",
            "generation_config=None,\n",
            "generation_max_length=None,\n",
            "generation_num_beams=None,\n",
            "gradient_accumulation_steps=4,\n",
            "gradient_checkpointing=False,\n",
            "greater_is_better=None,\n",
            "group_by_length=False,\n",
            "half_precision_backend=auto,\n",
            "hub_model_id=None,\n",
            "hub_private_repo=False,\n",
            "hub_strategy=every_save,\n",
            "hub_token=<HUB_TOKEN>,\n",
            "ignore_data_skip=False,\n",
            "include_inputs_for_metrics=False,\n",
            "jit_mode_eval=False,\n",
            "label_names=None,\n",
            "label_smoothing_factor=0.0,\n",
            "learning_rate=3e-05,\n",
            "length_column_name=length,\n",
            "load_best_model_at_end=False,\n",
            "local_rank=-1,\n",
            "log_level=passive,\n",
            "log_level_replica=warning,\n",
            "log_on_each_node=True,\n",
            "logging_dir=pegasus_sent_model/runs/May08_19-10-27_532485e9ca09,\n",
            "logging_first_step=False,\n",
            "logging_nan_inf_filter=True,\n",
            "logging_steps=50,\n",
            "logging_strategy=steps,\n",
            "lr_scheduler_type=linear,\n",
            "max_grad_norm=1.0,\n",
            "max_steps=-1,\n",
            "metric_for_best_model=None,\n",
            "mp_parameters=,\n",
            "no_cuda=False,\n",
            "num_train_epochs=5.0,\n",
            "optim=adamw_hf,\n",
            "optim_args=None,\n",
            "output_dir=pegasus_sent_model/,\n",
            "overwrite_output_dir=True,\n",
            "past_index=-1,\n",
            "per_device_eval_batch_size=4,\n",
            "per_device_train_batch_size=4,\n",
            "predict_with_generate=True,\n",
            "prediction_loss_only=False,\n",
            "push_to_hub=False,\n",
            "push_to_hub_model_id=None,\n",
            "push_to_hub_organization=None,\n",
            "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
            "ray_scope=last,\n",
            "remove_unused_columns=True,\n",
            "report_to=['tensorboard', 'wandb'],\n",
            "resume_from_checkpoint=None,\n",
            "run_name=pegasus_sent_model/,\n",
            "save_on_each_node=False,\n",
            "save_safetensors=False,\n",
            "save_steps=100,\n",
            "save_strategy=steps,\n",
            "save_total_limit=None,\n",
            "seed=42,\n",
            "sharded_ddp=[],\n",
            "skip_memory_metrics=True,\n",
            "sortish_sampler=False,\n",
            "tf32=None,\n",
            "torch_compile=False,\n",
            "torch_compile_backend=None,\n",
            "torch_compile_mode=None,\n",
            "torchdynamo=None,\n",
            "tpu_metrics_debug=False,\n",
            "tpu_num_cores=None,\n",
            "use_ipex=False,\n",
            "use_legacy_prediction_loop=False,\n",
            "use_mps_device=False,\n",
            "warmup_ratio=0.0,\n",
            "warmup_steps=0,\n",
            "weight_decay=0.0,\n",
            "xpu_backend=None,\n",
            ")\n",
            "05/08/2023 19:10:27 - INFO - __main__ -   42\n",
            "05/08/2023 19:10:27 - WARNING - datasets.builder -   Using custom data configuration default-f5bb283de44c43ec\n",
            "Downloading and preparing dataset json/default to /root/.cache/huggingface/datasets/json/default-f5bb283de44c43ec/0.0.0/ac0ca5f5289a6cf108e706efcf040422dbbfa8e658dee6a819f20d76bb84d26b...\n",
            "100% 2/2 [00:00<00:00, 11748.75it/s]\n",
            "100% 2/2 [00:00<00:00, 1756.78it/s]\n",
            "Dataset json downloaded and prepared to /root/.cache/huggingface/datasets/json/default-f5bb283de44c43ec/0.0.0/ac0ca5f5289a6cf108e706efcf040422dbbfa8e658dee6a819f20d76bb84d26b. Subsequent calls will reuse this data.\n",
            "100% 2/2 [00:00<00:00, 797.02it/s]\n",
            "Downloading (…)lve/main/config.json: 100% 3.09k/3.09k [00:00<00:00, 14.9MB/s]\n",
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--google--pegasus-large/snapshots/dec7796b22f29b7d1c476192313eae8ed57b6b77/config.json\n",
            "Model config PegasusConfig {\n",
            "  \"_name_or_path\": \"google/pegasus-large\",\n",
            "  \"activation_dropout\": 0.1,\n",
            "  \"activation_function\": \"relu\",\n",
            "  \"add_bias_logits\": false,\n",
            "  \"add_final_layer_norm\": true,\n",
            "  \"architectures\": [\n",
            "    \"PegasusForConditionalGeneration\"\n",
            "  ],\n",
            "  \"attention_dropout\": 0.1,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"classif_dropout\": 0.0,\n",
            "  \"classifier_dropout\": 0.0,\n",
            "  \"d_model\": 1024,\n",
            "  \"decoder_attention_heads\": 16,\n",
            "  \"decoder_ffn_dim\": 4096,\n",
            "  \"decoder_layerdrop\": 0.0,\n",
            "  \"decoder_layers\": 16,\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"dropout\": 0.1,\n",
            "  \"encoder_attention_heads\": 16,\n",
            "  \"encoder_ffn_dim\": 4096,\n",
            "  \"encoder_layerdrop\": 0.0,\n",
            "  \"encoder_layers\": 16,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"extra_pos_embeddings\": 1,\n",
            "  \"force_bos_token_to_be_generated\": false,\n",
            "  \"forced_eos_token_id\": 1,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\",\n",
            "    \"2\": \"LABEL_2\"\n",
            "  },\n",
            "  \"init_std\": 0.02,\n",
            "  \"is_encoder_decoder\": true,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1,\n",
            "    \"LABEL_2\": 2\n",
            "  },\n",
            "  \"length_penalty\": 0.8,\n",
            "  \"max_length\": 256,\n",
            "  \"max_position_embeddings\": 1024,\n",
            "  \"model_type\": \"pegasus\",\n",
            "  \"normalize_before\": true,\n",
            "  \"normalize_embedding\": false,\n",
            "  \"num_beams\": 8,\n",
            "  \"num_hidden_layers\": 16,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"scale_embedding\": true,\n",
            "  \"static_position_embeddings\": true,\n",
            "  \"task_specific_params\": {\n",
            "    \"summarization_aeslc\": {\n",
            "      \"length_penalty\": 0.6,\n",
            "      \"max_length\": 32,\n",
            "      \"max_position_embeddings\": 512\n",
            "    },\n",
            "    \"summarization_arxiv\": {\n",
            "      \"length_penalty\": 0.8,\n",
            "      \"max_length\": 256,\n",
            "      \"max_position_embeddings\": 1024\n",
            "    },\n",
            "    \"summarization_big_patent\": {\n",
            "      \"length_penalty\": 0.7,\n",
            "      \"max_length\": 256,\n",
            "      \"max_position_embeddings\": 1024\n",
            "    },\n",
            "    \"summarization_billsum\": {\n",
            "      \"length_penalty\": 0.6,\n",
            "      \"max_length\": 256,\n",
            "      \"max_position_embeddings\": 1024\n",
            "    },\n",
            "    \"summarization_cnn_dailymail\": {\n",
            "      \"length_penalty\": 0.8,\n",
            "      \"max_length\": 128,\n",
            "      \"max_position_embeddings\": 1024\n",
            "    },\n",
            "    \"summarization_gigaword\": {\n",
            "      \"length_penalty\": 0.6,\n",
            "      \"max_length\": 32,\n",
            "      \"max_position_embeddings\": 128\n",
            "    },\n",
            "    \"summarization_large\": {\n",
            "      \"length_penalty\": 0.8,\n",
            "      \"max_length\": 256,\n",
            "      \"max_position_embeddings\": 1024\n",
            "    },\n",
            "    \"summarization_multi_news\": {\n",
            "      \"length_penalty\": 0.8,\n",
            "      \"max_length\": 256,\n",
            "      \"max_position_embeddings\": 1024\n",
            "    },\n",
            "    \"summarization_newsroom\": {\n",
            "      \"length_penalty\": 0.8,\n",
            "      \"max_length\": 128,\n",
            "      \"max_position_embeddings\": 512\n",
            "    },\n",
            "    \"summarization_pubmed\": {\n",
            "      \"length_penalty\": 0.8,\n",
            "      \"max_length\": 256,\n",
            "      \"max_position_embeddings\": 1024\n",
            "    },\n",
            "    \"summarization_reddit_tifu\": {\n",
            "      \"length_penalty\": 0.6,\n",
            "      \"max_length\": 128,\n",
            "      \"max_position_embeddings\": 512\n",
            "    },\n",
            "    \"summarization_wikihow\": {\n",
            "      \"length_penalty\": 0.6,\n",
            "      \"max_length\": 256,\n",
            "      \"max_position_embeddings\": 512\n",
            "    },\n",
            "    \"summarization_xsum\": {\n",
            "      \"length_penalty\": 0.8,\n",
            "      \"max_length\": 64,\n",
            "      \"max_position_embeddings\": 512\n",
            "    }\n",
            "  },\n",
            "  \"transformers_version\": \"4.28.1\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 96103\n",
            "}\n",
            "\n",
            "Downloading (…)okenizer_config.json: 100% 88.0/88.0 [00:00<00:00, 820kB/s]\n",
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--google--pegasus-large/snapshots/dec7796b22f29b7d1c476192313eae8ed57b6b77/config.json\n",
            "Model config PegasusConfig {\n",
            "  \"_name_or_path\": \"google/pegasus-large\",\n",
            "  \"activation_dropout\": 0.1,\n",
            "  \"activation_function\": \"relu\",\n",
            "  \"add_bias_logits\": false,\n",
            "  \"add_final_layer_norm\": true,\n",
            "  \"architectures\": [\n",
            "    \"PegasusForConditionalGeneration\"\n",
            "  ],\n",
            "  \"attention_dropout\": 0.1,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"classif_dropout\": 0.0,\n",
            "  \"classifier_dropout\": 0.0,\n",
            "  \"d_model\": 1024,\n",
            "  \"decoder_attention_heads\": 16,\n",
            "  \"decoder_ffn_dim\": 4096,\n",
            "  \"decoder_layerdrop\": 0.0,\n",
            "  \"decoder_layers\": 16,\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"dropout\": 0.1,\n",
            "  \"encoder_attention_heads\": 16,\n",
            "  \"encoder_ffn_dim\": 4096,\n",
            "  \"encoder_layerdrop\": 0.0,\n",
            "  \"encoder_layers\": 16,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"extra_pos_embeddings\": 1,\n",
            "  \"force_bos_token_to_be_generated\": false,\n",
            "  \"forced_eos_token_id\": 1,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\",\n",
            "    \"2\": \"LABEL_2\"\n",
            "  },\n",
            "  \"init_std\": 0.02,\n",
            "  \"is_encoder_decoder\": true,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1,\n",
            "    \"LABEL_2\": 2\n",
            "  },\n",
            "  \"length_penalty\": 0.8,\n",
            "  \"max_length\": 256,\n",
            "  \"max_position_embeddings\": 1024,\n",
            "  \"model_type\": \"pegasus\",\n",
            "  \"normalize_before\": true,\n",
            "  \"normalize_embedding\": false,\n",
            "  \"num_beams\": 8,\n",
            "  \"num_hidden_layers\": 16,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"scale_embedding\": true,\n",
            "  \"static_position_embeddings\": true,\n",
            "  \"task_specific_params\": {\n",
            "    \"summarization_aeslc\": {\n",
            "      \"length_penalty\": 0.6,\n",
            "      \"max_length\": 32,\n",
            "      \"max_position_embeddings\": 512\n",
            "    },\n",
            "    \"summarization_arxiv\": {\n",
            "      \"length_penalty\": 0.8,\n",
            "      \"max_length\": 256,\n",
            "      \"max_position_embeddings\": 1024\n",
            "    },\n",
            "    \"summarization_big_patent\": {\n",
            "      \"length_penalty\": 0.7,\n",
            "      \"max_length\": 256,\n",
            "      \"max_position_embeddings\": 1024\n",
            "    },\n",
            "    \"summarization_billsum\": {\n",
            "      \"length_penalty\": 0.6,\n",
            "      \"max_length\": 256,\n",
            "      \"max_position_embeddings\": 1024\n",
            "    },\n",
            "    \"summarization_cnn_dailymail\": {\n",
            "      \"length_penalty\": 0.8,\n",
            "      \"max_length\": 128,\n",
            "      \"max_position_embeddings\": 1024\n",
            "    },\n",
            "    \"summarization_gigaword\": {\n",
            "      \"length_penalty\": 0.6,\n",
            "      \"max_length\": 32,\n",
            "      \"max_position_embeddings\": 128\n",
            "    },\n",
            "    \"summarization_large\": {\n",
            "      \"length_penalty\": 0.8,\n",
            "      \"max_length\": 256,\n",
            "      \"max_position_embeddings\": 1024\n",
            "    },\n",
            "    \"summarization_multi_news\": {\n",
            "      \"length_penalty\": 0.8,\n",
            "      \"max_length\": 256,\n",
            "      \"max_position_embeddings\": 1024\n",
            "    },\n",
            "    \"summarization_newsroom\": {\n",
            "      \"length_penalty\": 0.8,\n",
            "      \"max_length\": 128,\n",
            "      \"max_position_embeddings\": 512\n",
            "    },\n",
            "    \"summarization_pubmed\": {\n",
            "      \"length_penalty\": 0.8,\n",
            "      \"max_length\": 256,\n",
            "      \"max_position_embeddings\": 1024\n",
            "    },\n",
            "    \"summarization_reddit_tifu\": {\n",
            "      \"length_penalty\": 0.6,\n",
            "      \"max_length\": 128,\n",
            "      \"max_position_embeddings\": 512\n",
            "    },\n",
            "    \"summarization_wikihow\": {\n",
            "      \"length_penalty\": 0.6,\n",
            "      \"max_length\": 256,\n",
            "      \"max_position_embeddings\": 512\n",
            "    },\n",
            "    \"summarization_xsum\": {\n",
            "      \"length_penalty\": 0.8,\n",
            "      \"max_length\": 64,\n",
            "      \"max_position_embeddings\": 512\n",
            "    }\n",
            "  },\n",
            "  \"transformers_version\": \"4.28.1\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 96103\n",
            "}\n",
            "\n",
            "Downloading (…)ve/main/spiece.model: 100% 1.91M/1.91M [00:00<00:00, 5.85MB/s]\n",
            "Downloading (…)cial_tokens_map.json: 100% 65.0/65.0 [00:00<00:00, 620kB/s]\n",
            "loading file spiece.model from cache at /root/.cache/huggingface/hub/models--google--pegasus-large/snapshots/dec7796b22f29b7d1c476192313eae8ed57b6b77/spiece.model\n",
            "loading file tokenizer.json from cache at None\n",
            "loading file added_tokens.json from cache at None\n",
            "loading file special_tokens_map.json from cache at /root/.cache/huggingface/hub/models--google--pegasus-large/snapshots/dec7796b22f29b7d1c476192313eae8ed57b6b77/special_tokens_map.json\n",
            "loading file tokenizer_config.json from cache at /root/.cache/huggingface/hub/models--google--pegasus-large/snapshots/dec7796b22f29b7d1c476192313eae8ed57b6b77/tokenizer_config.json\n",
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--google--pegasus-large/snapshots/dec7796b22f29b7d1c476192313eae8ed57b6b77/config.json\n",
            "Model config PegasusConfig {\n",
            "  \"_name_or_path\": \"google/pegasus-large\",\n",
            "  \"activation_dropout\": 0.1,\n",
            "  \"activation_function\": \"relu\",\n",
            "  \"add_bias_logits\": false,\n",
            "  \"add_final_layer_norm\": true,\n",
            "  \"architectures\": [\n",
            "    \"PegasusForConditionalGeneration\"\n",
            "  ],\n",
            "  \"attention_dropout\": 0.1,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"classif_dropout\": 0.0,\n",
            "  \"classifier_dropout\": 0.0,\n",
            "  \"d_model\": 1024,\n",
            "  \"decoder_attention_heads\": 16,\n",
            "  \"decoder_ffn_dim\": 4096,\n",
            "  \"decoder_layerdrop\": 0.0,\n",
            "  \"decoder_layers\": 16,\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"dropout\": 0.1,\n",
            "  \"encoder_attention_heads\": 16,\n",
            "  \"encoder_ffn_dim\": 4096,\n",
            "  \"encoder_layerdrop\": 0.0,\n",
            "  \"encoder_layers\": 16,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"extra_pos_embeddings\": 1,\n",
            "  \"force_bos_token_to_be_generated\": false,\n",
            "  \"forced_eos_token_id\": 1,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\",\n",
            "    \"2\": \"LABEL_2\"\n",
            "  },\n",
            "  \"init_std\": 0.02,\n",
            "  \"is_encoder_decoder\": true,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1,\n",
            "    \"LABEL_2\": 2\n",
            "  },\n",
            "  \"length_penalty\": 0.8,\n",
            "  \"max_length\": 256,\n",
            "  \"max_position_embeddings\": 1024,\n",
            "  \"model_type\": \"pegasus\",\n",
            "  \"normalize_before\": true,\n",
            "  \"normalize_embedding\": false,\n",
            "  \"num_beams\": 8,\n",
            "  \"num_hidden_layers\": 16,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"scale_embedding\": true,\n",
            "  \"static_position_embeddings\": true,\n",
            "  \"task_specific_params\": {\n",
            "    \"summarization_aeslc\": {\n",
            "      \"length_penalty\": 0.6,\n",
            "      \"max_length\": 32,\n",
            "      \"max_position_embeddings\": 512\n",
            "    },\n",
            "    \"summarization_arxiv\": {\n",
            "      \"length_penalty\": 0.8,\n",
            "      \"max_length\": 256,\n",
            "      \"max_position_embeddings\": 1024\n",
            "    },\n",
            "    \"summarization_big_patent\": {\n",
            "      \"length_penalty\": 0.7,\n",
            "      \"max_length\": 256,\n",
            "      \"max_position_embeddings\": 1024\n",
            "    },\n",
            "    \"summarization_billsum\": {\n",
            "      \"length_penalty\": 0.6,\n",
            "      \"max_length\": 256,\n",
            "      \"max_position_embeddings\": 1024\n",
            "    },\n",
            "    \"summarization_cnn_dailymail\": {\n",
            "      \"length_penalty\": 0.8,\n",
            "      \"max_length\": 128,\n",
            "      \"max_position_embeddings\": 1024\n",
            "    },\n",
            "    \"summarization_gigaword\": {\n",
            "      \"length_penalty\": 0.6,\n",
            "      \"max_length\": 32,\n",
            "      \"max_position_embeddings\": 128\n",
            "    },\n",
            "    \"summarization_large\": {\n",
            "      \"length_penalty\": 0.8,\n",
            "      \"max_length\": 256,\n",
            "      \"max_position_embeddings\": 1024\n",
            "    },\n",
            "    \"summarization_multi_news\": {\n",
            "      \"length_penalty\": 0.8,\n",
            "      \"max_length\": 256,\n",
            "      \"max_position_embeddings\": 1024\n",
            "    },\n",
            "    \"summarization_newsroom\": {\n",
            "      \"length_penalty\": 0.8,\n",
            "      \"max_length\": 128,\n",
            "      \"max_position_embeddings\": 512\n",
            "    },\n",
            "    \"summarization_pubmed\": {\n",
            "      \"length_penalty\": 0.8,\n",
            "      \"max_length\": 256,\n",
            "      \"max_position_embeddings\": 1024\n",
            "    },\n",
            "    \"summarization_reddit_tifu\": {\n",
            "      \"length_penalty\": 0.6,\n",
            "      \"max_length\": 128,\n",
            "      \"max_position_embeddings\": 512\n",
            "    },\n",
            "    \"summarization_wikihow\": {\n",
            "      \"length_penalty\": 0.6,\n",
            "      \"max_length\": 256,\n",
            "      \"max_position_embeddings\": 512\n",
            "    },\n",
            "    \"summarization_xsum\": {\n",
            "      \"length_penalty\": 0.8,\n",
            "      \"max_length\": 64,\n",
            "      \"max_position_embeddings\": 512\n",
            "    }\n",
            "  },\n",
            "  \"transformers_version\": \"4.28.1\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 96103\n",
            "}\n",
            "\n",
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--google--pegasus-large/snapshots/dec7796b22f29b7d1c476192313eae8ed57b6b77/config.json\n",
            "Model config PegasusConfig {\n",
            "  \"_name_or_path\": \"google/pegasus-large\",\n",
            "  \"activation_dropout\": 0.1,\n",
            "  \"activation_function\": \"relu\",\n",
            "  \"add_bias_logits\": false,\n",
            "  \"add_final_layer_norm\": true,\n",
            "  \"architectures\": [\n",
            "    \"PegasusForConditionalGeneration\"\n",
            "  ],\n",
            "  \"attention_dropout\": 0.1,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"classif_dropout\": 0.0,\n",
            "  \"classifier_dropout\": 0.0,\n",
            "  \"d_model\": 1024,\n",
            "  \"decoder_attention_heads\": 16,\n",
            "  \"decoder_ffn_dim\": 4096,\n",
            "  \"decoder_layerdrop\": 0.0,\n",
            "  \"decoder_layers\": 16,\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"dropout\": 0.1,\n",
            "  \"encoder_attention_heads\": 16,\n",
            "  \"encoder_ffn_dim\": 4096,\n",
            "  \"encoder_layerdrop\": 0.0,\n",
            "  \"encoder_layers\": 16,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"extra_pos_embeddings\": 1,\n",
            "  \"force_bos_token_to_be_generated\": false,\n",
            "  \"forced_eos_token_id\": 1,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\",\n",
            "    \"2\": \"LABEL_2\"\n",
            "  },\n",
            "  \"init_std\": 0.02,\n",
            "  \"is_encoder_decoder\": true,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1,\n",
            "    \"LABEL_2\": 2\n",
            "  },\n",
            "  \"length_penalty\": 0.8,\n",
            "  \"max_length\": 256,\n",
            "  \"max_position_embeddings\": 1024,\n",
            "  \"model_type\": \"pegasus\",\n",
            "  \"normalize_before\": true,\n",
            "  \"normalize_embedding\": false,\n",
            "  \"num_beams\": 8,\n",
            "  \"num_hidden_layers\": 16,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"scale_embedding\": true,\n",
            "  \"static_position_embeddings\": true,\n",
            "  \"task_specific_params\": {\n",
            "    \"summarization_aeslc\": {\n",
            "      \"length_penalty\": 0.6,\n",
            "      \"max_length\": 32,\n",
            "      \"max_position_embeddings\": 512\n",
            "    },\n",
            "    \"summarization_arxiv\": {\n",
            "      \"length_penalty\": 0.8,\n",
            "      \"max_length\": 256,\n",
            "      \"max_position_embeddings\": 1024\n",
            "    },\n",
            "    \"summarization_big_patent\": {\n",
            "      \"length_penalty\": 0.7,\n",
            "      \"max_length\": 256,\n",
            "      \"max_position_embeddings\": 1024\n",
            "    },\n",
            "    \"summarization_billsum\": {\n",
            "      \"length_penalty\": 0.6,\n",
            "      \"max_length\": 256,\n",
            "      \"max_position_embeddings\": 1024\n",
            "    },\n",
            "    \"summarization_cnn_dailymail\": {\n",
            "      \"length_penalty\": 0.8,\n",
            "      \"max_length\": 128,\n",
            "      \"max_position_embeddings\": 1024\n",
            "    },\n",
            "    \"summarization_gigaword\": {\n",
            "      \"length_penalty\": 0.6,\n",
            "      \"max_length\": 32,\n",
            "      \"max_position_embeddings\": 128\n",
            "    },\n",
            "    \"summarization_large\": {\n",
            "      \"length_penalty\": 0.8,\n",
            "      \"max_length\": 256,\n",
            "      \"max_position_embeddings\": 1024\n",
            "    },\n",
            "    \"summarization_multi_news\": {\n",
            "      \"length_penalty\": 0.8,\n",
            "      \"max_length\": 256,\n",
            "      \"max_position_embeddings\": 1024\n",
            "    },\n",
            "    \"summarization_newsroom\": {\n",
            "      \"length_penalty\": 0.8,\n",
            "      \"max_length\": 128,\n",
            "      \"max_position_embeddings\": 512\n",
            "    },\n",
            "    \"summarization_pubmed\": {\n",
            "      \"length_penalty\": 0.8,\n",
            "      \"max_length\": 256,\n",
            "      \"max_position_embeddings\": 1024\n",
            "    },\n",
            "    \"summarization_reddit_tifu\": {\n",
            "      \"length_penalty\": 0.6,\n",
            "      \"max_length\": 128,\n",
            "      \"max_position_embeddings\": 512\n",
            "    },\n",
            "    \"summarization_wikihow\": {\n",
            "      \"length_penalty\": 0.6,\n",
            "      \"max_length\": 256,\n",
            "      \"max_position_embeddings\": 512\n",
            "    },\n",
            "    \"summarization_xsum\": {\n",
            "      \"length_penalty\": 0.8,\n",
            "      \"max_length\": 64,\n",
            "      \"max_position_embeddings\": 512\n",
            "    }\n",
            "  },\n",
            "  \"transformers_version\": \"4.28.1\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 96103\n",
            "}\n",
            "\n",
            "Assigning ['<clarity>', '<fluency>', '<coherence>', '<style>', '<meaning-changed>'] to the additional_special_tokens key of the tokenizer\n",
            "Downloading pytorch_model.bin: 100% 2.28G/2.28G [00:54<00:00, 41.7MB/s]\n",
            "loading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--google--pegasus-large/snapshots/dec7796b22f29b7d1c476192313eae8ed57b6b77/pytorch_model.bin\n",
            "Generate config GenerationConfig {\n",
            "  \"_from_model_config\": true,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"forced_eos_token_id\": 1,\n",
            "  \"length_penalty\": 0.8,\n",
            "  \"max_length\": 256,\n",
            "  \"num_beams\": 8,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"transformers_version\": \"4.28.1\"\n",
            "}\n",
            "\n",
            "All model checkpoint weights were used when initializing PegasusForConditionalGeneration.\n",
            "\n",
            "All the weights of PegasusForConditionalGeneration were initialized from the model checkpoint at google/pegasus-large.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use PegasusForConditionalGeneration for predictions without further training.\n",
            "Downloading (…)neration_config.json: 100% 260/260 [00:00<00:00, 2.00MB/s]\n",
            "loading configuration file generation_config.json from cache at /root/.cache/huggingface/hub/models--google--pegasus-large/snapshots/dec7796b22f29b7d1c476192313eae8ed57b6b77/generation_config.json\n",
            "Generate config GenerationConfig {\n",
            "  \"_from_model_config\": true,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"forced_eos_token_id\": 1,\n",
            "  \"length_penalty\": 0.8,\n",
            "  \"max_length\": 256,\n",
            "  \"num_beams\": 8,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"transformers_version\": \"4.28.1\"\n",
            "}\n",
            "\n",
            "05/08/2023 19:11:37 - WARNING - datasets.fingerprint -   Parameter 'function'=<function main.<locals>.preprocess_function at 0x7fe5aadc8dc0> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.\n",
            "Running tokenizer on train dataset:   0% 0/4 [00:00<?, ?ba/s]/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:3596: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
            "  warnings.warn(\n",
            "Running tokenizer on train dataset: 100% 4/4 [00:01<00:00,  3.03ba/s]\n",
            "Running tokenizer on validation dataset: 100% 1/1 [00:00<00:00,  7.38ba/s]\n",
            "Downloading: 5.60kB [00:00, 3.64MB/s]       \n",
            "Downloading: 6.06kB [00:00, 3.82MB/s]       \n",
            "Downloading: 4.07kB [00:00, 2.57MB/s]       \n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "***** Running training *****\n",
            "  Num examples = 3,254\n",
            "  Num Epochs = 5\n",
            "  Instantaneous batch size per device = 4\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
            "  Gradient Accumulation steps = 4\n",
            "  Total optimization steps = 1,015\n",
            "  Number of trainable parameters = 568,705,024\n",
            "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (1) Create a W&B account\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (2) Use an existing W&B account\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (3) Don't visualize my results\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Enter your choice: 3\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You chose \"Don't visualize my results\"\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.15.2\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n",
            "  0% 0/1015 [00:00<?, ?it/s]You're using a PegasusTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
            "{'loss': 2.474, 'learning_rate': 2.8522167487684728e-05, 'epoch': 0.25}\n",
            "{'loss': 1.8356, 'learning_rate': 2.7044334975369458e-05, 'epoch': 0.49}\n",
            " 10% 100/1015 [00:53<07:58,  1.91it/s]Saving model checkpoint to pegasus_sent_model/checkpoint-100\n",
            "Configuration saved in pegasus_sent_model/checkpoint-100/config.json\n",
            "Configuration saved in pegasus_sent_model/checkpoint-100/generation_config.json\n",
            "Model weights saved in pegasus_sent_model/checkpoint-100/pytorch_model.bin\n",
            "tokenizer config file saved in pegasus_sent_model/checkpoint-100/tokenizer_config.json\n",
            "Special tokens file saved in pegasus_sent_model/checkpoint-100/special_tokens_map.json\n",
            "{'loss': 1.4241, 'learning_rate': 2.5566502463054188e-05, 'epoch': 0.74}\n",
            "{'loss': 1.2931, 'learning_rate': 2.408866995073892e-05, 'epoch': 0.98}\n",
            " 20% 200/1015 [02:04<07:04,  1.92it/s]***** Running Evaluation *****\n",
            "  Num examples = 400\n",
            "  Batch size = 4\n",
            "Generate config GenerationConfig {\n",
            "  \"_from_model_config\": true,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"forced_eos_token_id\": 1,\n",
            "  \"length_penalty\": 0.8,\n",
            "  \"max_length\": 256,\n",
            "  \"num_beams\": 8,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"transformers_version\": \"4.28.1\"\n",
            "}\n",
            "\n",
            "\n",
            "  0% 0/100 [00:00<?, ?it/s]\u001b[A\n",
            "  2% 2/100 [00:01<00:58,  1.67it/s]\u001b[A\n",
            "  3% 3/100 [00:02<01:44,  1.08s/it]\u001b[A\n",
            "  4% 4/100 [00:04<02:01,  1.27s/it]\u001b[A\n",
            "  5% 5/100 [00:05<01:46,  1.13s/it]\u001b[A\n",
            "  6% 6/100 [00:06<01:55,  1.22s/it]\u001b[A\n",
            "  7% 7/100 [00:07<01:52,  1.21s/it]\u001b[A\n",
            "  8% 8/100 [00:09<01:51,  1.21s/it]\u001b[A\n",
            "  9% 9/100 [00:15<04:07,  2.72s/it]\u001b[A\n",
            " 10% 10/100 [00:16<03:31,  2.35s/it]\u001b[A\n",
            " 11% 11/100 [00:17<02:57,  2.00s/it]\u001b[A\n",
            " 12% 12/100 [00:20<03:10,  2.17s/it]\u001b[A\n",
            " 13% 13/100 [00:22<03:03,  2.11s/it]\u001b[A\n",
            " 14% 14/100 [00:23<02:35,  1.81s/it]\u001b[A\n",
            " 15% 15/100 [00:24<02:15,  1.59s/it]\u001b[A\n",
            " 16% 16/100 [00:26<02:12,  1.58s/it]\u001b[A\n",
            " 17% 17/100 [00:27<02:10,  1.58s/it]\u001b[A\n",
            " 18% 18/100 [00:28<01:57,  1.43s/it]\u001b[A\n",
            " 19% 19/100 [00:30<02:05,  1.55s/it]\u001b[A\n",
            " 20% 20/100 [00:31<01:55,  1.45s/it]\u001b[A\n",
            " 21% 21/100 [00:32<01:35,  1.21s/it]\u001b[A\n",
            " 22% 22/100 [00:34<01:43,  1.33s/it]\u001b[A\n",
            " 23% 23/100 [00:40<03:28,  2.70s/it]\u001b[A\n",
            " 24% 24/100 [00:41<02:48,  2.22s/it]\u001b[A\n",
            " 25% 25/100 [00:42<02:25,  1.94s/it]\u001b[A\n",
            " 26% 26/100 [00:43<02:04,  1.68s/it]\u001b[A\n",
            " 27% 27/100 [00:45<02:02,  1.68s/it]\u001b[A\n",
            " 28% 28/100 [00:48<02:40,  2.22s/it]\u001b[A\n",
            " 29% 29/100 [00:49<02:08,  1.81s/it]\u001b[A\n",
            " 30% 30/100 [00:50<01:45,  1.50s/it]\u001b[A\n",
            " 31% 31/100 [00:51<01:32,  1.33s/it]\u001b[A\n",
            " 32% 32/100 [00:52<01:30,  1.33s/it]\u001b[A\n",
            " 33% 33/100 [00:58<03:02,  2.73s/it]\u001b[A\n",
            " 34% 34/100 [01:01<03:10,  2.88s/it]\u001b[A\n",
            " 35% 35/100 [01:07<04:06,  3.80s/it]\u001b[A\n",
            " 36% 36/100 [01:09<03:20,  3.14s/it]\u001b[A\n",
            " 37% 37/100 [01:10<02:33,  2.43s/it]\u001b[A\n",
            " 38% 38/100 [01:11<02:01,  1.97s/it]\u001b[A\n",
            " 39% 39/100 [01:12<01:57,  1.92s/it]\u001b[A\n",
            " 40% 40/100 [01:15<02:05,  2.10s/it]\u001b[A\n",
            " 41% 41/100 [01:17<02:11,  2.22s/it]\u001b[A\n",
            " 42% 42/100 [01:19<01:52,  1.93s/it]\u001b[A\n",
            " 43% 43/100 [01:23<02:31,  2.65s/it]\u001b[A\n",
            " 44% 44/100 [01:25<02:09,  2.31s/it]\u001b[A\n",
            " 45% 45/100 [01:27<02:02,  2.23s/it]\u001b[A\n",
            " 46% 46/100 [01:28<01:53,  2.10s/it]\u001b[A\n",
            " 47% 47/100 [01:30<01:36,  1.83s/it]\u001b[A\n",
            " 48% 48/100 [01:30<01:19,  1.53s/it]\u001b[A\n",
            " 49% 49/100 [01:32<01:11,  1.40s/it]\u001b[A\n",
            " 50% 50/100 [01:33<01:18,  1.57s/it]\u001b[A\n",
            " 51% 51/100 [01:34<01:04,  1.33s/it]\u001b[A\n",
            " 52% 52/100 [01:40<02:08,  2.67s/it]\u001b[A\n",
            " 53% 53/100 [01:41<01:46,  2.26s/it]\u001b[A\n",
            " 54% 54/100 [01:43<01:32,  2.01s/it]\u001b[A\n",
            " 55% 55/100 [01:44<01:20,  1.79s/it]\u001b[A\n",
            " 56% 56/100 [01:45<01:09,  1.59s/it]\u001b[A\n",
            " 57% 57/100 [01:46<01:02,  1.46s/it]\u001b[A\n",
            " 58% 58/100 [01:48<00:59,  1.41s/it]\u001b[A\n",
            " 59% 59/100 [01:53<01:52,  2.74s/it]\u001b[A\n",
            " 60% 60/100 [01:55<01:36,  2.42s/it]\u001b[A\n",
            " 61% 61/100 [01:56<01:18,  2.02s/it]\u001b[A\n",
            " 62% 62/100 [01:58<01:15,  1.99s/it]\u001b[A\n",
            " 63% 63/100 [02:00<01:09,  1.87s/it]\u001b[A\n",
            " 64% 64/100 [02:06<01:50,  3.08s/it]\u001b[A\n",
            " 65% 65/100 [02:07<01:28,  2.54s/it]\u001b[A\n",
            " 66% 66/100 [02:08<01:16,  2.24s/it]\u001b[A\n",
            " 67% 67/100 [02:10<01:07,  2.04s/it]\u001b[A\n",
            " 68% 68/100 [02:13<01:18,  2.45s/it]\u001b[A\n",
            " 69% 69/100 [02:16<01:13,  2.36s/it]\u001b[A\n",
            " 70% 70/100 [02:17<01:01,  2.04s/it]\u001b[A\n",
            " 71% 71/100 [02:18<00:54,  1.87s/it]\u001b[A\n",
            " 72% 72/100 [02:20<00:51,  1.85s/it]\u001b[A\n",
            " 73% 73/100 [02:26<01:25,  3.15s/it]\u001b[A\n",
            " 74% 74/100 [02:28<01:10,  2.72s/it]\u001b[A\n",
            " 75% 75/100 [02:34<01:31,  3.66s/it]\u001b[A\n",
            " 76% 76/100 [02:35<01:09,  2.88s/it]\u001b[A\n",
            " 77% 77/100 [02:36<00:55,  2.42s/it]\u001b[A\n",
            " 78% 78/100 [02:38<00:47,  2.14s/it]\u001b[A\n",
            " 79% 79/100 [02:44<01:09,  3.31s/it]\u001b[A\n",
            " 80% 80/100 [02:45<00:51,  2.58s/it]\u001b[A\n",
            " 81% 81/100 [02:51<01:07,  3.57s/it]\u001b[A\n",
            " 82% 82/100 [02:52<00:50,  2.79s/it]\u001b[A\n",
            " 83% 83/100 [02:54<00:44,  2.61s/it]\u001b[A\n",
            " 84% 84/100 [02:56<00:39,  2.47s/it]\u001b[A\n",
            " 85% 85/100 [02:58<00:34,  2.27s/it]\u001b[A\n",
            " 86% 86/100 [03:04<00:47,  3.39s/it]\u001b[A\n",
            " 87% 87/100 [03:05<00:35,  2.69s/it]\u001b[A\n",
            " 88% 88/100 [03:06<00:26,  2.24s/it]\u001b[A\n",
            " 89% 89/100 [03:07<00:22,  2.02s/it]\u001b[A\n",
            " 90% 90/100 [03:09<00:19,  1.95s/it]\u001b[A\n",
            " 91% 91/100 [03:10<00:15,  1.73s/it]\u001b[A\n",
            " 92% 92/100 [03:11<00:12,  1.52s/it]\u001b[A\n",
            " 93% 93/100 [03:14<00:12,  1.83s/it]\u001b[A\n",
            " 94% 94/100 [03:15<00:10,  1.69s/it]\u001b[A\n",
            " 95% 95/100 [03:17<00:07,  1.59s/it]\u001b[A\n",
            " 96% 96/100 [03:18<00:05,  1.49s/it]\u001b[A\n",
            " 97% 97/100 [03:19<00:04,  1.37s/it]\u001b[A\n",
            " 98% 98/100 [03:21<00:03,  1.53s/it]\u001b[A\n",
            " 99% 99/100 [03:22<00:01,  1.27s/it]\u001b[A\n",
            "                                      \n",
            "\u001b[A{'eval_loss': 0.7263896465301514, 'eval_rouge1': 81.7961, 'eval_rouge2': 74.6325, 'eval_rougeL': 80.8426, 'eval_rougeLsum': 80.9355, 'eval_bleu': 67.8671, 'eval_gen_len': 36.95, 'eval_runtime': 216.3768, 'eval_samples_per_second': 1.849, 'eval_steps_per_second': 0.462, 'epoch': 0.98}\n",
            " 20% 200/1015 [05:40<07:04,  1.92it/s]\n",
            "100% 100/100 [03:34<00:00,  1.88s/it]\u001b[A\n",
            "                                     \u001b[ASaving model checkpoint to pegasus_sent_model/checkpoint-200\n",
            "Configuration saved in pegasus_sent_model/checkpoint-200/config.json\n",
            "Configuration saved in pegasus_sent_model/checkpoint-200/generation_config.json\n",
            "Model weights saved in pegasus_sent_model/checkpoint-200/pytorch_model.bin\n",
            "tokenizer config file saved in pegasus_sent_model/checkpoint-200/tokenizer_config.json\n",
            "Special tokens file saved in pegasus_sent_model/checkpoint-200/special_tokens_map.json\n",
            "{'loss': 1.0958, 'learning_rate': 2.2610837438423645e-05, 'epoch': 1.23}\n",
            "{'loss': 0.9889, 'learning_rate': 2.1133004926108376e-05, 'epoch': 1.47}\n",
            " 30% 300/1015 [06:51<06:23,  1.87it/s]Saving model checkpoint to pegasus_sent_model/checkpoint-300\n",
            "Configuration saved in pegasus_sent_model/checkpoint-300/config.json\n",
            "Configuration saved in pegasus_sent_model/checkpoint-300/generation_config.json\n",
            "Model weights saved in pegasus_sent_model/checkpoint-300/pytorch_model.bin\n",
            "tokenizer config file saved in pegasus_sent_model/checkpoint-300/tokenizer_config.json\n",
            "Special tokens file saved in pegasus_sent_model/checkpoint-300/special_tokens_map.json\n",
            "{'loss': 0.9541, 'learning_rate': 1.9655172413793102e-05, 'epoch': 1.72}\n",
            "{'loss': 0.8277, 'learning_rate': 1.8177339901477833e-05, 'epoch': 1.97}\n",
            " 39% 400/1015 [08:01<05:31,  1.85it/s]***** Running Evaluation *****\n",
            "  Num examples = 400\n",
            "  Batch size = 4\n",
            "\n",
            "  0% 0/100 [00:00<?, ?it/s]\u001b[A\n",
            "  2% 2/100 [00:01<00:58,  1.66it/s]\u001b[A\n",
            "  3% 3/100 [00:02<01:22,  1.18it/s]\u001b[A\n",
            "  4% 4/100 [00:03<01:47,  1.12s/it]\u001b[A\n",
            "  5% 5/100 [00:04<01:38,  1.03s/it]\u001b[A\n",
            "  6% 6/100 [00:06<02:06,  1.35s/it]\u001b[A\n",
            "  7% 7/100 [00:08<02:07,  1.37s/it]\u001b[A\n",
            "  8% 8/100 [00:09<02:08,  1.40s/it]\u001b[A\n",
            "  9% 9/100 [00:15<04:14,  2.80s/it]\u001b[A\n",
            " 10% 10/100 [00:17<03:36,  2.41s/it]\u001b[A\n",
            " 11% 11/100 [00:18<03:00,  2.02s/it]\u001b[A\n",
            " 12% 12/100 [00:20<03:09,  2.16s/it]\u001b[A\n",
            " 13% 13/100 [00:22<03:05,  2.13s/it]\u001b[A\n",
            " 14% 14/100 [00:23<02:35,  1.80s/it]\u001b[A\n",
            " 15% 15/100 [00:24<02:13,  1.57s/it]\u001b[A\n",
            " 16% 16/100 [00:26<02:11,  1.57s/it]\u001b[A\n",
            " 17% 17/100 [00:28<02:10,  1.57s/it]\u001b[A\n",
            " 18% 18/100 [00:29<01:56,  1.42s/it]\u001b[A\n",
            " 19% 19/100 [00:30<02:03,  1.52s/it]\u001b[A\n",
            " 20% 20/100 [00:32<02:15,  1.70s/it]\u001b[A\n",
            " 21% 21/100 [00:33<01:49,  1.39s/it]\u001b[A\n",
            " 22% 22/100 [00:35<01:54,  1.47s/it]\u001b[A\n",
            " 23% 23/100 [00:37<02:09,  1.69s/it]\u001b[A\n",
            " 24% 24/100 [00:38<01:44,  1.38s/it]\u001b[A\n",
            " 25% 25/100 [00:39<01:35,  1.27s/it]\u001b[A\n",
            " 26% 26/100 [00:40<01:29,  1.21s/it]\u001b[A\n",
            " 27% 27/100 [00:41<01:38,  1.35s/it]\u001b[A\n",
            " 28% 28/100 [00:43<01:36,  1.34s/it]\u001b[A\n",
            " 29% 29/100 [00:44<01:24,  1.19s/it]\u001b[A\n",
            " 30% 30/100 [00:44<01:15,  1.08s/it]\u001b[A\n",
            " 31% 31/100 [00:45<01:11,  1.04s/it]\u001b[A\n",
            " 32% 32/100 [00:47<01:17,  1.15s/it]\u001b[A\n",
            " 33% 33/100 [00:53<02:50,  2.54s/it]\u001b[A\n",
            " 34% 34/100 [00:54<02:25,  2.21s/it]\u001b[A\n",
            " 35% 35/100 [00:56<02:17,  2.12s/it]\u001b[A\n",
            " 36% 36/100 [00:57<02:04,  1.94s/it]\u001b[A\n",
            " 37% 37/100 [00:58<01:42,  1.63s/it]\u001b[A\n",
            " 38% 38/100 [01:04<02:58,  2.88s/it]\u001b[A\n",
            " 39% 39/100 [01:06<02:37,  2.58s/it]\u001b[A\n",
            " 40% 40/100 [01:08<02:16,  2.28s/it]\u001b[A\n",
            " 41% 41/100 [01:09<01:58,  2.01s/it]\u001b[A\n",
            " 42% 42/100 [01:10<01:48,  1.87s/it]\u001b[A\n",
            " 43% 43/100 [01:15<02:27,  2.58s/it]\u001b[A\n",
            " 44% 44/100 [01:16<02:06,  2.26s/it]\u001b[A\n",
            " 45% 45/100 [01:18<02:01,  2.20s/it]\u001b[A\n",
            " 46% 46/100 [01:20<01:57,  2.18s/it]\u001b[A\n",
            " 47% 47/100 [01:26<02:55,  3.31s/it]\u001b[A\n",
            " 48% 48/100 [01:27<02:13,  2.57s/it]\u001b[A\n",
            " 49% 49/100 [01:28<01:48,  2.13s/it]\u001b[A\n",
            " 50% 50/100 [01:30<01:33,  1.87s/it]\u001b[A\n",
            " 51% 51/100 [01:30<01:15,  1.53s/it]\u001b[A\n",
            " 52% 52/100 [01:36<02:14,  2.81s/it]\u001b[A\n",
            " 53% 53/100 [01:37<01:51,  2.37s/it]\u001b[A\n",
            " 54% 54/100 [01:39<01:33,  2.03s/it]\u001b[A\n",
            " 55% 55/100 [01:41<01:29,  2.00s/it]\u001b[A\n",
            " 56% 56/100 [01:42<01:16,  1.74s/it]\u001b[A\n",
            " 57% 57/100 [01:43<01:06,  1.56s/it]\u001b[A\n",
            " 58% 58/100 [01:44<01:02,  1.48s/it]\u001b[A\n",
            " 59% 59/100 [01:50<01:54,  2.79s/it]\u001b[A\n",
            " 60% 60/100 [01:52<01:37,  2.45s/it]\u001b[A\n",
            " 61% 61/100 [01:57<02:14,  3.45s/it]\u001b[A\n",
            " 62% 62/100 [01:59<01:49,  2.88s/it]\u001b[A\n",
            " 63% 63/100 [02:01<01:31,  2.49s/it]\u001b[A\n",
            " 64% 64/100 [02:06<02:05,  3.49s/it]\u001b[A\n",
            " 65% 65/100 [02:08<01:38,  2.81s/it]\u001b[A\n",
            " 66% 66/100 [02:09<01:22,  2.43s/it]\u001b[A\n",
            " 67% 67/100 [02:11<01:11,  2.17s/it]\u001b[A\n",
            " 68% 68/100 [02:14<01:21,  2.54s/it]\u001b[A\n",
            " 69% 69/100 [02:16<01:14,  2.40s/it]\u001b[A\n",
            " 70% 70/100 [02:18<01:01,  2.06s/it]\u001b[A\n",
            " 71% 71/100 [02:19<00:53,  1.85s/it]\u001b[A\n",
            " 72% 72/100 [02:21<00:51,  1.82s/it]\u001b[A\n",
            " 73% 73/100 [02:22<00:45,  1.68s/it]\u001b[A\n",
            " 74% 74/100 [02:24<00:44,  1.71s/it]\u001b[A\n",
            " 75% 75/100 [02:25<00:40,  1.64s/it]\u001b[A\n",
            " 76% 76/100 [02:31<01:09,  2.88s/it]\u001b[A\n",
            " 77% 77/100 [02:32<00:56,  2.44s/it]\u001b[A\n",
            " 78% 78/100 [02:34<00:47,  2.15s/it]\u001b[A\n",
            " 79% 79/100 [02:36<00:42,  2.00s/it]\u001b[A\n",
            " 80% 80/100 [02:37<00:33,  1.69s/it]\u001b[A\n",
            " 81% 81/100 [02:42<00:55,  2.93s/it]\u001b[A\n",
            " 82% 82/100 [02:43<00:42,  2.34s/it]\u001b[A\n",
            " 83% 83/100 [02:45<00:38,  2.27s/it]\u001b[A\n",
            " 84% 84/100 [02:48<00:35,  2.22s/it]\u001b[A\n",
            " 85% 85/100 [02:48<00:27,  1.84s/it]\u001b[A\n",
            " 86% 86/100 [02:55<00:43,  3.12s/it]\u001b[A\n",
            " 87% 87/100 [02:55<00:31,  2.45s/it]\u001b[A\n",
            " 88% 88/100 [02:57<00:26,  2.22s/it]\u001b[A\n",
            " 89% 89/100 [02:58<00:20,  1.87s/it]\u001b[A\n",
            " 90% 90/100 [03:04<00:30,  3.02s/it]\u001b[A\n",
            " 91% 91/100 [03:05<00:22,  2.48s/it]\u001b[A\n",
            " 92% 92/100 [03:06<00:15,  1.99s/it]\u001b[A\n",
            " 93% 93/100 [03:07<00:12,  1.78s/it]\u001b[A\n",
            " 94% 94/100 [03:09<00:09,  1.65s/it]\u001b[A\n",
            " 95% 95/100 [03:10<00:07,  1.56s/it]\u001b[A\n",
            " 96% 96/100 [03:12<00:06,  1.61s/it]\u001b[A\n",
            " 97% 97/100 [03:14<00:05,  1.70s/it]\u001b[A\n",
            " 98% 98/100 [03:15<00:03,  1.76s/it]\u001b[A\n",
            " 99% 99/100 [03:17<00:01,  1.63s/it]\u001b[A\n",
            "                                      \n",
            "\u001b[A{'eval_loss': 0.5894030928611755, 'eval_rouge1': 87.5257, 'eval_rouge2': 82.8646, 'eval_rougeL': 87.1881, 'eval_rougeLsum': 87.2873, 'eval_bleu': 78.1797, 'eval_gen_len': 37.15, 'eval_runtime': 209.1922, 'eval_samples_per_second': 1.912, 'eval_steps_per_second': 0.478, 'epoch': 1.97}\n",
            " 39% 400/1015 [11:30<05:31,  1.85it/s]\n",
            "100% 100/100 [03:27<00:00,  1.43s/it]\u001b[A\n",
            "                                     \u001b[ASaving model checkpoint to pegasus_sent_model/checkpoint-400\n",
            "Configuration saved in pegasus_sent_model/checkpoint-400/config.json\n",
            "Configuration saved in pegasus_sent_model/checkpoint-400/generation_config.json\n",
            "Model weights saved in pegasus_sent_model/checkpoint-400/pytorch_model.bin\n",
            "tokenizer config file saved in pegasus_sent_model/checkpoint-400/tokenizer_config.json\n",
            "Special tokens file saved in pegasus_sent_model/checkpoint-400/special_tokens_map.json\n",
            "{'loss': 0.8522, 'learning_rate': 1.6699507389162563e-05, 'epoch': 2.21}\n",
            "{'loss': 0.8425, 'learning_rate': 1.5221674876847293e-05, 'epoch': 2.46}\n",
            " 49% 500/1015 [12:41<04:49,  1.78it/s]Saving model checkpoint to pegasus_sent_model/checkpoint-500\n",
            "Configuration saved in pegasus_sent_model/checkpoint-500/config.json\n",
            "Configuration saved in pegasus_sent_model/checkpoint-500/generation_config.json\n",
            "Model weights saved in pegasus_sent_model/checkpoint-500/pytorch_model.bin\n",
            "tokenizer config file saved in pegasus_sent_model/checkpoint-500/tokenizer_config.json\n",
            "Special tokens file saved in pegasus_sent_model/checkpoint-500/special_tokens_map.json\n",
            "{'loss': 0.8196, 'learning_rate': 1.374384236453202e-05, 'epoch': 2.7}\n",
            "{'loss': 0.7653, 'learning_rate': 1.2266009852216749e-05, 'epoch': 2.95}\n",
            " 59% 600/1015 [13:51<03:37,  1.90it/s]***** Running Evaluation *****\n",
            "  Num examples = 400\n",
            "  Batch size = 4\n",
            "\n",
            "  0% 0/100 [00:00<?, ?it/s]\u001b[A\n",
            "  2% 2/100 [00:01<00:59,  1.64it/s]\u001b[A\n",
            "  3% 3/100 [00:02<01:42,  1.06s/it]\u001b[A\n",
            "  4% 4/100 [00:04<01:59,  1.25s/it]\u001b[A\n",
            "  5% 5/100 [00:05<01:46,  1.12s/it]\u001b[A\n",
            "  6% 6/100 [00:07<02:10,  1.39s/it]\u001b[A\n",
            "  7% 7/100 [00:08<01:50,  1.19s/it]\u001b[A\n",
            "  8% 8/100 [00:09<01:57,  1.27s/it]\u001b[A\n",
            "  9% 9/100 [00:15<04:09,  2.74s/it]\u001b[A\n",
            " 10% 10/100 [00:16<03:31,  2.35s/it]\u001b[A\n",
            " 11% 11/100 [00:18<02:56,  1.98s/it]\u001b[A\n",
            " 12% 12/100 [00:20<03:06,  2.12s/it]\u001b[A\n",
            " 13% 13/100 [00:22<03:02,  2.10s/it]\u001b[A\n",
            " 14% 14/100 [00:23<02:33,  1.78s/it]\u001b[A\n",
            " 15% 15/100 [00:24<02:12,  1.56s/it]\u001b[A\n",
            " 16% 16/100 [00:26<02:11,  1.56s/it]\u001b[A\n",
            " 17% 17/100 [00:27<02:10,  1.57s/it]\u001b[A\n",
            " 18% 18/100 [00:28<01:57,  1.43s/it]\u001b[A\n",
            " 19% 19/100 [00:30<01:51,  1.38s/it]\u001b[A\n",
            " 20% 20/100 [00:32<02:08,  1.61s/it]\u001b[A\n",
            " 21% 21/100 [00:33<01:44,  1.33s/it]\u001b[A\n",
            " 22% 22/100 [00:34<01:51,  1.43s/it]\u001b[A\n",
            " 23% 23/100 [00:35<01:43,  1.35s/it]\u001b[A\n",
            " 24% 24/100 [00:36<01:25,  1.12s/it]\u001b[A\n",
            " 25% 25/100 [00:37<01:12,  1.03it/s]\u001b[A\n",
            " 26% 26/100 [00:38<01:13,  1.01it/s]\u001b[A\n",
            " 27% 27/100 [00:39<01:27,  1.19s/it]\u001b[A\n",
            " 28% 28/100 [00:41<01:28,  1.23s/it]\u001b[A\n",
            " 29% 29/100 [00:42<01:33,  1.31s/it]\u001b[A\n",
            " 30% 30/100 [00:43<01:29,  1.28s/it]\u001b[A\n",
            " 31% 31/100 [00:44<01:20,  1.17s/it]\u001b[A\n",
            " 32% 32/100 [00:46<01:24,  1.24s/it]\u001b[A\n",
            " 33% 33/100 [00:51<02:53,  2.59s/it]\u001b[A\n",
            " 34% 34/100 [00:52<02:20,  2.13s/it]\u001b[A\n",
            " 35% 35/100 [00:54<02:07,  1.97s/it]\u001b[A\n",
            " 36% 36/100 [00:56<01:57,  1.83s/it]\u001b[A\n",
            " 37% 37/100 [01:00<02:51,  2.72s/it]\u001b[A\n",
            " 38% 38/100 [01:01<02:19,  2.25s/it]\u001b[A\n",
            " 39% 39/100 [01:03<02:09,  2.13s/it]\u001b[A\n",
            " 40% 40/100 [01:05<01:57,  1.96s/it]\u001b[A\n",
            " 41% 41/100 [01:06<01:44,  1.78s/it]\u001b[A\n",
            " 42% 42/100 [01:12<02:53,  2.99s/it]\u001b[A\n",
            " 43% 43/100 [01:13<02:12,  2.33s/it]\u001b[A\n",
            " 44% 44/100 [01:14<01:56,  2.09s/it]\u001b[A\n",
            " 45% 45/100 [01:16<01:53,  2.07s/it]\u001b[A\n",
            " 46% 46/100 [01:18<01:51,  2.07s/it]\u001b[A\n",
            " 47% 47/100 [01:20<01:33,  1.77s/it]\u001b[A\n",
            " 48% 48/100 [01:20<01:17,  1.48s/it]\u001b[A\n",
            " 49% 49/100 [01:21<01:10,  1.38s/it]\u001b[A\n",
            " 50% 50/100 [01:23<01:04,  1.30s/it]\u001b[A\n",
            " 51% 51/100 [01:23<00:55,  1.14s/it]\u001b[A\n",
            " 52% 52/100 [01:29<02:01,  2.53s/it]\u001b[A\n",
            " 53% 53/100 [01:30<01:42,  2.17s/it]\u001b[A\n",
            " 54% 54/100 [01:32<01:26,  1.89s/it]\u001b[A\n",
            " 55% 55/100 [01:33<01:16,  1.70s/it]\u001b[A\n",
            " 56% 56/100 [01:34<01:07,  1.53s/it]\u001b[A\n",
            " 57% 57/100 [01:35<01:00,  1.41s/it]\u001b[A\n",
            " 58% 58/100 [01:37<00:58,  1.38s/it]\u001b[A\n",
            " 59% 59/100 [01:40<01:18,  1.90s/it]\u001b[A\n",
            " 60% 60/100 [01:41<01:13,  1.83s/it]\u001b[A\n",
            " 61% 61/100 [01:47<01:58,  3.03s/it]\u001b[A\n",
            " 62% 62/100 [01:49<01:38,  2.59s/it]\u001b[A\n",
            " 63% 63/100 [01:50<01:24,  2.29s/it]\u001b[A\n",
            " 64% 64/100 [01:56<02:00,  3.34s/it]\u001b[A\n",
            " 65% 65/100 [01:57<01:35,  2.74s/it]\u001b[A\n",
            " 66% 66/100 [01:59<01:20,  2.38s/it]\u001b[A\n",
            " 67% 67/100 [02:01<01:10,  2.14s/it]\u001b[A\n",
            " 68% 68/100 [02:05<01:25,  2.68s/it]\u001b[A\n",
            " 69% 69/100 [02:07<01:17,  2.52s/it]\u001b[A\n",
            " 70% 70/100 [02:12<01:45,  3.51s/it]\u001b[A\n",
            " 71% 71/100 [02:14<01:23,  2.87s/it]\u001b[A\n",
            " 72% 72/100 [02:16<01:10,  2.54s/it]\u001b[A\n",
            " 73% 73/100 [02:17<00:58,  2.17s/it]\u001b[A\n",
            " 74% 74/100 [02:19<00:52,  2.03s/it]\u001b[A\n",
            " 75% 75/100 [02:20<00:46,  1.85s/it]\u001b[A\n",
            " 76% 76/100 [02:26<01:12,  3.03s/it]\u001b[A\n",
            " 77% 77/100 [02:27<00:58,  2.55s/it]\u001b[A\n",
            " 78% 78/100 [02:29<00:50,  2.28s/it]\u001b[A\n",
            " 79% 79/100 [02:31<00:43,  2.09s/it]\u001b[A\n",
            " 80% 80/100 [02:32<00:35,  1.75s/it]\u001b[A\n",
            " 81% 81/100 [02:37<00:56,  2.97s/it]\u001b[A\n",
            " 82% 82/100 [02:38<00:42,  2.36s/it]\u001b[A\n",
            " 83% 83/100 [02:40<00:39,  2.30s/it]\u001b[A\n",
            " 84% 84/100 [02:43<00:35,  2.24s/it]\u001b[A\n",
            " 85% 85/100 [02:43<00:27,  1.85s/it]\u001b[A\n",
            " 86% 86/100 [02:50<00:44,  3.14s/it]\u001b[A\n",
            " 87% 87/100 [02:50<00:31,  2.46s/it]\u001b[A\n",
            " 88% 88/100 [02:51<00:24,  2.02s/it]\u001b[A\n",
            " 89% 89/100 [02:52<00:17,  1.62s/it]\u001b[A\n",
            " 90% 90/100 [02:58<00:28,  2.86s/it]\u001b[A\n",
            " 91% 91/100 [02:59<00:21,  2.37s/it]\u001b[A\n",
            " 92% 92/100 [03:00<00:15,  1.91s/it]\u001b[A\n",
            " 93% 93/100 [03:01<00:12,  1.72s/it]\u001b[A\n",
            " 94% 94/100 [03:03<00:09,  1.61s/it]\u001b[A\n",
            " 95% 95/100 [03:04<00:07,  1.53s/it]\u001b[A\n",
            " 96% 96/100 [03:06<00:06,  1.59s/it]\u001b[A\n",
            " 97% 97/100 [03:08<00:05,  1.68s/it]\u001b[A\n",
            " 98% 98/100 [03:09<00:03,  1.75s/it]\u001b[A\n",
            " 99% 99/100 [03:11<00:01,  1.53s/it]\u001b[A\n",
            "                                      \n",
            "\u001b[A{'eval_loss': 0.5617870092391968, 'eval_rouge1': 88.7428, 'eval_rouge2': 84.3368, 'eval_rougeL': 88.4838, 'eval_rougeLsum': 88.5602, 'eval_bleu': 82.4576, 'eval_gen_len': 39.6975, 'eval_runtime': 202.0302, 'eval_samples_per_second': 1.98, 'eval_steps_per_second': 0.495, 'epoch': 2.95}\n",
            " 59% 600/1015 [17:13<03:37,  1.90it/s]\n",
            "100% 100/100 [03:20<00:00,  1.26s/it]\u001b[A\n",
            "                                     \u001b[ASaving model checkpoint to pegasus_sent_model/checkpoint-600\n",
            "Configuration saved in pegasus_sent_model/checkpoint-600/config.json\n",
            "Configuration saved in pegasus_sent_model/checkpoint-600/generation_config.json\n",
            "Model weights saved in pegasus_sent_model/checkpoint-600/pytorch_model.bin\n",
            "tokenizer config file saved in pegasus_sent_model/checkpoint-600/tokenizer_config.json\n",
            "Special tokens file saved in pegasus_sent_model/checkpoint-600/special_tokens_map.json\n",
            "{'loss': 0.6985, 'learning_rate': 1.0788177339901479e-05, 'epoch': 3.19}\n",
            "{'loss': 0.776, 'learning_rate': 9.310344827586207e-06, 'epoch': 3.44}\n",
            " 69% 700/1015 [18:24<02:51,  1.84it/s]Saving model checkpoint to pegasus_sent_model/checkpoint-700\n",
            "Configuration saved in pegasus_sent_model/checkpoint-700/config.json\n",
            "Configuration saved in pegasus_sent_model/checkpoint-700/generation_config.json\n",
            "Model weights saved in pegasus_sent_model/checkpoint-700/pytorch_model.bin\n",
            "tokenizer config file saved in pegasus_sent_model/checkpoint-700/tokenizer_config.json\n",
            "Special tokens file saved in pegasus_sent_model/checkpoint-700/special_tokens_map.json\n",
            "{'loss': 0.8041, 'learning_rate': 7.832512315270936e-06, 'epoch': 3.69}\n",
            "{'loss': 0.7646, 'learning_rate': 6.354679802955665e-06, 'epoch': 3.93}\n",
            " 79% 800/1015 [19:34<01:56,  1.85it/s]***** Running Evaluation *****\n",
            "  Num examples = 400\n",
            "  Batch size = 4\n",
            "\n",
            "  0% 0/100 [00:00<?, ?it/s]\u001b[A\n",
            "  2% 2/100 [00:01<00:59,  1.66it/s]\u001b[A\n",
            "  3% 3/100 [00:02<01:22,  1.17it/s]\u001b[A\n",
            "  4% 4/100 [00:03<01:46,  1.11s/it]\u001b[A\n",
            "  5% 5/100 [00:04<01:37,  1.03s/it]\u001b[A\n",
            "  6% 6/100 [00:06<02:05,  1.33s/it]\u001b[A\n",
            "  7% 7/100 [00:07<01:47,  1.16s/it]\u001b[A\n",
            "  8% 8/100 [00:09<01:56,  1.26s/it]\u001b[A\n",
            "  9% 9/100 [00:15<04:10,  2.76s/it]\u001b[A\n",
            " 10% 10/100 [00:16<03:32,  2.37s/it]\u001b[A\n",
            " 11% 11/100 [00:17<02:56,  1.99s/it]\u001b[A\n",
            " 12% 12/100 [00:20<03:06,  2.12s/it]\u001b[A\n",
            " 13% 13/100 [00:22<03:01,  2.09s/it]\u001b[A\n",
            " 14% 14/100 [00:23<02:32,  1.78s/it]\u001b[A\n",
            " 15% 15/100 [00:24<02:12,  1.56s/it]\u001b[A\n",
            " 16% 16/100 [00:25<02:11,  1.56s/it]\u001b[A\n",
            " 17% 17/100 [00:27<02:11,  1.59s/it]\u001b[A\n",
            " 18% 18/100 [00:28<01:58,  1.44s/it]\u001b[A\n",
            " 19% 19/100 [00:29<01:51,  1.38s/it]\u001b[A\n",
            " 20% 20/100 [00:31<02:08,  1.60s/it]\u001b[A\n",
            " 21% 21/100 [00:32<01:44,  1.32s/it]\u001b[A\n",
            " 22% 22/100 [00:34<01:51,  1.43s/it]\u001b[A\n",
            " 23% 23/100 [00:35<01:43,  1.34s/it]\u001b[A\n",
            " 24% 24/100 [00:36<01:25,  1.12s/it]\u001b[A\n",
            " 25% 25/100 [00:36<01:13,  1.03it/s]\u001b[A\n",
            " 26% 26/100 [00:37<01:13,  1.00it/s]\u001b[A\n",
            " 27% 27/100 [00:39<01:27,  1.20s/it]\u001b[A\n",
            " 28% 28/100 [00:40<01:29,  1.24s/it]\u001b[A\n",
            " 29% 29/100 [00:42<01:34,  1.33s/it]\u001b[A\n",
            " 30% 30/100 [00:43<01:22,  1.18s/it]\u001b[A\n",
            " 31% 31/100 [00:44<01:16,  1.11s/it]\u001b[A\n",
            " 32% 32/100 [00:45<01:21,  1.20s/it]\u001b[A\n",
            " 33% 33/100 [00:47<01:34,  1.41s/it]\u001b[A\n",
            " 34% 34/100 [00:48<01:25,  1.30s/it]\u001b[A\n",
            " 35% 35/100 [00:50<01:31,  1.40s/it]\u001b[A\n",
            " 36% 36/100 [00:51<01:32,  1.45s/it]\u001b[A\n",
            " 37% 37/100 [00:52<01:20,  1.28s/it]\u001b[A\n",
            " 38% 38/100 [00:58<02:43,  2.64s/it]\u001b[A\n",
            " 39% 39/100 [01:00<02:26,  2.40s/it]\u001b[A\n",
            " 40% 40/100 [01:01<02:09,  2.16s/it]\u001b[A\n",
            " 41% 41/100 [01:03<01:53,  1.92s/it]\u001b[A\n",
            " 42% 42/100 [01:08<02:58,  3.08s/it]\u001b[A\n",
            " 43% 43/100 [01:09<02:16,  2.39s/it]\u001b[A\n",
            " 44% 44/100 [01:11<01:58,  2.12s/it]\u001b[A\n",
            " 45% 45/100 [01:13<01:55,  2.10s/it]\u001b[A\n",
            " 46% 46/100 [01:15<01:54,  2.12s/it]\u001b[A\n",
            " 47% 47/100 [01:16<01:37,  1.84s/it]\u001b[A\n",
            " 48% 48/100 [01:17<01:19,  1.53s/it]\u001b[A\n",
            " 49% 49/100 [01:18<01:11,  1.40s/it]\u001b[A\n",
            " 50% 50/100 [01:19<01:05,  1.31s/it]\u001b[A\n",
            " 51% 51/100 [01:20<00:56,  1.15s/it]\u001b[A\n",
            " 52% 52/100 [01:23<01:18,  1.63s/it]\u001b[A\n",
            " 53% 53/100 [01:24<01:12,  1.54s/it]\u001b[A\n",
            " 54% 54/100 [01:25<01:06,  1.45s/it]\u001b[A\n",
            " 55% 55/100 [01:26<01:02,  1.39s/it]\u001b[A\n",
            " 56% 56/100 [01:28<00:57,  1.32s/it]\u001b[A\n",
            " 57% 57/100 [01:29<00:54,  1.27s/it]\u001b[A\n",
            " 58% 58/100 [01:30<00:54,  1.30s/it]\u001b[A\n",
            " 59% 59/100 [01:33<01:16,  1.85s/it]\u001b[A\n",
            " 60% 60/100 [01:35<01:11,  1.79s/it]\u001b[A\n",
            " 61% 61/100 [01:41<01:56,  3.00s/it]\u001b[A\n",
            " 62% 62/100 [01:42<01:38,  2.59s/it]\u001b[A\n",
            " 63% 63/100 [01:44<01:24,  2.29s/it]\u001b[A\n",
            " 64% 64/100 [01:50<02:01,  3.37s/it]\u001b[A\n",
            " 65% 65/100 [01:56<02:23,  4.11s/it]\u001b[A\n",
            " 66% 66/100 [01:57<01:53,  3.34s/it]\u001b[A\n",
            " 67% 67/100 [01:59<01:33,  2.83s/it]\u001b[A\n",
            " 68% 68/100 [02:03<01:41,  3.16s/it]\u001b[A\n",
            " 69% 69/100 [02:05<01:28,  2.86s/it]\u001b[A\n",
            " 70% 70/100 [02:06<01:10,  2.34s/it]\u001b[A\n",
            " 71% 71/100 [02:07<00:59,  2.04s/it]\u001b[A\n",
            " 72% 72/100 [02:13<01:29,  3.18s/it]\u001b[A\n",
            " 73% 73/100 [02:15<01:11,  2.66s/it]\u001b[A\n",
            " 74% 74/100 [02:16<01:01,  2.38s/it]\u001b[A\n",
            " 75% 75/100 [02:18<00:50,  2.02s/it]\u001b[A\n",
            " 76% 76/100 [02:23<01:15,  3.14s/it]\u001b[A\n",
            " 77% 77/100 [02:25<01:00,  2.63s/it]\u001b[A\n",
            " 78% 78/100 [02:26<00:51,  2.35s/it]\u001b[A\n",
            " 79% 79/100 [02:28<00:45,  2.15s/it]\u001b[A\n",
            " 80% 80/100 [02:29<00:35,  1.80s/it]\u001b[A\n",
            " 81% 81/100 [02:35<00:57,  3.03s/it]\u001b[A\n",
            " 82% 82/100 [02:36<00:43,  2.40s/it]\u001b[A\n",
            " 83% 83/100 [02:38<00:39,  2.32s/it]\u001b[A\n",
            " 84% 84/100 [02:40<00:36,  2.26s/it]\u001b[A\n",
            " 85% 85/100 [02:41<00:28,  1.87s/it]\u001b[A\n",
            " 86% 86/100 [02:47<00:43,  3.10s/it]\u001b[A\n",
            " 87% 87/100 [02:48<00:31,  2.43s/it]\u001b[A\n",
            " 88% 88/100 [02:49<00:23,  1.99s/it]\u001b[A\n",
            " 89% 89/100 [02:50<00:17,  1.61s/it]\u001b[A\n",
            " 90% 90/100 [02:56<00:28,  2.87s/it]\u001b[A\n",
            " 91% 91/100 [02:57<00:21,  2.37s/it]\u001b[A\n",
            " 92% 92/100 [02:58<00:15,  1.92s/it]\u001b[A\n",
            " 93% 93/100 [02:59<00:12,  1.72s/it]\u001b[A\n",
            " 94% 94/100 [03:00<00:09,  1.61s/it]\u001b[A\n",
            " 95% 95/100 [03:02<00:07,  1.53s/it]\u001b[A\n",
            " 96% 96/100 [03:03<00:06,  1.59s/it]\u001b[A\n",
            " 97% 97/100 [03:05<00:05,  1.67s/it]\u001b[A\n",
            " 98% 98/100 [03:07<00:03,  1.75s/it]\u001b[A\n",
            " 99% 99/100 [03:13<00:02,  2.94s/it]\u001b[A\n",
            "                                      \n",
            "\u001b[A{'eval_loss': 0.554432213306427, 'eval_rouge1': 89.6265, 'eval_rouge2': 85.2341, 'eval_rougeL': 89.3931, 'eval_rougeLsum': 89.4568, 'eval_bleu': 83.9462, 'eval_gen_len': 39.675, 'eval_runtime': 204.3195, 'eval_samples_per_second': 1.958, 'eval_steps_per_second': 0.489, 'epoch': 3.93}\n",
            " 79% 800/1015 [22:58<01:56,  1.85it/s]\n",
            "100% 100/100 [03:23<00:00,  2.24s/it]\u001b[A\n",
            "                                     \u001b[ASaving model checkpoint to pegasus_sent_model/checkpoint-800\n",
            "Configuration saved in pegasus_sent_model/checkpoint-800/config.json\n",
            "Configuration saved in pegasus_sent_model/checkpoint-800/generation_config.json\n",
            "Model weights saved in pegasus_sent_model/checkpoint-800/pytorch_model.bin\n",
            "tokenizer config file saved in pegasus_sent_model/checkpoint-800/tokenizer_config.json\n",
            "Special tokens file saved in pegasus_sent_model/checkpoint-800/special_tokens_map.json\n",
            "{'loss': 0.7844, 'learning_rate': 4.876847290640394e-06, 'epoch': 4.18}\n",
            "{'loss': 0.7914, 'learning_rate': 3.3990147783251234e-06, 'epoch': 4.42}\n",
            " 89% 900/1015 [24:09<00:59,  1.93it/s]Saving model checkpoint to pegasus_sent_model/checkpoint-900\n",
            "Configuration saved in pegasus_sent_model/checkpoint-900/config.json\n",
            "Configuration saved in pegasus_sent_model/checkpoint-900/generation_config.json\n",
            "Model weights saved in pegasus_sent_model/checkpoint-900/pytorch_model.bin\n",
            "tokenizer config file saved in pegasus_sent_model/checkpoint-900/tokenizer_config.json\n",
            "Special tokens file saved in pegasus_sent_model/checkpoint-900/special_tokens_map.json\n",
            "{'loss': 0.6936, 'learning_rate': 1.9211822660098524e-06, 'epoch': 4.67}\n",
            "{'loss': 0.7839, 'learning_rate': 4.4334975369458127e-07, 'epoch': 4.91}\n",
            " 99% 1000/1015 [25:20<00:08,  1.87it/s]***** Running Evaluation *****\n",
            "  Num examples = 400\n",
            "  Batch size = 4\n",
            "\n",
            "  0% 0/100 [00:00<?, ?it/s]\u001b[A\n",
            "  2% 2/100 [00:01<00:59,  1.66it/s]\u001b[A\n",
            "  3% 3/100 [00:02<01:21,  1.19it/s]\u001b[A\n",
            "  4% 4/100 [00:03<01:46,  1.11s/it]\u001b[A\n",
            "  5% 5/100 [00:04<01:37,  1.02s/it]\u001b[A\n",
            "  6% 6/100 [00:06<02:05,  1.34s/it]\u001b[A\n",
            "  7% 7/100 [00:07<01:47,  1.16s/it]\u001b[A\n",
            "  8% 8/100 [00:09<01:56,  1.26s/it]\u001b[A\n",
            "  9% 9/100 [00:14<04:06,  2.71s/it]\u001b[A\n",
            " 10% 10/100 [00:16<03:29,  2.33s/it]\u001b[A\n",
            " 11% 11/100 [00:17<02:54,  1.96s/it]\u001b[A\n",
            " 12% 12/100 [00:20<03:05,  2.11s/it]\u001b[A\n",
            " 13% 13/100 [00:22<03:02,  2.10s/it]\u001b[A\n",
            " 14% 14/100 [00:23<02:34,  1.79s/it]\u001b[A\n",
            " 15% 15/100 [00:24<02:13,  1.57s/it]\u001b[A\n",
            " 16% 16/100 [00:25<02:12,  1.58s/it]\u001b[A\n",
            " 17% 17/100 [00:27<02:12,  1.59s/it]\u001b[A\n",
            " 18% 18/100 [00:28<01:58,  1.44s/it]\u001b[A\n",
            " 19% 19/100 [00:29<01:51,  1.38s/it]\u001b[A\n",
            " 20% 20/100 [00:31<02:08,  1.61s/it]\u001b[A\n",
            " 21% 21/100 [00:32<01:44,  1.32s/it]\u001b[A\n",
            " 22% 22/100 [00:34<01:51,  1.43s/it]\u001b[A\n",
            " 23% 23/100 [00:35<01:43,  1.34s/it]\u001b[A\n",
            " 24% 24/100 [00:36<01:26,  1.14s/it]\u001b[A\n",
            " 25% 25/100 [00:36<01:14,  1.01it/s]\u001b[A\n",
            " 26% 26/100 [00:37<01:14,  1.01s/it]\u001b[A\n",
            " 27% 27/100 [00:39<01:28,  1.21s/it]\u001b[A\n",
            " 28% 28/100 [00:40<01:29,  1.24s/it]\u001b[A\n",
            " 29% 29/100 [00:42<01:33,  1.32s/it]\u001b[A\n",
            " 30% 30/100 [00:43<01:21,  1.17s/it]\u001b[A\n",
            " 31% 31/100 [00:43<01:15,  1.09s/it]\u001b[A\n",
            " 32% 32/100 [00:45<01:19,  1.17s/it]\u001b[A\n",
            " 33% 33/100 [00:46<01:16,  1.15s/it]\u001b[A\n",
            " 34% 34/100 [00:47<01:12,  1.10s/it]\u001b[A\n",
            " 35% 35/100 [00:49<01:21,  1.25s/it]\u001b[A\n",
            " 36% 36/100 [00:50<01:25,  1.34s/it]\u001b[A\n",
            " 37% 37/100 [00:51<01:14,  1.18s/it]\u001b[A\n",
            " 38% 38/100 [00:52<01:21,  1.32s/it]\u001b[A\n",
            " 39% 39/100 [00:54<01:29,  1.47s/it]\u001b[A\n",
            " 40% 40/100 [00:56<01:30,  1.50s/it]\u001b[A\n",
            " 41% 41/100 [00:57<01:26,  1.47s/it]\u001b[A\n",
            " 42% 42/100 [01:03<02:40,  2.76s/it]\u001b[A\n",
            " 43% 43/100 [01:04<02:03,  2.17s/it]\u001b[A\n",
            " 44% 44/100 [01:05<01:50,  1.97s/it]\u001b[A\n",
            " 45% 45/100 [01:07<01:49,  2.00s/it]\u001b[A\n",
            " 46% 46/100 [01:09<01:48,  2.02s/it]\u001b[A\n",
            " 47% 47/100 [01:11<01:32,  1.74s/it]\u001b[A\n",
            " 48% 48/100 [01:11<01:16,  1.46s/it]\u001b[A\n",
            " 49% 49/100 [01:13<01:09,  1.36s/it]\u001b[A\n",
            " 50% 50/100 [01:14<01:04,  1.28s/it]\u001b[A\n",
            " 51% 51/100 [01:14<00:55,  1.12s/it]\u001b[A\n",
            " 52% 52/100 [01:16<00:58,  1.22s/it]\u001b[A\n",
            " 53% 53/100 [01:17<00:59,  1.26s/it]\u001b[A\n",
            " 54% 54/100 [01:18<00:57,  1.24s/it]\u001b[A\n",
            " 55% 55/100 [01:20<00:55,  1.24s/it]\u001b[A\n",
            " 56% 56/100 [01:21<00:53,  1.21s/it]\u001b[A\n",
            " 57% 57/100 [01:22<00:51,  1.19s/it]\u001b[A\n",
            " 58% 58/100 [01:23<00:51,  1.23s/it]\u001b[A\n",
            " 59% 59/100 [01:26<01:14,  1.81s/it]\u001b[A\n",
            " 60% 60/100 [01:28<01:10,  1.76s/it]\u001b[A\n",
            " 61% 61/100 [01:34<01:55,  2.97s/it]\u001b[A\n",
            " 62% 62/100 [01:35<01:36,  2.54s/it]\u001b[A\n",
            " 63% 63/100 [01:37<01:23,  2.25s/it]\u001b[A\n",
            " 64% 64/100 [01:43<02:00,  3.36s/it]\u001b[A\n",
            " 65% 65/100 [01:49<02:23,  4.09s/it]\u001b[A\n",
            " 66% 66/100 [01:50<01:53,  3.32s/it]\u001b[A\n",
            " 67% 67/100 [01:52<01:32,  2.80s/it]\u001b[A\n",
            " 68% 68/100 [01:56<01:41,  3.16s/it]\u001b[A\n",
            " 69% 69/100 [01:58<01:28,  2.85s/it]\u001b[A\n",
            " 70% 70/100 [01:59<01:10,  2.34s/it]\u001b[A\n",
            " 71% 71/100 [02:00<00:59,  2.05s/it]\u001b[A\n",
            " 72% 72/100 [02:02<00:54,  1.96s/it]\u001b[A\n",
            " 73% 73/100 [02:04<00:48,  1.81s/it]\u001b[A\n",
            " 74% 74/100 [02:05<00:46,  1.77s/it]\u001b[A\n",
            " 75% 75/100 [02:06<00:39,  1.59s/it]\u001b[A\n",
            " 76% 76/100 [02:08<00:34,  1.43s/it]\u001b[A\n",
            " 77% 77/100 [02:09<00:33,  1.44s/it]\u001b[A\n",
            " 78% 78/100 [02:11<00:33,  1.52s/it]\u001b[A\n",
            " 79% 79/100 [02:12<00:32,  1.57s/it]\u001b[A\n",
            " 80% 80/100 [02:13<00:27,  1.38s/it]\u001b[A\n",
            " 81% 81/100 [02:19<00:51,  2.71s/it]\u001b[A\n",
            " 82% 82/100 [02:20<00:39,  2.18s/it]\u001b[A\n",
            " 83% 83/100 [02:22<00:36,  2.17s/it]\u001b[A\n",
            " 84% 84/100 [02:24<00:34,  2.15s/it]\u001b[A\n",
            " 85% 85/100 [02:25<00:26,  1.79s/it]\u001b[A\n",
            " 86% 86/100 [02:27<00:24,  1.77s/it]\u001b[A\n",
            " 87% 87/100 [02:28<00:19,  1.50s/it]\u001b[A\n",
            " 88% 88/100 [02:29<00:16,  1.35s/it]\u001b[A\n",
            " 89% 89/100 [02:30<00:12,  1.16s/it]\u001b[A\n",
            " 90% 90/100 [02:35<00:25,  2.54s/it]\u001b[A\n",
            " 91% 91/100 [02:37<00:19,  2.15s/it]\u001b[A\n",
            " 92% 92/100 [02:37<00:14,  1.76s/it]\u001b[A\n",
            " 93% 93/100 [02:39<00:11,  1.62s/it]\u001b[A\n",
            " 94% 94/100 [02:40<00:09,  1.54s/it]\u001b[A\n",
            " 95% 95/100 [02:41<00:07,  1.48s/it]\u001b[A\n",
            " 96% 96/100 [02:43<00:06,  1.55s/it]\u001b[A\n",
            " 97% 97/100 [02:45<00:04,  1.66s/it]\u001b[A\n",
            " 98% 98/100 [02:47<00:03,  1.74s/it]\u001b[A\n",
            " 99% 99/100 [02:48<00:01,  1.41s/it]\u001b[A\n",
            "                                       \n",
            "\u001b[A{'eval_loss': 0.5523967742919922, 'eval_rouge1': 89.6162, 'eval_rouge2': 85.1935, 'eval_rougeL': 89.3909, 'eval_rougeLsum': 89.4175, 'eval_bleu': 83.7635, 'eval_gen_len': 38.9, 'eval_runtime': 179.035, 'eval_samples_per_second': 2.234, 'eval_steps_per_second': 0.559, 'epoch': 4.91}\n",
            " 99% 1000/1015 [28:19<00:08,  1.87it/s]\n",
            "100% 100/100 [02:57<00:00,  1.16s/it]\u001b[A\n",
            "                                     \u001b[ASaving model checkpoint to pegasus_sent_model/checkpoint-1000\n",
            "Configuration saved in pegasus_sent_model/checkpoint-1000/config.json\n",
            "Configuration saved in pegasus_sent_model/checkpoint-1000/generation_config.json\n",
            "Model weights saved in pegasus_sent_model/checkpoint-1000/pytorch_model.bin\n",
            "tokenizer config file saved in pegasus_sent_model/checkpoint-1000/tokenizer_config.json\n",
            "Special tokens file saved in pegasus_sent_model/checkpoint-1000/special_tokens_map.json\n",
            "100% 1015/1015 [28:44<00:00,  1.07it/s]\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "{'train_runtime': 1731.1287, 'train_samples_per_second': 9.398, 'train_steps_per_second': 0.586, 'train_loss': 1.0080088638906997, 'epoch': 4.99}\n",
            "100% 1015/1015 [28:44<00:00,  1.70s/it]\n",
            "Saving model checkpoint to pegasus_sent_model/\n",
            "Configuration saved in pegasus_sent_model/config.json\n",
            "Configuration saved in pegasus_sent_model/generation_config.json\n",
            "Model weights saved in pegasus_sent_model/pytorch_model.bin\n",
            "tokenizer config file saved in pegasus_sent_model/tokenizer_config.json\n",
            "Special tokens file saved in pegasus_sent_model/special_tokens_map.json\n",
            "***** train metrics *****\n",
            "  epoch                    =       4.99\n",
            "  train_loss               =      1.008\n",
            "  train_runtime            = 0:28:51.12\n",
            "  train_samples            =       3254\n",
            "  train_samples_per_second =      9.398\n",
            "  train_steps_per_second   =      0.586\n",
            "05/08/2023 19:40:37 - INFO - __main__ -   *** Evaluate ***\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 400\n",
            "  Batch size = 4\n",
            "100% 100/100 [02:36<00:00,  1.57s/it]\n",
            "***** eval metrics *****\n",
            "  epoch                   =       4.99\n",
            "  eval_bleu               =    83.9398\n",
            "  eval_gen_len            =    39.0525\n",
            "  eval_loss               =     0.5524\n",
            "  eval_rouge1             =    89.6452\n",
            "  eval_rouge2             =    85.2326\n",
            "  eval_rougeL             =    89.3992\n",
            "  eval_rougeLsum          =    89.4568\n",
            "  eval_runtime            = 0:02:38.23\n",
            "  eval_samples            =        400\n",
            "  eval_samples_per_second =      2.528\n",
            "  eval_steps_per_second   =      0.632\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                      eval/bleu ▁▅▇███\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                   eval/gen_len ▁▂██▆▆\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                      eval/loss █▂▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                    eval/rouge1 ▁▆▇███\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                    eval/rouge2 ▁▆▇███\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                    eval/rougeL ▁▆▇███\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                 eval/rougeLsum ▁▆▇███\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                   eval/runtime █▇▆▇▄▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        eval/samples_per_second ▁▂▂▂▅█\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/steps_per_second ▁▂▂▂▅█\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                    train/epoch ▁▁▂▂▂▂▃▃▄▄▄▄▅▅▅▅▆▆▆▆▇▇█████\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:              train/global_step ▁▁▂▂▂▂▃▃▄▄▄▄▅▅▅▅▆▆▆▆▇▇█████\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            train/learning_rate ██▇▇▇▆▆▅▅▅▄▄▄▃▃▂▂▂▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                     train/loss █▅▄▃▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               train/total_flos ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               train/train_loss ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            train/train_runtime ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: train/train_samples_per_second ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   train/train_steps_per_second ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                      eval/bleu 83.9398\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                   eval/gen_len 39.0525\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                      eval/loss 0.55239\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                    eval/rouge1 89.6452\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                    eval/rouge2 85.2326\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                    eval/rougeL 89.3992\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                 eval/rougeLsum 89.4568\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                   eval/runtime 158.2355\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        eval/samples_per_second 2.528\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/steps_per_second 0.632\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                    train/epoch 4.99\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:              train/global_step 1015\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            train/learning_rate 0.0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                     train/loss 0.7839\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               train/total_flos 3006245053120512.0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               train/train_loss 1.00801\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            train/train_runtime 1731.1287\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: train/train_samples_per_second 9.398\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   train/train_steps_per_second 0.586\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /content/iterater/code/IteraTeR_ACL2022/model/generation/wandb/offline-run-20230508_191149-3h5g23be\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20230508_191149-3h5g23be/logs\u001b[0m\n",
            "CPU times: user 12.3 s, sys: 2.39 s, total: 14.7 s\n",
            "Wall time: 33min 1s\n"
          ]
        }
      ],
      "source": [
        "#training model\n",
        "%%time\n",
        "!mv /content/cs678-cp1-cp2/cp1files/train_sent_pegasus.sh /content/iterater/code/IteraTeR_ACL2022/model/generation\n",
        "%cd /content/iterater/code/IteraTeR_ACL2022/model/generation\n",
        "\n",
        "!sh train_sent_pegasus.sh"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b8d2196-8efa-4d5c-955d-953983722a64",
        "id": "yw_h142uC8LR"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/iterater/code/IteraTeR_ACL2022/model/generation\n",
            "2023-05-08 19:58:09.978012: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "  0% 0/75 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1313: UserWarning: Using `max_length`'s default (256) to control the generation length. This behaviour is deprecated and will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "100% 75/75 [02:19<00:00,  1.86s/it]\n",
            "100% 75/75 [00:00<00:00, 111.90it/s]\n",
            "100% 75/75 [00:00<00:00, 137.06it/s]\n",
            "BLEU     : 0.4750746495792065\n",
            "ROUGE     : {'rouge1': 85.45857360685321, 'rouge2': 81.92106112253073, 'rougeL': 85.53522946206498, 'rougeLsum': 85.53945484980423}\n",
            "SARI: 30.985572971521584, KEEP: 0.9295671891456474, ADD: 0.0, DELETE: 0.0\n",
            "CPU times: user 868 ms, sys: 176 ms, total: 1.04 s\n",
            "Wall time: 2min 44s\n"
          ]
        }
      ],
      "source": [
        "#printing metrics\n",
        "%%time\n",
        "%cd /content/iterater/code/IteraTeR_ACL2022/model/generation\n",
        "!python3 pegasus_inference_and_metrics.py --checkpoint pegasus_sent_model --reference /content/cs678-cp1-cp2/robust_data/test.json --output pegasus_robust_sent_output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LnDSvfBGd15Z"
      },
      "source": [
        "## Part 2: Multilinguality Test\n",
        "\n",
        "We translate the data and creat new train, test and dev files. We use 5 languages-\n",
        "\n",
        "\n",
        "1. **English** (Germanic branch of the Indo European language family)\n",
        "2. **French** (Romance branch of the Indo European language family)\n",
        "3. **Mandarin** (Sinitic branch of the Sino-Tibetan language family)\n",
        "4. **Hindi** (Indo-Aryan branch of the Indo-European language family)\n",
        "5. **Tamil** (Dravidian language family)\n",
        "\n",
        "We compare and contrast new models apart from Wanyu D et el. for both the tasks. For\n",
        "1. Intent Classifcation, we use:\n",
        "  1.  **RoBERTa** (Robustly Optimized BERT Approach)\n",
        "  2. **XLMRoBERTa** (Cross-lingual Language Model)\n",
        "2. Iterative Edit Generation, we use:\n",
        "  1.  **PEGASUS** (Pre-training with Extracted Gap-sentences for Abstractive Summarization)\n",
        "  2. **UNICORN** (UNIfied Crosslingual RepresentatiON)\n",
        "\n",
        "For both the tasks, namely Intent Classifcation and Iterative Edit Generation, we try\n",
        "1. **Zero Shot** (by training on baseline English models of Wanyu D et el) and\n",
        "2. **Fully Supervised Training**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k4PBJrvcleVA"
      },
      "source": [
        "### Translating into English, French, Mandarin, Hindi and Tamil"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HINQ7PTJlxMI"
      },
      "source": [
        "Install Google Translate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mIXWAdw1ls7K",
        "outputId": "186c4e08-4cba-435b-af28-404b3ce87f8e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting translate\n",
            "  Downloading translate-3.6.1-py2.py3-none-any.whl (12 kB)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from translate) (8.1.3)\n",
            "Collecting libretranslatepy==2.1.1\n",
            "  Downloading libretranslatepy-2.1.1-py3-none-any.whl (3.2 kB)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from translate) (4.9.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from translate) (2.27.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->translate) (3.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->translate) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->translate) (1.26.15)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->translate) (2.0.12)\n",
            "Installing collected packages: libretranslatepy, translate\n",
            "Successfully installed libretranslatepy-2.1.1 translate-3.6.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting googletrans==4.0.0-rc1\n",
            "  Downloading googletrans-4.0.0rc1.tar.gz (20 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting httpx==0.13.3\n",
            "  Downloading httpx-0.13.3-py3-none-any.whl (55 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.1/55.1 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting chardet==3.*\n",
            "  Downloading chardet-3.0.4-py2.py3-none-any.whl (133 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.4/133.4 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting rfc3986<2,>=1.3\n",
            "  Downloading rfc3986-1.5.0-py2.py3-none-any.whl (31 kB)\n",
            "Collecting hstspreload\n",
            "  Downloading hstspreload-2023.1.1-py3-none-any.whl (1.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m36.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (1.3.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (2022.12.7)\n",
            "Collecting idna==2.*\n",
            "  Downloading idna-2.10-py2.py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.8/58.8 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting httpcore==0.9.*\n",
            "  Downloading httpcore-0.9.1-py3-none-any.whl (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.6/42.6 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h2==3.*\n",
            "  Downloading h2-3.2.0-py2.py3-none-any.whl (65 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.0/65.0 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.10,>=0.8\n",
            "  Downloading h11-0.9.0-py2.py3-none-any.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.6/53.6 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting hyperframe<6,>=5.2.0\n",
            "  Downloading hyperframe-5.2.0-py2.py3-none-any.whl (12 kB)\n",
            "Collecting hpack<4,>=3.0\n",
            "  Downloading hpack-3.0.0-py2.py3-none-any.whl (38 kB)\n",
            "Building wheels for collected packages: googletrans\n",
            "  Building wheel for googletrans (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for googletrans: filename=googletrans-4.0.0rc1-py3-none-any.whl size=17413 sha256=320caf64641f7dd19dc9ecaf35a0a1217333d003cab0a625cb6b897c5ce0763e\n",
            "  Stored in directory: /root/.cache/pip/wheels/c0/59/9f/7372f0cf70160fe61b528532e1a7c8498c4becd6bcffb022de\n",
            "Successfully built googletrans\n",
            "Installing collected packages: rfc3986, hyperframe, hpack, h11, chardet, idna, hstspreload, h2, httpcore, httpx, googletrans\n",
            "  Attempting uninstall: chardet\n",
            "    Found existing installation: chardet 4.0.0\n",
            "    Uninstalling chardet-4.0.0:\n",
            "      Successfully uninstalled chardet-4.0.0\n",
            "  Attempting uninstall: idna\n",
            "    Found existing installation: idna 3.4\n",
            "    Uninstalling idna-3.4:\n",
            "      Successfully uninstalled idna-3.4\n",
            "Successfully installed chardet-3.0.4 googletrans-4.0.0rc1 h11-0.9.0 h2-3.2.0 hpack-3.0.0 hstspreload-2023.1.1 httpcore-0.9.1 httpx-0.13.3 hyperframe-5.2.0 idna-2.10 rfc3986-1.5.0\n"
          ]
        }
      ],
      "source": [
        "# Install the translate library\n",
        "!pip install translate\n",
        "!pip install googletrans==4.0.0-rc1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WVElUrBumHAK"
      },
      "source": [
        "Define Translate Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nc2EpAIsmJsw",
        "outputId": "4fcc860d-ae2a-41d4-d159-4c809e4c39d7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPU times: user 104 ms, sys: 12.3 ms, total: 116 ms\n",
            "Wall time: 309 ms\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "\n",
        "import requests\n",
        "import json\n",
        "import re\n",
        "\n",
        "class Translator:\n",
        "    def __init__(self):\n",
        "        self.endpoint = \"https://translate.googleapis.com/translate_a/single\"\n",
        "\n",
        "    def translate(self, text, dest=\"en\"):\n",
        "        params = {\n",
        "            \"client\": \"gtx\",\n",
        "            \"sl\": \"auto\",\n",
        "            \"tl\": dest,\n",
        "            \"dt\": \"t\",\n",
        "            \"q\": text,\n",
        "        }\n",
        "        response = requests.get(self.endpoint, params=params)\n",
        "        try:\n",
        "            result = json.loads(response.content.decode(\"utf-8\"))\n",
        "            if result and result[0] and result[0][0]:\n",
        "                return result[0][0][0]\n",
        "            else:\n",
        "                print(f\"Translation failed for the record due to empty text: {text}\")\n",
        "                return text\n",
        "        except (json.JSONDecodeError, IndexError):\n",
        "            print(f\"Translation failed for {text}\")\n",
        "            return text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nm7fH9_PmUR8"
      },
      "source": [
        "Begin Translation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ndodIEomTee",
        "outputId": "51b202c3-8835-4157-aed0-8e6caa37e55a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Translation failed for the record due to empty text:  \n",
            "Translation failed for the record due to empty text:  \n",
            "Translation failed for the record due to empty text:  \n",
            "Translation failed for the record due to empty text:  \n",
            "Translation failed for the record due to empty text:  \n",
            "Translation failed for the record due to empty text:  \n",
            "Translation failed for the record due to empty text:  \n",
            "Translation failed for the record due to empty text:  \n",
            "Translation failed for the record due to empty text:  \n",
            "Translation failed for the record due to empty text:  \n",
            "Translation failed for the record due to empty text:  \n",
            "Translation failed for the record due to empty text:  \n",
            "Translation failed for the record due to empty text:  \n",
            "Translation failed for the record due to empty text:  \n",
            "Translation failed for the record due to empty text:  \n",
            "Translation failed for the record due to empty text:  \n",
            "Translation failed for the record due to empty text:  \n",
            "Translation failed for the record due to empty text:  \n",
            "Translation failed for the record due to empty text:  \n",
            "Translation failed for the record due to empty text:  \n",
            "Translation failed for the record due to empty text:  \n",
            "Translation failed for the record due to empty text:  \n",
            "Translation failed for the record due to empty text:  \n",
            "Translation failed for the record due to empty text:  \n",
            "Translation failed for the record due to empty text:  \n",
            "Translation failed for the record due to empty text:  \n",
            "Translation failed for the record due to empty text:  \n",
            "Translation failed for the record due to empty text:  \n",
            "Translation failed for the record due to empty text:  \n",
            "Translation failed for the record due to empty text:  \n",
            "Translation failed for the record due to empty text:  \n",
            "Translation failed for the record due to empty text:  \n",
            "Translation failed for the record due to empty text:  \n",
            "Translation failed for the record due to empty text:  \n",
            "Translation failed for the record due to empty text:  \n",
            "Translation failed for the record due to empty text:  \n",
            "Translation failed for the record due to empty text:  \n",
            "Translation failed for the record due to empty text:  \n",
            "Translation failed for the record due to empty text:  \n",
            "Translation failed for the record due to empty text:  \n",
            "Translation failed for the record due to empty text:  \n",
            "Translation failed for the record due to empty text:  \n",
            "Translation failed for the record due to empty text:  \n",
            "Translation failed for the record due to empty text:  \n"
          ]
        }
      ],
      "source": [
        "# create a Translator object\n",
        "translator = Translator()\n",
        "\n",
        "# define the JSON files to loop over\n",
        "files = ['/content/train_data.json',\n",
        "         '/content/IteraTeR/human_sent_level/test.json',\n",
        "         '/content/IteraTeR/human_sent_level/dev.json']\n",
        "\n",
        "# define the target languages to loop over\n",
        "target_languages = ['fr', 'zh-cn', 'hi', 'ta']\n",
        "\n",
        "# loop over the target languages\n",
        "for target_language in target_languages:\n",
        "    # loop over the JSON files\n",
        "    for file in files:\n",
        "        # read the input data from the JSON file\n",
        "        with open(file) as f:\n",
        "            json_data = json.loads('[' + f.read().replace('}\\n{', '},\\n{') + ']')\n",
        "\n",
        "        # translate the text in the 'before_sent' and 'after_sent' fields and update the dictionary\n",
        "        for item in json_data:\n",
        "            before_sent = item['before_sent']\n",
        "            if isinstance(before_sent, list):\n",
        "                before_sent = ' '.join(filter(None, before_sent))\n",
        "            item['before_sent'] = translator.translate(before_sent, dest=target_language)\n",
        "\n",
        "            item['before_sent_with_intent'] = \"<\" + item['labels'] + \">  \" + item['before_sent']\n",
        "\n",
        "            after_sent = item['after_sent']\n",
        "            item['after_sent'] = translator.translate(after_sent, dest=target_language)\n",
        "\n",
        "        # write the output data to a new JSON file\n",
        "        with open(target_language + '_' + file.split('/')[-1], 'w') as f:\n",
        "            for item in json_data:\n",
        "                json.dump(item, f, ensure_ascii=False, indent=4)\n",
        "                f.write('\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mng24VhVn3Cc"
      },
      "source": [
        "Update the new train, dev and test files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5svXBnZmn3Zf"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "# Define the input file names\n",
        "train_files = [\n",
        "    'fr_train_data.json',\n",
        "    'zh-cn_train_data.json',\n",
        "    'hi_train_data.json',\n",
        "    'ta_train_data.json'\n",
        "]\n",
        "\n",
        "dev_files = [\n",
        "    'fr_dev.json',\n",
        "    'zh-cn_dev.json',\n",
        "    'hi_dev.json',\n",
        "    'ta_dev.json'\n",
        "]\n",
        "\n",
        "# Combine the data from all the input files into a single list for train\n",
        "train_data = []\n",
        "for file_name in train_files:\n",
        "    with open(file_name) as f:\n",
        "        # file_data = json.load(f)\n",
        "        file_data = json.loads('[' + f.read().replace('}\\n{', '},\\n{') + ']')\n",
        "        train_data.extend(file_data)\n",
        "\n",
        "# Write the combined data to a new file\n",
        "with open('train.json', 'w') as f:\n",
        "    json.dump(train_data, f, ensure_ascii=False, indent=4)\n",
        "\n",
        "\n",
        "# Combine the data from all the input files into a single list for dev\n",
        "dev_data = []\n",
        "for file_name in dev_files:\n",
        "    with open(file_name) as f:\n",
        "        # file_data = json.load(f)\n",
        "        file_data = json.loads('[' + f.read().replace('}\\n{', '},\\n{') + ']')\n",
        "        dev_data.extend(file_data)\n",
        "\n",
        "# Write the combined data to a new file\n",
        "with open('dev.json', 'w') as f:\n",
        "    json.dump(dev_data, f, ensure_ascii=False, indent=4)\n",
        "\n",
        "\n",
        "# Define the input file names\n",
        "input_files = [\n",
        "    'fr_test.json',\n",
        "    'zh-cn_test.json',\n",
        "    'hi_test.json',\n",
        "    'ta_test.json'\n",
        "]\n",
        "\n",
        "# Combine the data from all the input files into a single list\n",
        "test_data = []\n",
        "for file_name in input_files:\n",
        "    with open(file_name) as f:\n",
        "        # file_data = json.load(f)\n",
        "        file_data = json.loads('[' + f.read().replace('}\\n{', '},\\n{') + ']')\n",
        "        test_data.extend(file_data)\n",
        "\n",
        "# Write the combined data to a new file\n",
        "with open('test.json', 'w') as f:\n",
        "    json.dump(test_data, f, ensure_ascii=False, indent=4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D8__xnkkd61p"
      },
      "source": [
        "### Task 2.1: Intent CLassification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JzV51h8MieYm"
      },
      "source": [
        "#### Model 2.1.1 RoBERTA 10 Epochs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ehl3go_9jTiU"
      },
      "source": [
        "##### Zero Shot\n",
        "\n",
        "train: english human_sent_level>train.json\n",
        "\n",
        "dev: english human_sent_level>dev.json\n",
        "\n",
        "test: multilingual human_sent_level>test.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BiIUulB_jolX",
        "outputId": "994c2a26-4361-467d-fd42-e6f59ddccde0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-05-06 23:09:44.497100: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Using custom data configuration roberta_zeroshot-f0c4299871aa2fbc\n",
            "Reusing dataset json (/root/.cache/huggingface/datasets/json/roberta_zeroshot-f0c4299871aa2fbc/0.0.0/ac0ca5f5289a6cf108e706efcf040422dbbfa8e658dee6a819f20d76bb84d26b)\n",
            "100% 3/3 [00:00<00:00, 558.87it/s]\n",
            "[1258, 739, 311, 100, 807]\n",
            "[157, 115, 46, 13, 54]\n",
            "Downloading (…)olve/main/vocab.json: 100% 899k/899k [00:00<00:00, 18.4MB/s]\n",
            "Downloading (…)olve/main/merges.txt: 100% 456k/456k [00:00<00:00, 164MB/s]\n",
            "Downloading (…)lve/main/config.json: 100% 482/482 [00:00<00:00, 2.65MB/s]\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
            "Downloading (…)lve/main/config.json: 100% 482/482 [00:00<00:00, 3.61MB/s]\n",
            "Downloading pytorch_model.bin: 100% 1.43G/1.43G [00:14<00:00, 97.8MB/s]\n",
            "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.dense.weight', 'lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "{'loss': 1.4193, 'learning_rate': 9.502487562189056e-06, 'epoch': 0.5}\n",
            "{'loss': 1.2007, 'learning_rate': 9.00497512437811e-06, 'epoch': 1.0}\n",
            " 12% 250/2010 [19:54<2:21:05,  4.81s/it]\n",
            "  0% 0/7 [00:00<?, ?it/s]\n",
            " 29% 2/7 [00:03<00:08,  1.60s/it]\n",
            " 43% 3/7 [00:06<00:09,  2.27s/it]\n",
            " 57% 4/7 [00:09<00:07,  2.62s/it]\n",
            " 71% 5/7 [00:12<00:05,  2.83s/it]\n",
            " 86% 6/7 [00:16<00:02,  2.95s/it]/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "                                        \n",
            "{'eval_loss': 1.059614896774292, 'eval_accuracy': 0.6285714285714286, 'eval_P_Clarity': 0.6161616161616161, 'eval_R_Clarity': 0.7770700636942676, 'eval_f1_Clarity': 0.6873239436619719, 'eval_P_Fluency': 0.6503067484662577, 'eval_R_Fluency': 0.9217391304347826, 'eval_f1_Fluency': 0.7625899280575539, 'eval_P_Coherence': 1.0, 'eval_R_Coherence': 0.021739130434782608, 'eval_f1_Coherence': 0.042553191489361694, 'eval_P_Style': 0.0, 'eval_R_Style': 0.0, 'eval_f1_Style': 0.0, 'eval_P_Meaning-Changed': 0.5652173913043478, 'eval_R_Meaning-Changed': 0.24074074074074073, 'eval_f1_Meaning-Changed': 0.33766233766233766, 'eval_runtime': 19.3404, 'eval_samples_per_second': 19.907, 'eval_steps_per_second': 0.362, 'epoch': 1.24}\n",
            " 12% 250/2010 [20:14<2:21:05,  4.81s/it]\n",
            "100% 7/7 [00:16<00:00,  2.95s/it]\n",
            "{'loss': 1.0024, 'learning_rate': 8.507462686567165e-06, 'epoch': 1.49}\n",
            "{'loss': 0.9254, 'learning_rate': 8.00995024875622e-06, 'epoch': 1.99}\n",
            "{'loss': 0.7749, 'learning_rate': 7.512437810945274e-06, 'epoch': 2.49}\n",
            " 25% 500/2010 [40:35<2:01:07,  4.81s/it]\n",
            "  0% 0/7 [00:00<?, ?it/s]\n",
            " 29% 2/7 [00:03<00:08,  1.60s/it]\n",
            " 43% 3/7 [00:06<00:09,  2.28s/it]\n",
            " 57% 4/7 [00:09<00:07,  2.62s/it]\n",
            " 71% 5/7 [00:12<00:05,  2.83s/it]\n",
            " 86% 6/7 [00:16<00:02,  2.96s/it]/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "                                        \n",
            "{'eval_loss': 1.0383014678955078, 'eval_accuracy': 0.625974025974026, 'eval_P_Clarity': 0.6571428571428571, 'eval_R_Clarity': 0.5859872611464968, 'eval_f1_Clarity': 0.6195286195286195, 'eval_P_Fluency': 0.68, 'eval_R_Fluency': 0.8869565217391304, 'eval_f1_Fluency': 0.769811320754717, 'eval_P_Coherence': 0.8333333333333334, 'eval_R_Coherence': 0.10869565217391304, 'eval_f1_Coherence': 0.1923076923076923, 'eval_P_Style': 0.0, 'eval_R_Style': 0.0, 'eval_f1_Style': 0.0, 'eval_P_Meaning-Changed': 0.47191011235955055, 'eval_R_Meaning-Changed': 0.7777777777777778, 'eval_f1_Meaning-Changed': 0.5874125874125875, 'eval_runtime': 19.3673, 'eval_samples_per_second': 19.879, 'eval_steps_per_second': 0.361, 'epoch': 2.49}\n",
            " 25% 500/2010 [40:54<2:01:07,  4.81s/it]\n",
            "100% 7/7 [00:16<00:00,  2.96s/it]\n",
            "{'loss': 0.7587, 'learning_rate': 7.014925373134329e-06, 'epoch': 2.99}\n",
            "{'loss': 0.5891, 'learning_rate': 6.517412935323384e-06, 'epoch': 3.48}\n",
            " 37% 750/2010 [1:01:14<1:40:58,  4.81s/it]\n",
            "  0% 0/7 [00:00<?, ?it/s]\n",
            " 29% 2/7 [00:03<00:08,  1.60s/it]\n",
            " 43% 3/7 [00:06<00:09,  2.27s/it]\n",
            " 57% 4/7 [00:09<00:07,  2.62s/it]\n",
            " 71% 5/7 [00:12<00:05,  2.83s/it]\n",
            " 86% 6/7 [00:16<00:02,  2.95s/it]/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "                                          \n",
            "{'eval_loss': 0.9416082501411438, 'eval_accuracy': 0.6961038961038961, 'eval_P_Clarity': 0.68, 'eval_R_Clarity': 0.7579617834394905, 'eval_f1_Clarity': 0.7168674698795181, 'eval_P_Fluency': 0.768, 'eval_R_Fluency': 0.8347826086956521, 'eval_f1_Fluency': 0.8, 'eval_P_Coherence': 0.6, 'eval_R_Coherence': 0.32608695652173914, 'eval_f1_Coherence': 0.4225352112676057, 'eval_P_Style': 0.0, 'eval_R_Style': 0.0, 'eval_f1_Style': 0.0, 'eval_P_Meaning-Changed': 0.6333333333333333, 'eval_R_Meaning-Changed': 0.7037037037037037, 'eval_f1_Meaning-Changed': 0.6666666666666667, 'eval_runtime': 19.3286, 'eval_samples_per_second': 19.919, 'eval_steps_per_second': 0.362, 'epoch': 3.73}\n",
            " 37% 750/2010 [1:01:33<1:40:58,  4.81s/it]\n",
            "100% 7/7 [00:16<00:00,  2.95s/it]\n",
            "{'loss': 0.5788, 'learning_rate': 6.019900497512439e-06, 'epoch': 3.98}\n",
            "{'loss': 0.3955, 'learning_rate': 5.522388059701493e-06, 'epoch': 4.48}\n",
            "{'loss': 0.5298, 'learning_rate': 5.024875621890548e-06, 'epoch': 4.98}\n",
            " 50% 1000/2010 [1:21:54<1:21:11,  4.82s/it]\n",
            "  0% 0/7 [00:00<?, ?it/s]\n",
            " 29% 2/7 [00:03<00:08,  1.60s/it]\n",
            " 43% 3/7 [00:06<00:09,  2.27s/it]\n",
            " 57% 4/7 [00:09<00:07,  2.63s/it]\n",
            " 71% 5/7 [00:12<00:05,  2.83s/it]\n",
            " 86% 6/7 [00:16<00:02,  2.96s/it]/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "                                           \n",
            "{'eval_loss': 0.9919940829277039, 'eval_accuracy': 0.7220779220779221, 'eval_P_Clarity': 0.7109826589595376, 'eval_R_Clarity': 0.7834394904458599, 'eval_f1_Clarity': 0.7454545454545456, 'eval_P_Fluency': 0.8260869565217391, 'eval_R_Fluency': 0.8260869565217391, 'eval_f1_Fluency': 0.8260869565217391, 'eval_P_Coherence': 0.5666666666666667, 'eval_R_Coherence': 0.3695652173913043, 'eval_f1_Coherence': 0.4473684210526315, 'eval_P_Style': 0.0, 'eval_R_Style': 0.0, 'eval_f1_Style': 0.0, 'eval_P_Meaning-Changed': 0.6417910447761194, 'eval_R_Meaning-Changed': 0.7962962962962963, 'eval_f1_Meaning-Changed': 0.7107438016528925, 'eval_runtime': 19.3647, 'eval_samples_per_second': 19.882, 'eval_steps_per_second': 0.361, 'epoch': 4.98}\n",
            " 50% 1000/2010 [1:22:13<1:21:11,  4.82s/it]\n",
            "100% 7/7 [00:16<00:00,  2.96s/it]\n",
            "{'loss': 0.3581, 'learning_rate': 4.527363184079602e-06, 'epoch': 5.47}\n",
            "{'loss': 0.3878, 'learning_rate': 4.029850746268657e-06, 'epoch': 5.97}\n",
            " 62% 1250/2010 [1:42:34<1:00:52,  4.81s/it]\n",
            "  0% 0/7 [00:00<?, ?it/s]\n",
            " 29% 2/7 [00:03<00:07,  1.60s/it]\n",
            " 43% 3/7 [00:06<00:09,  2.27s/it]\n",
            " 57% 4/7 [00:09<00:07,  2.62s/it]\n",
            " 71% 5/7 [00:12<00:05,  2.83s/it]\n",
            "                                           \n",
            "{'eval_loss': 1.3198530673980713, 'eval_accuracy': 0.6675324675324675, 'eval_P_Clarity': 0.75, 'eval_R_Clarity': 0.5732484076433121, 'eval_f1_Clarity': 0.6498194945848377, 'eval_P_Fluency': 0.7786885245901639, 'eval_R_Fluency': 0.8260869565217391, 'eval_f1_Fluency': 0.8016877637130801, 'eval_P_Coherence': 0.44642857142857145, 'eval_R_Coherence': 0.5434782608695652, 'eval_f1_Coherence': 0.4901960784313726, 'eval_P_Style': 0.0, 'eval_R_Style': 0.0, 'eval_f1_Style': 0.0, 'eval_P_Meaning-Changed': 0.5465116279069767, 'eval_R_Meaning-Changed': 0.8703703703703703, 'eval_f1_Meaning-Changed': 0.6714285714285714, 'eval_runtime': 19.3098, 'eval_samples_per_second': 19.938, 'eval_steps_per_second': 0.363, 'epoch': 6.22}\n",
            " 62% 1250/2010 [1:42:53<1:00:52,  4.81s/it]\n",
            "100% 7/7 [00:16<00:00,  2.95s/it]\n",
            "{'loss': 0.3074, 'learning_rate': 3.5323383084577117e-06, 'epoch': 6.47}\n",
            "{'loss': 0.2666, 'learning_rate': 3.0348258706467666e-06, 'epoch': 6.97}\n",
            "{'loss': 0.2458, 'learning_rate': 2.537313432835821e-06, 'epoch': 7.46}\n",
            " 75% 1500/2010 [2:03:14<40:52,  4.81s/it]\n",
            "  0% 0/7 [00:00<?, ?it/s]\n",
            " 29% 2/7 [00:03<00:07,  1.60s/it]\n",
            " 43% 3/7 [00:06<00:09,  2.27s/it]\n",
            " 57% 4/7 [00:09<00:07,  2.62s/it]\n",
            " 71% 5/7 [00:12<00:05,  2.83s/it]\n",
            "                                         \n",
            "{'eval_loss': 1.2341676950454712, 'eval_accuracy': 0.6935064935064935, 'eval_P_Clarity': 0.7018633540372671, 'eval_R_Clarity': 0.7197452229299363, 'eval_f1_Clarity': 0.7106918238993711, 'eval_P_Fluency': 0.7461538461538462, 'eval_R_Fluency': 0.8434782608695652, 'eval_f1_Fluency': 0.7918367346938776, 'eval_P_Coherence': 0.5294117647058824, 'eval_R_Coherence': 0.391304347826087, 'eval_f1_Coherence': 0.45, 'eval_P_Style': 0.0, 'eval_R_Style': 0.0, 'eval_f1_Style': 0.0, 'eval_P_Meaning-Changed': 0.7090909090909091, 'eval_R_Meaning-Changed': 0.7222222222222222, 'eval_f1_Meaning-Changed': 0.7155963302752293, 'eval_runtime': 19.3453, 'eval_samples_per_second': 19.901, 'eval_steps_per_second': 0.362, 'epoch': 7.46}\n",
            " 75% 1500/2010 [2:03:33<40:52,  4.81s/it]\n",
            "100% 7/7 [00:16<00:00,  2.96s/it]\n",
            "{'loss': 0.246, 'learning_rate': 2.0398009950248755e-06, 'epoch': 7.96}\n",
            "{'loss': 0.1941, 'learning_rate': 1.5422885572139304e-06, 'epoch': 8.46}\n",
            " 87% 1750/2010 [2:23:54<20:51,  4.81s/it]\n",
            "  0% 0/7 [00:00<?, ?it/s]\n",
            " 29% 2/7 [00:03<00:08,  1.60s/it]\n",
            " 43% 3/7 [00:06<00:09,  2.27s/it]\n",
            " 57% 4/7 [00:09<00:07,  2.62s/it]\n",
            " 71% 5/7 [00:12<00:05,  2.83s/it]\n",
            "                                         \n",
            "{'eval_loss': 1.3295902013778687, 'eval_accuracy': 0.7090909090909091, 'eval_P_Clarity': 0.7142857142857143, 'eval_R_Clarity': 0.732484076433121, 'eval_f1_Clarity': 0.7232704402515723, 'eval_P_Fluency': 0.7596899224806202, 'eval_R_Fluency': 0.8521739130434782, 'eval_f1_Fluency': 0.8032786885245902, 'eval_P_Coherence': 0.5384615384615384, 'eval_R_Coherence': 0.45652173913043476, 'eval_f1_Coherence': 0.49411764705882355, 'eval_P_Style': 0.0, 'eval_R_Style': 0.0, 'eval_f1_Style': 0.0, 'eval_P_Meaning-Changed': 0.7358490566037735, 'eval_R_Meaning-Changed': 0.7222222222222222, 'eval_f1_Meaning-Changed': 0.7289719626168224, 'eval_runtime': 19.3407, 'eval_samples_per_second': 19.906, 'eval_steps_per_second': 0.362, 'epoch': 8.71}\n",
            " 87% 1750/2010 [2:24:13<20:51,  4.81s/it]\n",
            "100% 7/7 [00:16<00:00,  2.96s/it]\n",
            "{'loss': 0.21, 'learning_rate': 1.044776119402985e-06, 'epoch': 8.96}\n",
            "{'loss': 0.1648, 'learning_rate': 5.472636815920398e-07, 'epoch': 9.45}\n",
            "{'loss': 0.1713, 'learning_rate': 4.975124378109453e-08, 'epoch': 9.95}\n",
            "100% 2000/2010 [2:44:34<00:48,  4.80s/it]\n",
            "  0% 0/7 [00:00<?, ?it/s]\n",
            " 29% 2/7 [00:03<00:08,  1.60s/it]\n",
            " 43% 3/7 [00:06<00:09,  2.27s/it]\n",
            " 57% 4/7 [00:09<00:07,  2.62s/it]\n",
            " 71% 5/7 [00:12<00:05,  2.83s/it]\n",
            "                                         \n",
            "{'eval_loss': 1.4524645805358887, 'eval_accuracy': 0.7038961038961039, 'eval_P_Clarity': 0.7037037037037037, 'eval_R_Clarity': 0.7261146496815286, 'eval_f1_Clarity': 0.7147335423197492, 'eval_P_Fluency': 0.768, 'eval_R_Fluency': 0.8347826086956521, 'eval_f1_Fluency': 0.8, 'eval_P_Coherence': 0.5428571428571428, 'eval_R_Coherence': 0.41304347826086957, 'eval_f1_Coherence': 0.46913580246913583, 'eval_P_Style': 0.0, 'eval_R_Style': 0.0, 'eval_f1_Style': 0.0, 'eval_P_Meaning-Changed': 0.6774193548387096, 'eval_R_Meaning-Changed': 0.7777777777777778, 'eval_f1_Meaning-Changed': 0.7241379310344828, 'eval_runtime': 19.3191, 'eval_samples_per_second': 19.928, 'eval_steps_per_second': 0.362, 'epoch': 9.95}\n",
            "100% 2000/2010 [2:44:53<00:48,  4.80s/it]\n",
            "100% 7/7 [00:16<00:00,  2.95s/it]\n",
            "{'train_runtime': 9958.7218, 'train_samples_per_second': 3.228, 'train_steps_per_second': 0.202, 'train_loss': 0.5343093791411291, 'epoch': 10.0}\n",
            "100% 2010/2010 [2:45:58<00:00,  4.95s/it]\n",
            "100% 7/7 [00:16<00:00,  2.30s/it]\n",
            "{'eval_loss': 1.4526865482330322, 'eval_accuracy': 0.7064935064935065, 'eval_P_Clarity': 0.7080745341614907, 'eval_R_Clarity': 0.7261146496815286, 'eval_f1_Clarity': 0.7169811320754716, 'eval_P_Fluency': 0.7698412698412699, 'eval_R_Fluency': 0.8434782608695652, 'eval_f1_Fluency': 0.8049792531120332, 'eval_P_Coherence': 0.5428571428571428, 'eval_R_Coherence': 0.41304347826086957, 'eval_f1_Coherence': 0.46913580246913583, 'eval_P_Style': 0.0, 'eval_R_Style': 0.0, 'eval_f1_Style': 0.0, 'eval_P_Meaning-Changed': 0.6774193548387096, 'eval_R_Meaning-Changed': 0.7777777777777778, 'eval_f1_Meaning-Changed': 0.7241379310344828, 'eval_runtime': 19.3051, 'eval_samples_per_second': 19.943, 'eval_steps_per_second': 0.363, 'epoch': 10.0}\n",
            "CPU times: user 38.8 s, sys: 4.95 s, total: 43.8 s\n",
            "Wall time: 2h 46min 53s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "# # change directory to intent_classification model\n",
        "%cd /content/iterater/code/IteraTeR_ACL2022/model/intent_classification\n",
        "\n",
        "!python 'train_intent_classifier.py' --upsample_values 1 1 1 1 1 --weights 1. 1. 1. 1. 1. -e 10  -s roberta-large-ten -d '/content/cs678-cp1-cp2/multi_data/zeroshot_multi'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1GTtAqsujwM1"
      },
      "source": [
        "##### Fully Supervised\n",
        "\n",
        "train: multilingual human_sent_level>train.json\n",
        "\n",
        "dev: multilingual human_sent_level>dev.json\n",
        "\n",
        "test: multilingual human_sent_level>test.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V_5fetkIj_n_",
        "outputId": "4e445f37-0dd7-4f81-e766-f2fbb5eb4966"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "`WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
            "Downloading (…)lve/main/config.json: 100% 482/482 [00:00<00:00, 3.12MB/s]\n",
            "Downloading pytorch_model.bin: 100% 1.43G/1.43G [00:05<00:00, 258MB/s]\n",
            "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.weight']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "{'loss': 1.3729, 'learning_rate': 9.662162162162164e-06, 'epoch': 0.34}\n",
            "{'loss': 1.3314, 'learning_rate': 9.324324324324325e-06, 'epoch': 0.68}\n",
            "  8% 250/2960 [21:36<3:54:50,  5.20s/it]\n",
            "  0% 0/25 [00:00<?, ?it/s]\n",
            "  8% 2/25 [00:06<01:16,  3.33s/it]\n",
            " 12% 3/25 [00:13<01:43,  4.72s/it]\n",
            " 16% 4/25 [00:20<01:54,  5.46s/it]\n",
            " 20% 5/25 [00:26<01:58,  5.90s/it]\n",
            " 24% 6/25 [00:33<01:57,  6.17s/it]\n",
            " 28% 7/25 [00:40<01:54,  6.35s/it]\n",
            " 32% 8/25 [00:46<01:49,  6.47s/it]\n",
            " 36% 9/25 [00:53<01:44,  6.55s/it]\n",
            " 40% 10/25 [01:00<01:38,  6.60s/it]\n",
            " 44% 11/25 [01:07<01:32,  6.64s/it]\n",
            " 48% 12/25 [01:13<01:26,  6.64s/it]\n",
            " 52% 13/25 [01:20<01:21,  6.82s/it]\n",
            " 56% 14/25 [01:28<01:15,  6.89s/it]\n",
            " 60% 15/25 [01:35<01:09,  6.95s/it]\n",
            " 64% 16/25 [01:42<01:03,  7.01s/it]\n",
            " 68% 17/25 [01:49<00:56,  7.06s/it]\n",
            " 72% 18/25 [01:56<00:49,  7.09s/it]\n",
            " 76% 19/25 [02:03<00:42,  7.16s/it]\n",
            " 80% 20/25 [02:11<00:35,  7.20s/it]\n",
            " 84% 21/25 [02:18<00:28,  7.23s/it]\n",
            " 88% 22/25 [02:25<00:21,  7.24s/it]\n",
            " 92% 23/25 [02:33<00:14,  7.26s/it]\n",
            " 96% 24/25 [02:40<00:07,  7.27s/it]\n",
            "100% 25/25 [02:40<00:00,  5.23s/it]/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "                                        \n",
            "{'eval_loss': 1.3487491607666016, 'eval_accuracy': 0.43116883116883115, 'eval_P_Clarity': 0.45285714285714285, 'eval_R_Clarity': 0.5047770700636943, 'eval_f1_Clarity': 0.47740963855421686, 'eval_P_Fluency': 0.48794063079777367, 'eval_R_Fluency': 0.5717391304347826, 'eval_f1_Fluency': 0.5265265265265265, 'eval_P_Coherence': 0.0, 'eval_R_Coherence': 0.0, 'eval_f1_Coherence': 0.0, 'eval_P_Style': 0.0, 'eval_R_Style': 0.0, 'eval_f1_Style': 0.0, 'eval_P_Meaning-Changed': 0.27906976744186046, 'eval_R_Meaning-Changed': 0.3888888888888889, 'eval_f1_Meaning-Changed': 0.32495164410058025, 'eval_runtime': 167.7068, 'eval_samples_per_second': 9.183, 'eval_steps_per_second': 0.149, 'epoch': 0.84}\n",
            "  8% 250/2960 [24:24<3:54:50,  5.20s/it]\n",
            "100% 25/25 [02:40<00:00,  5.23s/it]\n",
            "{'loss': 1.2828, 'learning_rate': 8.986486486486488e-06, 'epoch': 1.01}\n",
            "{'loss': 1.2688, 'learning_rate': 8.64864864864865e-06, 'epoch': 1.35}\n",
            "{'loss': 1.2467, 'learning_rate': 8.31081081081081e-06, 'epoch': 1.69}\n",
            " 17% 500/2960 [46:19<3:32:43,  5.19s/it]\n",
            "  0% 0/25 [00:00<?, ?it/s]\n",
            "  8% 2/25 [00:06<01:16,  3.33s/it]\n",
            " 12% 3/25 [00:13<01:43,  4.71s/it]\n",
            " 16% 4/25 [00:19<01:54,  5.44s/it]\n",
            " 20% 5/25 [00:26<01:57,  5.88s/it]\n",
            " 24% 6/25 [00:33<01:56,  6.14s/it]\n",
            " 28% 7/25 [00:40<01:53,  6.32s/it]\n",
            " 32% 8/25 [00:46<01:49,  6.45s/it]\n",
            " 36% 9/25 [00:53<01:44,  6.51s/it]\n",
            " 40% 10/25 [01:00<01:38,  6.57s/it]\n",
            " 44% 11/25 [01:06<01:32,  6.62s/it]\n",
            " 48% 12/25 [01:13<01:26,  6.64s/it]\n",
            " 52% 13/25 [01:20<01:21,  6.83s/it]\n",
            " 56% 14/25 [01:27<01:16,  6.91s/it]\n",
            " 60% 15/25 [01:35<01:09,  6.98s/it]\n",
            " 64% 16/25 [01:42<01:03,  7.03s/it]\n",
            " 68% 17/25 [01:49<00:56,  7.09s/it]\n",
            " 72% 18/25 [01:56<00:49,  7.11s/it]\n",
            " 76% 19/25 [02:03<00:43,  7.17s/it]\n",
            " 80% 20/25 [02:11<00:36,  7.21s/it]\n",
            " 84% 21/25 [02:18<00:28,  7.23s/it]\n",
            " 88% 22/25 [02:25<00:21,  7.25s/it]\n",
            " 92% 23/25 [02:33<00:14,  7.26s/it]\n",
            " 96% 24/25 [02:40<00:07,  7.27s/it]\n",
            "100% 25/25 [02:40<00:00,  5.23s/it]/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "                                        \n",
            "{'eval_loss': 1.3419559001922607, 'eval_accuracy': 0.44805194805194803, 'eval_P_Clarity': 0.4889589905362776, 'eval_R_Clarity': 0.49363057324840764, 'eval_f1_Clarity': 0.491283676703645, 'eval_P_Fluency': 0.47086614173228347, 'eval_R_Fluency': 0.65, 'eval_f1_Fluency': 0.5461187214611871, 'eval_P_Coherence': 0.0, 'eval_R_Coherence': 0.0, 'eval_f1_Coherence': 0.0, 'eval_P_Style': 0.0, 'eval_R_Style': 0.0, 'eval_f1_Style': 0.0, 'eval_P_Meaning-Changed': 0.2988929889298893, 'eval_R_Meaning-Changed': 0.375, 'eval_f1_Meaning-Changed': 0.33264887063655035, 'eval_runtime': 167.4744, 'eval_samples_per_second': 9.195, 'eval_steps_per_second': 0.149, 'epoch': 1.69}\n",
            " 17% 500/2960 [49:07<3:32:43,  5.19s/it]\n",
            "100% 25/25 [02:40<00:00,  5.23s/it]\n",
            "{'loss': 1.2175, 'learning_rate': 7.972972972972974e-06, 'epoch': 2.03}\n",
            "{'loss': 1.1837, 'learning_rate': 7.635135135135135e-06, 'epoch': 2.36}\n",
            " 25% 750/2960 [1:11:04<3:11:04,  5.19s/it]\n",
            "  0% 0/25 [00:00<?, ?it/s]\n",
            "  8% 2/25 [00:06<01:15,  3.29s/it]\n",
            " 12% 3/25 [00:13<01:42,  4.66s/it]\n",
            " 16% 4/25 [00:19<01:53,  5.39s/it]\n",
            " 20% 5/25 [00:26<01:56,  5.80s/it]\n",
            " 24% 6/25 [00:32<01:55,  6.08s/it]\n",
            " 28% 7/25 [00:39<01:52,  6.27s/it]\n",
            " 32% 8/25 [00:46<01:49,  6.41s/it]\n",
            " 36% 9/25 [00:53<01:43,  6.49s/it]\n",
            " 40% 10/25 [00:59<01:38,  6.56s/it]\n",
            " 44% 11/25 [01:06<01:32,  6.61s/it]\n",
            " 48% 12/25 [01:13<01:26,  6.62s/it]\n",
            " 52% 13/25 [01:20<01:21,  6.82s/it]\n",
            " 56% 14/25 [01:27<01:15,  6.90s/it]\n",
            " 60% 15/25 [01:34<01:09,  6.96s/it]\n",
            " 64% 16/25 [01:41<01:03,  7.02s/it]\n",
            " 68% 17/25 [01:48<00:56,  7.08s/it]\n",
            " 72% 18/25 [01:56<00:49,  7.11s/it]\n",
            " 76% 19/25 [02:03<00:42,  7.16s/it]\n",
            " 80% 20/25 [02:10<00:36,  7.20s/it]\n",
            " 84% 21/25 [02:18<00:28,  7.23s/it]\n",
            " 88% 22/25 [02:25<00:21,  7.25s/it]\n",
            " 92% 23/25 [02:32<00:14,  7.26s/it]\n",
            " 96% 24/25 [02:39<00:07,  7.27s/it]\n",
            "100% 25/25 [02:40<00:00,  5.23s/it]/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "                                          \n",
            "{'eval_loss': 1.3134055137634277, 'eval_accuracy': 0.4733766233766234, 'eval_P_Clarity': 0.491025641025641, 'eval_R_Clarity': 0.6098726114649682, 'eval_f1_Clarity': 0.5440340909090908, 'eval_P_Fluency': 0.5222437137330754, 'eval_R_Fluency': 0.5869565217391305, 'eval_f1_Fluency': 0.5527123848515865, 'eval_P_Coherence': 0.0, 'eval_R_Coherence': 0.0, 'eval_f1_Coherence': 0.0, 'eval_P_Style': 0.0, 'eval_R_Style': 0.0, 'eval_f1_Style': 0.0, 'eval_P_Meaning-Changed': 0.31275720164609055, 'eval_R_Meaning-Changed': 0.35185185185185186, 'eval_f1_Meaning-Changed': 0.3311546840958606, 'eval_runtime': 166.9631, 'eval_samples_per_second': 9.224, 'eval_steps_per_second': 0.15, 'epoch': 2.53}\n",
            " 25% 750/2960 [1:13:51<3:11:04,  5.19s/it]\n",
            "100% 25/25 [02:40<00:00,  5.23s/it]\n",
            "{'loss': 1.171, 'learning_rate': 7.297297297297298e-06, 'epoch': 2.7}\n",
            "{'loss': 1.1585, 'learning_rate': 6.95945945945946e-06, 'epoch': 3.04}\n",
            "{'loss': 1.0901, 'learning_rate': 6.621621621621622e-06, 'epoch': 3.38}\n",
            " 34% 1000/2960 [1:35:46<2:49:21,  5.18s/it]\n",
            "  0% 0/25 [00:00<?, ?it/s]\n",
            "  8% 2/25 [00:06<01:15,  3.27s/it]\n",
            " 12% 3/25 [00:13<01:41,  4.63s/it]\n",
            " 16% 4/25 [00:19<01:53,  5.39s/it]\n",
            " 20% 5/25 [00:26<01:56,  5.83s/it]\n",
            " 24% 6/25 [00:32<01:55,  6.08s/it]\n",
            " 28% 7/25 [00:39<01:52,  6.27s/it]\n",
            " 32% 8/25 [00:46<01:48,  6.40s/it]\n",
            " 36% 9/25 [00:52<01:43,  6.48s/it]\n",
            " 40% 10/25 [00:59<01:38,  6.54s/it]\n",
            " 44% 11/25 [01:06<01:32,  6.59s/it]\n",
            " 48% 12/25 [01:13<01:25,  6.61s/it]\n",
            " 52% 13/25 [01:20<01:21,  6.81s/it]\n",
            " 56% 14/25 [01:27<01:15,  6.90s/it]\n",
            " 60% 15/25 [01:34<01:09,  6.97s/it]\n",
            " 64% 16/25 [01:41<01:03,  7.03s/it]\n",
            " 68% 17/25 [01:48<00:56,  7.08s/it]\n",
            " 72% 18/25 [01:56<00:49,  7.10s/it]\n",
            " 76% 19/25 [02:03<00:42,  7.16s/it]\n",
            " 80% 20/25 [02:10<00:35,  7.20s/it]\n",
            " 84% 21/25 [02:17<00:28,  7.22s/it]\n",
            " 88% 22/25 [02:25<00:21,  7.24s/it]\n",
            " 92% 23/25 [02:32<00:14,  7.26s/it]\n",
            " 96% 24/25 [02:39<00:07,  7.27s/it]\n",
            "100% 25/25 [02:40<00:00,  5.23s/it]/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "                                           \n",
            "{'eval_loss': 1.38189697265625, 'eval_accuracy': 0.4837662337662338, 'eval_P_Clarity': 0.5097783572359843, 'eval_R_Clarity': 0.6226114649681529, 'eval_f1_Clarity': 0.560573476702509, 'eval_P_Fluency': 0.5366336633663367, 'eval_R_Fluency': 0.5891304347826087, 'eval_f1_Fluency': 0.5616580310880829, 'eval_P_Coherence': 0.0, 'eval_R_Coherence': 0.0, 'eval_f1_Coherence': 0.0, 'eval_P_Style': 0.0, 'eval_R_Style': 0.0, 'eval_f1_Style': 0.0, 'eval_P_Meaning-Changed': 0.30970149253731344, 'eval_R_Meaning-Changed': 0.38425925925925924, 'eval_f1_Meaning-Changed': 0.34297520661157027, 'eval_runtime': 166.8678, 'eval_samples_per_second': 9.229, 'eval_steps_per_second': 0.15, 'epoch': 3.38}\n",
            " 34% 1000/2960 [1:38:33<2:49:21,  5.18s/it]\n",
            "100% 25/25 [02:40<00:00,  5.23s/it]\n",
            "{'loss': 1.1055, 'learning_rate': 6.283783783783784e-06, 'epoch': 3.71}\n",
            "{'loss': 1.1216, 'learning_rate': 5.945945945945947e-06, 'epoch': 4.05}\n",
            " 42% 1250/2960 [2:00:27<2:27:55,  5.19s/it]\n",
            "  0% 0/25 [00:00<?, ?it/s]\n",
            "  8% 2/25 [00:06<01:16,  3.32s/it]\n",
            " 12% 3/25 [00:13<01:43,  4.70s/it]\n",
            " 16% 4/25 [00:19<01:54,  5.43s/it]\n",
            " 20% 5/25 [00:26<01:57,  5.85s/it]\n",
            " 24% 6/25 [00:33<01:56,  6.11s/it]\n",
            " 28% 7/25 [00:39<01:53,  6.30s/it]\n",
            " 32% 8/25 [00:46<01:49,  6.43s/it]\n",
            " 36% 9/25 [00:53<01:44,  6.51s/it]\n",
            " 40% 10/25 [01:00<01:38,  6.58s/it]\n",
            " 44% 11/25 [01:06<01:32,  6.64s/it]\n",
            " 48% 12/25 [01:13<01:26,  6.67s/it]\n",
            " 52% 13/25 [01:20<01:21,  6.83s/it]\n",
            " 56% 14/25 [01:27<01:15,  6.90s/it]\n",
            " 60% 15/25 [01:34<01:09,  6.95s/it]\n",
            " 64% 16/25 [01:42<01:03,  7.01s/it]\n",
            " 68% 17/25 [01:49<00:56,  7.05s/it]\n",
            " 72% 18/25 [01:56<00:49,  7.08s/it]\n",
            " 76% 19/25 [02:03<00:42,  7.14s/it]\n",
            " 80% 20/25 [02:10<00:35,  7.19s/it]\n",
            " 84% 21/25 [02:18<00:28,  7.22s/it]\n",
            " 88% 22/25 [02:25<00:21,  7.24s/it]\n",
            " 92% 23/25 [02:32<00:14,  7.25s/it]\n",
            " 96% 24/25 [02:40<00:07,  7.27s/it]\n",
            "100% 25/25 [02:40<00:00,  5.23s/it]/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "                                           \n",
            "{'eval_loss': 1.4042915105819702, 'eval_accuracy': 0.4818181818181818, 'eval_P_Clarity': 0.4730127576054956, 'eval_R_Clarity': 0.767515923566879, 'eval_f1_Clarity': 0.5853066180935034, 'eval_P_Fluency': 0.6293436293436293, 'eval_R_Fluency': 0.35434782608695653, 'eval_f1_Fluency': 0.45340751043115446, 'eval_P_Coherence': 0.8333333333333334, 'eval_R_Coherence': 0.05434782608695652, 'eval_f1_Coherence': 0.1020408163265306, 'eval_P_Style': 0.0, 'eval_R_Style': 0.0, 'eval_f1_Style': 0.0, 'eval_P_Meaning-Changed': 0.348, 'eval_R_Meaning-Changed': 0.4027777777777778, 'eval_f1_Meaning-Changed': 0.37339055793991416, 'eval_runtime': 167.1772, 'eval_samples_per_second': 9.212, 'eval_steps_per_second': 0.15, 'epoch': 4.22}\n",
            " 42% 1250/2960 [2:03:14<2:27:55,  5.19s/it]\n",
            "100% 25/25 [02:40<00:00,  5.23s/it]\n",
            "{'loss': 1.0302, 'learning_rate': 5.608108108108109e-06, 'epoch': 4.39}\n",
            "{'loss': 1.0238, 'learning_rate': 5.2702702702702705e-06, 'epoch': 4.73}\n",
            "{'loss': 1.0261, 'learning_rate': 4.932432432432433e-06, 'epoch': 5.06}\n",
            " 51% 1500/2960 [2:25:09<2:07:00,  5.22s/it]\n",
            "  0% 0/25 [00:00<?, ?it/s]\n",
            "  8% 2/25 [00:06<01:16,  3.33s/it]\n",
            " 12% 3/25 [00:13<01:43,  4.70s/it]\n",
            " 16% 4/25 [00:19<01:53,  5.41s/it]\n",
            " 20% 5/25 [00:26<01:56,  5.84s/it]\n",
            " 24% 6/25 [00:33<01:55,  6.08s/it]\n",
            " 28% 7/25 [00:39<01:53,  6.28s/it]\n",
            " 32% 8/25 [00:46<01:49,  6.42s/it]\n",
            " 36% 9/25 [00:53<01:43,  6.50s/it]\n",
            " 40% 10/25 [00:59<01:38,  6.57s/it]\n",
            " 44% 11/25 [01:06<01:32,  6.61s/it]\n",
            " 48% 12/25 [01:13<01:26,  6.62s/it]\n",
            " 52% 13/25 [01:20<01:21,  6.80s/it]\n",
            " 56% 14/25 [01:27<01:15,  6.88s/it]\n",
            " 60% 15/25 [01:34<01:09,  6.94s/it]\n",
            " 64% 16/25 [01:41<01:02,  7.00s/it]\n",
            " 68% 17/25 [01:48<00:56,  7.05s/it]\n",
            " 72% 18/25 [01:56<00:49,  7.08s/it]\n",
            " 76% 19/25 [02:03<00:42,  7.14s/it]\n",
            " 80% 20/25 [02:10<00:35,  7.19s/it]\n",
            " 84% 21/25 [02:17<00:28,  7.22s/it]\n",
            " 88% 22/25 [02:25<00:21,  7.24s/it]\n",
            " 92% 23/25 [02:32<00:14,  7.25s/it]\n",
            " 96% 24/25 [02:39<00:07,  7.27s/it]\n",
            "100% 25/25 [02:40<00:00,  5.23s/it]/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "                                           \n",
            "{'eval_loss': 1.452147126197815, 'eval_accuracy': 0.44545454545454544, 'eval_P_Clarity': 0.5433070866141733, 'eval_R_Clarity': 0.4394904458598726, 'eval_f1_Clarity': 0.4859154929577465, 'eval_P_Fluency': 0.5300970873786408, 'eval_R_Fluency': 0.5934782608695652, 'eval_f1_Fluency': 0.56, 'eval_P_Coherence': 0.8571428571428571, 'eval_R_Coherence': 0.06521739130434782, 'eval_f1_Coherence': 0.12121212121212122, 'eval_P_Style': 0.0, 'eval_R_Style': 0.0, 'eval_f1_Style': 0.0, 'eval_P_Meaning-Changed': 0.2485089463220676, 'eval_R_Meaning-Changed': 0.5787037037037037, 'eval_f1_Meaning-Changed': 0.34770514603616137, 'eval_runtime': 166.9235, 'eval_samples_per_second': 9.226, 'eval_steps_per_second': 0.15, 'epoch': 5.06}\n",
            " 51% 1500/2960 [2:27:56<2:07:00,  5.22s/it]\n",
            "100% 25/25 [02:40<00:00,  5.23s/it]\n",
            "{'loss': 0.9701, 'learning_rate': 4.594594594594596e-06, 'epoch': 5.4}\n",
            "{'loss': 0.9418, 'learning_rate': 4.256756756756757e-06, 'epoch': 5.74}\n",
            " 59% 1750/2960 [2:49:49<1:44:23,  5.18s/it]\n",
            "  0% 0/25 [00:00<?, ?it/s]\n",
            "  8% 2/25 [00:06<01:16,  3.31s/it]\n",
            " 12% 3/25 [00:13<01:42,  4.67s/it]\n",
            " 16% 4/25 [00:19<01:53,  5.38s/it]\n",
            " 20% 5/25 [00:26<01:56,  5.82s/it]\n",
            " 24% 6/25 [00:33<01:55,  6.09s/it]\n",
            " 28% 7/25 [00:39<01:52,  6.27s/it]\n",
            " 32% 8/25 [00:46<01:48,  6.41s/it]\n",
            " 36% 9/25 [00:53<01:43,  6.49s/it]\n",
            " 40% 10/25 [00:59<01:38,  6.57s/it]\n",
            " 44% 11/25 [01:06<01:32,  6.62s/it]\n",
            " 48% 12/25 [01:13<01:26,  6.64s/it]\n",
            " 52% 13/25 [01:20<01:21,  6.82s/it]\n",
            " 56% 14/25 [01:27<01:15,  6.90s/it]\n",
            " 60% 15/25 [01:34<01:09,  6.96s/it]\n",
            " 64% 16/25 [01:41<01:03,  7.01s/it]\n",
            " 68% 17/25 [01:48<00:56,  7.06s/it]\n",
            " 72% 18/25 [01:56<00:49,  7.09s/it]\n",
            " 76% 19/25 [02:03<00:42,  7.15s/it]\n",
            " 80% 20/25 [02:10<00:35,  7.20s/it]\n",
            " 84% 21/25 [02:18<00:28,  7.22s/it]\n",
            " 88% 22/25 [02:25<00:21,  7.24s/it]\n",
            " 92% 23/25 [02:32<00:14,  7.26s/it]\n",
            " 96% 24/25 [02:39<00:07,  7.27s/it]\n",
            "100% 25/25 [02:40<00:00,  5.23s/it]/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "                                           \n",
            "{'eval_loss': 1.3812793493270874, 'eval_accuracy': 0.4824675324675325, 'eval_P_Clarity': 0.545144804088586, 'eval_R_Clarity': 0.5095541401273885, 'eval_f1_Clarity': 0.5267489711934157, 'eval_P_Fluency': 0.5, 'eval_R_Fluency': 0.6456521739130435, 'eval_f1_Fluency': 0.5635673624288424, 'eval_P_Coherence': 0.6410256410256411, 'eval_R_Coherence': 0.1358695652173913, 'eval_f1_Coherence': 0.2242152466367713, 'eval_P_Style': 0.0, 'eval_R_Style': 0.0, 'eval_f1_Style': 0.0, 'eval_P_Meaning-Changed': 0.315625, 'eval_R_Meaning-Changed': 0.4675925925925926, 'eval_f1_Meaning-Changed': 0.3768656716417911, 'eval_runtime': 166.9558, 'eval_samples_per_second': 9.224, 'eval_steps_per_second': 0.15, 'epoch': 5.91}\n",
            " 59% 1750/2960 [2:52:36<1:44:23,  5.18s/it]\n",
            "100% 25/25 [02:40<00:00,  5.23s/it]\n",
            "{'loss': 0.9487, 'learning_rate': 3.918918918918919e-06, 'epoch': 6.08}\n",
            "{'loss': 0.9098, 'learning_rate': 3.5810810810810816e-06, 'epoch': 6.41}\n",
            "{'loss': 0.8743, 'learning_rate': 3.2432432432432437e-06, 'epoch': 6.75}\n",
            " 68% 2000/2960 [3:14:31<1:23:13,  5.20s/it]\n",
            "  0% 0/25 [00:00<?, ?it/s]\n",
            "  8% 2/25 [00:06<01:16,  3.33s/it]\n",
            " 12% 3/25 [00:13<01:43,  4.72s/it]\n",
            " 16% 4/25 [00:19<01:54,  5.44s/it]\n",
            " 20% 5/25 [00:26<01:57,  5.89s/it]\n",
            " 24% 6/25 [00:33<01:56,  6.14s/it]\n",
            " 28% 7/25 [00:40<01:53,  6.32s/it]\n",
            " 32% 8/25 [00:46<01:49,  6.45s/it]\n",
            " 36% 9/25 [00:53<01:44,  6.54s/it]\n",
            " 40% 10/25 [01:00<01:38,  6.60s/it]\n",
            " 44% 11/25 [01:07<01:33,  6.65s/it]\n",
            " 48% 12/25 [01:13<01:26,  6.66s/it]\n",
            " 52% 13/25 [01:20<01:22,  6.84s/it]\n",
            " 56% 14/25 [01:28<01:16,  6.92s/it]\n",
            " 60% 15/25 [01:35<01:09,  6.97s/it]\n",
            " 64% 16/25 [01:42<01:03,  7.03s/it]\n",
            " 68% 17/25 [01:49<00:56,  7.08s/it]\n",
            " 72% 18/25 [01:56<00:49,  7.10s/it]\n",
            " 76% 19/25 [02:03<00:42,  7.16s/it]\n",
            " 80% 20/25 [02:11<00:35,  7.20s/it]\n",
            " 84% 21/25 [02:18<00:28,  7.22s/it]\n",
            " 88% 22/25 [02:25<00:21,  7.24s/it]\n",
            " 92% 23/25 [02:33<00:14,  7.25s/it]\n",
            " 96% 24/25 [02:40<00:07,  7.26s/it]\n",
            "100% 25/25 [02:40<00:00,  5.22s/it]/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "                                           \n",
            "{'eval_loss': 1.4653006792068481, 'eval_accuracy': 0.4668831168831169, 'eval_P_Clarity': 0.5166931637519873, 'eval_R_Clarity': 0.517515923566879, 'eval_f1_Clarity': 0.5171042163882259, 'eval_P_Fluency': 0.5407098121085595, 'eval_R_Fluency': 0.5630434782608695, 'eval_f1_Fluency': 0.551650692225772, 'eval_P_Coherence': 0.45614035087719296, 'eval_R_Coherence': 0.14130434782608695, 'eval_f1_Coherence': 0.21576763485477177, 'eval_P_Style': 0.0, 'eval_R_Style': 0.0, 'eval_f1_Style': 0.0, 'eval_P_Meaning-Changed': 0.2906666666666667, 'eval_R_Meaning-Changed': 0.5046296296296297, 'eval_f1_Meaning-Changed': 0.36886632825719123, 'eval_runtime': 167.4933, 'eval_samples_per_second': 9.194, 'eval_steps_per_second': 0.149, 'epoch': 6.75}\n",
            " 68% 2000/2960 [3:17:19<1:23:13,  5.20s/it]\n",
            "100% 25/25 [02:40<00:00,  5.22s/it]\n",
            "{'loss': 0.898, 'learning_rate': 2.9054054054054054e-06, 'epoch': 7.09}\n",
            "{'loss': 0.8111, 'learning_rate': 2.5675675675675675e-06, 'epoch': 7.43}\n",
            " 76% 2250/2960 [3:39:13<1:01:29,  5.20s/it]\n",
            "  0% 0/25 [00:00<?, ?it/s]\n",
            "  8% 2/25 [00:06<01:16,  3.33s/it]\n",
            " 12% 3/25 [00:13<01:43,  4.70s/it]\n",
            " 16% 4/25 [00:19<01:54,  5.44s/it]\n",
            " 20% 5/25 [00:26<01:57,  5.87s/it]\n",
            " 24% 6/25 [00:33<01:56,  6.14s/it]\n",
            " 28% 7/25 [00:40<01:53,  6.31s/it]\n",
            " 32% 8/25 [00:46<01:49,  6.46s/it]\n",
            " 36% 9/25 [00:53<01:44,  6.53s/it]\n",
            " 40% 10/25 [01:00<01:38,  6.59s/it]\n",
            " 44% 11/25 [01:06<01:32,  6.63s/it]\n",
            " 48% 12/25 [01:13<01:26,  6.65s/it]\n",
            " 52% 13/25 [01:20<01:22,  6.85s/it]\n",
            " 56% 14/25 [01:28<01:16,  6.93s/it]\n",
            " 60% 15/25 [01:35<01:09,  7.00s/it]\n",
            " 64% 16/25 [01:42<01:03,  7.05s/it]\n",
            " 68% 17/25 [01:49<00:56,  7.11s/it]\n",
            " 72% 18/25 [01:56<00:49,  7.13s/it]\n",
            " 76% 19/25 [02:04<00:43,  7.18s/it]\n",
            " 80% 20/25 [02:11<00:36,  7.22s/it]\n",
            " 84% 21/25 [02:18<00:28,  7.24s/it]\n",
            " 88% 22/25 [02:25<00:21,  7.25s/it]\n",
            " 92% 23/25 [02:33<00:14,  7.26s/it]\n",
            " 96% 24/25 [02:40<00:07,  7.27s/it]\n",
            "100% 25/25 [02:41<00:00,  5.24s/it]/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "                                           \n",
            "{'eval_loss': 1.4815458059310913, 'eval_accuracy': 0.4688311688311688, 'eval_P_Clarity': 0.5126182965299685, 'eval_R_Clarity': 0.517515923566879, 'eval_f1_Clarity': 0.515055467511886, 'eval_P_Fluency': 0.5222672064777328, 'eval_R_Fluency': 0.5608695652173913, 'eval_f1_Fluency': 0.5408805031446541, 'eval_P_Coherence': 0.4069767441860465, 'eval_R_Coherence': 0.19021739130434784, 'eval_f1_Coherence': 0.2592592592592593, 'eval_P_Style': 0.0, 'eval_R_Style': 0.0, 'eval_f1_Style': 0.0, 'eval_P_Meaning-Changed': 0.31901840490797545, 'eval_R_Meaning-Changed': 0.48148148148148145, 'eval_f1_Meaning-Changed': 0.3837638376383764, 'eval_runtime': 167.6832, 'eval_samples_per_second': 9.184, 'eval_steps_per_second': 0.149, 'epoch': 7.59}\n",
            " 76% 2250/2960 [3:42:00<1:01:29,  5.20s/it]\n",
            "100% 25/25 [02:41<00:00,  5.24s/it]\n",
            "{'loss': 0.8223, 'learning_rate': 2.22972972972973e-06, 'epoch': 7.76}\n",
            "{'loss': 0.8105, 'learning_rate': 1.8918918918918922e-06, 'epoch': 8.1}\n",
            "{'loss': 0.7905, 'learning_rate': 1.5540540540540541e-06, 'epoch': 8.44}\n",
            " 84% 2500/2960 [4:03:57<39:51,  5.20s/it]\n",
            "  0% 0/25 [00:00<?, ?it/s]\n",
            "  8% 2/25 [00:06<01:15,  3.30s/it]\n",
            " 12% 3/25 [00:13<01:43,  4.68s/it]\n",
            " 16% 4/25 [00:19<01:53,  5.41s/it]\n",
            " 20% 5/25 [00:26<01:57,  5.87s/it]\n",
            " 24% 6/25 [00:33<01:56,  6.14s/it]\n",
            " 28% 7/25 [00:39<01:53,  6.32s/it]\n",
            " 32% 8/25 [00:46<01:49,  6.46s/it]\n",
            " 36% 9/25 [00:53<01:44,  6.53s/it]\n",
            " 40% 10/25 [01:00<01:38,  6.60s/it]\n",
            " 44% 11/25 [01:06<01:32,  6.64s/it]\n",
            " 48% 12/25 [01:13<01:26,  6.66s/it]\n",
            " 52% 13/25 [01:20<01:22,  6.85s/it]\n",
            " 56% 14/25 [01:28<01:16,  6.93s/it]\n",
            " 60% 15/25 [01:35<01:09,  7.00s/it]\n",
            " 64% 16/25 [01:42<01:03,  7.05s/it]\n",
            " 68% 17/25 [01:49<00:56,  7.11s/it]\n",
            " 72% 18/25 [01:56<00:49,  7.14s/it]\n",
            " 76% 19/25 [02:04<00:43,  7.19s/it]\n",
            " 80% 20/25 [02:11<00:36,  7.23s/it]\n",
            " 84% 21/25 [02:18<00:29,  7.25s/it]\n",
            " 88% 22/25 [02:26<00:21,  7.26s/it]\n",
            " 92% 23/25 [02:33<00:14,  7.28s/it]\n",
            " 96% 24/25 [02:40<00:07,  7.29s/it]\n",
            "100% 25/25 [02:41<00:00,  5.25s/it]/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "                                         \n",
            "{'eval_loss': 1.4906901121139526, 'eval_accuracy': 0.4844155844155844, 'eval_P_Clarity': 0.5041095890410959, 'eval_R_Clarity': 0.5859872611464968, 'eval_f1_Clarity': 0.5419734904270987, 'eval_P_Fluency': 0.5448717948717948, 'eval_R_Fluency': 0.5543478260869565, 'eval_f1_Fluency': 0.5495689655172414, 'eval_P_Coherence': 0.38144329896907214, 'eval_R_Coherence': 0.20108695652173914, 'eval_f1_Coherence': 0.2633451957295374, 'eval_P_Style': 0.0, 'eval_R_Style': 0.0, 'eval_f1_Style': 0.0, 'eval_P_Meaning-Changed': 0.3510204081632653, 'eval_R_Meaning-Changed': 0.39814814814814814, 'eval_f1_Meaning-Changed': 0.37310195227765725, 'eval_runtime': 167.7902, 'eval_samples_per_second': 9.178, 'eval_steps_per_second': 0.149, 'epoch': 8.44}\n",
            " 84% 2500/2960 [4:06:44<39:51,  5.20s/it]\n",
            "100% 25/25 [02:41<00:00,  5.25s/it]\n",
            "{'loss': 0.7782, 'learning_rate': 1.2162162162162164e-06, 'epoch': 8.78}\n",
            "{'loss': 0.7279, 'learning_rate': 8.783783783783785e-07, 'epoch': 9.11}\n",
            " 93% 2750/2960 [4:28:41<18:12,  5.20s/it]\n",
            "  0% 0/25 [00:00<?, ?it/s]\n",
            "  8% 2/25 [00:06<01:15,  3.30s/it]\n",
            " 12% 3/25 [00:13<01:42,  4.66s/it]\n",
            " 16% 4/25 [00:19<01:53,  5.39s/it]\n",
            " 20% 5/25 [00:26<01:56,  5.82s/it]\n",
            " 24% 6/25 [00:33<01:55,  6.10s/it]\n",
            " 28% 7/25 [00:39<01:53,  6.29s/it]\n",
            " 32% 8/25 [00:46<01:49,  6.43s/it]\n",
            " 36% 9/25 [00:53<01:44,  6.50s/it]\n",
            " 40% 10/25 [00:59<01:38,  6.56s/it]\n",
            " 44% 11/25 [01:06<01:32,  6.59s/it]\n",
            " 48% 12/25 [01:13<01:25,  6.61s/it]\n",
            " 52% 13/25 [01:20<01:21,  6.80s/it]\n",
            " 56% 14/25 [01:27<01:15,  6.89s/it]\n",
            " 60% 15/25 [01:34<01:09,  6.95s/it]\n",
            " 64% 16/25 [01:41<01:03,  7.02s/it]\n",
            " 68% 17/25 [01:48<00:56,  7.07s/it]\n",
            " 72% 18/25 [01:56<00:49,  7.10s/it]\n",
            " 76% 19/25 [02:03<00:42,  7.15s/it]\n",
            " 80% 20/25 [02:10<00:35,  7.20s/it]\n",
            " 84% 21/25 [02:17<00:28,  7.22s/it]\n",
            " 88% 22/25 [02:25<00:21,  7.25s/it]\n",
            " 92% 23/25 [02:32<00:14,  7.26s/it]\n",
            " 96% 24/25 [02:39<00:07,  7.27s/it]\n",
            "100% 25/25 [02:40<00:00,  5.23s/it]/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "                                         \n",
            "{'eval_loss': 1.534913182258606, 'eval_accuracy': 0.4694805194805195, 'eval_P_Clarity': 0.49768160741885625, 'eval_R_Clarity': 0.5127388535031847, 'eval_f1_Clarity': 0.5050980392156864, 'eval_P_Fluency': 0.5469728601252609, 'eval_R_Fluency': 0.5695652173913044, 'eval_f1_Fluency': 0.5580404685835995, 'eval_P_Coherence': 0.36792452830188677, 'eval_R_Coherence': 0.21195652173913043, 'eval_f1_Coherence': 0.2689655172413793, 'eval_P_Style': 0.0, 'eval_R_Style': 0.0, 'eval_f1_Style': 0.0, 'eval_P_Meaning-Changed': 0.3246753246753247, 'eval_R_Meaning-Changed': 0.46296296296296297, 'eval_f1_Meaning-Changed': 0.38167938931297707, 'eval_runtime': 166.9458, 'eval_samples_per_second': 9.225, 'eval_steps_per_second': 0.15, 'epoch': 9.28}\n",
            " 93% 2750/2960 [4:31:28<18:12,  5.20s/it]\n",
            "100% 25/25 [02:40<00:00,  5.23s/it]\n",
            "{'loss': 0.7588, 'learning_rate': 5.405405405405406e-07, 'epoch': 9.45}\n",
            "{'loss': 0.7266, 'learning_rate': 2.0270270270270273e-07, 'epoch': 9.79}\n",
            "{'train_runtime': 17395.8889, 'train_samples_per_second': 2.725, 'train_steps_per_second': 0.17, 'train_loss': 1.0083160851452801, 'epoch': 9.99}\n",
            "100% 2960/2960 [4:49:55<00:00,  5.88s/it]\n",
            "100% 25/25 [02:40<00:00,  5.25s/it]/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "100% 25/25 [02:40<00:00,  6.44s/it]\n",
            "{'eval_loss': 1.5406630039215088, 'eval_accuracy': 0.475974025974026, 'eval_P_Clarity': 0.49719887955182074, 'eval_R_Clarity': 0.5652866242038217, 'eval_f1_Clarity': 0.5290611028315947, 'eval_P_Fluency': 0.5446623093681917, 'eval_R_Fluency': 0.5434782608695652, 'eval_f1_Fluency': 0.544069640914037, 'eval_P_Coherence': 0.3958333333333333, 'eval_R_Coherence': 0.20652173913043478, 'eval_f1_Coherence': 0.27142857142857146, 'eval_P_Style': 0.0, 'eval_R_Style': 0.0, 'eval_f1_Style': 0.0, 'eval_P_Meaning-Changed': 0.33210332103321033, 'eval_R_Meaning-Changed': 0.4166666666666667, 'eval_f1_Meaning-Changed': 0.3696098562628337, 'eval_runtime': 167.5902, 'eval_samples_per_second': 9.189, 'eval_steps_per_second': 0.149, 'epoch': 9.99}\n",
            "CPU times: user 1min 33s, sys: 12.4 s, total: 1min 45s\n",
            "Wall time: 4h 53min 30s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "!python 'train_intent_classifier.py' --upsample_values 1 1 1 1 1 --weights 1. 1. 1. 1. 1. -e 10  -s roberta-large-ten -d '/content/cs678-cp1-cp2/multi_data/fully_multi'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EN9zfkTEkInP"
      },
      "source": [
        "#### Model 2.1.2 XLM-RoBERTa 5 epochs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Drxi4kFhkInP"
      },
      "source": [
        "##### Zero Shot\n",
        "\n",
        "train: english human_sent_level>train.json\n",
        "\n",
        "dev: english human_sent_level>dev.json\n",
        "\n",
        "test: multilingual human_sent_level>test.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_w4DIxE4kInP",
        "outputId": "fc0c577c-3691-47d5-df10-dc0fee499431"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/iterater/code/IteraTeR_ACL2022/model/intent_classification\n",
            "2023-05-06 23:14:59.782132: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Using custom data configuration zeroshot_multi-f2a30da9140d8237\n",
            "Downloading and preparing dataset json/zeroshot_multi to /root/.cache/huggingface/datasets/json/zeroshot_multi-f2a30da9140d8237/0.0.0/ac0ca5f5289a6cf108e706efcf040422dbbfa8e658dee6a819f20d76bb84d26b...\n",
            "100% 3/3 [00:00<00:00, 11439.01it/s]\n",
            "100% 3/3 [00:00<00:00, 1917.25it/s]\n",
            "Dataset json downloaded and prepared to /root/.cache/huggingface/datasets/json/zeroshot_multi-f2a30da9140d8237/0.0.0/ac0ca5f5289a6cf108e706efcf040422dbbfa8e658dee6a819f20d76bb84d26b. Subsequent calls will reuse this data.\n",
            "100% 3/3 [00:00<00:00, 487.90it/s]\n",
            "[1258, 739, 311, 100, 807]\n",
            "[157, 115, 46, 13, 54]\n",
            "Downloading (…)tencepiece.bpe.model: 100% 5.07M/5.07M [00:00<00:00, 11.8MB/s]\n",
            "Downloading (…)lve/main/config.json: 100% 616/616 [00:00<00:00, 4.47MB/s]\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
            "Downloading (…)lve/main/config.json: 100% 616/616 [00:00<00:00, 4.12MB/s]\n",
            "Downloading pytorch_model.bin: 100% 2.24G/2.24G [00:08<00:00, 250MB/s]\n",
            "Some weights of the model checkpoint at xlm-roberta-large were not used when initializing XLMRobertaModel: ['lm_head.dense.weight', 'lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight']\n",
            "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "{'loss': 1.4177, 'learning_rate': 9.502487562189056e-06, 'epoch': 0.25}\n",
            "{'loss': 1.3912, 'learning_rate': 9.00497512437811e-06, 'epoch': 0.5}\n",
            " 12% 250/2010 [11:25<1:20:36,  2.75s/it]\n",
            "  0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            " 29% 2/7 [00:03<00:09,  1.95s/it]\u001b[A\n",
            " 43% 3/7 [00:07<00:11,  2.76s/it]\u001b[A\n",
            " 57% 4/7 [00:11<00:09,  3.19s/it]\u001b[A\n",
            " 71% 5/7 [00:15<00:06,  3.46s/it]\u001b[A\n",
            " 86% 6/7 [00:19<00:03,  3.60s/it]\u001b[A/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "\n",
            "{'eval_loss': 1.3349980115890503, 'eval_accuracy': 0.43636363636363634, 'eval_P_Clarity': 0.42120343839541546, 'eval_R_Clarity': 0.9363057324840764, 'eval_f1_Clarity': 0.5810276679841897, 'eval_P_Fluency': 0.75, 'eval_R_Fluency': 0.10434782608695652, 'eval_f1_Fluency': 0.183206106870229, 'eval_P_Coherence': 0.0, 'eval_R_Coherence': 0.0, 'eval_f1_Coherence': 0.0, 'eval_P_Style': 0.0, 'eval_R_Style': 0.0, 'eval_f1_Style': 0.0, 'eval_P_Meaning-Changed': 0.45, 'eval_R_Meaning-Changed': 0.16666666666666666, 'eval_f1_Meaning-Changed': 0.24324324324324323, 'eval_runtime': 23.5891, 'eval_samples_per_second': 16.321, 'eval_steps_per_second': 0.297, 'epoch': 0.62}\n",
            "\n",
            " 12% 250/2010 [11:48<1:20:36,  2.75s/it]\n",
            "{'loss': 1.2777, 'learning_rate': 8.507462686567165e-06, 'epoch': 0.75}\n",
            "{'loss': 1.2235, 'learning_rate': 8.00995024875622e-06, 'epoch': 1.0}\n",
            "{'loss': 1.0858, 'learning_rate': 7.512437810945274e-06, 'epoch': 1.24}\n",
            " 25% 500/2010 [23:43<1:09:09,  2.75s/it]\n",
            "  0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            " 29% 2/7 [00:03<00:09,  1.96s/it]\u001b[A\n",
            " 43% 3/7 [00:07<00:11,  2.78s/it]\u001b[A\n",
            " 57% 4/7 [00:11<00:09,  3.20s/it]\u001b[A\n",
            " 71% 5/7 [00:15<00:06,  3.46s/it]\u001b[A\n",
            " 86% 6/7 [00:19<00:03,  3.60s/it]\u001b[A/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "\n",
            "{'eval_loss': 1.0409525632858276, 'eval_accuracy': 0.6441558441558441, 'eval_P_Clarity': 0.6290322580645161, 'eval_R_Clarity': 0.7452229299363057, 'eval_f1_Clarity': 0.6822157434402333, 'eval_P_Fluency': 0.6770186335403726, 'eval_R_Fluency': 0.9478260869565217, 'eval_f1_Fluency': 0.7898550724637681, 'eval_P_Coherence': 0.0, 'eval_R_Coherence': 0.0, 'eval_f1_Coherence': 0.0, 'eval_P_Style': 0.0, 'eval_R_Style': 0.0, 'eval_f1_Style': 0.0, 'eval_P_Meaning-Changed': 0.5789473684210527, 'eval_R_Meaning-Changed': 0.4074074074074074, 'eval_f1_Meaning-Changed': 0.47826086956521735, 'eval_runtime': 23.6097, 'eval_samples_per_second': 16.307, 'eval_steps_per_second': 0.296, 'epoch': 1.24}\n",
            "\n",
            " 25% 500/2010 [24:07<1:09:09,  2.75s/it]\n",
            "{'loss': 0.9462, 'learning_rate': 7.014925373134329e-06, 'epoch': 1.49}\n",
            "{'loss': 0.9193, 'learning_rate': 6.517412935323384e-06, 'epoch': 1.74}\n",
            " 37% 750/2010 [36:03<57:35,  2.74s/it]\n",
            "  0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            " 29% 2/7 [00:03<00:09,  1.95s/it]\u001b[A\n",
            " 43% 3/7 [00:07<00:11,  2.77s/it]\u001b[A\n",
            " 57% 4/7 [00:11<00:09,  3.19s/it]\u001b[A\n",
            " 71% 5/7 [00:15<00:06,  3.46s/it]\u001b[A\n",
            " 86% 6/7 [00:19<00:03,  3.61s/it]\u001b[A/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "\n",
            "{'eval_loss': 0.9258266687393188, 'eval_accuracy': 0.6779220779220779, 'eval_P_Clarity': 0.6354679802955665, 'eval_R_Clarity': 0.821656050955414, 'eval_f1_Clarity': 0.7166666666666668, 'eval_P_Fluency': 0.7863247863247863, 'eval_R_Fluency': 0.8, 'eval_f1_Fluency': 0.793103448275862, 'eval_P_Coherence': 0.7142857142857143, 'eval_R_Coherence': 0.10869565217391304, 'eval_f1_Coherence': 0.18867924528301885, 'eval_P_Style': 0.0, 'eval_R_Style': 0.0, 'eval_f1_Style': 0.0, 'eval_P_Meaning-Changed': 0.603448275862069, 'eval_R_Meaning-Changed': 0.6481481481481481, 'eval_f1_Meaning-Changed': 0.625, 'eval_runtime': 23.6032, 'eval_samples_per_second': 16.311, 'eval_steps_per_second': 0.297, 'epoch': 1.87}\n",
            "\n",
            " 37% 750/2010 [36:26<57:35,  2.74s/it]\n",
            "{'loss': 0.9098, 'learning_rate': 6.019900497512439e-06, 'epoch': 1.99}\n",
            "{'loss': 0.7689, 'learning_rate': 5.522388059701493e-06, 'epoch': 2.24}\n",
            "{'loss': 0.7897, 'learning_rate': 5.024875621890548e-06, 'epoch': 2.49}\n",
            " 50% 1000/2010 [48:22<46:08,  2.74s/it]\n",
            "  0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            " 29% 2/7 [00:03<00:09,  1.95s/it]\u001b[A\n",
            " 43% 3/7 [00:07<00:11,  2.77s/it]\u001b[A\n",
            " 57% 4/7 [00:11<00:09,  3.19s/it]\u001b[A\n",
            " 71% 5/7 [00:15<00:06,  3.45s/it]\u001b[A\n",
            " 86% 6/7 [00:19<00:03,  3.60s/it]\u001b[A/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "\n",
            "{'eval_loss': 0.8699326515197754, 'eval_accuracy': 0.7142857142857143, 'eval_P_Clarity': 0.7041420118343196, 'eval_R_Clarity': 0.7579617834394905, 'eval_f1_Clarity': 0.7300613496932516, 'eval_P_Fluency': 0.8290598290598291, 'eval_R_Fluency': 0.8434782608695652, 'eval_f1_Fluency': 0.8362068965517241, 'eval_P_Coherence': 0.6428571428571429, 'eval_R_Coherence': 0.391304347826087, 'eval_f1_Coherence': 0.4864864864864865, 'eval_P_Style': 0.0, 'eval_R_Style': 0.0, 'eval_f1_Style': 0.0, 'eval_P_Meaning-Changed': 0.5774647887323944, 'eval_R_Meaning-Changed': 0.7592592592592593, 'eval_f1_Meaning-Changed': 0.656, 'eval_runtime': 23.5646, 'eval_samples_per_second': 16.338, 'eval_steps_per_second': 0.297, 'epoch': 2.49}\n",
            "\n",
            " 50% 1000/2010 [48:46<46:08,  2.74s/it]\n",
            "{'loss': 0.6879, 'learning_rate': 4.527363184079602e-06, 'epoch': 2.74}\n",
            "{'loss': 0.7281, 'learning_rate': 4.029850746268657e-06, 'epoch': 2.99}\n",
            " 62% 1250/2010 [1:00:42<34:48,  2.75s/it]\n",
            "  0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            " 29% 2/7 [00:03<00:09,  1.95s/it]\u001b[A\n",
            " 43% 3/7 [00:07<00:11,  2.77s/it]\u001b[A\n",
            " 57% 4/7 [00:11<00:09,  3.20s/it]\u001b[A\n",
            " 71% 5/7 [00:15<00:06,  3.46s/it]\u001b[A\n",
            " 86% 6/7 [00:19<00:03,  3.61s/it]\u001b[A/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "\n",
            "{'eval_loss': 0.8657949566841125, 'eval_accuracy': 0.7168831168831169, 'eval_P_Clarity': 0.7283950617283951, 'eval_R_Clarity': 0.7515923566878981, 'eval_f1_Clarity': 0.7398119122257054, 'eval_P_Fluency': 0.7795275590551181, 'eval_R_Fluency': 0.8608695652173913, 'eval_f1_Fluency': 0.8181818181818182, 'eval_P_Coherence': 0.5641025641025641, 'eval_R_Coherence': 0.4782608695652174, 'eval_f1_Coherence': 0.5176470588235293, 'eval_P_Style': 0.0, 'eval_R_Style': 0.0, 'eval_f1_Style': 0.0, 'eval_P_Meaning-Changed': 0.6491228070175439, 'eval_R_Meaning-Changed': 0.6851851851851852, 'eval_f1_Meaning-Changed': 0.6666666666666666, 'eval_runtime': 23.6077, 'eval_samples_per_second': 16.308, 'eval_steps_per_second': 0.297, 'epoch': 3.11}\n",
            "\n",
            " 62% 1250/2010 [1:01:05<34:48,  2.75s/it]\n",
            "{'loss': 0.5634, 'learning_rate': 3.5323383084577117e-06, 'epoch': 3.23}\n",
            "{'loss': 0.5871, 'learning_rate': 3.0348258706467666e-06, 'epoch': 3.48}\n",
            "{'loss': 0.5209, 'learning_rate': 2.537313432835821e-06, 'epoch': 3.73}\n",
            " 75% 1500/2010 [1:13:03<23:18,  2.74s/it]\n",
            "  0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            " 29% 2/7 [00:03<00:09,  1.96s/it]\u001b[A\n",
            " 43% 3/7 [00:07<00:11,  2.78s/it]\u001b[A\n",
            " 57% 4/7 [00:11<00:09,  3.20s/it]\u001b[A\n",
            " 71% 5/7 [00:15<00:06,  3.46s/it]\u001b[A\n",
            " 86% 6/7 [00:19<00:03,  3.61s/it]\u001b[A/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "\n",
            "{'eval_loss': 0.95295649766922, 'eval_accuracy': 0.7142857142857143, 'eval_P_Clarity': 0.7341772151898734, 'eval_R_Clarity': 0.7388535031847133, 'eval_f1_Clarity': 0.7365079365079364, 'eval_P_Fluency': 0.8070175438596491, 'eval_R_Fluency': 0.8, 'eval_f1_Fluency': 0.8034934497816594, 'eval_P_Coherence': 0.5192307692307693, 'eval_R_Coherence': 0.5869565217391305, 'eval_f1_Coherence': 0.5510204081632654, 'eval_P_Style': 0.0, 'eval_R_Style': 0.0, 'eval_f1_Style': 0.0, 'eval_P_Meaning-Changed': 0.6557377049180327, 'eval_R_Meaning-Changed': 0.7407407407407407, 'eval_f1_Meaning-Changed': 0.6956521739130433, 'eval_runtime': 23.612, 'eval_samples_per_second': 16.305, 'eval_steps_per_second': 0.296, 'epoch': 3.73}\n",
            "\n",
            " 75% 1500/2010 [1:13:27<23:18,  2.74s/it]\n",
            "{'loss': 0.6384, 'learning_rate': 2.0398009950248755e-06, 'epoch': 3.98}\n",
            "{'loss': 0.4499, 'learning_rate': 1.5422885572139304e-06, 'epoch': 4.23}\n",
            " 87% 1750/2010 [1:25:23<11:53,  2.74s/it]\n",
            "  0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            " 29% 2/7 [00:03<00:09,  1.95s/it]\u001b[A\n",
            " 43% 3/7 [00:07<00:11,  2.77s/it]\u001b[A\n",
            " 57% 4/7 [00:11<00:09,  3.19s/it]\u001b[A\n",
            " 71% 5/7 [00:15<00:06,  3.45s/it]\u001b[A\n",
            " 86% 6/7 [00:19<00:03,  3.61s/it]\u001b[A/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "\n",
            "{'eval_loss': 0.9253208637237549, 'eval_accuracy': 0.7272727272727273, 'eval_P_Clarity': 0.6752577319587629, 'eval_R_Clarity': 0.8343949044585988, 'eval_f1_Clarity': 0.7464387464387465, 'eval_P_Fluency': 0.8392857142857143, 'eval_R_Fluency': 0.8173913043478261, 'eval_f1_Fluency': 0.8281938325991189, 'eval_P_Coherence': 0.75, 'eval_R_Coherence': 0.391304347826087, 'eval_f1_Coherence': 0.5142857142857143, 'eval_P_Style': 0.0, 'eval_R_Style': 0.0, 'eval_f1_Style': 0.0, 'eval_P_Meaning-Changed': 0.6727272727272727, 'eval_R_Meaning-Changed': 0.6851851851851852, 'eval_f1_Meaning-Changed': 0.6788990825688074, 'eval_runtime': 23.5895, 'eval_samples_per_second': 16.321, 'eval_steps_per_second': 0.297, 'epoch': 4.35}\n",
            "\n",
            " 87% 1750/2010 [1:25:46<11:53,  2.74s/it]\n",
            "{'loss': 0.4078, 'learning_rate': 1.044776119402985e-06, 'epoch': 4.48}\n",
            "{'loss': 0.5169, 'learning_rate': 5.472636815920398e-07, 'epoch': 4.73}\n",
            "{'loss': 0.4858, 'learning_rate': 4.975124378109453e-08, 'epoch': 4.98}\n",
            "100% 2000/2010 [1:37:42<00:27,  2.76s/it]\n",
            "  0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            " 29% 2/7 [00:03<00:09,  1.95s/it]\u001b[A\n",
            " 43% 3/7 [00:07<00:11,  2.77s/it]\u001b[A\n",
            " 57% 4/7 [00:11<00:09,  3.19s/it]\u001b[A\n",
            " 71% 5/7 [00:15<00:06,  3.45s/it]\u001b[A\n",
            " 86% 6/7 [00:19<00:03,  3.61s/it]\u001b[A/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "\n",
            "{'eval_loss': 0.9483374953269958, 'eval_accuracy': 0.7246753246753247, 'eval_P_Clarity': 0.7109826589595376, 'eval_R_Clarity': 0.7834394904458599, 'eval_f1_Clarity': 0.7454545454545456, 'eval_P_Fluency': 0.8333333333333334, 'eval_R_Fluency': 0.8260869565217391, 'eval_f1_Fluency': 0.8296943231441049, 'eval_P_Coherence': 0.5945945945945946, 'eval_R_Coherence': 0.4782608695652174, 'eval_f1_Coherence': 0.5301204819277109, 'eval_P_Style': 0.0, 'eval_R_Style': 0.0, 'eval_f1_Style': 0.0, 'eval_P_Meaning-Changed': 0.639344262295082, 'eval_R_Meaning-Changed': 0.7222222222222222, 'eval_f1_Meaning-Changed': 0.6782608695652174, 'eval_runtime': 23.5957, 'eval_samples_per_second': 16.317, 'eval_steps_per_second': 0.297, 'epoch': 4.98}\n",
            "\n",
            "100% 2000/2010 [1:38:06<00:27,  2.76s/it]\n",
            "{'train_runtime': 5942.7921, 'train_samples_per_second': 2.705, 'train_steps_per_second': 0.338, 'train_loss': 0.8137577676061374, 'epoch': 5.0}\n",
            "100% 2010/2010 [1:39:02<00:00,  2.96s/it]\n",
            " 86% 6/7 [00:20<00:03,  3.67s/it]/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "100% 7/7 [00:20<00:00,  2.88s/it]\n",
            "{'eval_loss': 0.9485331177711487, 'eval_accuracy': 0.7246753246753247, 'eval_P_Clarity': 0.7109826589595376, 'eval_R_Clarity': 0.7834394904458599, 'eval_f1_Clarity': 0.7454545454545456, 'eval_P_Fluency': 0.8333333333333334, 'eval_R_Fluency': 0.8260869565217391, 'eval_f1_Fluency': 0.8296943231441049, 'eval_P_Coherence': 0.5945945945945946, 'eval_R_Coherence': 0.4782608695652174, 'eval_f1_Coherence': 0.5301204819277109, 'eval_P_Style': 0.0, 'eval_R_Style': 0.0, 'eval_f1_Style': 0.0, 'eval_P_Meaning-Changed': 0.639344262295082, 'eval_R_Meaning-Changed': 0.7222222222222222, 'eval_f1_Meaning-Changed': 0.6782608695652174, 'eval_runtime': 24.346, 'eval_samples_per_second': 15.814, 'eval_steps_per_second': 0.288, 'epoch': 5.0}\n",
            "CPU times: user 22.5 s, sys: 2.94 s, total: 25.4 s\n",
            "Wall time: 1h 40min 6s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "%cd /content/iterater/code/IteraTeR_ACL2022/model/intent_classification\n",
        "\n",
        "!python 'xlmroberta_train_intent_classifier.py' --upsample_values 1 1 1 1 1 --weights 1. 1. 1. 1. 1. -e 5  -s xlmroberta-large-ten -d '/content/cs678-cp1-cp2/multi_data/zeroshot_multi'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jfsPdGJukInQ"
      },
      "source": [
        "##### Fully Supervised\n",
        "\n",
        "train: multilingual human_sent_level>train.json\n",
        "\n",
        "dev: multilingual human_sent_level>dev.json\n",
        "\n",
        "test: multilingual human_sent_level>test.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ohnyGl2MkInQ",
        "outputId": "15e69bf2-f1c2-40d7-f19c-d80ad1a85e13"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "s2023-05-02 21:08:15.348436: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Using custom data configuration xlmroberta_data-dd1f94c45d371e0d\n",
            "Downloading and preparing dataset json/xlmroberta_data to /root/.cache/huggingface/datasets/json/xlmroberta_data-dd1f94c45d371e0d/0.0.0/ac0ca5f5289a6cf108e706efcf040422dbbfa8e658dee6a819f20d76bb84d26b...\n",
            "100% 3/3 [00:00<00:00, 11346.18it/s]\n",
            "100% 3/3 [00:00<00:00, 1451.82it/s]\n",
            "Dataset json downloaded and prepared to /root/.cache/huggingface/datasets/json/xlmroberta_data-dd1f94c45d371e0d/0.0.0/ac0ca5f5289a6cf108e706efcf040422dbbfa8e658dee6a819f20d76bb84d26b. Subsequent calls will reuse this data.\n",
            "100% 3/3 [00:00<00:00, 411.17it/s]\n",
            "[1960, 908, 364, 108, 1400]\n",
            "[628, 460, 184, 52, 216]\n",
            "Downloading (…)tencepiece.bpe.model: 100% 5.07M/5.07M [00:00<00:00, 64.2MB/s]\n",
            "Downloading (…)lve/main/config.json: 100% 616/616 [00:00<00:00, 3.62MB/s]\n",
            "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
            "Downloading (…)lve/main/config.json: 100% 616/616 [00:00<00:00, 4.03MB/s]\n",
            "Downloading pytorch_model.bin: 100% 2.24G/2.24G [00:10<00:00, 206MB/s]\n",
            "Some weights of the model checkpoint at xlm-roberta-large were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.decoder.weight', 'lm_head.dense.weight']\n",
            "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "{'loss': 1.3821, 'learning_rate': 9.324324324324325e-06, 'epoch': 0.34}\n",
            "{'loss': 1.312, 'learning_rate': 8.64864864864865e-06, 'epoch': 0.68}\n",
            " 17% 250/1480 [09:50<49:23,  2.41s/it]\n",
            "  0% 0/25 [00:00<?, ?it/s]\n",
            "  8% 2/25 [00:02<00:24,  1.07s/it]\n",
            " 12% 3/25 [00:04<00:33,  1.52s/it]\n",
            " 16% 4/25 [00:06<00:37,  1.76s/it]\n",
            " 20% 5/25 [00:08<00:38,  1.91s/it]\n",
            " 24% 6/25 [00:10<00:37,  1.99s/it]\n",
            " 28% 7/25 [00:12<00:36,  2.03s/it]\n",
            " 32% 8/25 [00:15<00:34,  2.05s/it]\n",
            " 36% 9/25 [00:17<00:33,  2.07s/it]\n",
            " 40% 10/25 [00:19<00:31,  2.08s/it]\n",
            " 44% 11/25 [00:21<00:29,  2.09s/it]\n",
            " 48% 12/25 [00:23<00:27,  2.10s/it]\n",
            " 52% 13/25 [00:25<00:25,  2.11s/it]\n",
            " 56% 14/25 [00:27<00:23,  2.12s/it]\n",
            " 60% 15/25 [00:29<00:21,  2.13s/it]\n",
            " 64% 16/25 [00:32<00:19,  2.14s/it]\n",
            " 68% 17/25 [00:34<00:17,  2.16s/it]\n",
            " 72% 18/25 [00:36<00:15,  2.16s/it]\n",
            " 76% 19/25 [00:38<00:12,  2.16s/it]\n",
            " 80% 20/25 [00:40<00:10,  2.17s/it]\n",
            " 84% 21/25 [00:42<00:08,  2.16s/it]\n",
            " 88% 22/25 [00:45<00:06,  2.17s/it]\n",
            " 92% 23/25 [00:47<00:04,  2.18s/it]\n",
            " 96% 24/25 [00:49<00:02,  2.18s/it]\n",
            "100% 25/25 [00:49<00:00,  1.58s/it]/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "                                      \n",
            "{'eval_loss': 1.3284872770309448, 'eval_accuracy': 0.4253246753246753, 'eval_P_Clarity': 0.42166517457475383, 'eval_R_Clarity': 0.75, 'eval_f1_Clarity': 0.5398280802292265, 'eval_P_Fluency': 0.43125, 'eval_R_Fluency': 0.3, 'eval_f1_Fluency': 0.35384615384615387, 'eval_P_Coherence': 0.0, 'eval_R_Coherence': 0.0, 'eval_f1_Coherence': 0.0, 'eval_P_Style': 0.0, 'eval_R_Style': 0.0, 'eval_f1_Style': 0.0, 'eval_P_Meaning-Changed': 0.44660194174757284, 'eval_R_Meaning-Changed': 0.21296296296296297, 'eval_f1_Meaning-Changed': 0.2884012539184953, 'eval_runtime': 51.8561, 'eval_samples_per_second': 29.698, 'eval_steps_per_second': 0.482, 'epoch': 0.84}\n",
            " 17% 250/1480 [10:42<49:23,  2.41s/it]\n",
            "100% 25/25 [00:49<00:00,  1.58s/it]\n",
            "{'loss': 1.2161, 'learning_rate': 7.972972972972974e-06, 'epoch': 1.01}\n",
            "{'loss': 1.1637, 'learning_rate': 7.297297297297298e-06, 'epoch': 1.35}\n",
            "{'loss': 1.1043, 'learning_rate': 6.621621621621622e-06, 'epoch': 1.69}\n",
            " 34% 500/1480 [21:14<39:22,  2.41s/it]\n",
            "  0% 0/25 [00:00<?, ?it/s]\n",
            "  8% 2/25 [00:02<00:24,  1.07s/it]\n",
            " 12% 3/25 [00:04<00:33,  1.52s/it]\n",
            " 16% 4/25 [00:06<00:36,  1.76s/it]\n",
            " 20% 5/25 [00:08<00:38,  1.90s/it]\n",
            " 24% 6/25 [00:10<00:37,  1.98s/it]\n",
            " 28% 7/25 [00:12<00:36,  2.02s/it]\n",
            " 32% 8/25 [00:14<00:34,  2.04s/it]\n",
            " 36% 9/25 [00:17<00:32,  2.06s/it]\n",
            " 40% 10/25 [00:19<00:31,  2.07s/it]\n",
            " 44% 11/25 [00:21<00:29,  2.08s/it]\n",
            " 48% 12/25 [00:23<00:27,  2.09s/it]\n",
            " 52% 13/25 [00:25<00:25,  2.10s/it]\n",
            " 56% 14/25 [00:27<00:23,  2.12s/it]\n",
            " 60% 15/25 [00:29<00:21,  2.12s/it]\n",
            " 64% 16/25 [00:31<00:19,  2.13s/it]\n",
            " 68% 17/25 [00:34<00:17,  2.14s/it]\n",
            " 72% 18/25 [00:36<00:15,  2.15s/it]\n",
            " 76% 19/25 [00:38<00:12,  2.15s/it]\n",
            " 80% 20/25 [00:40<00:10,  2.15s/it]\n",
            " 84% 21/25 [00:42<00:08,  2.14s/it]\n",
            " 88% 22/25 [00:44<00:06,  2.15s/it]\n",
            " 92% 23/25 [00:47<00:04,  2.16s/it]\n",
            " 96% 24/25 [00:49<00:02,  2.16s/it]\n",
            "100% 25/25 [00:49<00:00,  1.57s/it]/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "                                      \n",
            "{'eval_loss': 1.3885070085525513, 'eval_accuracy': 0.42142857142857143, 'eval_P_Clarity': 0.47018739352640543, 'eval_R_Clarity': 0.4394904458598726, 'eval_f1_Clarity': 0.45432098765432094, 'eval_P_Fluency': 0.43890675241157556, 'eval_R_Fluency': 0.5934782608695652, 'eval_f1_Fluency': 0.5046210720887246, 'eval_P_Coherence': 0.0, 'eval_R_Coherence': 0.0, 'eval_f1_Coherence': 0.0, 'eval_P_Style': 0.0, 'eval_R_Style': 0.0, 'eval_f1_Style': 0.0, 'eval_P_Meaning-Changed': 0.3021148036253776, 'eval_R_Meaning-Changed': 0.46296296296296297, 'eval_f1_Meaning-Changed': 0.36563071297989036, 'eval_runtime': 51.5322, 'eval_samples_per_second': 29.884, 'eval_steps_per_second': 0.485, 'epoch': 1.69}\n",
            " 34% 500/1480 [22:06<39:22,  2.41s/it]\n",
            "100% 25/25 [00:49<00:00,  1.57s/it]\n",
            "{'loss': 1.056, 'learning_rate': 5.945945945945947e-06, 'epoch': 2.03}\n",
            "{'loss': 0.9527, 'learning_rate': 5.2702702702702705e-06, 'epoch': 2.36}\n",
            " 51% 750/1480 [32:35<29:18,  2.41s/it]\n",
            "  0% 0/25 [00:00<?, ?it/s]\n",
            "  8% 2/25 [00:02<00:24,  1.07s/it]\n",
            " 12% 3/25 [00:04<00:33,  1.52s/it]\n",
            " 16% 4/25 [00:06<00:36,  1.76s/it]\n",
            " 20% 5/25 [00:08<00:38,  1.91s/it]\n",
            " 24% 6/25 [00:10<00:37,  1.99s/it]\n",
            " 28% 7/25 [00:12<00:36,  2.02s/it]\n",
            " 32% 8/25 [00:14<00:34,  2.05s/it]\n",
            " 36% 9/25 [00:17<00:32,  2.06s/it]\n",
            " 40% 10/25 [00:19<00:31,  2.08s/it]\n",
            " 44% 11/25 [00:21<00:29,  2.09s/it]\n",
            " 48% 12/25 [00:23<00:27,  2.09s/it]\n",
            " 52% 13/25 [00:25<00:25,  2.11s/it]\n",
            " 56% 14/25 [00:27<00:23,  2.12s/it]\n",
            " 60% 15/25 [00:29<00:21,  2.13s/it]\n",
            " 64% 16/25 [00:32<00:19,  2.14s/it]\n",
            " 68% 17/25 [00:34<00:17,  2.15s/it]\n",
            " 72% 18/25 [00:36<00:15,  2.15s/it]\n",
            " 76% 19/25 [00:38<00:12,  2.15s/it]\n",
            " 80% 20/25 [00:40<00:10,  2.15s/it]\n",
            " 84% 21/25 [00:42<00:08,  2.15s/it]\n",
            " 88% 22/25 [00:44<00:06,  2.16s/it]\n",
            " 92% 23/25 [00:47<00:04,  2.17s/it]\n",
            " 96% 24/25 [00:49<00:02,  2.17s/it]\n",
            "100% 25/25 [00:49<00:00,  1.57s/it]/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "                                      \n",
            "{'eval_loss': 1.4302741289138794, 'eval_accuracy': 0.4409090909090909, 'eval_P_Clarity': 0.49503311258278143, 'eval_R_Clarity': 0.47611464968152867, 'eval_f1_Clarity': 0.48538961038961037, 'eval_P_Fluency': 0.4160887656033287, 'eval_R_Fluency': 0.6521739130434783, 'eval_f1_Fluency': 0.5080440304826418, 'eval_P_Coherence': 0.0, 'eval_R_Coherence': 0.0, 'eval_f1_Coherence': 0.0, 'eval_P_Style': 0.0, 'eval_R_Style': 0.0, 'eval_f1_Style': 0.0, 'eval_P_Meaning-Changed': 0.37209302325581395, 'eval_R_Meaning-Changed': 0.37037037037037035, 'eval_f1_Meaning-Changed': 0.37122969837587005, 'eval_runtime': 51.6649, 'eval_samples_per_second': 29.807, 'eval_steps_per_second': 0.484, 'epoch': 2.53}\n",
            " 51% 750/1480 [33:27<29:18,  2.41s/it]\n",
            "100% 25/25 [00:49<00:00,  1.57s/it]\n",
            "{'loss': 0.9098, 'learning_rate': 4.594594594594596e-06, 'epoch': 2.7}\n",
            "{'loss': 0.8498, 'learning_rate': 3.918918918918919e-06, 'epoch': 3.04}\n",
            "{'loss': 0.7205, 'learning_rate': 3.2432432432432437e-06, 'epoch': 3.38}\n",
            " 68% 1000/1480 [43:57<19:19,  2.41s/it]\n",
            "  0% 0/25 [00:00<?, ?it/s]\n",
            "  8% 2/25 [00:02<00:24,  1.07s/it]\n",
            " 12% 3/25 [00:04<00:33,  1.52s/it]\n",
            " 16% 4/25 [00:06<00:37,  1.76s/it]\n",
            " 20% 5/25 [00:08<00:38,  1.91s/it]\n",
            " 24% 6/25 [00:10<00:37,  1.99s/it]\n",
            " 28% 7/25 [00:12<00:36,  2.03s/it]\n",
            " 32% 8/25 [00:15<00:34,  2.05s/it]\n",
            " 36% 9/25 [00:17<00:33,  2.07s/it]\n",
            " 40% 10/25 [00:19<00:31,  2.08s/it]\n",
            " 44% 11/25 [00:21<00:29,  2.09s/it]\n",
            " 48% 12/25 [00:23<00:27,  2.10s/it]\n",
            " 52% 13/25 [00:25<00:25,  2.12s/it]\n",
            " 56% 14/25 [00:27<00:23,  2.13s/it]\n",
            " 60% 15/25 [00:29<00:21,  2.14s/it]\n",
            " 64% 16/25 [00:32<00:19,  2.15s/it]\n",
            " 68% 17/25 [00:34<00:17,  2.16s/it]\n",
            " 72% 18/25 [00:36<00:15,  2.16s/it]\n",
            " 76% 19/25 [00:38<00:12,  2.16s/it]\n",
            " 80% 20/25 [00:40<00:10,  2.16s/it]\n",
            " 84% 21/25 [00:42<00:08,  2.16s/it]\n",
            " 88% 22/25 [00:45<00:06,  2.17s/it]\n",
            " 92% 23/25 [00:47<00:04,  2.17s/it]\n",
            " 96% 24/25 [00:49<00:02,  2.18s/it]\n",
            "100% 25/25 [00:49<00:00,  1.58s/it]/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "                                       \n",
            "{'eval_loss': 1.6106215715408325, 'eval_accuracy': 0.45, 'eval_P_Clarity': 0.5094066570188133, 'eval_R_Clarity': 0.5605095541401274, 'eval_f1_Clarity': 0.5337376800606519, 'eval_P_Fluency': 0.4379310344827586, 'eval_R_Fluency': 0.5521739130434783, 'eval_f1_Fluency': 0.48846153846153845, 'eval_P_Coherence': 0.0, 'eval_R_Coherence': 0.0, 'eval_f1_Coherence': 0.0, 'eval_P_Style': 0.0, 'eval_R_Style': 0.0, 'eval_f1_Style': 0.0, 'eval_P_Meaning-Changed': 0.32342007434944237, 'eval_R_Meaning-Changed': 0.4027777777777778, 'eval_f1_Meaning-Changed': 0.3587628865979382, 'eval_runtime': 51.8604, 'eval_samples_per_second': 29.695, 'eval_steps_per_second': 0.482, 'epoch': 3.38}\n",
            " 68% 1000/1480 [44:49<19:19,  2.41s/it]\n",
            "100% 25/25 [00:49<00:00,  1.58s/it]\n",
            "{'loss': 0.7272, 'learning_rate': 2.5675675675675675e-06, 'epoch': 3.71}\n",
            "{'loss': 0.722, 'learning_rate': 1.8918918918918922e-06, 'epoch': 4.05}\n",
            " 84% 1250/1480 [55:18<09:15,  2.42s/it]\n",
            "  0% 0/25 [00:00<?, ?it/s]\n",
            "  8% 2/25 [00:02<00:24,  1.07s/it]\n",
            " 12% 3/25 [00:04<00:33,  1.52s/it]\n",
            " 16% 4/25 [00:06<00:36,  1.76s/it]\n",
            " 20% 5/25 [00:08<00:38,  1.90s/it]\n",
            " 24% 6/25 [00:10<00:37,  1.99s/it]\n",
            " 28% 7/25 [00:12<00:36,  2.02s/it]\n",
            " 32% 8/25 [00:14<00:34,  2.04s/it]\n",
            " 36% 9/25 [00:17<00:32,  2.06s/it]\n",
            " 40% 10/25 [00:19<00:31,  2.07s/it]\n",
            " 44% 11/25 [00:21<00:29,  2.08s/it]\n",
            " 48% 12/25 [00:23<00:27,  2.09s/it]\n",
            " 52% 13/25 [00:25<00:25,  2.11s/it]\n",
            " 56% 14/25 [00:27<00:23,  2.12s/it]\n",
            " 60% 15/25 [00:29<00:21,  2.12s/it]\n",
            " 64% 16/25 [00:31<00:19,  2.14s/it]\n",
            " 68% 17/25 [00:34<00:17,  2.15s/it]\n",
            " 72% 18/25 [00:36<00:15,  2.15s/it]\n",
            " 76% 19/25 [00:38<00:12,  2.15s/it]\n",
            " 80% 20/25 [00:40<00:10,  2.15s/it]\n",
            " 84% 21/25 [00:42<00:08,  2.14s/it]\n",
            " 88% 22/25 [00:44<00:06,  2.15s/it]\n",
            " 92% 23/25 [00:47<00:04,  2.16s/it]\n",
            " 96% 24/25 [00:49<00:02,  2.16s/it]\n",
            "100% 25/25 [00:49<00:00,  1.57s/it]/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "                                       \n",
            "{'eval_loss': 1.6725329160690308, 'eval_accuracy': 0.45, 'eval_P_Clarity': 0.4852752880921895, 'eval_R_Clarity': 0.6035031847133758, 'eval_f1_Clarity': 0.5379701916252662, 'eval_P_Fluency': 0.46938775510204084, 'eval_R_Fluency': 0.45, 'eval_f1_Fluency': 0.4594894561598224, 'eval_P_Coherence': 0.3333333333333333, 'eval_R_Coherence': 0.043478260869565216, 'eval_f1_Coherence': 0.07692307692307691, 'eval_P_Style': 0.0, 'eval_R_Style': 0.0, 'eval_f1_Style': 0.0, 'eval_P_Meaning-Changed': 0.336734693877551, 'eval_R_Meaning-Changed': 0.4583333333333333, 'eval_f1_Meaning-Changed': 0.38823529411764707, 'eval_runtime': 51.578, 'eval_samples_per_second': 29.858, 'eval_steps_per_second': 0.485, 'epoch': 4.22}\n",
            " 84% 1250/1480 [56:10<09:15,  2.42s/it]\n",
            "100% 25/25 [00:49<00:00,  1.57s/it]\n",
            "{'loss': 0.5776, 'learning_rate': 1.2162162162162164e-06, 'epoch': 4.39}\n",
            "{'loss': 0.5783, 'learning_rate': 5.405405405405406e-07, 'epoch': 4.73}\n",
            "{'train_runtime': 3951.3421, 'train_samples_per_second': 5.998, 'train_steps_per_second': 0.375, 'train_loss': 0.9296253977595149, 'epoch': 5.0}\n",
            "100% 1480/1480 [1:05:51<00:00,  2.67s/it]\n",
            "100% 25/25 [00:49<00:00,  1.58s/it]/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "100% 25/25 [00:49<00:00,  1.99s/it]\n",
            "{'eval_loss': 1.7574317455291748, 'eval_accuracy': 0.44805194805194803, 'eval_P_Clarity': 0.5225694444444444, 'eval_R_Clarity': 0.47929936305732485, 'eval_f1_Clarity': 0.5, 'eval_P_Fluency': 0.4464579901153213, 'eval_R_Fluency': 0.5891304347826087, 'eval_f1_Fluency': 0.5079662605435802, 'eval_P_Coherence': 0.38, 'eval_R_Coherence': 0.10326086956521739, 'eval_f1_Coherence': 0.1623931623931624, 'eval_P_Style': 0.0, 'eval_R_Style': 0.0, 'eval_f1_Style': 0.0, 'eval_P_Meaning-Changed': 0.32247557003257327, 'eval_R_Meaning-Changed': 0.4583333333333333, 'eval_f1_Meaning-Changed': 0.378585086042065, 'eval_runtime': 51.9221, 'eval_samples_per_second': 29.66, 'eval_steps_per_second': 0.481, 'epoch': 5.0}\n",
            "CPU times: user 26 s, sys: 3.4 s, total: 29.4 s\n",
            "Wall time: 1h 7min 19s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "!python '/content/cs678-cp1-cp2/intent_classification/xlmroberta_train_intent_classifier.py' --upsample_values 1 1 1 1 1 --weights 1. 1. 1. 1. 1. -e 5  -s mass-large-ten -d '/content/cs678-cp1-cp2/multi_data/fully_multi'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WszWmTmCkbOS"
      },
      "source": [
        "### Task 2.2: Iterative Text Generation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0GW-3Xx7ki-p"
      },
      "source": [
        "#### Model 2.2.1 pegasus"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0AgpC342kwsl"
      },
      "source": [
        "##### Zero Shot\n",
        "\n",
        "train: english human_sent_level>train.json\n",
        "\n",
        "dev: english human_sent_level>dev.json\n",
        "\n",
        "test: multilingual human_sent_level>test.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9ed82844-36af-40b8-a320-2cf8c26cec1f",
        "id": "uPbm-5r5RoCi"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mv: cannot stat '/content/cs678-cp1-cp2/edit_generation/multilingual/pegasus_zeroshot_multilingual_train.sh': No such file or directory\n",
            "/content/iterater/code/IteraTeR_ACL2022/model/generation\n",
            "+ export TOKENIZERS_PARALLELISM=false\n",
            "+ PYTHON=/usr/local/bin/python\n",
            "+ git clone https://github.com/huggingface/transformers\n",
            "fatal: destination path 'transformers' already exists and is not an empty directory.\n",
            "+ cp run_summarization.py ./transformers/examples/pytorch/summarization/\n",
            "+ TRAIN_SCRIPT=./transformers/examples/pytorch/summarization/run_summarization.py\n",
            "+ TRAIN=/content/cs678-cp1-cp2/multi_data/zeroshot_multi/train.json\n",
            "+ VALID=/content/cs678-cp1-cp2/multi_data/zeroshot_multi/dev.json\n",
            "+ OUTPUT=pegasus_model_zero/\n",
            "+ sha1sum ./transformers/examples/pytorch/summarization/run_summarization.py\n",
            "1a98b8a4f2cf13523ec0e86d2094d61c4c53c7c1  ./transformers/examples/pytorch/summarization/run_summarization.py\n",
            "+ /usr/local/bin/python ./transformers/examples/pytorch/summarization/run_summarization.py --model_name_or_path google/pegasus-large --do_train --do_eval --train_file /content/cs678-cp1-cp2/multi_data/zeroshot_multi/train.json --validation_file /content/cs678-cp1-cp2/multi_data/zeroshot_multi/dev.json --per_device_train_batch_size=4 --per_device_eval_batch_size=4 --num_train_epochs 5 --gradient_accumulation_steps 4 --evaluation_strategy steps --eval_steps 200 --save_steps 100 --predict_with_generate --logging_steps 50 --output_dir pegasus_model_zero/ --overwrite_output_dir --text_column before_sent_with_intent --summary_column after_sent --learning_rate 3e-5\n",
            "2023-05-08 20:03:21.603926: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "05/08/2023 20:03:25 - WARNING - __main__ -   Process rank: -1, device: cuda:0, n_gpu: 1distributed training: False, 16-bits training: False\n",
            "05/08/2023 20:03:25 - INFO - __main__ -   Training/evaluation parameters Seq2SeqTrainingArguments(\n",
            "_n_gpu=1,\n",
            "adafactor=False,\n",
            "adam_beta1=0.9,\n",
            "adam_beta2=0.999,\n",
            "adam_epsilon=1e-08,\n",
            "auto_find_batch_size=False,\n",
            "bf16=False,\n",
            "bf16_full_eval=False,\n",
            "data_seed=None,\n",
            "dataloader_drop_last=False,\n",
            "dataloader_num_workers=0,\n",
            "dataloader_pin_memory=True,\n",
            "ddp_bucket_cap_mb=None,\n",
            "ddp_find_unused_parameters=None,\n",
            "ddp_timeout=1800,\n",
            "debug=[],\n",
            "deepspeed=None,\n",
            "disable_tqdm=False,\n",
            "do_eval=True,\n",
            "do_predict=False,\n",
            "do_train=True,\n",
            "eval_accumulation_steps=None,\n",
            "eval_delay=0,\n",
            "eval_steps=200,\n",
            "evaluation_strategy=steps,\n",
            "fp16=False,\n",
            "fp16_backend=auto,\n",
            "fp16_full_eval=False,\n",
            "fp16_opt_level=O1,\n",
            "fsdp=[],\n",
            "fsdp_config={'fsdp_min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},\n",
            "fsdp_min_num_params=0,\n",
            "fsdp_transformer_layer_cls_to_wrap=None,\n",
            "full_determinism=False,\n",
            "generation_config=None,\n",
            "generation_max_length=None,\n",
            "generation_num_beams=None,\n",
            "gradient_accumulation_steps=4,\n",
            "gradient_checkpointing=False,\n",
            "greater_is_better=None,\n",
            "group_by_length=False,\n",
            "half_precision_backend=auto,\n",
            "hub_model_id=None,\n",
            "hub_private_repo=False,\n",
            "hub_strategy=every_save,\n",
            "hub_token=<HUB_TOKEN>,\n",
            "ignore_data_skip=False,\n",
            "include_inputs_for_metrics=False,\n",
            "jit_mode_eval=False,\n",
            "label_names=None,\n",
            "label_smoothing_factor=0.0,\n",
            "learning_rate=3e-05,\n",
            "length_column_name=length,\n",
            "load_best_model_at_end=False,\n",
            "local_rank=-1,\n",
            "log_level=passive,\n",
            "log_level_replica=warning,\n",
            "log_on_each_node=True,\n",
            "logging_dir=pegasus_model_zero/runs/May08_20-03-25_532485e9ca09,\n",
            "logging_first_step=False,\n",
            "logging_nan_inf_filter=True,\n",
            "logging_steps=50,\n",
            "logging_strategy=steps,\n",
            "lr_scheduler_type=linear,\n",
            "max_grad_norm=1.0,\n",
            "max_steps=-1,\n",
            "metric_for_best_model=None,\n",
            "mp_parameters=,\n",
            "no_cuda=False,\n",
            "num_train_epochs=5.0,\n",
            "optim=adamw_hf,\n",
            "optim_args=None,\n",
            "output_dir=pegasus_model_zero/,\n",
            "overwrite_output_dir=True,\n",
            "past_index=-1,\n",
            "per_device_eval_batch_size=4,\n",
            "per_device_train_batch_size=4,\n",
            "predict_with_generate=True,\n",
            "prediction_loss_only=False,\n",
            "push_to_hub=False,\n",
            "push_to_hub_model_id=None,\n",
            "push_to_hub_organization=None,\n",
            "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
            "ray_scope=last,\n",
            "remove_unused_columns=True,\n",
            "report_to=['tensorboard', 'wandb'],\n",
            "resume_from_checkpoint=None,\n",
            "run_name=pegasus_model_zero/,\n",
            "save_on_each_node=False,\n",
            "save_safetensors=False,\n",
            "save_steps=100,\n",
            "save_strategy=steps,\n",
            "save_total_limit=None,\n",
            "seed=42,\n",
            "sharded_ddp=[],\n",
            "skip_memory_metrics=True,\n",
            "sortish_sampler=False,\n",
            "tf32=None,\n",
            "torch_compile=False,\n",
            "torch_compile_backend=None,\n",
            "torch_compile_mode=None,\n",
            "torchdynamo=None,\n",
            "tpu_metrics_debug=False,\n",
            "tpu_num_cores=None,\n",
            "use_ipex=False,\n",
            "use_legacy_prediction_loop=False,\n",
            "use_mps_device=False,\n",
            "warmup_ratio=0.0,\n",
            "warmup_steps=0,\n",
            "weight_decay=0.0,\n",
            "xpu_backend=None,\n",
            ")\n",
            "05/08/2023 20:03:25 - INFO - __main__ -   Seq2SeqTrainingArguments(\n",
            "_n_gpu=1,\n",
            "adafactor=False,\n",
            "adam_beta1=0.9,\n",
            "adam_beta2=0.999,\n",
            "adam_epsilon=1e-08,\n",
            "auto_find_batch_size=False,\n",
            "bf16=False,\n",
            "bf16_full_eval=False,\n",
            "data_seed=None,\n",
            "dataloader_drop_last=False,\n",
            "dataloader_num_workers=0,\n",
            "dataloader_pin_memory=True,\n",
            "ddp_bucket_cap_mb=None,\n",
            "ddp_find_unused_parameters=None,\n",
            "ddp_timeout=1800,\n",
            "debug=[],\n",
            "deepspeed=None,\n",
            "disable_tqdm=False,\n",
            "do_eval=True,\n",
            "do_predict=False,\n",
            "do_train=True,\n",
            "eval_accumulation_steps=None,\n",
            "eval_delay=0,\n",
            "eval_steps=200,\n",
            "evaluation_strategy=steps,\n",
            "fp16=False,\n",
            "fp16_backend=auto,\n",
            "fp16_full_eval=False,\n",
            "fp16_opt_level=O1,\n",
            "fsdp=[],\n",
            "fsdp_config={'fsdp_min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},\n",
            "fsdp_min_num_params=0,\n",
            "fsdp_transformer_layer_cls_to_wrap=None,\n",
            "full_determinism=False,\n",
            "generation_config=None,\n",
            "generation_max_length=None,\n",
            "generation_num_beams=None,\n",
            "gradient_accumulation_steps=4,\n",
            "gradient_checkpointing=False,\n",
            "greater_is_better=None,\n",
            "group_by_length=False,\n",
            "half_precision_backend=auto,\n",
            "hub_model_id=None,\n",
            "hub_private_repo=False,\n",
            "hub_strategy=every_save,\n",
            "hub_token=<HUB_TOKEN>,\n",
            "ignore_data_skip=False,\n",
            "include_inputs_for_metrics=False,\n",
            "jit_mode_eval=False,\n",
            "label_names=None,\n",
            "label_smoothing_factor=0.0,\n",
            "learning_rate=3e-05,\n",
            "length_column_name=length,\n",
            "load_best_model_at_end=False,\n",
            "local_rank=-1,\n",
            "log_level=passive,\n",
            "log_level_replica=warning,\n",
            "log_on_each_node=True,\n",
            "logging_dir=pegasus_model_zero/runs/May08_20-03-25_532485e9ca09,\n",
            "logging_first_step=False,\n",
            "logging_nan_inf_filter=True,\n",
            "logging_steps=50,\n",
            "logging_strategy=steps,\n",
            "lr_scheduler_type=linear,\n",
            "max_grad_norm=1.0,\n",
            "max_steps=-1,\n",
            "metric_for_best_model=None,\n",
            "mp_parameters=,\n",
            "no_cuda=False,\n",
            "num_train_epochs=5.0,\n",
            "optim=adamw_hf,\n",
            "optim_args=None,\n",
            "output_dir=pegasus_model_zero/,\n",
            "overwrite_output_dir=True,\n",
            "past_index=-1,\n",
            "per_device_eval_batch_size=4,\n",
            "per_device_train_batch_size=4,\n",
            "predict_with_generate=True,\n",
            "prediction_loss_only=False,\n",
            "push_to_hub=False,\n",
            "push_to_hub_model_id=None,\n",
            "push_to_hub_organization=None,\n",
            "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
            "ray_scope=last,\n",
            "remove_unused_columns=True,\n",
            "report_to=['tensorboard', 'wandb'],\n",
            "resume_from_checkpoint=None,\n",
            "run_name=pegasus_model_zero/,\n",
            "save_on_each_node=False,\n",
            "save_safetensors=False,\n",
            "save_steps=100,\n",
            "save_strategy=steps,\n",
            "save_total_limit=None,\n",
            "seed=42,\n",
            "sharded_ddp=[],\n",
            "skip_memory_metrics=True,\n",
            "sortish_sampler=False,\n",
            "tf32=None,\n",
            "torch_compile=False,\n",
            "torch_compile_backend=None,\n",
            "torch_compile_mode=None,\n",
            "torchdynamo=None,\n",
            "tpu_metrics_debug=False,\n",
            "tpu_num_cores=None,\n",
            "use_ipex=False,\n",
            "use_legacy_prediction_loop=False,\n",
            "use_mps_device=False,\n",
            "warmup_ratio=0.0,\n",
            "warmup_steps=0,\n",
            "weight_decay=0.0,\n",
            "xpu_backend=None,\n",
            ")\n",
            "05/08/2023 20:03:25 - INFO - __main__ -   42\n",
            "05/08/2023 20:03:25 - WARNING - datasets.builder -   Using custom data configuration default-3d7463f522204d08\n",
            "05/08/2023 20:03:25 - WARNING - datasets.builder -   Reusing dataset json (/root/.cache/huggingface/datasets/json/default-3d7463f522204d08/0.0.0/ac0ca5f5289a6cf108e706efcf040422dbbfa8e658dee6a819f20d76bb84d26b)\n",
            "100% 2/2 [00:00<00:00, 603.24it/s]\n",
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--google--pegasus-large/snapshots/dec7796b22f29b7d1c476192313eae8ed57b6b77/config.json\n",
            "Model config PegasusConfig {\n",
            "  \"_name_or_path\": \"google/pegasus-large\",\n",
            "  \"activation_dropout\": 0.1,\n",
            "  \"activation_function\": \"relu\",\n",
            "  \"add_bias_logits\": false,\n",
            "  \"add_final_layer_norm\": true,\n",
            "  \"architectures\": [\n",
            "    \"PegasusForConditionalGeneration\"\n",
            "  ],\n",
            "  \"attention_dropout\": 0.1,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"classif_dropout\": 0.0,\n",
            "  \"classifier_dropout\": 0.0,\n",
            "  \"d_model\": 1024,\n",
            "  \"decoder_attention_heads\": 16,\n",
            "  \"decoder_ffn_dim\": 4096,\n",
            "  \"decoder_layerdrop\": 0.0,\n",
            "  \"decoder_layers\": 16,\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"dropout\": 0.1,\n",
            "  \"encoder_attention_heads\": 16,\n",
            "  \"encoder_ffn_dim\": 4096,\n",
            "  \"encoder_layerdrop\": 0.0,\n",
            "  \"encoder_layers\": 16,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"extra_pos_embeddings\": 1,\n",
            "  \"force_bos_token_to_be_generated\": false,\n",
            "  \"forced_eos_token_id\": 1,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\",\n",
            "    \"2\": \"LABEL_2\"\n",
            "  },\n",
            "  \"init_std\": 0.02,\n",
            "  \"is_encoder_decoder\": true,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1,\n",
            "    \"LABEL_2\": 2\n",
            "  },\n",
            "  \"length_penalty\": 0.8,\n",
            "  \"max_length\": 256,\n",
            "  \"max_position_embeddings\": 1024,\n",
            "  \"model_type\": \"pegasus\",\n",
            "  \"normalize_before\": true,\n",
            "  \"normalize_embedding\": false,\n",
            "  \"num_beams\": 8,\n",
            "  \"num_hidden_layers\": 16,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"scale_embedding\": true,\n",
            "  \"static_position_embeddings\": true,\n",
            "  \"task_specific_params\": {\n",
            "    \"summarization_aeslc\": {\n",
            "      \"length_penalty\": 0.6,\n",
            "      \"max_length\": 32,\n",
            "      \"max_position_embeddings\": 512\n",
            "    },\n",
            "    \"summarization_arxiv\": {\n",
            "      \"length_penalty\": 0.8,\n",
            "      \"max_length\": 256,\n",
            "      \"max_position_embeddings\": 1024\n",
            "    },\n",
            "    \"summarization_big_patent\": {\n",
            "      \"length_penalty\": 0.7,\n",
            "      \"max_length\": 256,\n",
            "      \"max_position_embeddings\": 1024\n",
            "    },\n",
            "    \"summarization_billsum\": {\n",
            "      \"length_penalty\": 0.6,\n",
            "      \"max_length\": 256,\n",
            "      \"max_position_embeddings\": 1024\n",
            "    },\n",
            "    \"summarization_cnn_dailymail\": {\n",
            "      \"length_penalty\": 0.8,\n",
            "      \"max_length\": 128,\n",
            "      \"max_position_embeddings\": 1024\n",
            "    },\n",
            "    \"summarization_gigaword\": {\n",
            "      \"length_penalty\": 0.6,\n",
            "      \"max_length\": 32,\n",
            "      \"max_position_embeddings\": 128\n",
            "    },\n",
            "    \"summarization_large\": {\n",
            "      \"length_penalty\": 0.8,\n",
            "      \"max_length\": 256,\n",
            "      \"max_position_embeddings\": 1024\n",
            "    },\n",
            "    \"summarization_multi_news\": {\n",
            "      \"length_penalty\": 0.8,\n",
            "      \"max_length\": 256,\n",
            "      \"max_position_embeddings\": 1024\n",
            "    },\n",
            "    \"summarization_newsroom\": {\n",
            "      \"length_penalty\": 0.8,\n",
            "      \"max_length\": 128,\n",
            "      \"max_position_embeddings\": 512\n",
            "    },\n",
            "    \"summarization_pubmed\": {\n",
            "      \"length_penalty\": 0.8,\n",
            "      \"max_length\": 256,\n",
            "      \"max_position_embeddings\": 1024\n",
            "    },\n",
            "    \"summarization_reddit_tifu\": {\n",
            "      \"length_penalty\": 0.6,\n",
            "      \"max_length\": 128,\n",
            "      \"max_position_embeddings\": 512\n",
            "    },\n",
            "    \"summarization_wikihow\": {\n",
            "      \"length_penalty\": 0.6,\n",
            "      \"max_length\": 256,\n",
            "      \"max_position_embeddings\": 512\n",
            "    },\n",
            "    \"summarization_xsum\": {\n",
            "      \"length_penalty\": 0.8,\n",
            "      \"max_length\": 64,\n",
            "      \"max_position_embeddings\": 512\n",
            "    }\n",
            "  },\n",
            "  \"transformers_version\": \"4.28.1\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 96103\n",
            "}\n",
            "\n",
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--google--pegasus-large/snapshots/dec7796b22f29b7d1c476192313eae8ed57b6b77/config.json\n",
            "Model config PegasusConfig {\n",
            "  \"_name_or_path\": \"google/pegasus-large\",\n",
            "  \"activation_dropout\": 0.1,\n",
            "  \"activation_function\": \"relu\",\n",
            "  \"add_bias_logits\": false,\n",
            "  \"add_final_layer_norm\": true,\n",
            "  \"architectures\": [\n",
            "    \"PegasusForConditionalGeneration\"\n",
            "  ],\n",
            "  \"attention_dropout\": 0.1,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"classif_dropout\": 0.0,\n",
            "  \"classifier_dropout\": 0.0,\n",
            "  \"d_model\": 1024,\n",
            "  \"decoder_attention_heads\": 16,\n",
            "  \"decoder_ffn_dim\": 4096,\n",
            "  \"decoder_layerdrop\": 0.0,\n",
            "  \"decoder_layers\": 16,\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"dropout\": 0.1,\n",
            "  \"encoder_attention_heads\": 16,\n",
            "  \"encoder_ffn_dim\": 4096,\n",
            "  \"encoder_layerdrop\": 0.0,\n",
            "  \"encoder_layers\": 16,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"extra_pos_embeddings\": 1,\n",
            "  \"force_bos_token_to_be_generated\": false,\n",
            "  \"forced_eos_token_id\": 1,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\",\n",
            "    \"2\": \"LABEL_2\"\n",
            "  },\n",
            "  \"init_std\": 0.02,\n",
            "  \"is_encoder_decoder\": true,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1,\n",
            "    \"LABEL_2\": 2\n",
            "  },\n",
            "  \"length_penalty\": 0.8,\n",
            "  \"max_length\": 256,\n",
            "  \"max_position_embeddings\": 1024,\n",
            "  \"model_type\": \"pegasus\",\n",
            "  \"normalize_before\": true,\n",
            "  \"normalize_embedding\": false,\n",
            "  \"num_beams\": 8,\n",
            "  \"num_hidden_layers\": 16,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"scale_embedding\": true,\n",
            "  \"static_position_embeddings\": true,\n",
            "  \"task_specific_params\": {\n",
            "    \"summarization_aeslc\": {\n",
            "      \"length_penalty\": 0.6,\n",
            "      \"max_length\": 32,\n",
            "      \"max_position_embeddings\": 512\n",
            "    },\n",
            "    \"summarization_arxiv\": {\n",
            "      \"length_penalty\": 0.8,\n",
            "      \"max_length\": 256,\n",
            "      \"max_position_embeddings\": 1024\n",
            "    },\n",
            "    \"summarization_big_patent\": {\n",
            "      \"length_penalty\": 0.7,\n",
            "      \"max_length\": 256,\n",
            "      \"max_position_embeddings\": 1024\n",
            "    },\n",
            "    \"summarization_billsum\": {\n",
            "      \"length_penalty\": 0.6,\n",
            "      \"max_length\": 256,\n",
            "      \"max_position_embeddings\": 1024\n",
            "    },\n",
            "    \"summarization_cnn_dailymail\": {\n",
            "      \"length_penalty\": 0.8,\n",
            "      \"max_length\": 128,\n",
            "      \"max_position_embeddings\": 1024\n",
            "    },\n",
            "    \"summarization_gigaword\": {\n",
            "      \"length_penalty\": 0.6,\n",
            "      \"max_length\": 32,\n",
            "      \"max_position_embeddings\": 128\n",
            "    },\n",
            "    \"summarization_large\": {\n",
            "      \"length_penalty\": 0.8,\n",
            "      \"max_length\": 256,\n",
            "      \"max_position_embeddings\": 1024\n",
            "    },\n",
            "    \"summarization_multi_news\": {\n",
            "      \"length_penalty\": 0.8,\n",
            "      \"max_length\": 256,\n",
            "      \"max_position_embeddings\": 1024\n",
            "    },\n",
            "    \"summarization_newsroom\": {\n",
            "      \"length_penalty\": 0.8,\n",
            "      \"max_length\": 128,\n",
            "      \"max_position_embeddings\": 512\n",
            "    },\n",
            "    \"summarization_pubmed\": {\n",
            "      \"length_penalty\": 0.8,\n",
            "      \"max_length\": 256,\n",
            "      \"max_position_embeddings\": 1024\n",
            "    },\n",
            "    \"summarization_reddit_tifu\": {\n",
            "      \"length_penalty\": 0.6,\n",
            "      \"max_length\": 128,\n",
            "      \"max_position_embeddings\": 512\n",
            "    },\n",
            "    \"summarization_wikihow\": {\n",
            "      \"length_penalty\": 0.6,\n",
            "      \"max_length\": 256,\n",
            "      \"max_position_embeddings\": 512\n",
            "    },\n",
            "    \"summarization_xsum\": {\n",
            "      \"length_penalty\": 0.8,\n",
            "      \"max_length\": 64,\n",
            "      \"max_position_embeddings\": 512\n",
            "    }\n",
            "  },\n",
            "  \"transformers_version\": \"4.28.1\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 96103\n",
            "}\n",
            "\n",
            "loading file spiece.model from cache at /root/.cache/huggingface/hub/models--google--pegasus-large/snapshots/dec7796b22f29b7d1c476192313eae8ed57b6b77/spiece.model\n",
            "loading file tokenizer.json from cache at None\n",
            "loading file added_tokens.json from cache at None\n",
            "loading file special_tokens_map.json from cache at /root/.cache/huggingface/hub/models--google--pegasus-large/snapshots/dec7796b22f29b7d1c476192313eae8ed57b6b77/special_tokens_map.json\n",
            "loading file tokenizer_config.json from cache at /root/.cache/huggingface/hub/models--google--pegasus-large/snapshots/dec7796b22f29b7d1c476192313eae8ed57b6b77/tokenizer_config.json\n",
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--google--pegasus-large/snapshots/dec7796b22f29b7d1c476192313eae8ed57b6b77/config.json\n",
            "Model config PegasusConfig {\n",
            "  \"_name_or_path\": \"google/pegasus-large\",\n",
            "  \"activation_dropout\": 0.1,\n",
            "  \"activation_function\": \"relu\",\n",
            "  \"add_bias_logits\": false,\n",
            "  \"add_final_layer_norm\": true,\n",
            "  \"architectures\": [\n",
            "    \"PegasusForConditionalGeneration\"\n",
            "  ],\n",
            "  \"attention_dropout\": 0.1,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"classif_dropout\": 0.0,\n",
            "  \"classifier_dropout\": 0.0,\n",
            "  \"d_model\": 1024,\n",
            "  \"decoder_attention_heads\": 16,\n",
            "  \"decoder_ffn_dim\": 4096,\n",
            "  \"decoder_layerdrop\": 0.0,\n",
            "  \"decoder_layers\": 16,\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"dropout\": 0.1,\n",
            "  \"encoder_attention_heads\": 16,\n",
            "  \"encoder_ffn_dim\": 4096,\n",
            "  \"encoder_layerdrop\": 0.0,\n",
            "  \"encoder_layers\": 16,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"extra_pos_embeddings\": 1,\n",
            "  \"force_bos_token_to_be_generated\": false,\n",
            "  \"forced_eos_token_id\": 1,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\",\n",
            "    \"2\": \"LABEL_2\"\n",
            "  },\n",
            "  \"init_std\": 0.02,\n",
            "  \"is_encoder_decoder\": true,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1,\n",
            "    \"LABEL_2\": 2\n",
            "  },\n",
            "  \"length_penalty\": 0.8,\n",
            "  \"max_length\": 256,\n",
            "  \"max_position_embeddings\": 1024,\n",
            "  \"model_type\": \"pegasus\",\n",
            "  \"normalize_before\": true,\n",
            "  \"normalize_embedding\": false,\n",
            "  \"num_beams\": 8,\n",
            "  \"num_hidden_layers\": 16,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"scale_embedding\": true,\n",
            "  \"static_position_embeddings\": true,\n",
            "  \"task_specific_params\": {\n",
            "    \"summarization_aeslc\": {\n",
            "      \"length_penalty\": 0.6,\n",
            "      \"max_length\": 32,\n",
            "      \"max_position_embeddings\": 512\n",
            "    },\n",
            "    \"summarization_arxiv\": {\n",
            "      \"length_penalty\": 0.8,\n",
            "      \"max_length\": 256,\n",
            "      \"max_position_embeddings\": 1024\n",
            "    },\n",
            "    \"summarization_big_patent\": {\n",
            "      \"length_penalty\": 0.7,\n",
            "      \"max_length\": 256,\n",
            "      \"max_position_embeddings\": 1024\n",
            "    },\n",
            "    \"summarization_billsum\": {\n",
            "      \"length_penalty\": 0.6,\n",
            "      \"max_length\": 256,\n",
            "      \"max_position_embeddings\": 1024\n",
            "    },\n",
            "    \"summarization_cnn_dailymail\": {\n",
            "      \"length_penalty\": 0.8,\n",
            "      \"max_length\": 128,\n",
            "      \"max_position_embeddings\": 1024\n",
            "    },\n",
            "    \"summarization_gigaword\": {\n",
            "      \"length_penalty\": 0.6,\n",
            "      \"max_length\": 32,\n",
            "      \"max_position_embeddings\": 128\n",
            "    },\n",
            "    \"summarization_large\": {\n",
            "      \"length_penalty\": 0.8,\n",
            "      \"max_length\": 256,\n",
            "      \"max_position_embeddings\": 1024\n",
            "    },\n",
            "    \"summarization_multi_news\": {\n",
            "      \"length_penalty\": 0.8,\n",
            "      \"max_length\": 256,\n",
            "      \"max_position_embeddings\": 1024\n",
            "    },\n",
            "    \"summarization_newsroom\": {\n",
            "      \"length_penalty\": 0.8,\n",
            "      \"max_length\": 128,\n",
            "      \"max_position_embeddings\": 512\n",
            "    },\n",
            "    \"summarization_pubmed\": {\n",
            "      \"length_penalty\": 0.8,\n",
            "      \"max_length\": 256,\n",
            "      \"max_position_embeddings\": 1024\n",
            "    },\n",
            "    \"summarization_reddit_tifu\": {\n",
            "      \"length_penalty\": 0.6,\n",
            "      \"max_length\": 128,\n",
            "      \"max_position_embeddings\": 512\n",
            "    },\n",
            "    \"summarization_wikihow\": {\n",
            "      \"length_penalty\": 0.6,\n",
            "      \"max_length\": 256,\n",
            "      \"max_position_embeddings\": 512\n",
            "    },\n",
            "    \"summarization_xsum\": {\n",
            "      \"length_penalty\": 0.8,\n",
            "      \"max_length\": 64,\n",
            "      \"max_position_embeddings\": 512\n",
            "    }\n",
            "  },\n",
            "  \"transformers_version\": \"4.28.1\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 96103\n",
            "}\n",
            "\n",
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--google--pegasus-large/snapshots/dec7796b22f29b7d1c476192313eae8ed57b6b77/config.json\n",
            "Model config PegasusConfig {\n",
            "  \"_name_or_path\": \"google/pegasus-large\",\n",
            "  \"activation_dropout\": 0.1,\n",
            "  \"activation_function\": \"relu\",\n",
            "  \"add_bias_logits\": false,\n",
            "  \"add_final_layer_norm\": true,\n",
            "  \"architectures\": [\n",
            "    \"PegasusForConditionalGeneration\"\n",
            "  ],\n",
            "  \"attention_dropout\": 0.1,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"classif_dropout\": 0.0,\n",
            "  \"classifier_dropout\": 0.0,\n",
            "  \"d_model\": 1024,\n",
            "  \"decoder_attention_heads\": 16,\n",
            "  \"decoder_ffn_dim\": 4096,\n",
            "  \"decoder_layerdrop\": 0.0,\n",
            "  \"decoder_layers\": 16,\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"dropout\": 0.1,\n",
            "  \"encoder_attention_heads\": 16,\n",
            "  \"encoder_ffn_dim\": 4096,\n",
            "  \"encoder_layerdrop\": 0.0,\n",
            "  \"encoder_layers\": 16,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"extra_pos_embeddings\": 1,\n",
            "  \"force_bos_token_to_be_generated\": false,\n",
            "  \"forced_eos_token_id\": 1,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\",\n",
            "    \"2\": \"LABEL_2\"\n",
            "  },\n",
            "  \"init_std\": 0.02,\n",
            "  \"is_encoder_decoder\": true,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1,\n",
            "    \"LABEL_2\": 2\n",
            "  },\n",
            "  \"length_penalty\": 0.8,\n",
            "  \"max_length\": 256,\n",
            "  \"max_position_embeddings\": 1024,\n",
            "  \"model_type\": \"pegasus\",\n",
            "  \"normalize_before\": true,\n",
            "  \"normalize_embedding\": false,\n",
            "  \"num_beams\": 8,\n",
            "  \"num_hidden_layers\": 16,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"scale_embedding\": true,\n",
            "  \"static_position_embeddings\": true,\n",
            "  \"task_specific_params\": {\n",
            "    \"summarization_aeslc\": {\n",
            "      \"length_penalty\": 0.6,\n",
            "      \"max_length\": 32,\n",
            "      \"max_position_embeddings\": 512\n",
            "    },\n",
            "    \"summarization_arxiv\": {\n",
            "      \"length_penalty\": 0.8,\n",
            "      \"max_length\": 256,\n",
            "      \"max_position_embeddings\": 1024\n",
            "    },\n",
            "    \"summarization_big_patent\": {\n",
            "      \"length_penalty\": 0.7,\n",
            "      \"max_length\": 256,\n",
            "      \"max_position_embeddings\": 1024\n",
            "    },\n",
            "    \"summarization_billsum\": {\n",
            "      \"length_penalty\": 0.6,\n",
            "      \"max_length\": 256,\n",
            "      \"max_position_embeddings\": 1024\n",
            "    },\n",
            "    \"summarization_cnn_dailymail\": {\n",
            "      \"length_penalty\": 0.8,\n",
            "      \"max_length\": 128,\n",
            "      \"max_position_embeddings\": 1024\n",
            "    },\n",
            "    \"summarization_gigaword\": {\n",
            "      \"length_penalty\": 0.6,\n",
            "      \"max_length\": 32,\n",
            "      \"max_position_embeddings\": 128\n",
            "    },\n",
            "    \"summarization_large\": {\n",
            "      \"length_penalty\": 0.8,\n",
            "      \"max_length\": 256,\n",
            "      \"max_position_embeddings\": 1024\n",
            "    },\n",
            "    \"summarization_multi_news\": {\n",
            "      \"length_penalty\": 0.8,\n",
            "      \"max_length\": 256,\n",
            "      \"max_position_embeddings\": 1024\n",
            "    },\n",
            "    \"summarization_newsroom\": {\n",
            "      \"length_penalty\": 0.8,\n",
            "      \"max_length\": 128,\n",
            "      \"max_position_embeddings\": 512\n",
            "    },\n",
            "    \"summarization_pubmed\": {\n",
            "      \"length_penalty\": 0.8,\n",
            "      \"max_length\": 256,\n",
            "      \"max_position_embeddings\": 1024\n",
            "    },\n",
            "    \"summarization_reddit_tifu\": {\n",
            "      \"length_penalty\": 0.6,\n",
            "      \"max_length\": 128,\n",
            "      \"max_position_embeddings\": 512\n",
            "    },\n",
            "    \"summarization_wikihow\": {\n",
            "      \"length_penalty\": 0.6,\n",
            "      \"max_length\": 256,\n",
            "      \"max_position_embeddings\": 512\n",
            "    },\n",
            "    \"summarization_xsum\": {\n",
            "      \"length_penalty\": 0.8,\n",
            "      \"max_length\": 64,\n",
            "      \"max_position_embeddings\": 512\n",
            "    }\n",
            "  },\n",
            "  \"transformers_version\": \"4.28.1\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 96103\n",
            "}\n",
            "\n",
            "Assigning ['<clarity>', '<fluency>', '<coherence>', '<style>', '<meaning-changed>'] to the additional_special_tokens key of the tokenizer\n",
            "loading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--google--pegasus-large/snapshots/dec7796b22f29b7d1c476192313eae8ed57b6b77/pytorch_model.bin\n",
            "Generate config GenerationConfig {\n",
            "  \"_from_model_config\": true,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"forced_eos_token_id\": 1,\n",
            "  \"length_penalty\": 0.8,\n",
            "  \"max_length\": 256,\n",
            "  \"num_beams\": 8,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"transformers_version\": \"4.28.1\"\n",
            "}\n",
            "\n",
            "All model checkpoint weights were used when initializing PegasusForConditionalGeneration.\n",
            "\n",
            "All the weights of PegasusForConditionalGeneration were initialized from the model checkpoint at google/pegasus-large.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use PegasusForConditionalGeneration for predictions without further training.\n",
            "loading configuration file generation_config.json from cache at /root/.cache/huggingface/hub/models--google--pegasus-large/snapshots/dec7796b22f29b7d1c476192313eae8ed57b6b77/generation_config.json\n",
            "Generate config GenerationConfig {\n",
            "  \"_from_model_config\": true,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"forced_eos_token_id\": 1,\n",
            "  \"length_penalty\": 0.8,\n",
            "  \"max_length\": 256,\n",
            "  \"num_beams\": 8,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"transformers_version\": \"4.28.1\"\n",
            "}\n",
            "\n",
            "05/08/2023 20:03:39 - WARNING - datasets.fingerprint -   Parameter 'function'=<function main.<locals>.preprocess_function at 0x7fd54aae1240> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.\n",
            "05/08/2023 20:03:39 - WARNING - datasets.arrow_dataset -   Loading cached processed dataset at /root/.cache/huggingface/datasets/json/default-3d7463f522204d08/0.0.0/ac0ca5f5289a6cf108e706efcf040422dbbfa8e658dee6a819f20d76bb84d26b/cache-1c80317fa3b1799d.arrow\n",
            "05/08/2023 20:03:39 - WARNING - datasets.arrow_dataset -   Loading cached processed dataset at /root/.cache/huggingface/datasets/json/default-3d7463f522204d08/0.0.0/ac0ca5f5289a6cf108e706efcf040422dbbfa8e658dee6a819f20d76bb84d26b/cache-bdd640fb06671ad1.arrow\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "***** Running training *****\n",
            "  Num examples = 3,254\n",
            "  Num Epochs = 5\n",
            "  Instantaneous batch size per device = 4\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
            "  Gradient Accumulation steps = 4\n",
            "  Total optimization steps = 1,015\n",
            "  Number of trainable parameters = 568,705,024\n",
            "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (1) Create a W&B account\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (2) Use an existing W&B account\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (3) Don't visualize my results\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Enter your choice: 3\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You chose \"Don't visualize my results\"\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.15.2\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n",
            "  0% 0/1015 [00:00<?, ?it/s]You're using a PegasusTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
            "{'loss': 2.474, 'learning_rate': 2.8522167487684728e-05, 'epoch': 0.25}\n",
            "{'loss': 1.8356, 'learning_rate': 2.7044334975369458e-05, 'epoch': 0.49}\n",
            " 10% 100/1015 [00:54<08:05,  1.88it/s]Saving model checkpoint to pegasus_model_zero/checkpoint-100\n",
            "Configuration saved in pegasus_model_zero/checkpoint-100/config.json\n",
            "Configuration saved in pegasus_model_zero/checkpoint-100/generation_config.json\n",
            "Model weights saved in pegasus_model_zero/checkpoint-100/pytorch_model.bin\n",
            "tokenizer config file saved in pegasus_model_zero/checkpoint-100/tokenizer_config.json\n",
            "Special tokens file saved in pegasus_model_zero/checkpoint-100/special_tokens_map.json\n",
            "{'loss': 1.4241, 'learning_rate': 2.5566502463054188e-05, 'epoch': 0.74}\n",
            "{'loss': 1.2931, 'learning_rate': 2.408866995073892e-05, 'epoch': 0.98}\n",
            " 20% 200/1015 [02:06<07:12,  1.88it/s]***** Running Evaluation *****\n",
            "  Num examples = 400\n",
            "  Batch size = 4\n",
            "Generate config GenerationConfig {\n",
            "  \"_from_model_config\": true,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"forced_eos_token_id\": 1,\n",
            "  \"length_penalty\": 0.8,\n",
            "  \"max_length\": 256,\n",
            "  \"num_beams\": 8,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"transformers_version\": \"4.28.1\"\n",
            "}\n",
            "\n",
            "\n",
            "  0% 0/100 [00:00<?, ?it/s]\u001b[A\n",
            "  2% 2/100 [00:01<01:01,  1.59it/s]\u001b[A\n",
            "  3% 3/100 [00:03<01:49,  1.12s/it]\u001b[A\n",
            "  4% 4/100 [00:04<02:06,  1.31s/it]\u001b[A\n",
            "  5% 5/100 [00:05<01:50,  1.16s/it]\u001b[A\n",
            "  6% 6/100 [00:07<01:58,  1.26s/it]\u001b[A\n",
            "  7% 7/100 [00:08<01:55,  1.24s/it]\u001b[A\n",
            "  8% 8/100 [00:09<01:53,  1.24s/it]\u001b[A\n",
            "  9% 9/100 [00:15<04:14,  2.79s/it]\u001b[A\n",
            " 10% 10/100 [00:17<03:36,  2.41s/it]\u001b[A\n",
            " 11% 11/100 [00:18<03:01,  2.04s/it]\u001b[A\n",
            " 12% 12/100 [00:20<03:12,  2.19s/it]\u001b[A\n",
            " 13% 13/100 [00:22<03:03,  2.11s/it]\u001b[A\n",
            " 14% 14/100 [00:24<02:36,  1.81s/it]\u001b[A\n",
            " 15% 15/100 [00:25<02:16,  1.61s/it]\u001b[A\n",
            " 16% 16/100 [00:26<02:14,  1.61s/it]\u001b[A\n",
            " 17% 17/100 [00:28<02:13,  1.61s/it]\u001b[A\n",
            " 18% 18/100 [00:29<01:59,  1.46s/it]\u001b[A\n",
            " 19% 19/100 [00:31<02:08,  1.59s/it]\u001b[A\n",
            " 20% 20/100 [00:32<01:59,  1.50s/it]\u001b[A\n",
            " 21% 21/100 [00:33<01:38,  1.25s/it]\u001b[A\n",
            " 22% 22/100 [00:34<01:46,  1.36s/it]\u001b[A\n",
            " 23% 23/100 [00:41<03:33,  2.77s/it]\u001b[A\n",
            " 24% 24/100 [00:42<02:52,  2.27s/it]\u001b[A\n",
            " 25% 25/100 [00:43<02:29,  1.99s/it]\u001b[A\n",
            " 26% 26/100 [00:44<02:07,  1.72s/it]\u001b[A\n",
            " 27% 27/100 [00:46<02:06,  1.73s/it]\u001b[A\n",
            " 28% 28/100 [00:50<02:46,  2.32s/it]\u001b[A\n",
            " 29% 29/100 [00:50<02:14,  1.89s/it]\u001b[A\n",
            " 30% 30/100 [00:51<01:49,  1.56s/it]\u001b[A\n",
            " 31% 31/100 [00:52<01:35,  1.38s/it]\u001b[A\n",
            " 32% 32/100 [00:53<01:33,  1.37s/it]\u001b[A\n",
            " 33% 33/100 [01:00<03:07,  2.81s/it]\u001b[A\n",
            " 34% 34/100 [01:03<03:15,  2.97s/it]\u001b[A\n",
            " 35% 35/100 [01:09<04:13,  3.91s/it]\u001b[A\n",
            " 36% 36/100 [01:11<03:25,  3.21s/it]\u001b[A\n",
            " 37% 37/100 [01:11<02:36,  2.48s/it]\u001b[A\n",
            " 38% 38/100 [01:12<02:04,  2.01s/it]\u001b[A\n",
            " 39% 39/100 [01:14<01:59,  1.96s/it]\u001b[A\n",
            " 40% 40/100 [01:17<02:08,  2.15s/it]\u001b[A\n",
            " 41% 41/100 [01:19<02:15,  2.29s/it]\u001b[A\n",
            " 42% 42/100 [01:21<01:55,  2.00s/it]\u001b[A\n",
            " 43% 43/100 [01:25<02:35,  2.72s/it]\u001b[A\n",
            " 44% 44/100 [01:27<02:12,  2.37s/it]\u001b[A\n",
            " 45% 45/100 [01:29<02:06,  2.30s/it]\u001b[A\n",
            " 46% 46/100 [01:31<01:56,  2.16s/it]\u001b[A\n",
            " 47% 47/100 [01:32<01:40,  1.89s/it]\u001b[A\n",
            " 48% 48/100 [01:33<01:22,  1.59s/it]\u001b[A\n",
            " 49% 49/100 [01:34<01:14,  1.47s/it]\u001b[A\n",
            " 50% 50/100 [01:36<01:22,  1.64s/it]\u001b[A\n",
            " 51% 51/100 [01:37<01:07,  1.39s/it]\u001b[A\n",
            " 52% 52/100 [01:43<02:12,  2.76s/it]\u001b[A\n",
            " 53% 53/100 [01:44<01:49,  2.33s/it]\u001b[A\n",
            " 54% 54/100 [01:46<01:35,  2.07s/it]\u001b[A\n",
            " 55% 55/100 [01:47<01:22,  1.84s/it]\u001b[A\n",
            " 56% 56/100 [01:48<01:12,  1.64s/it]\u001b[A\n",
            " 57% 57/100 [01:49<01:05,  1.52s/it]\u001b[A\n",
            " 58% 58/100 [01:51<01:01,  1.47s/it]\u001b[A\n",
            " 59% 59/100 [01:57<01:57,  2.86s/it]\u001b[A\n",
            " 60% 60/100 [01:58<01:40,  2.51s/it]\u001b[A\n",
            " 61% 61/100 [02:00<01:21,  2.10s/it]\u001b[A\n",
            " 62% 62/100 [02:02<01:18,  2.06s/it]\u001b[A\n",
            " 63% 63/100 [02:03<01:11,  1.94s/it]\u001b[A\n",
            " 64% 64/100 [02:09<01:55,  3.20s/it]\u001b[A\n",
            " 65% 65/100 [02:11<01:32,  2.63s/it]\u001b[A\n",
            " 66% 66/100 [02:12<01:18,  2.32s/it]\u001b[A\n",
            " 67% 67/100 [02:14<01:09,  2.11s/it]\u001b[A\n",
            " 68% 68/100 [02:17<01:21,  2.54s/it]\u001b[A\n",
            " 69% 69/100 [02:20<01:15,  2.44s/it]\u001b[A\n",
            " 70% 70/100 [02:21<01:03,  2.10s/it]\u001b[A\n",
            " 71% 71/100 [02:22<00:55,  1.92s/it]\u001b[A\n",
            " 72% 72/100 [02:24<00:52,  1.88s/it]\u001b[A\n",
            " 73% 73/100 [02:30<01:24,  3.15s/it]\u001b[A\n",
            " 74% 74/100 [02:32<01:10,  2.73s/it]\u001b[A\n",
            " 75% 75/100 [02:38<01:33,  3.73s/it]\u001b[A\n",
            " 76% 76/100 [02:39<01:10,  2.94s/it]\u001b[A\n",
            " 77% 77/100 [02:41<00:56,  2.47s/it]\u001b[A\n",
            " 78% 78/100 [02:42<00:47,  2.18s/it]\u001b[A\n",
            " 79% 79/100 [02:48<01:10,  3.35s/it]\u001b[A\n",
            " 80% 80/100 [02:49<00:52,  2.61s/it]\u001b[A\n",
            " 81% 81/100 [02:55<01:08,  3.62s/it]\u001b[A\n",
            " 82% 82/100 [02:56<00:50,  2.83s/it]\u001b[A\n",
            " 83% 83/100 [02:58<00:44,  2.63s/it]\u001b[A\n",
            " 84% 84/100 [03:00<00:39,  2.48s/it]\u001b[A\n",
            " 85% 85/100 [03:02<00:34,  2.27s/it]\u001b[A\n",
            " 86% 86/100 [03:08<00:48,  3.43s/it]\u001b[A\n",
            " 87% 87/100 [03:09<00:35,  2.72s/it]\u001b[A\n",
            " 88% 88/100 [03:11<00:27,  2.26s/it]\u001b[A\n",
            " 89% 89/100 [03:12<00:22,  2.04s/it]\u001b[A\n",
            " 90% 90/100 [03:14<00:19,  1.95s/it]\u001b[A\n",
            " 91% 91/100 [03:15<00:15,  1.73s/it]\u001b[A\n",
            " 92% 92/100 [03:16<00:12,  1.52s/it]\u001b[A\n",
            " 93% 93/100 [03:19<00:12,  1.83s/it]\u001b[A\n",
            " 94% 94/100 [03:20<00:10,  1.70s/it]\u001b[A\n",
            " 95% 95/100 [03:21<00:08,  1.62s/it]\u001b[A\n",
            " 96% 96/100 [03:23<00:06,  1.52s/it]\u001b[A\n",
            " 97% 97/100 [03:24<00:04,  1.39s/it]\u001b[A\n",
            " 98% 98/100 [03:26<00:03,  1.54s/it]\u001b[A\n",
            " 99% 99/100 [03:26<00:01,  1.28s/it]\u001b[A\n",
            "                                      \n",
            "\u001b[A{'eval_loss': 0.7263896465301514, 'eval_rouge1': 81.7961, 'eval_rouge2': 74.6325, 'eval_rougeL': 80.8426, 'eval_rougeLsum': 80.9355, 'eval_bleu': 67.8671, 'eval_gen_len': 36.95, 'eval_runtime': 220.9446, 'eval_samples_per_second': 1.81, 'eval_steps_per_second': 0.453, 'epoch': 0.98}\n",
            " 20% 200/1015 [05:47<07:12,  1.88it/s]\n",
            "100% 100/100 [03:39<00:00,  1.87s/it]\u001b[A\n",
            "                                     \u001b[ASaving model checkpoint to pegasus_model_zero/checkpoint-200\n",
            "Configuration saved in pegasus_model_zero/checkpoint-200/config.json\n",
            "Configuration saved in pegasus_model_zero/checkpoint-200/generation_config.json\n",
            "Model weights saved in pegasus_model_zero/checkpoint-200/pytorch_model.bin\n",
            "tokenizer config file saved in pegasus_model_zero/checkpoint-200/tokenizer_config.json\n",
            "Special tokens file saved in pegasus_model_zero/checkpoint-200/special_tokens_map.json\n",
            "{'loss': 1.0958, 'learning_rate': 2.2610837438423645e-05, 'epoch': 1.23}\n",
            "{'loss': 0.9889, 'learning_rate': 2.1133004926108376e-05, 'epoch': 1.47}\n",
            " 30% 300/1015 [06:58<06:24,  1.86it/s]Saving model checkpoint to pegasus_model_zero/checkpoint-300\n",
            "Configuration saved in pegasus_model_zero/checkpoint-300/config.json\n",
            "Configuration saved in pegasus_model_zero/checkpoint-300/generation_config.json\n",
            "Model weights saved in pegasus_model_zero/checkpoint-300/pytorch_model.bin\n",
            "tokenizer config file saved in pegasus_model_zero/checkpoint-300/tokenizer_config.json\n",
            "Special tokens file saved in pegasus_model_zero/checkpoint-300/special_tokens_map.json\n",
            "{'loss': 0.9541, 'learning_rate': 1.9655172413793102e-05, 'epoch': 1.72}\n",
            "{'loss': 0.8277, 'learning_rate': 1.8177339901477833e-05, 'epoch': 1.97}\n",
            " 39% 400/1015 [08:11<05:38,  1.82it/s]***** Running Evaluation *****\n",
            "  Num examples = 400\n",
            "  Batch size = 4\n",
            "\n",
            "  0% 0/100 [00:00<?, ?it/s]\u001b[A\n",
            "  2% 2/100 [00:01<01:00,  1.62it/s]\u001b[A\n",
            "  3% 3/100 [00:02<01:24,  1.14it/s]\u001b[A\n",
            "  4% 4/100 [00:04<01:50,  1.15s/it]\u001b[A\n",
            "  5% 5/100 [00:04<01:41,  1.07s/it]\u001b[A\n",
            "  6% 6/100 [00:06<02:09,  1.37s/it]\u001b[A\n",
            "  7% 7/100 [00:08<02:10,  1.40s/it]\u001b[A\n",
            "  8% 8/100 [00:09<02:12,  1.44s/it]\u001b[A\n",
            "  9% 9/100 [00:16<04:23,  2.90s/it]\u001b[A\n",
            " 10% 10/100 [00:17<03:44,  2.49s/it]\u001b[A\n",
            " 11% 11/100 [00:18<03:06,  2.09s/it]\u001b[A\n",
            " 12% 12/100 [00:21<03:15,  2.22s/it]\u001b[A\n",
            " 13% 13/100 [00:23<03:10,  2.19s/it]\u001b[A\n",
            " 14% 14/100 [00:24<02:39,  1.86s/it]\u001b[A\n",
            " 15% 15/100 [00:25<02:17,  1.62s/it]\u001b[A\n",
            " 16% 16/100 [00:27<02:16,  1.62s/it]\u001b[A\n",
            " 17% 17/100 [00:28<02:14,  1.62s/it]\u001b[A\n",
            " 18% 18/100 [00:30<02:01,  1.48s/it]\u001b[A\n",
            " 19% 19/100 [00:31<02:07,  1.58s/it]\u001b[A\n",
            " 20% 20/100 [00:34<02:20,  1.76s/it]\u001b[A\n",
            " 21% 21/100 [00:34<01:53,  1.44s/it]\u001b[A\n",
            " 22% 22/100 [00:36<01:58,  1.52s/it]\u001b[A\n",
            " 23% 23/100 [00:38<02:14,  1.74s/it]\u001b[A\n",
            " 24% 24/100 [00:39<01:47,  1.42s/it]\u001b[A\n",
            " 25% 25/100 [00:40<01:39,  1.32s/it]\u001b[A\n",
            " 26% 26/100 [00:41<01:32,  1.25s/it]\u001b[A\n",
            " 27% 27/100 [00:43<01:42,  1.40s/it]\u001b[A\n",
            " 28% 28/100 [00:44<01:40,  1.39s/it]\u001b[A\n",
            " 29% 29/100 [00:45<01:27,  1.24s/it]\u001b[A\n",
            " 30% 30/100 [00:46<01:18,  1.12s/it]\u001b[A\n",
            " 31% 31/100 [00:47<01:14,  1.08s/it]\u001b[A\n",
            " 32% 32/100 [00:48<01:20,  1.18s/it]\u001b[A\n",
            " 33% 33/100 [00:54<02:55,  2.62s/it]\u001b[A\n",
            " 34% 34/100 [00:56<02:30,  2.28s/it]\u001b[A\n",
            " 35% 35/100 [00:58<02:22,  2.19s/it]\u001b[A\n",
            " 36% 36/100 [00:59<02:08,  2.01s/it]\u001b[A\n",
            " 37% 37/100 [01:00<01:46,  1.68s/it]\u001b[A\n",
            " 38% 38/100 [01:06<03:03,  2.96s/it]\u001b[A\n",
            " 39% 39/100 [01:08<02:41,  2.64s/it]\u001b[A\n",
            " 40% 40/100 [01:10<02:20,  2.34s/it]\u001b[A\n",
            " 41% 41/100 [01:11<02:01,  2.06s/it]\u001b[A\n",
            " 42% 42/100 [01:13<01:51,  1.92s/it]\u001b[A\n",
            " 43% 43/100 [01:17<02:31,  2.66s/it]\u001b[A\n",
            " 44% 44/100 [01:19<02:10,  2.32s/it]\u001b[A\n",
            " 45% 45/100 [01:21<02:04,  2.26s/it]\u001b[A\n",
            " 46% 46/100 [01:23<01:59,  2.21s/it]\u001b[A\n",
            " 47% 47/100 [01:29<02:57,  3.35s/it]\u001b[A\n",
            " 48% 48/100 [01:30<02:15,  2.61s/it]\u001b[A\n",
            " 49% 49/100 [01:31<01:50,  2.17s/it]\u001b[A\n",
            " 50% 50/100 [01:32<01:35,  1.91s/it]\u001b[A\n",
            " 51% 51/100 [01:33<01:17,  1.58s/it]\u001b[A\n",
            " 52% 52/100 [01:39<02:18,  2.88s/it]\u001b[A\n",
            " 53% 53/100 [01:40<01:54,  2.44s/it]\u001b[A\n",
            " 54% 54/100 [01:42<01:36,  2.09s/it]\u001b[A\n",
            " 55% 55/100 [01:44<01:32,  2.07s/it]\u001b[A\n",
            " 56% 56/100 [01:45<01:19,  1.80s/it]\u001b[A\n",
            " 57% 57/100 [01:46<01:08,  1.60s/it]\u001b[A\n",
            " 58% 58/100 [01:47<01:04,  1.53s/it]\u001b[A\n",
            " 59% 59/100 [01:53<01:57,  2.86s/it]\u001b[A\n",
            " 60% 60/100 [01:55<01:40,  2.52s/it]\u001b[A\n",
            " 61% 61/100 [02:01<02:18,  3.56s/it]\u001b[A\n",
            " 62% 62/100 [02:03<01:53,  2.97s/it]\u001b[A\n",
            " 63% 63/100 [02:04<01:34,  2.56s/it]\u001b[A\n",
            " 64% 64/100 [02:10<02:09,  3.58s/it]\u001b[A\n",
            " 65% 65/100 [02:11<01:41,  2.89s/it]\u001b[A\n",
            " 66% 66/100 [02:13<01:25,  2.52s/it]\u001b[A\n",
            " 67% 67/100 [02:15<01:14,  2.25s/it]\u001b[A\n",
            " 68% 68/100 [02:18<01:23,  2.62s/it]\u001b[A\n",
            " 69% 69/100 [02:20<01:16,  2.48s/it]\u001b[A\n",
            " 70% 70/100 [02:22<01:03,  2.13s/it]\u001b[A\n",
            " 71% 71/100 [02:23<00:55,  1.91s/it]\u001b[A\n",
            " 72% 72/100 [02:25<00:52,  1.88s/it]\u001b[A\n",
            " 73% 73/100 [02:26<00:46,  1.72s/it]\u001b[A\n",
            " 74% 74/100 [02:28<00:44,  1.73s/it]\u001b[A\n",
            " 75% 75/100 [02:29<00:41,  1.66s/it]\u001b[A\n",
            " 76% 76/100 [02:35<01:10,  2.95s/it]\u001b[A\n",
            " 77% 77/100 [02:37<00:57,  2.51s/it]\u001b[A\n",
            " 78% 78/100 [02:38<00:48,  2.21s/it]\u001b[A\n",
            " 79% 79/100 [02:40<00:43,  2.07s/it]\u001b[A\n",
            " 80% 80/100 [02:41<00:34,  1.74s/it]\u001b[A\n",
            " 81% 81/100 [02:47<00:57,  3.01s/it]\u001b[A\n",
            " 82% 82/100 [02:48<00:43,  2.40s/it]\u001b[A\n",
            " 83% 83/100 [02:50<00:39,  2.34s/it]\u001b[A\n",
            " 84% 84/100 [02:52<00:36,  2.29s/it]\u001b[A\n",
            " 85% 85/100 [02:53<00:28,  1.89s/it]\u001b[A\n",
            " 86% 86/100 [03:00<00:44,  3.21s/it]\u001b[A\n",
            " 87% 87/100 [03:01<00:32,  2.52s/it]\u001b[A\n",
            " 88% 88/100 [03:02<00:27,  2.30s/it]\u001b[A\n",
            " 89% 89/100 [03:03<00:21,  1.93s/it]\u001b[A\n",
            " 90% 90/100 [03:09<00:31,  3.13s/it]\u001b[A\n",
            " 91% 91/100 [03:11<00:23,  2.57s/it]\u001b[A\n",
            " 92% 92/100 [03:12<00:16,  2.06s/it]\u001b[A\n",
            " 93% 93/100 [03:13<00:12,  1.85s/it]\u001b[A\n",
            " 94% 94/100 [03:14<00:10,  1.72s/it]\u001b[A\n",
            " 95% 95/100 [03:16<00:08,  1.63s/it]\u001b[A\n",
            " 96% 96/100 [03:17<00:06,  1.68s/it]\u001b[A\n",
            " 97% 97/100 [03:19<00:05,  1.76s/it]\u001b[A\n",
            " 98% 98/100 [03:21<00:03,  1.83s/it]\u001b[A\n",
            " 99% 99/100 [03:23<00:01,  1.69s/it]\u001b[A\n",
            "                                      \n",
            "\u001b[A{'eval_loss': 0.5894030928611755, 'eval_rouge1': 87.5257, 'eval_rouge2': 82.8646, 'eval_rougeL': 87.1881, 'eval_rougeLsum': 87.2873, 'eval_bleu': 78.1797, 'eval_gen_len': 37.15, 'eval_runtime': 215.5472, 'eval_samples_per_second': 1.856, 'eval_steps_per_second': 0.464, 'epoch': 1.97}\n",
            " 39% 400/1015 [11:46<05:38,  1.82it/s]\n",
            "100% 100/100 [03:33<00:00,  1.49s/it]\u001b[A\n",
            "                                     \u001b[ASaving model checkpoint to pegasus_model_zero/checkpoint-400\n",
            "Configuration saved in pegasus_model_zero/checkpoint-400/config.json\n",
            "Configuration saved in pegasus_model_zero/checkpoint-400/generation_config.json\n",
            "Model weights saved in pegasus_model_zero/checkpoint-400/pytorch_model.bin\n",
            "tokenizer config file saved in pegasus_model_zero/checkpoint-400/tokenizer_config.json\n",
            "Special tokens file saved in pegasus_model_zero/checkpoint-400/special_tokens_map.json\n",
            "{'loss': 0.8522, 'learning_rate': 1.6699507389162563e-05, 'epoch': 2.21}\n",
            "{'loss': 0.8425, 'learning_rate': 1.5221674876847293e-05, 'epoch': 2.46}\n",
            " 49% 500/1015 [12:58<04:55,  1.75it/s]Saving model checkpoint to pegasus_model_zero/checkpoint-500\n",
            "Configuration saved in pegasus_model_zero/checkpoint-500/config.json\n",
            "Configuration saved in pegasus_model_zero/checkpoint-500/generation_config.json\n",
            "Model weights saved in pegasus_model_zero/checkpoint-500/pytorch_model.bin\n",
            "tokenizer config file saved in pegasus_model_zero/checkpoint-500/tokenizer_config.json\n",
            "Special tokens file saved in pegasus_model_zero/checkpoint-500/special_tokens_map.json\n",
            "{'loss': 0.8196, 'learning_rate': 1.374384236453202e-05, 'epoch': 2.7}\n",
            "{'loss': 0.7653, 'learning_rate': 1.2266009852216749e-05, 'epoch': 2.95}\n",
            " 59% 600/1015 [14:10<03:47,  1.83it/s]***** Running Evaluation *****\n",
            "  Num examples = 400\n",
            "  Batch size = 4\n",
            "\n",
            "  0% 0/100 [00:00<?, ?it/s]\u001b[A\n",
            "  2% 2/100 [00:01<01:01,  1.58it/s]\u001b[A\n",
            "  3% 3/100 [00:03<01:46,  1.09s/it]\u001b[A\n",
            "  4% 4/100 [00:04<02:04,  1.29s/it]\u001b[A\n",
            "  5% 5/100 [00:05<01:50,  1.16s/it]\u001b[A\n",
            "  6% 6/100 [00:07<02:15,  1.44s/it]\u001b[A\n",
            "  7% 7/100 [00:08<01:54,  1.23s/it]\u001b[A\n",
            "  8% 8/100 [00:09<02:01,  1.32s/it]\u001b[A\n",
            "  9% 9/100 [00:16<04:18,  2.84s/it]\u001b[A\n",
            " 10% 10/100 [00:17<03:39,  2.44s/it]\u001b[A\n",
            " 11% 11/100 [00:18<03:02,  2.05s/it]\u001b[A\n",
            " 12% 12/100 [00:21<03:13,  2.20s/it]\u001b[A\n",
            " 13% 13/100 [00:23<03:09,  2.18s/it]\u001b[A\n",
            " 14% 14/100 [00:24<02:39,  1.85s/it]\u001b[A\n",
            " 15% 15/100 [00:25<02:17,  1.62s/it]\u001b[A\n",
            " 16% 16/100 [00:27<02:15,  1.62s/it]\u001b[A\n",
            " 17% 17/100 [00:28<02:15,  1.63s/it]\u001b[A\n",
            " 18% 18/100 [00:30<02:01,  1.49s/it]\u001b[A\n",
            " 19% 19/100 [00:31<01:55,  1.43s/it]\u001b[A\n",
            " 20% 20/100 [00:33<02:13,  1.66s/it]\u001b[A\n",
            " 21% 21/100 [00:34<01:48,  1.37s/it]\u001b[A\n",
            " 22% 22/100 [00:35<01:55,  1.48s/it]\u001b[A\n",
            " 23% 23/100 [00:37<01:47,  1.40s/it]\u001b[A\n",
            " 24% 24/100 [00:37<01:28,  1.17s/it]\u001b[A\n",
            " 25% 25/100 [00:38<01:16,  1.01s/it]\u001b[A\n",
            " 26% 26/100 [00:39<01:16,  1.04s/it]\u001b[A\n",
            " 27% 27/100 [00:41<01:31,  1.25s/it]\u001b[A\n",
            " 28% 28/100 [00:42<01:32,  1.29s/it]\u001b[A\n",
            " 29% 29/100 [00:44<01:37,  1.37s/it]\u001b[A\n",
            " 30% 30/100 [00:45<01:34,  1.34s/it]\u001b[A\n",
            " 31% 31/100 [00:46<01:25,  1.23s/it]\u001b[A\n",
            " 32% 32/100 [00:47<01:28,  1.30s/it]\u001b[A\n",
            " 33% 33/100 [00:53<03:01,  2.70s/it]\u001b[A\n",
            " 34% 34/100 [00:55<02:26,  2.22s/it]\u001b[A\n",
            " 35% 35/100 [00:56<02:13,  2.05s/it]\u001b[A\n",
            " 36% 36/100 [00:58<02:02,  1.92s/it]\u001b[A\n",
            " 37% 37/100 [01:03<02:57,  2.82s/it]\u001b[A\n",
            " 38% 38/100 [01:04<02:24,  2.33s/it]\u001b[A\n",
            " 39% 39/100 [01:06<02:14,  2.20s/it]\u001b[A\n",
            " 40% 40/100 [01:07<02:01,  2.03s/it]\u001b[A\n",
            " 41% 41/100 [01:09<01:48,  1.84s/it]\u001b[A\n",
            " 42% 42/100 [01:15<03:00,  3.11s/it]\u001b[A\n",
            " 43% 43/100 [01:16<02:18,  2.44s/it]\u001b[A\n",
            " 44% 44/100 [01:17<02:02,  2.18s/it]\u001b[A\n",
            " 45% 45/100 [01:19<01:58,  2.16s/it]\u001b[A\n",
            " 46% 46/100 [01:22<01:56,  2.15s/it]\u001b[A\n",
            " 47% 47/100 [01:23<01:37,  1.84s/it]\u001b[A\n",
            " 48% 48/100 [01:24<01:20,  1.54s/it]\u001b[A\n",
            " 49% 49/100 [01:25<01:12,  1.43s/it]\u001b[A\n",
            " 50% 50/100 [01:26<01:07,  1.34s/it]\u001b[A\n",
            " 51% 51/100 [01:27<00:57,  1.18s/it]\u001b[A\n",
            " 52% 52/100 [01:33<02:06,  2.63s/it]\u001b[A\n",
            " 53% 53/100 [01:34<01:45,  2.25s/it]\u001b[A\n",
            " 54% 54/100 [01:35<01:30,  1.96s/it]\u001b[A\n",
            " 55% 55/100 [01:37<01:19,  1.76s/it]\u001b[A\n",
            " 56% 56/100 [01:38<01:09,  1.58s/it]\u001b[A\n",
            " 57% 57/100 [01:39<01:02,  1.45s/it]\u001b[A\n",
            " 58% 58/100 [01:40<00:59,  1.42s/it]\u001b[A\n",
            " 59% 59/100 [01:43<01:20,  1.97s/it]\u001b[A\n",
            " 60% 60/100 [01:45<01:15,  1.89s/it]\u001b[A\n",
            " 61% 61/100 [01:51<02:01,  3.11s/it]\u001b[A\n",
            " 62% 62/100 [01:53<01:40,  2.66s/it]\u001b[A\n",
            " 63% 63/100 [01:54<01:26,  2.35s/it]\u001b[A\n",
            " 64% 64/100 [02:00<02:04,  3.45s/it]\u001b[A\n",
            " 65% 65/100 [02:02<01:39,  2.83s/it]\u001b[A\n",
            " 66% 66/100 [02:03<01:23,  2.47s/it]\u001b[A\n",
            " 67% 67/100 [02:05<01:13,  2.22s/it]\u001b[A\n",
            " 68% 68/100 [02:09<01:28,  2.77s/it]\u001b[A\n",
            " 69% 69/100 [02:11<01:20,  2.60s/it]\u001b[A\n",
            " 70% 70/100 [02:17<01:49,  3.64s/it]\u001b[A\n",
            " 71% 71/100 [02:19<01:26,  2.98s/it]\u001b[A\n",
            " 72% 72/100 [02:21<01:13,  2.63s/it]\u001b[A\n",
            " 73% 73/100 [02:22<01:00,  2.25s/it]\u001b[A\n",
            " 74% 74/100 [02:24<00:54,  2.10s/it]\u001b[A\n",
            " 75% 75/100 [02:25<00:47,  1.91s/it]\u001b[A\n",
            " 76% 76/100 [02:31<01:15,  3.14s/it]\u001b[A\n",
            " 77% 77/100 [02:33<01:01,  2.67s/it]\u001b[A\n",
            " 78% 78/100 [02:35<00:52,  2.40s/it]\u001b[A\n",
            " 79% 79/100 [02:36<00:46,  2.20s/it]\u001b[A\n",
            " 80% 80/100 [02:37<00:36,  1.83s/it]\u001b[A\n",
            " 81% 81/100 [02:43<00:58,  3.08s/it]\u001b[A\n",
            " 82% 82/100 [02:44<00:44,  2.45s/it]\u001b[A\n",
            " 83% 83/100 [02:46<00:40,  2.38s/it]\u001b[A\n",
            " 84% 84/100 [02:49<00:37,  2.32s/it]\u001b[A\n",
            " 85% 85/100 [02:50<00:28,  1.91s/it]\u001b[A\n",
            " 86% 86/100 [02:56<00:45,  3.22s/it]\u001b[A\n",
            " 87% 87/100 [02:57<00:32,  2.53s/it]\u001b[A\n",
            " 88% 88/100 [02:58<00:24,  2.07s/it]\u001b[A\n",
            " 89% 89/100 [02:59<00:18,  1.67s/it]\u001b[A\n",
            " 90% 90/100 [03:04<00:29,  2.95s/it]\u001b[A\n",
            " 91% 91/100 [03:06<00:22,  2.45s/it]\u001b[A\n",
            " 92% 92/100 [03:07<00:15,  1.98s/it]\u001b[A\n",
            " 93% 93/100 [03:08<00:12,  1.78s/it]\u001b[A\n",
            " 94% 94/100 [03:09<00:09,  1.66s/it]\u001b[A\n",
            " 95% 95/100 [03:11<00:07,  1.58s/it]\u001b[A\n",
            " 96% 96/100 [03:12<00:06,  1.63s/it]\u001b[A\n",
            " 97% 97/100 [03:14<00:05,  1.72s/it]\u001b[A\n",
            " 98% 98/100 [03:16<00:03,  1.80s/it]\u001b[A\n",
            " 99% 99/100 [03:17<00:01,  1.58s/it]\u001b[A\n",
            "                                      \n",
            "\u001b[A{'eval_loss': 0.5617870092391968, 'eval_rouge1': 88.7428, 'eval_rouge2': 84.3368, 'eval_rougeL': 88.4838, 'eval_rougeLsum': 88.5602, 'eval_bleu': 82.4576, 'eval_gen_len': 39.6975, 'eval_runtime': 208.9757, 'eval_samples_per_second': 1.914, 'eval_steps_per_second': 0.479, 'epoch': 2.95}\n",
            " 59% 600/1015 [17:39<03:47,  1.83it/s]\n",
            "100% 100/100 [03:27<00:00,  1.31s/it]\u001b[A\n",
            "                                     \u001b[ASaving model checkpoint to pegasus_model_zero/checkpoint-600\n",
            "Configuration saved in pegasus_model_zero/checkpoint-600/config.json\n",
            "Configuration saved in pegasus_model_zero/checkpoint-600/generation_config.json\n",
            "Model weights saved in pegasus_model_zero/checkpoint-600/pytorch_model.bin\n",
            "tokenizer config file saved in pegasus_model_zero/checkpoint-600/tokenizer_config.json\n",
            "Special tokens file saved in pegasus_model_zero/checkpoint-600/special_tokens_map.json\n",
            "{'loss': 0.6985, 'learning_rate': 1.0788177339901479e-05, 'epoch': 3.19}\n",
            "{'loss': 0.776, 'learning_rate': 9.310344827586207e-06, 'epoch': 3.44}\n",
            " 69% 700/1015 [18:51<02:58,  1.77it/s]Saving model checkpoint to pegasus_model_zero/checkpoint-700\n",
            "Configuration saved in pegasus_model_zero/checkpoint-700/config.json\n",
            "Configuration saved in pegasus_model_zero/checkpoint-700/generation_config.json\n",
            "Model weights saved in pegasus_model_zero/checkpoint-700/pytorch_model.bin\n",
            "tokenizer config file saved in pegasus_model_zero/checkpoint-700/tokenizer_config.json\n",
            "Special tokens file saved in pegasus_model_zero/checkpoint-700/special_tokens_map.json\n",
            "{'loss': 0.8041, 'learning_rate': 7.832512315270936e-06, 'epoch': 3.69}\n",
            "{'loss': 0.7646, 'learning_rate': 6.354679802955665e-06, 'epoch': 3.93}\n",
            " 79% 800/1015 [20:02<01:55,  1.85it/s]***** Running Evaluation *****\n",
            "  Num examples = 400\n",
            "  Batch size = 4\n",
            "\n",
            "  0% 0/100 [00:00<?, ?it/s]\u001b[A\n",
            "  2% 2/100 [00:01<01:02,  1.58it/s]\u001b[A\n",
            "  3% 3/100 [00:02<01:25,  1.13it/s]\u001b[A\n",
            "  4% 4/100 [00:04<01:51,  1.16s/it]\u001b[A\n",
            "  5% 5/100 [00:05<01:42,  1.08s/it]\u001b[A\n",
            "  6% 6/100 [00:07<02:10,  1.39s/it]\u001b[A\n",
            "  7% 7/100 [00:07<01:51,  1.20s/it]\u001b[A\n",
            "  8% 8/100 [00:09<01:59,  1.30s/it]\u001b[A\n",
            "  9% 9/100 [00:15<04:15,  2.81s/it]\u001b[A\n",
            " 10% 10/100 [00:17<03:38,  2.42s/it]\u001b[A\n",
            " 11% 11/100 [00:18<03:02,  2.05s/it]\u001b[A\n",
            " 12% 12/100 [00:20<03:15,  2.22s/it]\u001b[A\n",
            " 13% 13/100 [00:23<03:10,  2.19s/it]\u001b[A\n",
            " 14% 14/100 [00:24<02:40,  1.86s/it]\u001b[A\n",
            " 15% 15/100 [00:25<02:18,  1.63s/it]\u001b[A\n",
            " 16% 16/100 [00:26<02:16,  1.62s/it]\u001b[A\n",
            " 17% 17/100 [00:28<02:15,  1.64s/it]\u001b[A\n",
            " 18% 18/100 [00:29<02:01,  1.49s/it]\u001b[A\n",
            " 19% 19/100 [00:30<01:55,  1.42s/it]\u001b[A\n",
            " 20% 20/100 [00:33<02:12,  1.66s/it]\u001b[A\n",
            " 21% 21/100 [00:33<01:48,  1.38s/it]\u001b[A\n",
            " 22% 22/100 [00:35<01:56,  1.49s/it]\u001b[A\n",
            " 23% 23/100 [00:36<01:48,  1.40s/it]\u001b[A\n",
            " 24% 24/100 [00:37<01:29,  1.17s/it]\u001b[A\n",
            " 25% 25/100 [00:38<01:16,  1.02s/it]\u001b[A\n",
            " 26% 26/100 [00:39<01:17,  1.04s/it]\u001b[A\n",
            " 27% 27/100 [00:40<01:30,  1.25s/it]\u001b[A\n",
            " 28% 28/100 [00:42<01:31,  1.27s/it]\u001b[A\n",
            " 29% 29/100 [00:43<01:36,  1.36s/it]\u001b[A\n",
            " 30% 30/100 [00:44<01:24,  1.21s/it]\u001b[A\n",
            " 31% 31/100 [00:45<01:18,  1.14s/it]\u001b[A\n",
            " 32% 32/100 [00:47<01:23,  1.23s/it]\u001b[A\n",
            " 33% 33/100 [00:49<01:37,  1.45s/it]\u001b[A\n",
            " 34% 34/100 [00:50<01:28,  1.35s/it]\u001b[A\n",
            " 35% 35/100 [00:51<01:34,  1.45s/it]\u001b[A\n",
            " 36% 36/100 [00:53<01:35,  1.49s/it]\u001b[A\n",
            " 37% 37/100 [00:54<01:23,  1.32s/it]\u001b[A\n",
            " 38% 38/100 [01:00<02:47,  2.70s/it]\u001b[A\n",
            " 39% 39/100 [01:02<02:30,  2.46s/it]\u001b[A\n",
            " 40% 40/100 [01:03<02:13,  2.22s/it]\u001b[A\n",
            " 41% 41/100 [01:05<01:57,  1.99s/it]\u001b[A\n",
            " 42% 42/100 [01:11<03:06,  3.21s/it]\u001b[A\n",
            " 43% 43/100 [01:12<02:21,  2.49s/it]\u001b[A\n",
            " 44% 44/100 [01:13<02:03,  2.21s/it]\u001b[A\n",
            " 45% 45/100 [01:15<01:59,  2.18s/it]\u001b[A\n",
            " 46% 46/100 [01:17<01:57,  2.17s/it]\u001b[A\n",
            " 47% 47/100 [01:19<01:40,  1.90s/it]\u001b[A\n",
            " 48% 48/100 [01:20<01:22,  1.59s/it]\u001b[A\n",
            " 49% 49/100 [01:21<01:14,  1.46s/it]\u001b[A\n",
            " 50% 50/100 [01:22<01:08,  1.36s/it]\u001b[A\n",
            " 51% 51/100 [01:23<00:58,  1.20s/it]\u001b[A\n",
            " 52% 52/100 [01:26<01:20,  1.68s/it]\u001b[A\n",
            " 53% 53/100 [01:27<01:14,  1.59s/it]\u001b[A\n",
            " 54% 54/100 [01:28<01:08,  1.50s/it]\u001b[A\n",
            " 55% 55/100 [01:29<01:04,  1.43s/it]\u001b[A\n",
            " 56% 56/100 [01:31<00:59,  1.36s/it]\u001b[A\n",
            " 57% 57/100 [01:32<00:56,  1.31s/it]\u001b[A\n",
            " 58% 58/100 [01:33<00:55,  1.32s/it]\u001b[A\n",
            " 59% 59/100 [01:37<01:18,  1.92s/it]\u001b[A\n",
            " 60% 60/100 [01:38<01:15,  1.88s/it]\u001b[A\n",
            " 61% 61/100 [01:44<02:02,  3.13s/it]\u001b[A\n",
            " 62% 62/100 [01:46<01:41,  2.68s/it]\u001b[A\n",
            " 63% 63/100 [01:48<01:27,  2.37s/it]\u001b[A\n",
            " 64% 64/100 [01:54<02:05,  3.49s/it]\u001b[A\n",
            " 65% 65/100 [02:00<02:28,  4.25s/it]\u001b[A\n",
            " 66% 66/100 [02:01<01:57,  3.46s/it]\u001b[A\n",
            " 67% 67/100 [02:03<01:35,  2.91s/it]\u001b[A\n",
            " 68% 68/100 [02:07<01:44,  3.26s/it]\u001b[A\n",
            " 69% 69/100 [02:09<01:31,  2.95s/it]\u001b[A\n",
            " 70% 70/100 [02:10<01:12,  2.42s/it]\u001b[A\n",
            " 71% 71/100 [02:12<01:01,  2.12s/it]\u001b[A\n",
            " 72% 72/100 [02:18<01:31,  3.28s/it]\u001b[A\n",
            " 73% 73/100 [02:19<01:13,  2.74s/it]\u001b[A\n",
            " 74% 74/100 [02:21<01:03,  2.45s/it]\u001b[A\n",
            " 75% 75/100 [02:22<00:52,  2.08s/it]\u001b[A\n",
            " 76% 76/100 [02:28<01:18,  3.26s/it]\u001b[A\n",
            " 77% 77/100 [02:30<01:02,  2.73s/it]\u001b[A\n",
            " 78% 78/100 [02:32<00:53,  2.44s/it]\u001b[A\n",
            " 79% 79/100 [02:33<00:46,  2.22s/it]\u001b[A\n",
            " 80% 80/100 [02:34<00:37,  1.85s/it]\u001b[A\n",
            " 81% 81/100 [02:40<00:59,  3.13s/it]\u001b[A\n",
            " 82% 82/100 [02:41<00:44,  2.48s/it]\u001b[A\n",
            " 83% 83/100 [02:44<00:40,  2.41s/it]\u001b[A\n",
            " 84% 84/100 [02:46<00:37,  2.34s/it]\u001b[A\n",
            " 85% 85/100 [02:47<00:29,  1.94s/it]\u001b[A\n",
            " 86% 86/100 [02:53<00:45,  3.22s/it]\u001b[A\n",
            " 87% 87/100 [02:54<00:32,  2.52s/it]\u001b[A\n",
            " 88% 88/100 [02:55<00:24,  2.07s/it]\u001b[A\n",
            " 89% 89/100 [02:56<00:18,  1.68s/it]\u001b[A\n",
            " 90% 90/100 [03:02<00:29,  2.97s/it]\u001b[A\n",
            " 91% 91/100 [03:03<00:22,  2.45s/it]\u001b[A\n",
            " 92% 92/100 [03:04<00:15,  1.98s/it]\u001b[A\n",
            " 93% 93/100 [03:05<00:12,  1.78s/it]\u001b[A\n",
            " 94% 94/100 [03:07<00:10,  1.67s/it]\u001b[A\n",
            " 95% 95/100 [03:08<00:07,  1.59s/it]\u001b[A\n",
            " 96% 96/100 [03:10<00:06,  1.65s/it]\u001b[A\n",
            " 97% 97/100 [03:12<00:05,  1.75s/it]\u001b[A\n",
            " 98% 98/100 [03:14<00:03,  1.83s/it]\u001b[A\n",
            " 99% 99/100 [03:20<00:03,  3.06s/it]\u001b[A\n",
            "                                      \n",
            "\u001b[A{'eval_loss': 0.554432213306427, 'eval_rouge1': 89.6265, 'eval_rouge2': 85.2341, 'eval_rougeL': 89.3931, 'eval_rougeLsum': 89.4568, 'eval_bleu': 83.9462, 'eval_gen_len': 39.675, 'eval_runtime': 211.2199, 'eval_samples_per_second': 1.894, 'eval_steps_per_second': 0.473, 'epoch': 3.93}\n",
            " 79% 800/1015 [23:33<01:55,  1.85it/s]\n",
            "100% 100/100 [03:29<00:00,  2.32s/it]\u001b[A\n",
            "                                     \u001b[ASaving model checkpoint to pegasus_model_zero/checkpoint-800\n",
            "Configuration saved in pegasus_model_zero/checkpoint-800/config.json\n",
            "Configuration saved in pegasus_model_zero/checkpoint-800/generation_config.json\n",
            "Model weights saved in pegasus_model_zero/checkpoint-800/pytorch_model.bin\n",
            "tokenizer config file saved in pegasus_model_zero/checkpoint-800/tokenizer_config.json\n",
            "Special tokens file saved in pegasus_model_zero/checkpoint-800/special_tokens_map.json\n",
            "{'loss': 0.7844, 'learning_rate': 4.876847290640394e-06, 'epoch': 4.18}\n",
            "{'loss': 0.7914, 'learning_rate': 3.3990147783251234e-06, 'epoch': 4.42}\n",
            " 89% 900/1015 [24:45<01:00,  1.89it/s]Saving model checkpoint to pegasus_model_zero/checkpoint-900\n",
            "Configuration saved in pegasus_model_zero/checkpoint-900/config.json\n",
            "Configuration saved in pegasus_model_zero/checkpoint-900/generation_config.json\n",
            "Model weights saved in pegasus_model_zero/checkpoint-900/pytorch_model.bin\n",
            "tokenizer config file saved in pegasus_model_zero/checkpoint-900/tokenizer_config.json\n",
            "Special tokens file saved in pegasus_model_zero/checkpoint-900/special_tokens_map.json\n",
            "{'loss': 0.6936, 'learning_rate': 1.9211822660098524e-06, 'epoch': 4.67}\n",
            "{'loss': 0.7839, 'learning_rate': 4.4334975369458127e-07, 'epoch': 4.91}\n",
            " 99% 1000/1015 [25:57<00:08,  1.83it/s]***** Running Evaluation *****\n",
            "  Num examples = 400\n",
            "  Batch size = 4\n",
            "\n",
            "  0% 0/100 [00:00<?, ?it/s]\u001b[A\n",
            "  2% 2/100 [00:01<01:01,  1.59it/s]\u001b[A\n",
            "  3% 3/100 [00:02<01:24,  1.15it/s]\u001b[A\n",
            "  4% 4/100 [00:04<01:50,  1.15s/it]\u001b[A\n",
            "  5% 5/100 [00:05<01:41,  1.07s/it]\u001b[A\n",
            "  6% 6/100 [00:07<02:16,  1.45s/it]\u001b[A\n",
            "  7% 7/100 [00:08<01:56,  1.25s/it]\u001b[A\n",
            "  8% 8/100 [00:09<02:03,  1.34s/it]\u001b[A\n",
            "  9% 9/100 [00:15<04:16,  2.82s/it]\u001b[A\n",
            " 10% 10/100 [00:17<03:38,  2.43s/it]\u001b[A\n",
            " 11% 11/100 [00:18<03:01,  2.04s/it]\u001b[A\n",
            " 12% 12/100 [00:20<03:14,  2.21s/it]\u001b[A\n",
            " 13% 13/100 [00:23<03:10,  2.19s/it]\u001b[A\n",
            " 14% 14/100 [00:24<02:40,  1.86s/it]\u001b[A\n",
            " 15% 15/100 [00:25<02:18,  1.63s/it]\u001b[A\n",
            " 16% 16/100 [00:26<02:16,  1.63s/it]\u001b[A\n",
            " 17% 17/100 [00:28<02:16,  1.64s/it]\u001b[A\n",
            " 18% 18/100 [00:29<02:01,  1.49s/it]\u001b[A\n",
            " 19% 19/100 [00:31<01:55,  1.43s/it]\u001b[A\n",
            " 20% 20/100 [00:33<02:13,  1.67s/it]\u001b[A\n",
            " 21% 21/100 [00:33<01:48,  1.38s/it]\u001b[A\n",
            " 22% 22/100 [00:35<01:56,  1.50s/it]\u001b[A\n",
            " 23% 23/100 [00:36<01:48,  1.41s/it]\u001b[A\n",
            " 24% 24/100 [00:37<01:31,  1.20s/it]\u001b[A\n",
            " 25% 25/100 [00:38<01:18,  1.04s/it]\u001b[A\n",
            " 26% 26/100 [00:39<01:18,  1.06s/it]\u001b[A\n",
            " 27% 27/100 [00:41<01:32,  1.26s/it]\u001b[A\n",
            " 28% 28/100 [00:42<01:33,  1.29s/it]\u001b[A\n",
            " 29% 29/100 [00:44<01:37,  1.37s/it]\u001b[A\n",
            " 30% 30/100 [00:44<01:25,  1.21s/it]\u001b[A\n",
            " 31% 31/100 [00:45<01:18,  1.14s/it]\u001b[A\n",
            " 32% 32/100 [00:47<01:23,  1.22s/it]\u001b[A\n",
            " 33% 33/100 [00:48<01:20,  1.20s/it]\u001b[A\n",
            " 34% 34/100 [00:49<01:15,  1.15s/it]\u001b[A\n",
            " 35% 35/100 [00:51<01:24,  1.31s/it]\u001b[A\n",
            " 36% 36/100 [00:52<01:29,  1.40s/it]\u001b[A\n",
            " 37% 37/100 [00:53<01:18,  1.24s/it]\u001b[A\n",
            " 38% 38/100 [00:55<01:26,  1.40s/it]\u001b[A\n",
            " 39% 39/100 [00:57<01:34,  1.55s/it]\u001b[A\n",
            " 40% 40/100 [00:59<01:34,  1.58s/it]\u001b[A\n",
            " 41% 41/100 [01:00<01:30,  1.53s/it]\u001b[A\n",
            " 42% 42/100 [01:06<02:47,  2.88s/it]\u001b[A\n",
            " 43% 43/100 [01:07<02:09,  2.27s/it]\u001b[A\n",
            " 44% 44/100 [01:08<01:55,  2.06s/it]\u001b[A\n",
            " 45% 45/100 [01:11<01:58,  2.15s/it]\u001b[A\n",
            " 46% 46/100 [01:13<01:56,  2.15s/it]\u001b[A\n",
            " 47% 47/100 [01:14<01:37,  1.84s/it]\u001b[A\n",
            " 48% 48/100 [01:15<01:20,  1.54s/it]\u001b[A\n",
            " 49% 49/100 [01:16<01:12,  1.42s/it]\u001b[A\n",
            " 50% 50/100 [01:17<01:06,  1.34s/it]\u001b[A\n",
            " 51% 51/100 [01:18<00:57,  1.18s/it]\u001b[A\n",
            " 52% 52/100 [01:19<01:01,  1.28s/it]\u001b[A\n",
            " 53% 53/100 [01:21<01:01,  1.31s/it]\u001b[A\n",
            " 54% 54/100 [01:22<01:00,  1.31s/it]\u001b[A\n",
            " 55% 55/100 [01:23<00:59,  1.31s/it]\u001b[A\n",
            " 56% 56/100 [01:25<00:56,  1.27s/it]\u001b[A\n",
            " 57% 57/100 [01:26<00:54,  1.26s/it]\u001b[A\n",
            " 58% 58/100 [01:27<00:54,  1.30s/it]\u001b[A\n",
            " 59% 59/100 [01:31<01:17,  1.89s/it]\u001b[A\n",
            " 60% 60/100 [01:32<01:13,  1.84s/it]\u001b[A\n",
            " 61% 61/100 [01:38<02:00,  3.09s/it]\u001b[A\n",
            " 62% 62/100 [01:40<01:41,  2.66s/it]\u001b[A\n",
            " 63% 63/100 [01:42<01:27,  2.37s/it]\u001b[A\n",
            " 64% 64/100 [01:48<02:04,  3.47s/it]\u001b[A\n",
            " 65% 65/100 [01:54<02:28,  4.24s/it]\u001b[A\n",
            " 66% 66/100 [01:55<01:57,  3.45s/it]\u001b[A\n",
            " 67% 67/100 [01:57<01:36,  2.92s/it]\u001b[A\n",
            " 68% 68/100 [02:01<01:44,  3.27s/it]\u001b[A\n",
            " 69% 69/100 [02:03<01:31,  2.96s/it]\u001b[A\n",
            " 70% 70/100 [02:04<01:12,  2.42s/it]\u001b[A\n",
            " 71% 71/100 [02:06<01:01,  2.12s/it]\u001b[A\n",
            " 72% 72/100 [02:08<00:56,  2.03s/it]\u001b[A\n",
            " 73% 73/100 [02:09<00:50,  1.88s/it]\u001b[A\n",
            " 74% 74/100 [02:11<00:48,  1.85s/it]\u001b[A\n",
            " 75% 75/100 [02:12<00:41,  1.67s/it]\u001b[A\n",
            " 76% 76/100 [02:13<00:35,  1.50s/it]\u001b[A\n",
            " 77% 77/100 [02:15<00:34,  1.50s/it]\u001b[A\n",
            " 78% 78/100 [02:17<00:34,  1.58s/it]\u001b[A\n",
            " 79% 79/100 [02:18<00:34,  1.62s/it]\u001b[A\n",
            " 80% 80/100 [02:19<00:28,  1.43s/it]\u001b[A\n",
            " 81% 81/100 [02:25<00:53,  2.82s/it]\u001b[A\n",
            " 82% 82/100 [02:26<00:40,  2.27s/it]\u001b[A\n",
            " 83% 83/100 [02:29<00:38,  2.28s/it]\u001b[A\n",
            " 84% 84/100 [02:31<00:36,  2.25s/it]\u001b[A\n",
            " 85% 85/100 [02:32<00:28,  1.88s/it]\u001b[A\n",
            " 86% 86/100 [02:34<00:25,  1.84s/it]\u001b[A\n",
            " 87% 87/100 [02:35<00:20,  1.55s/it]\u001b[A\n",
            " 88% 88/100 [02:36<00:16,  1.39s/it]\u001b[A\n",
            " 89% 89/100 [02:36<00:13,  1.20s/it]\u001b[A\n",
            " 90% 90/100 [02:42<00:26,  2.64s/it]\u001b[A\n",
            " 91% 91/100 [02:44<00:20,  2.23s/it]\u001b[A\n",
            " 92% 92/100 [02:44<00:14,  1.83s/it]\u001b[A\n",
            " 93% 93/100 [02:46<00:11,  1.67s/it]\u001b[A\n",
            " 94% 94/100 [02:47<00:09,  1.58s/it]\u001b[A\n",
            " 95% 95/100 [02:48<00:07,  1.52s/it]\u001b[A\n",
            " 96% 96/100 [02:50<00:06,  1.59s/it]\u001b[A\n",
            " 97% 97/100 [02:52<00:05,  1.70s/it]\u001b[A\n",
            " 98% 98/100 [02:54<00:03,  1.80s/it]\u001b[A\n",
            " 99% 99/100 [02:55<00:01,  1.46s/it]\u001b[A\n",
            "                                       \n",
            "\u001b[A{'eval_loss': 0.5523967742919922, 'eval_rouge1': 89.6162, 'eval_rouge2': 85.1935, 'eval_rougeL': 89.3909, 'eval_rougeLsum': 89.4175, 'eval_bleu': 83.7635, 'eval_gen_len': 38.9, 'eval_runtime': 186.4813, 'eval_samples_per_second': 2.145, 'eval_steps_per_second': 0.536, 'epoch': 4.91}\n",
            " 99% 1000/1015 [29:04<00:08,  1.83it/s]\n",
            "100% 100/100 [03:05<00:00,  1.21s/it]\u001b[A\n",
            "                                     \u001b[ASaving model checkpoint to pegasus_model_zero/checkpoint-1000\n",
            "Configuration saved in pegasus_model_zero/checkpoint-1000/config.json\n",
            "Configuration saved in pegasus_model_zero/checkpoint-1000/generation_config.json\n",
            "Model weights saved in pegasus_model_zero/checkpoint-1000/pytorch_model.bin\n",
            "tokenizer config file saved in pegasus_model_zero/checkpoint-1000/tokenizer_config.json\n",
            "Special tokens file saved in pegasus_model_zero/checkpoint-1000/special_tokens_map.json\n",
            "100% 1015/1015 [29:29<00:00,  1.03it/s]\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "{'train_runtime': 1786.1464, 'train_samples_per_second': 9.109, 'train_steps_per_second': 0.568, 'train_loss': 1.0080088638906997, 'epoch': 4.99}\n",
            "100% 1015/1015 [29:29<00:00,  1.74s/it]\n",
            "Saving model checkpoint to pegasus_model_zero/\n",
            "Configuration saved in pegasus_model_zero/config.json\n",
            "Configuration saved in pegasus_model_zero/generation_config.json\n",
            "Model weights saved in pegasus_model_zero/pytorch_model.bin\n",
            "tokenizer config file saved in pegasus_model_zero/tokenizer_config.json\n",
            "Special tokens file saved in pegasus_model_zero/special_tokens_map.json\n",
            "***** train metrics *****\n",
            "  epoch                    =       4.99\n",
            "  train_loss               =      1.008\n",
            "  train_runtime            = 0:29:46.14\n",
            "  train_samples            =       3254\n",
            "  train_samples_per_second =      9.109\n",
            "  train_steps_per_second   =      0.568\n",
            "05/08/2023 20:33:32 - INFO - __main__ -   *** Evaluate ***\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 400\n",
            "  Batch size = 4\n",
            "100% 100/100 [02:42<00:00,  1.62s/it]\n",
            "***** eval metrics *****\n",
            "  epoch                   =       4.99\n",
            "  eval_bleu               =    83.9398\n",
            "  eval_gen_len            =    39.0525\n",
            "  eval_loss               =     0.5524\n",
            "  eval_rouge1             =    89.6452\n",
            "  eval_rouge2             =    85.2326\n",
            "  eval_rougeL             =    89.3992\n",
            "  eval_rougeLsum          =    89.4568\n",
            "  eval_runtime            = 0:02:43.36\n",
            "  eval_samples            =        400\n",
            "  eval_samples_per_second =      2.448\n",
            "  eval_steps_per_second   =      0.612\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                      eval/bleu ▁▅▇███\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                   eval/gen_len ▁▂██▆▆\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                      eval/loss █▂▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                    eval/rouge1 ▁▆▇███\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                    eval/rouge2 ▁▆▇███\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                    eval/rougeL ▁▆▇███\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                 eval/rougeLsum ▁▆▇███\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                   eval/runtime █▇▇▇▄▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        eval/samples_per_second ▁▂▂▂▅█\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/steps_per_second ▁▁▂▂▅█\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                    train/epoch ▁▁▂▂▂▂▃▃▄▄▄▄▅▅▅▅▆▆▆▆▇▇█████\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:              train/global_step ▁▁▂▂▂▂▃▃▄▄▄▄▅▅▅▅▆▆▆▆▇▇█████\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            train/learning_rate ██▇▇▇▆▆▅▅▅▄▄▄▃▃▂▂▂▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                     train/loss █▅▄▃▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               train/total_flos ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               train/train_loss ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            train/train_runtime ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: train/train_samples_per_second ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   train/train_steps_per_second ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                      eval/bleu 83.9398\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                   eval/gen_len 39.0525\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                      eval/loss 0.55239\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                    eval/rouge1 89.6452\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                    eval/rouge2 85.2326\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                    eval/rougeL 89.3992\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                 eval/rougeLsum 89.4568\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                   eval/runtime 163.3663\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        eval/samples_per_second 2.448\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/steps_per_second 0.612\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                    train/epoch 4.99\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:              train/global_step 1015\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            train/learning_rate 0.0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                     train/loss 0.7839\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               train/total_flos 3006245053120512.0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               train/train_loss 1.00801\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            train/train_runtime 1786.1464\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: train/train_samples_per_second 9.109\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   train/train_steps_per_second 0.568\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /content/iterater/code/IteraTeR_ACL2022/model/generation/wandb/offline-run-20230508_200359-9is5tm8b\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20230508_200359-9is5tm8b/logs\u001b[0m\n",
            "CPU times: user 12.3 s, sys: 2.56 s, total: 14.8 s\n",
            "Wall time: 33min 1s\n"
          ]
        }
      ],
      "source": [
        "#training model\n",
        "%%time\n",
        "!mv /content/cs678-cp1-cp2/edit_generation/multilingual/pegasus_zeroshot_multilingual_train.sh /content/iterater/code/IteraTeR_ACL2022/model/generation\n",
        "%cd /content/iterater/code/IteraTeR_ACL2022/model/generation\n",
        "!sh pegasus_zeroshot_multilingual_train.sh"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e6941b45-03e8-4d10-d1c7-c25472f671c6",
        "id": "RCUGBBUmRuEp"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/iterater/code/IteraTeR_ACL2022/model/generation\n",
            "2023-05-08 20:39:04.407354: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "  0% 0/1440 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1313: UserWarning: Using `max_length`'s default (256) to control the generation length. This behaviour is deprecated and will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "100% 1440/1440 [48:56<00:00,  2.04s/it]\n",
            "100% 1440/1440 [00:12<00:00, 119.88it/s]\n",
            "100% 1440/1440 [00:12<00:00, 116.68it/s]\n",
            "BLEU     : 0.2479653899851835\n",
            "ROUGE     : {'rouge1': 27.861634981263272, 'rouge2': 20.146005398667764, 'rougeL': 27.670150102962648, 'rougeLsum': 27.62254995601035}\n",
            "SARI: 18.07523499839495, KEEP: 0.2663301166325079, ADD: 0.00047193938440071714, DELETE: 0.2754549939349396\n",
            "CPU times: user 17.1 s, sys: 3.65 s, total: 20.7 s\n",
            "Wall time: 49min 48s\n"
          ]
        }
      ],
      "source": [
        "#printing metrics\n",
        "%%time\n",
        "%cd /content/iterater/code/IteraTeR_ACL2022/model/generation\n",
        "!python3 pegasus_inference_and_metrics.py --checkpoint pegasus_model_zero --reference /content/cs678-cp1-cp2/multi_data/zeroshot_multi/test.json --output pegasus_zeroshot_sent_output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nyyygjmok_LE"
      },
      "source": [
        "##### Fully Supervised Training\n",
        "\n",
        "train: multilingual human_sent_level>train.json\n",
        "\n",
        "dev: multilingual human_sent_level>dev.json\n",
        "\n",
        "test: multilingual human_sent_level>test.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "94e314a5-a3c3-4a82-d9da-032d8c16e438",
        "id": "Ge7yDdIhlsUC"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mv: cannot stat '/content/cs678-cp1-cp2/edit_generation/multilingual/pegasus_fullysup_multilingual_train.sh': No such file or directory\n",
            "/content/iterater/code/IteraTeR_ACL2022/model/generation\n",
            "+ export TOKENIZERS_PARALLELISM=false\n",
            "+ PYTHON=/usr/local/bin/python\n",
            "+ git clone https://github.com/huggingface/transformers\n",
            "fatal: destination path 'transformers' already exists and is not an empty directory.\n",
            "+ cp run_summarization.py ./transformers/examples/pytorch/summarization/\n",
            "+ TRAIN_SCRIPT=./transformers/examples/pytorch/summarization/run_summarization.py\n",
            "+ TRAIN=/content/cs678-cp1-cp2/multi_data/fully_multi/train.json\n",
            "+ VALID=/content/cs678-cp1-cp2/multi_data/fully_multi/dev.json\n",
            "+ OUTPUT=pegasus_model_full/\n",
            "+ sha1sum ./transformers/examples/pytorch/summarization/run_summarization.py\n",
            "1a98b8a4f2cf13523ec0e86d2094d61c4c53c7c1  ./transformers/examples/pytorch/summarization/run_summarization.py\n",
            "+ /usr/local/bin/python ./transformers/examples/pytorch/summarization/run_summarization.py --model_name_or_path google/pegasus-large --do_train --do_eval --train_file /content/cs678-cp1-cp2/multi_data/fully_multi/train.json --validation_file /content/cs678-cp1-cp2/multi_data/fully_multi/dev.json --per_device_train_batch_size=4 --per_device_eval_batch_size=4 --num_train_epochs 5 --gradient_accumulation_steps 4 --evaluation_strategy steps --eval_steps 600 --save_steps 300 --predict_with_generate --logging_steps 50 --output_dir pegasus_model_full/ --overwrite_output_dir --text_column before_sent_with_intent --summary_column after_sent --learning_rate 3e-5\n",
            "2023-05-08 21:49:59.463843: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "05/08/2023 21:50:03 - WARNING - __main__ -   Process rank: -1, device: cuda:0, n_gpu: 1distributed training: False, 16-bits training: False\n",
            "05/08/2023 21:50:03 - INFO - __main__ -   Training/evaluation parameters Seq2SeqTrainingArguments(\n",
            "_n_gpu=1,\n",
            "adafactor=False,\n",
            "adam_beta1=0.9,\n",
            "adam_beta2=0.999,\n",
            "adam_epsilon=1e-08,\n",
            "auto_find_batch_size=False,\n",
            "bf16=False,\n",
            "bf16_full_eval=False,\n",
            "data_seed=None,\n",
            "dataloader_drop_last=False,\n",
            "dataloader_num_workers=0,\n",
            "dataloader_pin_memory=True,\n",
            "ddp_bucket_cap_mb=None,\n",
            "ddp_find_unused_parameters=None,\n",
            "ddp_timeout=1800,\n",
            "debug=[],\n",
            "deepspeed=None,\n",
            "disable_tqdm=False,\n",
            "do_eval=True,\n",
            "do_predict=False,\n",
            "do_train=True,\n",
            "eval_accumulation_steps=None,\n",
            "eval_delay=0,\n",
            "eval_steps=600,\n",
            "evaluation_strategy=steps,\n",
            "fp16=False,\n",
            "fp16_backend=auto,\n",
            "fp16_full_eval=False,\n",
            "fp16_opt_level=O1,\n",
            "fsdp=[],\n",
            "fsdp_config={'fsdp_min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},\n",
            "fsdp_min_num_params=0,\n",
            "fsdp_transformer_layer_cls_to_wrap=None,\n",
            "full_determinism=False,\n",
            "generation_config=None,\n",
            "generation_max_length=None,\n",
            "generation_num_beams=None,\n",
            "gradient_accumulation_steps=4,\n",
            "gradient_checkpointing=False,\n",
            "greater_is_better=None,\n",
            "group_by_length=False,\n",
            "half_precision_backend=auto,\n",
            "hub_model_id=None,\n",
            "hub_private_repo=False,\n",
            "hub_strategy=every_save,\n",
            "hub_token=<HUB_TOKEN>,\n",
            "ignore_data_skip=False,\n",
            "include_inputs_for_metrics=False,\n",
            "jit_mode_eval=False,\n",
            "label_names=None,\n",
            "label_smoothing_factor=0.0,\n",
            "learning_rate=3e-05,\n",
            "length_column_name=length,\n",
            "load_best_model_at_end=False,\n",
            "local_rank=-1,\n",
            "log_level=passive,\n",
            "log_level_replica=warning,\n",
            "log_on_each_node=True,\n",
            "logging_dir=pegasus_model_full/runs/May08_21-50-03_532485e9ca09,\n",
            "logging_first_step=False,\n",
            "logging_nan_inf_filter=True,\n",
            "logging_steps=50,\n",
            "logging_strategy=steps,\n",
            "lr_scheduler_type=linear,\n",
            "max_grad_norm=1.0,\n",
            "max_steps=-1,\n",
            "metric_for_best_model=None,\n",
            "mp_parameters=,\n",
            "no_cuda=False,\n",
            "num_train_epochs=5.0,\n",
            "optim=adamw_hf,\n",
            "optim_args=None,\n",
            "output_dir=pegasus_model_full/,\n",
            "overwrite_output_dir=True,\n",
            "past_index=-1,\n",
            "per_device_eval_batch_size=4,\n",
            "per_device_train_batch_size=4,\n",
            "predict_with_generate=True,\n",
            "prediction_loss_only=False,\n",
            "push_to_hub=False,\n",
            "push_to_hub_model_id=None,\n",
            "push_to_hub_organization=None,\n",
            "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
            "ray_scope=last,\n",
            "remove_unused_columns=True,\n",
            "report_to=['tensorboard', 'wandb'],\n",
            "resume_from_checkpoint=None,\n",
            "run_name=pegasus_model_full/,\n",
            "save_on_each_node=False,\n",
            "save_safetensors=False,\n",
            "save_steps=300,\n",
            "save_strategy=steps,\n",
            "save_total_limit=None,\n",
            "seed=42,\n",
            "sharded_ddp=[],\n",
            "skip_memory_metrics=True,\n",
            "sortish_sampler=False,\n",
            "tf32=None,\n",
            "torch_compile=False,\n",
            "torch_compile_backend=None,\n",
            "torch_compile_mode=None,\n",
            "torchdynamo=None,\n",
            "tpu_metrics_debug=False,\n",
            "tpu_num_cores=None,\n",
            "use_ipex=False,\n",
            "use_legacy_prediction_loop=False,\n",
            "use_mps_device=False,\n",
            "warmup_ratio=0.0,\n",
            "warmup_steps=0,\n",
            "weight_decay=0.0,\n",
            "xpu_backend=None,\n",
            ")\n",
            "05/08/2023 21:50:03 - INFO - __main__ -   Seq2SeqTrainingArguments(\n",
            "_n_gpu=1,\n",
            "adafactor=False,\n",
            "adam_beta1=0.9,\n",
            "adam_beta2=0.999,\n",
            "adam_epsilon=1e-08,\n",
            "auto_find_batch_size=False,\n",
            "bf16=False,\n",
            "bf16_full_eval=False,\n",
            "data_seed=None,\n",
            "dataloader_drop_last=False,\n",
            "dataloader_num_workers=0,\n",
            "dataloader_pin_memory=True,\n",
            "ddp_bucket_cap_mb=None,\n",
            "ddp_find_unused_parameters=None,\n",
            "ddp_timeout=1800,\n",
            "debug=[],\n",
            "deepspeed=None,\n",
            "disable_tqdm=False,\n",
            "do_eval=True,\n",
            "do_predict=False,\n",
            "do_train=True,\n",
            "eval_accumulation_steps=None,\n",
            "eval_delay=0,\n",
            "eval_steps=600,\n",
            "evaluation_strategy=steps,\n",
            "fp16=False,\n",
            "fp16_backend=auto,\n",
            "fp16_full_eval=False,\n",
            "fp16_opt_level=O1,\n",
            "fsdp=[],\n",
            "fsdp_config={'fsdp_min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},\n",
            "fsdp_min_num_params=0,\n",
            "fsdp_transformer_layer_cls_to_wrap=None,\n",
            "full_determinism=False,\n",
            "generation_config=None,\n",
            "generation_max_length=None,\n",
            "generation_num_beams=None,\n",
            "gradient_accumulation_steps=4,\n",
            "gradient_checkpointing=False,\n",
            "greater_is_better=None,\n",
            "group_by_length=False,\n",
            "half_precision_backend=auto,\n",
            "hub_model_id=None,\n",
            "hub_private_repo=False,\n",
            "hub_strategy=every_save,\n",
            "hub_token=<HUB_TOKEN>,\n",
            "ignore_data_skip=False,\n",
            "include_inputs_for_metrics=False,\n",
            "jit_mode_eval=False,\n",
            "label_names=None,\n",
            "label_smoothing_factor=0.0,\n",
            "learning_rate=3e-05,\n",
            "length_column_name=length,\n",
            "load_best_model_at_end=False,\n",
            "local_rank=-1,\n",
            "log_level=passive,\n",
            "log_level_replica=warning,\n",
            "log_on_each_node=True,\n",
            "logging_dir=pegasus_model_full/runs/May08_21-50-03_532485e9ca09,\n",
            "logging_first_step=False,\n",
            "logging_nan_inf_filter=True,\n",
            "logging_steps=50,\n",
            "logging_strategy=steps,\n",
            "lr_scheduler_type=linear,\n",
            "max_grad_norm=1.0,\n",
            "max_steps=-1,\n",
            "metric_for_best_model=None,\n",
            "mp_parameters=,\n",
            "no_cuda=False,\n",
            "num_train_epochs=5.0,\n",
            "optim=adamw_hf,\n",
            "optim_args=None,\n",
            "output_dir=pegasus_model_full/,\n",
            "overwrite_output_dir=True,\n",
            "past_index=-1,\n",
            "per_device_eval_batch_size=4,\n",
            "per_device_train_batch_size=4,\n",
            "predict_with_generate=True,\n",
            "prediction_loss_only=False,\n",
            "push_to_hub=False,\n",
            "push_to_hub_model_id=None,\n",
            "push_to_hub_organization=None,\n",
            "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
            "ray_scope=last,\n",
            "remove_unused_columns=True,\n",
            "report_to=['tensorboard', 'wandb'],\n",
            "resume_from_checkpoint=None,\n",
            "run_name=pegasus_model_full/,\n",
            "save_on_each_node=False,\n",
            "save_safetensors=False,\n",
            "save_steps=300,\n",
            "save_strategy=steps,\n",
            "save_total_limit=None,\n",
            "seed=42,\n",
            "sharded_ddp=[],\n",
            "skip_memory_metrics=True,\n",
            "sortish_sampler=False,\n",
            "tf32=None,\n",
            "torch_compile=False,\n",
            "torch_compile_backend=None,\n",
            "torch_compile_mode=None,\n",
            "torchdynamo=None,\n",
            "tpu_metrics_debug=False,\n",
            "tpu_num_cores=None,\n",
            "use_ipex=False,\n",
            "use_legacy_prediction_loop=False,\n",
            "use_mps_device=False,\n",
            "warmup_ratio=0.0,\n",
            "warmup_steps=0,\n",
            "weight_decay=0.0,\n",
            "xpu_backend=None,\n",
            ")\n",
            "05/08/2023 21:50:03 - INFO - __main__ -   42\n",
            "05/08/2023 21:50:03 - WARNING - datasets.builder -   Using custom data configuration default-f80eca47a15136ba\n",
            "05/08/2023 21:50:03 - WARNING - datasets.builder -   Reusing dataset json (/root/.cache/huggingface/datasets/json/default-f80eca47a15136ba/0.0.0/ac0ca5f5289a6cf108e706efcf040422dbbfa8e658dee6a819f20d76bb84d26b)\n",
            "100% 2/2 [00:00<00:00, 670.23it/s]\n",
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--google--pegasus-large/snapshots/dec7796b22f29b7d1c476192313eae8ed57b6b77/config.json\n",
            "Model config PegasusConfig {\n",
            "  \"_name_or_path\": \"google/pegasus-large\",\n",
            "  \"activation_dropout\": 0.1,\n",
            "  \"activation_function\": \"relu\",\n",
            "  \"add_bias_logits\": false,\n",
            "  \"add_final_layer_norm\": true,\n",
            "  \"architectures\": [\n",
            "    \"PegasusForConditionalGeneration\"\n",
            "  ],\n",
            "  \"attention_dropout\": 0.1,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"classif_dropout\": 0.0,\n",
            "  \"classifier_dropout\": 0.0,\n",
            "  \"d_model\": 1024,\n",
            "  \"decoder_attention_heads\": 16,\n",
            "  \"decoder_ffn_dim\": 4096,\n",
            "  \"decoder_layerdrop\": 0.0,\n",
            "  \"decoder_layers\": 16,\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"dropout\": 0.1,\n",
            "  \"encoder_attention_heads\": 16,\n",
            "  \"encoder_ffn_dim\": 4096,\n",
            "  \"encoder_layerdrop\": 0.0,\n",
            "  \"encoder_layers\": 16,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"extra_pos_embeddings\": 1,\n",
            "  \"force_bos_token_to_be_generated\": false,\n",
            "  \"forced_eos_token_id\": 1,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\",\n",
            "    \"2\": \"LABEL_2\"\n",
            "  },\n",
            "  \"init_std\": 0.02,\n",
            "  \"is_encoder_decoder\": true,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1,\n",
            "    \"LABEL_2\": 2\n",
            "  },\n",
            "  \"length_penalty\": 0.8,\n",
            "  \"max_length\": 256,\n",
            "  \"max_position_embeddings\": 1024,\n",
            "  \"model_type\": \"pegasus\",\n",
            "  \"normalize_before\": true,\n",
            "  \"normalize_embedding\": false,\n",
            "  \"num_beams\": 8,\n",
            "  \"num_hidden_layers\": 16,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"scale_embedding\": true,\n",
            "  \"static_position_embeddings\": true,\n",
            "  \"task_specific_params\": {\n",
            "    \"summarization_aeslc\": {\n",
            "      \"length_penalty\": 0.6,\n",
            "      \"max_length\": 32,\n",
            "      \"max_position_embeddings\": 512\n",
            "    },\n",
            "    \"summarization_arxiv\": {\n",
            "      \"length_penalty\": 0.8,\n",
            "      \"max_length\": 256,\n",
            "      \"max_position_embeddings\": 1024\n",
            "    },\n",
            "    \"summarization_big_patent\": {\n",
            "      \"length_penalty\": 0.7,\n",
            "      \"max_length\": 256,\n",
            "      \"max_position_embeddings\": 1024\n",
            "    },\n",
            "    \"summarization_billsum\": {\n",
            "      \"length_penalty\": 0.6,\n",
            "      \"max_length\": 256,\n",
            "      \"max_position_embeddings\": 1024\n",
            "    },\n",
            "    \"summarization_cnn_dailymail\": {\n",
            "      \"length_penalty\": 0.8,\n",
            "      \"max_length\": 128,\n",
            "      \"max_position_embeddings\": 1024\n",
            "    },\n",
            "    \"summarization_gigaword\": {\n",
            "      \"length_penalty\": 0.6,\n",
            "      \"max_length\": 32,\n",
            "      \"max_position_embeddings\": 128\n",
            "    },\n",
            "    \"summarization_large\": {\n",
            "      \"length_penalty\": 0.8,\n",
            "      \"max_length\": 256,\n",
            "      \"max_position_embeddings\": 1024\n",
            "    },\n",
            "    \"summarization_multi_news\": {\n",
            "      \"length_penalty\": 0.8,\n",
            "      \"max_length\": 256,\n",
            "      \"max_position_embeddings\": 1024\n",
            "    },\n",
            "    \"summarization_newsroom\": {\n",
            "      \"length_penalty\": 0.8,\n",
            "      \"max_length\": 128,\n",
            "      \"max_position_embeddings\": 512\n",
            "    },\n",
            "    \"summarization_pubmed\": {\n",
            "      \"length_penalty\": 0.8,\n",
            "      \"max_length\": 256,\n",
            "      \"max_position_embeddings\": 1024\n",
            "    },\n",
            "    \"summarization_reddit_tifu\": {\n",
            "      \"length_penalty\": 0.6,\n",
            "      \"max_length\": 128,\n",
            "      \"max_position_embeddings\": 512\n",
            "    },\n",
            "    \"summarization_wikihow\": {\n",
            "      \"length_penalty\": 0.6,\n",
            "      \"max_length\": 256,\n",
            "      \"max_position_embeddings\": 512\n",
            "    },\n",
            "    \"summarization_xsum\": {\n",
            "      \"length_penalty\": 0.8,\n",
            "      \"max_length\": 64,\n",
            "      \"max_position_embeddings\": 512\n",
            "    }\n",
            "  },\n",
            "  \"transformers_version\": \"4.28.1\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 96103\n",
            "}\n",
            "\n",
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--google--pegasus-large/snapshots/dec7796b22f29b7d1c476192313eae8ed57b6b77/config.json\n",
            "Model config PegasusConfig {\n",
            "  \"_name_or_path\": \"google/pegasus-large\",\n",
            "  \"activation_dropout\": 0.1,\n",
            "  \"activation_function\": \"relu\",\n",
            "  \"add_bias_logits\": false,\n",
            "  \"add_final_layer_norm\": true,\n",
            "  \"architectures\": [\n",
            "    \"PegasusForConditionalGeneration\"\n",
            "  ],\n",
            "  \"attention_dropout\": 0.1,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"classif_dropout\": 0.0,\n",
            "  \"classifier_dropout\": 0.0,\n",
            "  \"d_model\": 1024,\n",
            "  \"decoder_attention_heads\": 16,\n",
            "  \"decoder_ffn_dim\": 4096,\n",
            "  \"decoder_layerdrop\": 0.0,\n",
            "  \"decoder_layers\": 16,\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"dropout\": 0.1,\n",
            "  \"encoder_attention_heads\": 16,\n",
            "  \"encoder_ffn_dim\": 4096,\n",
            "  \"encoder_layerdrop\": 0.0,\n",
            "  \"encoder_layers\": 16,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"extra_pos_embeddings\": 1,\n",
            "  \"force_bos_token_to_be_generated\": false,\n",
            "  \"forced_eos_token_id\": 1,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\",\n",
            "    \"2\": \"LABEL_2\"\n",
            "  },\n",
            "  \"init_std\": 0.02,\n",
            "  \"is_encoder_decoder\": true,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1,\n",
            "    \"LABEL_2\": 2\n",
            "  },\n",
            "  \"length_penalty\": 0.8,\n",
            "  \"max_length\": 256,\n",
            "  \"max_position_embeddings\": 1024,\n",
            "  \"model_type\": \"pegasus\",\n",
            "  \"normalize_before\": true,\n",
            "  \"normalize_embedding\": false,\n",
            "  \"num_beams\": 8,\n",
            "  \"num_hidden_layers\": 16,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"scale_embedding\": true,\n",
            "  \"static_position_embeddings\": true,\n",
            "  \"task_specific_params\": {\n",
            "    \"summarization_aeslc\": {\n",
            "      \"length_penalty\": 0.6,\n",
            "      \"max_length\": 32,\n",
            "      \"max_position_embeddings\": 512\n",
            "    },\n",
            "    \"summarization_arxiv\": {\n",
            "      \"length_penalty\": 0.8,\n",
            "      \"max_length\": 256,\n",
            "      \"max_position_embeddings\": 1024\n",
            "    },\n",
            "    \"summarization_big_patent\": {\n",
            "      \"length_penalty\": 0.7,\n",
            "      \"max_length\": 256,\n",
            "      \"max_position_embeddings\": 1024\n",
            "    },\n",
            "    \"summarization_billsum\": {\n",
            "      \"length_penalty\": 0.6,\n",
            "      \"max_length\": 256,\n",
            "      \"max_position_embeddings\": 1024\n",
            "    },\n",
            "    \"summarization_cnn_dailymail\": {\n",
            "      \"length_penalty\": 0.8,\n",
            "      \"max_length\": 128,\n",
            "      \"max_position_embeddings\": 1024\n",
            "    },\n",
            "    \"summarization_gigaword\": {\n",
            "      \"length_penalty\": 0.6,\n",
            "      \"max_length\": 32,\n",
            "      \"max_position_embeddings\": 128\n",
            "    },\n",
            "    \"summarization_large\": {\n",
            "      \"length_penalty\": 0.8,\n",
            "      \"max_length\": 256,\n",
            "      \"max_position_embeddings\": 1024\n",
            "    },\n",
            "    \"summarization_multi_news\": {\n",
            "      \"length_penalty\": 0.8,\n",
            "      \"max_length\": 256,\n",
            "      \"max_position_embeddings\": 1024\n",
            "    },\n",
            "    \"summarization_newsroom\": {\n",
            "      \"length_penalty\": 0.8,\n",
            "      \"max_length\": 128,\n",
            "      \"max_position_embeddings\": 512\n",
            "    },\n",
            "    \"summarization_pubmed\": {\n",
            "      \"length_penalty\": 0.8,\n",
            "      \"max_length\": 256,\n",
            "      \"max_position_embeddings\": 1024\n",
            "    },\n",
            "    \"summarization_reddit_tifu\": {\n",
            "      \"length_penalty\": 0.6,\n",
            "      \"max_length\": 128,\n",
            "      \"max_position_embeddings\": 512\n",
            "    },\n",
            "    \"summarization_wikihow\": {\n",
            "      \"length_penalty\": 0.6,\n",
            "      \"max_length\": 256,\n",
            "      \"max_position_embeddings\": 512\n",
            "    },\n",
            "    \"summarization_xsum\": {\n",
            "      \"length_penalty\": 0.8,\n",
            "      \"max_length\": 64,\n",
            "      \"max_position_embeddings\": 512\n",
            "    }\n",
            "  },\n",
            "  \"transformers_version\": \"4.28.1\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 96103\n",
            "}\n",
            "\n",
            "loading file spiece.model from cache at /root/.cache/huggingface/hub/models--google--pegasus-large/snapshots/dec7796b22f29b7d1c476192313eae8ed57b6b77/spiece.model\n",
            "loading file tokenizer.json from cache at None\n",
            "loading file added_tokens.json from cache at None\n",
            "loading file special_tokens_map.json from cache at /root/.cache/huggingface/hub/models--google--pegasus-large/snapshots/dec7796b22f29b7d1c476192313eae8ed57b6b77/special_tokens_map.json\n",
            "loading file tokenizer_config.json from cache at /root/.cache/huggingface/hub/models--google--pegasus-large/snapshots/dec7796b22f29b7d1c476192313eae8ed57b6b77/tokenizer_config.json\n",
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--google--pegasus-large/snapshots/dec7796b22f29b7d1c476192313eae8ed57b6b77/config.json\n",
            "Model config PegasusConfig {\n",
            "  \"_name_or_path\": \"google/pegasus-large\",\n",
            "  \"activation_dropout\": 0.1,\n",
            "  \"activation_function\": \"relu\",\n",
            "  \"add_bias_logits\": false,\n",
            "  \"add_final_layer_norm\": true,\n",
            "  \"architectures\": [\n",
            "    \"PegasusForConditionalGeneration\"\n",
            "  ],\n",
            "  \"attention_dropout\": 0.1,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"classif_dropout\": 0.0,\n",
            "  \"classifier_dropout\": 0.0,\n",
            "  \"d_model\": 1024,\n",
            "  \"decoder_attention_heads\": 16,\n",
            "  \"decoder_ffn_dim\": 4096,\n",
            "  \"decoder_layerdrop\": 0.0,\n",
            "  \"decoder_layers\": 16,\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"dropout\": 0.1,\n",
            "  \"encoder_attention_heads\": 16,\n",
            "  \"encoder_ffn_dim\": 4096,\n",
            "  \"encoder_layerdrop\": 0.0,\n",
            "  \"encoder_layers\": 16,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"extra_pos_embeddings\": 1,\n",
            "  \"force_bos_token_to_be_generated\": false,\n",
            "  \"forced_eos_token_id\": 1,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\",\n",
            "    \"2\": \"LABEL_2\"\n",
            "  },\n",
            "  \"init_std\": 0.02,\n",
            "  \"is_encoder_decoder\": true,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1,\n",
            "    \"LABEL_2\": 2\n",
            "  },\n",
            "  \"length_penalty\": 0.8,\n",
            "  \"max_length\": 256,\n",
            "  \"max_position_embeddings\": 1024,\n",
            "  \"model_type\": \"pegasus\",\n",
            "  \"normalize_before\": true,\n",
            "  \"normalize_embedding\": false,\n",
            "  \"num_beams\": 8,\n",
            "  \"num_hidden_layers\": 16,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"scale_embedding\": true,\n",
            "  \"static_position_embeddings\": true,\n",
            "  \"task_specific_params\": {\n",
            "    \"summarization_aeslc\": {\n",
            "      \"length_penalty\": 0.6,\n",
            "      \"max_length\": 32,\n",
            "      \"max_position_embeddings\": 512\n",
            "    },\n",
            "    \"summarization_arxiv\": {\n",
            "      \"length_penalty\": 0.8,\n",
            "      \"max_length\": 256,\n",
            "      \"max_position_embeddings\": 1024\n",
            "    },\n",
            "    \"summarization_big_patent\": {\n",
            "      \"length_penalty\": 0.7,\n",
            "      \"max_length\": 256,\n",
            "      \"max_position_embeddings\": 1024\n",
            "    },\n",
            "    \"summarization_billsum\": {\n",
            "      \"length_penalty\": 0.6,\n",
            "      \"max_length\": 256,\n",
            "      \"max_position_embeddings\": 1024\n",
            "    },\n",
            "    \"summarization_cnn_dailymail\": {\n",
            "      \"length_penalty\": 0.8,\n",
            "      \"max_length\": 128,\n",
            "      \"max_position_embeddings\": 1024\n",
            "    },\n",
            "    \"summarization_gigaword\": {\n",
            "      \"length_penalty\": 0.6,\n",
            "      \"max_length\": 32,\n",
            "      \"max_position_embeddings\": 128\n",
            "    },\n",
            "    \"summarization_large\": {\n",
            "      \"length_penalty\": 0.8,\n",
            "      \"max_length\": 256,\n",
            "      \"max_position_embeddings\": 1024\n",
            "    },\n",
            "    \"summarization_multi_news\": {\n",
            "      \"length_penalty\": 0.8,\n",
            "      \"max_length\": 256,\n",
            "      \"max_position_embeddings\": 1024\n",
            "    },\n",
            "    \"summarization_newsroom\": {\n",
            "      \"length_penalty\": 0.8,\n",
            "      \"max_length\": 128,\n",
            "      \"max_position_embeddings\": 512\n",
            "    },\n",
            "    \"summarization_pubmed\": {\n",
            "      \"length_penalty\": 0.8,\n",
            "      \"max_length\": 256,\n",
            "      \"max_position_embeddings\": 1024\n",
            "    },\n",
            "    \"summarization_reddit_tifu\": {\n",
            "      \"length_penalty\": 0.6,\n",
            "      \"max_length\": 128,\n",
            "      \"max_position_embeddings\": 512\n",
            "    },\n",
            "    \"summarization_wikihow\": {\n",
            "      \"length_penalty\": 0.6,\n",
            "      \"max_length\": 256,\n",
            "      \"max_position_embeddings\": 512\n",
            "    },\n",
            "    \"summarization_xsum\": {\n",
            "      \"length_penalty\": 0.8,\n",
            "      \"max_length\": 64,\n",
            "      \"max_position_embeddings\": 512\n",
            "    }\n",
            "  },\n",
            "  \"transformers_version\": \"4.28.1\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 96103\n",
            "}\n",
            "\n",
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--google--pegasus-large/snapshots/dec7796b22f29b7d1c476192313eae8ed57b6b77/config.json\n",
            "Model config PegasusConfig {\n",
            "  \"_name_or_path\": \"google/pegasus-large\",\n",
            "  \"activation_dropout\": 0.1,\n",
            "  \"activation_function\": \"relu\",\n",
            "  \"add_bias_logits\": false,\n",
            "  \"add_final_layer_norm\": true,\n",
            "  \"architectures\": [\n",
            "    \"PegasusForConditionalGeneration\"\n",
            "  ],\n",
            "  \"attention_dropout\": 0.1,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"classif_dropout\": 0.0,\n",
            "  \"classifier_dropout\": 0.0,\n",
            "  \"d_model\": 1024,\n",
            "  \"decoder_attention_heads\": 16,\n",
            "  \"decoder_ffn_dim\": 4096,\n",
            "  \"decoder_layerdrop\": 0.0,\n",
            "  \"decoder_layers\": 16,\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"dropout\": 0.1,\n",
            "  \"encoder_attention_heads\": 16,\n",
            "  \"encoder_ffn_dim\": 4096,\n",
            "  \"encoder_layerdrop\": 0.0,\n",
            "  \"encoder_layers\": 16,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"extra_pos_embeddings\": 1,\n",
            "  \"force_bos_token_to_be_generated\": false,\n",
            "  \"forced_eos_token_id\": 1,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\",\n",
            "    \"2\": \"LABEL_2\"\n",
            "  },\n",
            "  \"init_std\": 0.02,\n",
            "  \"is_encoder_decoder\": true,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1,\n",
            "    \"LABEL_2\": 2\n",
            "  },\n",
            "  \"length_penalty\": 0.8,\n",
            "  \"max_length\": 256,\n",
            "  \"max_position_embeddings\": 1024,\n",
            "  \"model_type\": \"pegasus\",\n",
            "  \"normalize_before\": true,\n",
            "  \"normalize_embedding\": false,\n",
            "  \"num_beams\": 8,\n",
            "  \"num_hidden_layers\": 16,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"scale_embedding\": true,\n",
            "  \"static_position_embeddings\": true,\n",
            "  \"task_specific_params\": {\n",
            "    \"summarization_aeslc\": {\n",
            "      \"length_penalty\": 0.6,\n",
            "      \"max_length\": 32,\n",
            "      \"max_position_embeddings\": 512\n",
            "    },\n",
            "    \"summarization_arxiv\": {\n",
            "      \"length_penalty\": 0.8,\n",
            "      \"max_length\": 256,\n",
            "      \"max_position_embeddings\": 1024\n",
            "    },\n",
            "    \"summarization_big_patent\": {\n",
            "      \"length_penalty\": 0.7,\n",
            "      \"max_length\": 256,\n",
            "      \"max_position_embeddings\": 1024\n",
            "    },\n",
            "    \"summarization_billsum\": {\n",
            "      \"length_penalty\": 0.6,\n",
            "      \"max_length\": 256,\n",
            "      \"max_position_embeddings\": 1024\n",
            "    },\n",
            "    \"summarization_cnn_dailymail\": {\n",
            "      \"length_penalty\": 0.8,\n",
            "      \"max_length\": 128,\n",
            "      \"max_position_embeddings\": 1024\n",
            "    },\n",
            "    \"summarization_gigaword\": {\n",
            "      \"length_penalty\": 0.6,\n",
            "      \"max_length\": 32,\n",
            "      \"max_position_embeddings\": 128\n",
            "    },\n",
            "    \"summarization_large\": {\n",
            "      \"length_penalty\": 0.8,\n",
            "      \"max_length\": 256,\n",
            "      \"max_position_embeddings\": 1024\n",
            "    },\n",
            "    \"summarization_multi_news\": {\n",
            "      \"length_penalty\": 0.8,\n",
            "      \"max_length\": 256,\n",
            "      \"max_position_embeddings\": 1024\n",
            "    },\n",
            "    \"summarization_newsroom\": {\n",
            "      \"length_penalty\": 0.8,\n",
            "      \"max_length\": 128,\n",
            "      \"max_position_embeddings\": 512\n",
            "    },\n",
            "    \"summarization_pubmed\": {\n",
            "      \"length_penalty\": 0.8,\n",
            "      \"max_length\": 256,\n",
            "      \"max_position_embeddings\": 1024\n",
            "    },\n",
            "    \"summarization_reddit_tifu\": {\n",
            "      \"length_penalty\": 0.6,\n",
            "      \"max_length\": 128,\n",
            "      \"max_position_embeddings\": 512\n",
            "    },\n",
            "    \"summarization_wikihow\": {\n",
            "      \"length_penalty\": 0.6,\n",
            "      \"max_length\": 256,\n",
            "      \"max_position_embeddings\": 512\n",
            "    },\n",
            "    \"summarization_xsum\": {\n",
            "      \"length_penalty\": 0.8,\n",
            "      \"max_length\": 64,\n",
            "      \"max_position_embeddings\": 512\n",
            "    }\n",
            "  },\n",
            "  \"transformers_version\": \"4.28.1\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 96103\n",
            "}\n",
            "\n",
            "Assigning ['<clarity>', '<fluency>', '<coherence>', '<style>', '<meaning-changed>'] to the additional_special_tokens key of the tokenizer\n",
            "loading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--google--pegasus-large/snapshots/dec7796b22f29b7d1c476192313eae8ed57b6b77/pytorch_model.bin\n",
            "Generate config GenerationConfig {\n",
            "  \"_from_model_config\": true,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"forced_eos_token_id\": 1,\n",
            "  \"length_penalty\": 0.8,\n",
            "  \"max_length\": 256,\n",
            "  \"num_beams\": 8,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"transformers_version\": \"4.28.1\"\n",
            "}\n",
            "\n",
            "All model checkpoint weights were used when initializing PegasusForConditionalGeneration.\n",
            "\n",
            "All the weights of PegasusForConditionalGeneration were initialized from the model checkpoint at google/pegasus-large.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use PegasusForConditionalGeneration for predictions without further training.\n",
            "loading configuration file generation_config.json from cache at /root/.cache/huggingface/hub/models--google--pegasus-large/snapshots/dec7796b22f29b7d1c476192313eae8ed57b6b77/generation_config.json\n",
            "Generate config GenerationConfig {\n",
            "  \"_from_model_config\": true,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"forced_eos_token_id\": 1,\n",
            "  \"length_penalty\": 0.8,\n",
            "  \"max_length\": 256,\n",
            "  \"num_beams\": 8,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"transformers_version\": \"4.28.1\"\n",
            "}\n",
            "\n",
            "05/08/2023 21:50:17 - WARNING - datasets.fingerprint -   Parameter 'function'=<function main.<locals>.preprocess_function at 0x7f928e71d000> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.\n",
            "05/08/2023 21:50:17 - WARNING - datasets.arrow_dataset -   Loading cached processed dataset at /root/.cache/huggingface/datasets/json/default-f80eca47a15136ba/0.0.0/ac0ca5f5289a6cf108e706efcf040422dbbfa8e658dee6a819f20d76bb84d26b/cache-1c80317fa3b1799d.arrow\n",
            "05/08/2023 21:50:17 - WARNING - datasets.arrow_dataset -   Loading cached processed dataset at /root/.cache/huggingface/datasets/json/default-f80eca47a15136ba/0.0.0/ac0ca5f5289a6cf108e706efcf040422dbbfa8e658dee6a819f20d76bb84d26b/cache-bdd640fb06671ad1.arrow\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "***** Running training *****\n",
            "  Num examples = 4,800\n",
            "  Num Epochs = 5\n",
            "  Instantaneous batch size per device = 4\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
            "  Gradient Accumulation steps = 4\n",
            "  Total optimization steps = 1,500\n",
            "  Number of trainable parameters = 568,705,024\n",
            "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (1) Create a W&B account\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (2) Use an existing W&B account\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (3) Don't visualize my results\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Enter your choice: 3\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You chose \"Don't visualize my results\"\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.15.2\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n",
            "  0% 0/1500 [00:00<?, ?it/s]You're using a PegasusTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
            "{'loss': 1.4572, 'learning_rate': 2.9e-05, 'epoch': 0.17}\n",
            "{'loss': 0.989, 'learning_rate': 2.8e-05, 'epoch': 0.33}\n",
            "{'loss': 0.9842, 'learning_rate': 2.7000000000000002e-05, 'epoch': 0.5}\n",
            "{'loss': 0.7603, 'learning_rate': 2.6000000000000002e-05, 'epoch': 0.67}\n",
            "{'loss': 0.6976, 'learning_rate': 2.5e-05, 'epoch': 0.83}\n",
            "{'loss': 0.7078, 'learning_rate': 2.4e-05, 'epoch': 1.0}\n",
            " 20% 300/1500 [02:48<11:12,  1.79it/s]Saving model checkpoint to pegasus_model_full/checkpoint-300\n",
            "Configuration saved in pegasus_model_full/checkpoint-300/config.json\n",
            "Configuration saved in pegasus_model_full/checkpoint-300/generation_config.json\n",
            "Model weights saved in pegasus_model_full/checkpoint-300/pytorch_model.bin\n",
            "tokenizer config file saved in pegasus_model_full/checkpoint-300/tokenizer_config.json\n",
            "Special tokens file saved in pegasus_model_full/checkpoint-300/special_tokens_map.json\n",
            "{'loss': 0.6988, 'learning_rate': 2.3000000000000003e-05, 'epoch': 1.17}\n",
            "{'loss': 0.5552, 'learning_rate': 2.2e-05, 'epoch': 1.33}\n",
            "{'loss': 0.5923, 'learning_rate': 2.1e-05, 'epoch': 1.5}\n",
            "{'loss': 0.5682, 'learning_rate': 1.9999999999999998e-05, 'epoch': 1.67}\n",
            "{'loss': 0.5729, 'learning_rate': 1.9e-05, 'epoch': 1.83}\n",
            "{'loss': 0.5142, 'learning_rate': 1.8e-05, 'epoch': 2.0}\n",
            " 40% 600/1500 [05:54<08:37,  1.74it/s]***** Running Evaluation *****\n",
            "  Num examples = 1600\n",
            "  Batch size = 4\n",
            "Generate config GenerationConfig {\n",
            "  \"_from_model_config\": true,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"forced_eos_token_id\": 1,\n",
            "  \"length_penalty\": 0.8,\n",
            "  \"max_length\": 256,\n",
            "  \"num_beams\": 8,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"transformers_version\": \"4.28.1\"\n",
            "}\n",
            "\n",
            "\n",
            "  0% 0/400 [00:00<?, ?it/s]\u001b[A\n",
            "  0% 2/400 [00:02<07:48,  1.18s/it]\u001b[A\n",
            "  1% 3/400 [00:03<08:42,  1.32s/it]\u001b[A\n",
            "  1% 4/400 [00:05<09:08,  1.38s/it]\u001b[A\n",
            "  1% 5/400 [00:06<09:31,  1.45s/it]\u001b[A\n",
            "  2% 6/400 [00:08<09:25,  1.43s/it]\u001b[A\n",
            "  2% 7/400 [00:09<09:24,  1.44s/it]\u001b[A\n",
            "  2% 8/400 [00:11<09:46,  1.50s/it]\u001b[A\n",
            "  2% 9/400 [00:13<10:23,  1.60s/it]\u001b[A\n",
            "  2% 10/400 [00:14<09:59,  1.54s/it]\u001b[A\n",
            "  3% 11/400 [00:16<11:03,  1.71s/it]\u001b[A\n",
            "  3% 12/400 [00:18<12:00,  1.86s/it]\u001b[A\n",
            "  3% 13/400 [00:21<12:31,  1.94s/it]\u001b[A\n",
            "  4% 14/400 [00:23<13:13,  2.06s/it]\u001b[A\n",
            "  4% 15/400 [00:25<13:53,  2.17s/it]\u001b[A\n",
            "  4% 16/400 [00:27<12:52,  2.01s/it]\u001b[A\n",
            "  4% 17/400 [00:29<12:28,  1.95s/it]\u001b[A\n",
            "  4% 18/400 [00:31<12:19,  1.94s/it]\u001b[A\n",
            "  5% 19/400 [00:33<13:13,  2.08s/it]\u001b[A\n",
            "  5% 20/400 [00:36<13:52,  2.19s/it]\u001b[A\n",
            "  5% 21/400 [00:37<12:15,  1.94s/it]\u001b[A\n",
            "  6% 22/400 [00:39<12:29,  1.98s/it]\u001b[A\n",
            "  6% 23/400 [00:41<12:05,  1.93s/it]\u001b[A\n",
            "  6% 24/400 [00:42<10:12,  1.63s/it]\u001b[A\n",
            "  6% 25/400 [00:48<18:21,  2.94s/it]\u001b[A\n",
            "  6% 26/400 [00:50<17:11,  2.76s/it]\u001b[A\n",
            "  7% 27/400 [00:52<16:07,  2.59s/it]\u001b[A\n",
            "  7% 28/400 [00:54<14:11,  2.29s/it]\u001b[A\n",
            "  7% 29/400 [00:56<13:25,  2.17s/it]\u001b[A\n",
            "  8% 30/400 [00:57<12:15,  1.99s/it]\u001b[A\n",
            "  8% 31/400 [00:59<10:54,  1.77s/it]\u001b[A\n",
            "  8% 32/400 [01:00<10:23,  1.69s/it]\u001b[A\n",
            "  8% 33/400 [01:02<10:11,  1.67s/it]\u001b[A\n",
            "  8% 34/400 [01:03<09:29,  1.56s/it]\u001b[A\n",
            "  9% 35/400 [01:05<09:40,  1.59s/it]\u001b[A\n",
            "  9% 36/400 [01:06<09:38,  1.59s/it]\u001b[A\n",
            "  9% 37/400 [01:08<09:32,  1.58s/it]\u001b[A\n",
            " 10% 38/400 [01:14<17:37,  2.92s/it]\u001b[A\n",
            " 10% 39/400 [01:20<23:59,  3.99s/it]\u001b[A\n",
            " 10% 40/400 [01:22<20:39,  3.44s/it]\u001b[A\n",
            " 10% 41/400 [01:25<18:07,  3.03s/it]\u001b[A\n",
            " 10% 42/400 [01:27<16:21,  2.74s/it]\u001b[A\n",
            " 11% 43/400 [01:28<13:53,  2.33s/it]\u001b[A\n",
            " 11% 44/400 [01:30<13:41,  2.31s/it]\u001b[A\n",
            " 11% 45/400 [01:33<13:39,  2.31s/it]\u001b[A\n",
            " 12% 46/400 [01:37<16:46,  2.84s/it]\u001b[A\n",
            " 12% 47/400 [01:39<15:01,  2.55s/it]\u001b[A\n",
            " 12% 48/400 [01:40<13:21,  2.28s/it]\u001b[A\n",
            " 12% 49/400 [01:42<12:37,  2.16s/it]\u001b[A\n",
            " 12% 50/400 [01:48<19:23,  3.32s/it]\u001b[A\n",
            " 13% 51/400 [01:50<16:19,  2.81s/it]\u001b[A\n",
            " 13% 52/400 [01:56<21:40,  3.74s/it]\u001b[A\n",
            " 13% 53/400 [01:58<18:48,  3.25s/it]\u001b[A\n",
            " 14% 54/400 [02:00<16:24,  2.85s/it]\u001b[A\n",
            " 14% 55/400 [02:01<14:41,  2.56s/it]\u001b[A\n",
            " 14% 56/400 [02:04<13:53,  2.42s/it]\u001b[A\n",
            " 14% 57/400 [02:05<12:37,  2.21s/it]\u001b[A\n",
            " 14% 58/400 [02:08<12:43,  2.23s/it]\u001b[A\n",
            " 15% 59/400 [02:14<19:12,  3.38s/it]\u001b[A\n",
            " 15% 60/400 [02:20<23:50,  4.21s/it]\u001b[A\n",
            " 15% 61/400 [02:26<26:39,  4.72s/it]\u001b[A\n",
            " 16% 62/400 [02:28<22:14,  3.95s/it]\u001b[A\n",
            " 16% 63/400 [02:30<19:10,  3.41s/it]\u001b[A\n",
            " 16% 64/400 [02:31<15:48,  2.82s/it]\u001b[A\n",
            " 16% 65/400 [02:37<20:55,  3.75s/it]\u001b[A\n",
            " 16% 66/400 [02:39<17:36,  3.16s/it]\u001b[A\n",
            " 17% 67/400 [02:41<16:01,  2.89s/it]\u001b[A\n",
            " 17% 68/400 [02:44<15:01,  2.72s/it]\u001b[A\n",
            " 17% 69/400 [02:46<14:08,  2.56s/it]\u001b[A\n",
            " 18% 70/400 [02:48<13:31,  2.46s/it]\u001b[A\n",
            " 18% 71/400 [02:50<11:47,  2.15s/it]\u001b[A\n",
            " 18% 72/400 [02:56<18:05,  3.31s/it]\u001b[A\n",
            " 18% 73/400 [03:02<22:52,  4.20s/it]\u001b[A\n",
            " 18% 74/400 [03:08<25:40,  4.72s/it]\u001b[A\n",
            " 19% 75/400 [03:09<20:09,  3.72s/it]\u001b[A\n",
            " 19% 76/400 [03:15<23:40,  4.38s/it]\u001b[A\n",
            " 19% 77/400 [03:17<20:16,  3.77s/it]\u001b[A\n",
            " 20% 78/400 [03:20<17:50,  3.32s/it]\u001b[A\n",
            " 20% 79/400 [03:26<22:16,  4.17s/it]\u001b[A\n",
            " 20% 80/400 [03:32<24:57,  4.68s/it]\u001b[A\n",
            " 20% 81/400 [03:38<27:04,  5.09s/it]\u001b[A\n",
            " 20% 82/400 [03:39<21:22,  4.03s/it]\u001b[A\n",
            " 21% 83/400 [03:42<19:16,  3.65s/it]\u001b[A\n",
            " 21% 84/400 [03:45<17:44,  3.37s/it]\u001b[A\n",
            " 21% 85/400 [03:46<14:55,  2.84s/it]\u001b[A\n",
            " 22% 86/400 [03:49<14:24,  2.75s/it]\u001b[A\n",
            " 22% 87/400 [03:50<12:22,  2.37s/it]\u001b[A\n",
            " 22% 88/400 [03:52<10:57,  2.11s/it]\u001b[A\n",
            " 22% 89/400 [03:54<10:04,  1.94s/it]\u001b[A\n",
            " 22% 90/400 [03:59<16:07,  3.12s/it]\u001b[A\n",
            " 23% 91/400 [04:05<20:24,  3.96s/it]\u001b[A\n",
            " 23% 92/400 [04:07<16:54,  3.29s/it]\u001b[A\n",
            " 23% 93/400 [04:09<14:44,  2.88s/it]\u001b[A\n",
            " 24% 94/400 [04:15<19:39,  3.85s/it]\u001b[A\n",
            " 24% 95/400 [04:21<23:10,  4.56s/it]\u001b[A\n",
            " 24% 96/400 [04:23<19:09,  3.78s/it]\u001b[A\n",
            " 24% 97/400 [04:25<15:55,  3.15s/it]\u001b[A\n",
            " 24% 98/400 [04:28<15:01,  2.98s/it]\u001b[A\n",
            " 25% 99/400 [04:34<19:35,  3.90s/it]\u001b[A\n",
            " 25% 100/400 [04:34<14:59,  3.00s/it]\u001b[A\n",
            " 25% 101/400 [04:41<20:12,  4.05s/it]\u001b[A\n",
            " 26% 102/400 [04:47<23:45,  4.78s/it]\u001b[A\n",
            " 26% 103/400 [04:48<17:25,  3.52s/it]\u001b[A\n",
            " 26% 104/400 [04:49<12:54,  2.62s/it]\u001b[A\n",
            " 26% 105/400 [04:49<10:09,  2.07s/it]\u001b[A\n",
            " 26% 106/400 [04:55<15:58,  3.26s/it]\u001b[A\n",
            " 27% 107/400 [04:56<12:01,  2.46s/it]\u001b[A\n",
            " 27% 108/400 [04:57<09:17,  1.91s/it]\u001b[A\n",
            " 27% 109/400 [04:57<07:18,  1.51s/it]\u001b[A\n",
            " 28% 110/400 [05:03<14:11,  2.94s/it]\u001b[A\n",
            " 28% 111/400 [05:09<18:35,  3.86s/it]\u001b[A\n",
            " 28% 112/400 [05:16<21:43,  4.53s/it]\u001b[A\n",
            " 28% 113/400 [05:22<23:43,  4.96s/it]\u001b[A\n",
            " 28% 114/400 [05:22<17:26,  3.66s/it]\u001b[A\n",
            " 29% 115/400 [05:29<21:25,  4.51s/it]\u001b[A\n",
            " 29% 116/400 [05:35<23:32,  4.97s/it]\u001b[A\n",
            " 29% 117/400 [05:35<17:19,  3.67s/it]\u001b[A\n",
            " 30% 118/400 [05:36<12:54,  2.75s/it]\u001b[A\n",
            " 30% 119/400 [05:36<09:45,  2.08s/it]\u001b[A\n",
            " 30% 120/400 [05:42<15:12,  3.26s/it]\u001b[A\n",
            " 30% 121/400 [05:49<19:21,  4.16s/it]\u001b[A\n",
            " 30% 122/400 [05:55<21:52,  4.72s/it]\u001b[A\n",
            " 31% 123/400 [06:01<23:29,  5.09s/it]\u001b[A\n",
            " 31% 124/400 [06:01<17:01,  3.70s/it]\u001b[A\n",
            " 31% 125/400 [06:07<20:29,  4.47s/it]\u001b[A\n",
            " 32% 126/400 [06:08<15:09,  3.32s/it]\u001b[A\n",
            " 32% 127/400 [06:09<11:18,  2.48s/it]\u001b[A\n",
            " 32% 128/400 [06:10<09:23,  2.07s/it]\u001b[A\n",
            " 32% 129/400 [06:10<07:17,  1.62s/it]\u001b[A\n",
            " 32% 130/400 [06:11<05:51,  1.30s/it]\u001b[A\n",
            " 33% 131/400 [06:11<04:55,  1.10s/it]\u001b[A\n",
            " 33% 132/400 [06:18<11:36,  2.60s/it]\u001b[A\n",
            " 33% 133/400 [06:24<16:34,  3.73s/it]\u001b[A\n",
            " 34% 134/400 [06:25<12:35,  2.84s/it]\u001b[A\n",
            " 34% 135/400 [06:26<09:55,  2.25s/it]\u001b[A\n",
            " 34% 136/400 [06:26<07:48,  1.78s/it]\u001b[A\n",
            " 34% 137/400 [06:27<06:11,  1.41s/it]\u001b[A\n",
            " 34% 138/400 [06:33<12:02,  2.76s/it]\u001b[A\n",
            " 35% 139/400 [06:39<16:48,  3.87s/it]\u001b[A\n",
            " 35% 140/400 [06:40<13:09,  3.04s/it]\u001b[A\n",
            " 35% 141/400 [06:42<11:10,  2.59s/it]\u001b[A\n",
            " 36% 142/400 [06:42<08:29,  1.97s/it]\u001b[A\n",
            " 36% 143/400 [06:48<13:25,  3.14s/it]\u001b[A\n",
            " 36% 144/400 [06:54<16:58,  3.98s/it]\u001b[A\n",
            " 36% 145/400 [06:55<12:39,  2.98s/it]\u001b[A\n",
            " 36% 146/400 [06:55<09:41,  2.29s/it]\u001b[A\n",
            " 37% 147/400 [07:01<14:11,  3.37s/it]\u001b[A\n",
            " 37% 148/400 [07:07<17:32,  4.18s/it]\u001b[A\n",
            " 37% 149/400 [07:08<13:00,  3.11s/it]\u001b[A\n",
            " 38% 150/400 [07:14<16:30,  3.96s/it]\u001b[A\n",
            " 38% 151/400 [07:14<12:09,  2.93s/it]\u001b[A\n",
            " 38% 152/400 [07:20<15:42,  3.80s/it]\u001b[A\n",
            " 38% 153/400 [07:21<11:46,  2.86s/it]\u001b[A\n",
            " 38% 154/400 [07:22<09:08,  2.23s/it]\u001b[A\n",
            " 39% 155/400 [07:23<07:22,  1.80s/it]\u001b[A\n",
            " 39% 156/400 [07:29<12:38,  3.11s/it]\u001b[A\n",
            " 39% 157/400 [07:29<09:35,  2.37s/it]\u001b[A\n",
            " 40% 158/400 [07:30<07:28,  1.85s/it]\u001b[A\n",
            " 40% 159/400 [07:31<06:10,  1.54s/it]\u001b[A\n",
            " 40% 160/400 [07:37<11:46,  2.94s/it]\u001b[A\n",
            " 40% 161/400 [07:38<08:57,  2.25s/it]\u001b[A\n",
            " 40% 162/400 [07:39<07:44,  1.95s/it]\u001b[A\n",
            " 41% 163/400 [07:40<06:51,  1.74s/it]\u001b[A\n",
            " 41% 164/400 [07:46<11:53,  3.02s/it]\u001b[A\n",
            " 41% 165/400 [07:52<15:09,  3.87s/it]\u001b[A\n",
            " 42% 166/400 [07:58<17:37,  4.52s/it]\u001b[A\n",
            " 42% 167/400 [08:04<19:33,  5.04s/it]\u001b[A\n",
            " 42% 168/400 [08:05<14:33,  3.77s/it]\u001b[A\n",
            " 42% 169/400 [08:06<11:02,  2.87s/it]\u001b[A\n",
            " 42% 170/400 [08:12<14:46,  3.85s/it]\u001b[A\n",
            " 43% 171/400 [08:13<11:48,  3.09s/it]\u001b[A\n",
            " 43% 172/400 [08:15<09:53,  2.60s/it]\u001b[A\n",
            " 43% 173/400 [08:16<07:49,  2.07s/it]\u001b[A\n",
            " 44% 174/400 [08:17<06:44,  1.79s/it]\u001b[A\n",
            " 44% 175/400 [08:23<11:41,  3.12s/it]\u001b[A\n",
            " 44% 176/400 [08:24<08:50,  2.37s/it]\u001b[A\n",
            " 44% 177/400 [08:24<07:00,  1.89s/it]\u001b[A\n",
            " 44% 178/400 [08:30<11:38,  3.14s/it]\u001b[A\n",
            " 45% 179/400 [08:31<08:55,  2.42s/it]\u001b[A\n",
            " 45% 180/400 [08:37<13:06,  3.58s/it]\u001b[A\n",
            " 45% 181/400 [08:38<09:52,  2.71s/it]\u001b[A\n",
            " 46% 182/400 [08:45<14:02,  3.86s/it]\u001b[A\n",
            " 46% 183/400 [08:45<10:24,  2.88s/it]\u001b[A\n",
            " 46% 184/400 [08:46<07:49,  2.17s/it]\u001b[A\n",
            " 46% 185/400 [08:52<11:46,  3.28s/it]\u001b[A\n",
            " 46% 186/400 [08:53<09:09,  2.57s/it]\u001b[A\n",
            " 47% 187/400 [08:59<12:46,  3.60s/it]\u001b[A\n",
            " 47% 188/400 [08:59<09:43,  2.75s/it]\u001b[A\n",
            " 47% 189/400 [09:05<12:59,  3.69s/it]\u001b[A\n",
            " 48% 190/400 [09:11<15:13,  4.35s/it]\u001b[A\n",
            " 48% 191/400 [09:17<16:55,  4.86s/it]\u001b[A\n",
            " 48% 192/400 [09:18<12:22,  3.57s/it]\u001b[A\n",
            " 48% 193/400 [09:24<14:41,  4.26s/it]\u001b[A\n",
            " 48% 194/400 [09:26<12:16,  3.58s/it]\u001b[A\n",
            " 49% 195/400 [09:26<09:09,  2.68s/it]\u001b[A\n",
            " 49% 196/400 [09:27<07:00,  2.06s/it]\u001b[A\n",
            " 49% 197/400 [09:27<05:33,  1.64s/it]\u001b[A\n",
            " 50% 198/400 [09:29<05:17,  1.57s/it]\u001b[A\n",
            " 50% 199/400 [09:35<09:54,  2.96s/it]\u001b[A\n",
            " 50% 200/400 [09:41<12:57,  3.89s/it]\u001b[A\n",
            " 50% 201/400 [09:43<11:22,  3.43s/it]\u001b[A\n",
            " 50% 202/400 [09:45<09:36,  2.91s/it]\u001b[A\n",
            " 51% 203/400 [09:47<08:32,  2.60s/it]\u001b[A\n",
            " 51% 204/400 [09:53<11:47,  3.61s/it]\u001b[A\n",
            " 51% 205/400 [09:55<10:05,  3.10s/it]\u001b[A\n",
            " 52% 206/400 [09:56<08:33,  2.65s/it]\u001b[A\n",
            " 52% 207/400 [09:58<07:50,  2.44s/it]\u001b[A\n",
            " 52% 208/400 [10:01<07:41,  2.40s/it]\u001b[A\n",
            " 52% 209/400 [10:03<07:39,  2.40s/it]\u001b[A\n",
            " 52% 210/400 [10:05<07:06,  2.25s/it]\u001b[A\n",
            " 53% 211/400 [10:07<07:06,  2.26s/it]\u001b[A\n",
            " 53% 212/400 [10:10<07:20,  2.35s/it]\u001b[A\n",
            " 53% 213/400 [10:12<07:31,  2.42s/it]\u001b[A\n",
            " 54% 214/400 [10:16<08:05,  2.61s/it]\u001b[A\n",
            " 54% 215/400 [10:18<08:12,  2.66s/it]\u001b[A\n",
            " 54% 216/400 [10:20<07:35,  2.48s/it]\u001b[A\n",
            " 54% 217/400 [10:23<07:42,  2.53s/it]\u001b[A\n",
            " 55% 218/400 [10:26<07:41,  2.53s/it]\u001b[A\n",
            " 55% 219/400 [10:29<08:27,  2.80s/it]\u001b[A\n",
            " 55% 220/400 [10:32<08:44,  2.91s/it]\u001b[A\n",
            " 55% 221/400 [10:34<07:26,  2.49s/it]\u001b[A\n",
            " 56% 222/400 [10:36<06:48,  2.30s/it]\u001b[A\n",
            " 56% 223/400 [10:37<05:55,  2.01s/it]\u001b[A\n",
            " 56% 224/400 [10:43<09:19,  3.18s/it]\u001b[A\n",
            " 56% 225/400 [10:45<08:08,  2.79s/it]\u001b[A\n",
            " 56% 226/400 [10:47<07:55,  2.73s/it]\u001b[A\n",
            " 57% 227/400 [10:50<07:44,  2.69s/it]\u001b[A\n",
            " 57% 228/400 [10:51<06:45,  2.36s/it]\u001b[A\n",
            " 57% 229/400 [10:53<06:24,  2.25s/it]\u001b[A\n",
            " 57% 230/400 [10:55<05:50,  2.06s/it]\u001b[A\n",
            " 58% 231/400 [10:57<05:40,  2.01s/it]\u001b[A\n",
            " 58% 232/400 [11:03<09:03,  3.23s/it]\u001b[A\n",
            " 58% 233/400 [11:05<08:04,  2.90s/it]\u001b[A\n",
            " 58% 234/400 [11:07<07:05,  2.57s/it]\u001b[A\n",
            " 59% 235/400 [11:09<06:31,  2.37s/it]\u001b[A\n",
            " 59% 236/400 [11:11<06:02,  2.21s/it]\u001b[A\n",
            " 59% 237/400 [11:12<05:39,  2.09s/it]\u001b[A\n",
            " 60% 238/400 [11:19<08:53,  3.29s/it]\u001b[A\n",
            " 60% 239/400 [11:20<07:44,  2.88s/it]\u001b[A\n",
            " 60% 240/400 [11:24<07:53,  2.96s/it]\u001b[A\n",
            " 60% 241/400 [11:26<07:37,  2.88s/it]\u001b[A\n",
            " 60% 242/400 [11:29<07:41,  2.92s/it]\u001b[A\n",
            " 61% 243/400 [11:31<06:46,  2.59s/it]\u001b[A\n",
            " 61% 244/400 [11:34<06:56,  2.67s/it]\u001b[A\n",
            " 61% 245/400 [11:37<06:59,  2.71s/it]\u001b[A\n",
            " 62% 246/400 [11:40<07:04,  2.76s/it]\u001b[A\n",
            " 62% 247/400 [11:42<06:56,  2.72s/it]\u001b[A\n",
            " 62% 248/400 [11:44<06:24,  2.53s/it]\u001b[A\n",
            " 62% 249/400 [11:47<06:07,  2.43s/it]\u001b[A\n",
            " 62% 250/400 [11:49<06:19,  2.53s/it]\u001b[A\n",
            " 63% 251/400 [11:51<05:55,  2.39s/it]\u001b[A\n",
            " 63% 252/400 [11:57<08:32,  3.47s/it]\u001b[A\n",
            " 63% 253/400 [12:02<09:28,  3.87s/it]\u001b[A\n",
            " 64% 254/400 [12:05<08:33,  3.52s/it]\u001b[A\n",
            " 64% 255/400 [12:08<07:51,  3.25s/it]\u001b[A\n",
            " 64% 256/400 [12:10<07:00,  2.92s/it]\u001b[A\n",
            " 64% 257/400 [12:12<06:15,  2.63s/it]\u001b[A\n",
            " 64% 258/400 [12:15<06:48,  2.88s/it]\u001b[A\n",
            " 65% 259/400 [12:18<06:54,  2.94s/it]\u001b[A\n",
            " 65% 260/400 [12:24<08:57,  3.84s/it]\u001b[A\n",
            " 65% 261/400 [12:30<10:22,  4.48s/it]\u001b[A\n",
            " 66% 262/400 [12:33<09:00,  3.92s/it]\u001b[A\n",
            " 66% 263/400 [12:36<08:24,  3.68s/it]\u001b[A\n",
            " 66% 264/400 [12:42<09:53,  4.36s/it]\u001b[A\n",
            " 66% 265/400 [12:48<10:55,  4.85s/it]\u001b[A\n",
            " 66% 266/400 [12:50<08:56,  4.01s/it]\u001b[A\n",
            " 67% 267/400 [12:54<09:06,  4.11s/it]\u001b[A\n",
            " 67% 268/400 [13:00<10:19,  4.69s/it]\u001b[A\n",
            " 67% 269/400 [13:03<08:46,  4.02s/it]\u001b[A\n",
            " 68% 270/400 [13:05<07:47,  3.60s/it]\u001b[A\n",
            " 68% 271/400 [13:08<06:51,  3.19s/it]\u001b[A\n",
            " 68% 272/400 [13:10<06:24,  3.00s/it]\u001b[A\n",
            " 68% 273/400 [13:16<08:12,  3.88s/it]\u001b[A\n",
            " 68% 274/400 [13:18<06:50,  3.26s/it]\u001b[A\n",
            " 69% 275/400 [13:24<08:32,  4.10s/it]\u001b[A\n",
            " 69% 276/400 [13:30<09:38,  4.67s/it]\u001b[A\n",
            " 69% 277/400 [13:33<08:21,  4.08s/it]\u001b[A\n",
            " 70% 278/400 [13:35<07:23,  3.63s/it]\u001b[A\n",
            " 70% 279/400 [13:39<07:08,  3.54s/it]\u001b[A\n",
            " 70% 280/400 [13:45<08:39,  4.33s/it]\u001b[A\n",
            " 70% 281/400 [13:51<09:33,  4.82s/it]\u001b[A\n",
            " 70% 282/400 [13:53<07:55,  4.03s/it]\u001b[A\n",
            " 71% 283/400 [13:59<09:06,  4.67s/it]\u001b[A\n",
            " 71% 284/400 [14:05<09:50,  5.09s/it]\u001b[A\n",
            " 71% 285/400 [14:07<07:57,  4.15s/it]\u001b[A\n",
            " 72% 286/400 [14:10<07:24,  3.90s/it]\u001b[A\n",
            " 72% 287/400 [14:12<06:19,  3.35s/it]\u001b[A\n",
            " 72% 288/400 [14:15<05:35,  2.99s/it]\u001b[A\n",
            " 72% 289/400 [14:16<04:47,  2.59s/it]\u001b[A\n",
            " 72% 290/400 [14:19<04:36,  2.51s/it]\u001b[A\n",
            " 73% 291/400 [14:24<06:24,  3.53s/it]\u001b[A\n",
            " 73% 292/400 [14:26<05:32,  3.08s/it]\u001b[A\n",
            " 73% 293/400 [14:28<04:47,  2.69s/it]\u001b[A\n",
            " 74% 294/400 [14:31<04:41,  2.65s/it]\u001b[A\n",
            " 74% 295/400 [14:33<04:34,  2.61s/it]\u001b[A\n",
            " 74% 296/400 [14:35<04:17,  2.47s/it]\u001b[A\n",
            " 74% 297/400 [14:38<04:05,  2.38s/it]\u001b[A\n",
            " 74% 298/400 [14:44<05:51,  3.45s/it]\u001b[A\n",
            " 75% 299/400 [14:45<04:46,  2.83s/it]\u001b[A\n",
            " 75% 300/400 [14:47<04:04,  2.45s/it]\u001b[A\n",
            " 75% 301/400 [14:48<03:27,  2.10s/it]\u001b[A\n",
            " 76% 302/400 [14:49<02:56,  1.80s/it]\u001b[A\n",
            " 76% 303/400 [14:50<02:30,  1.55s/it]\u001b[A\n",
            " 76% 304/400 [14:51<02:17,  1.44s/it]\u001b[A\n",
            " 76% 305/400 [14:52<02:14,  1.42s/it]\u001b[A\n",
            " 76% 306/400 [14:54<02:07,  1.36s/it]\u001b[A\n",
            " 77% 307/400 [14:55<01:59,  1.29s/it]\u001b[A\n",
            " 77% 308/400 [14:56<01:59,  1.30s/it]\u001b[A\n",
            " 77% 309/400 [14:57<01:57,  1.29s/it]\u001b[A\n",
            " 78% 310/400 [14:59<01:52,  1.25s/it]\u001b[A\n",
            " 78% 311/400 [15:00<02:04,  1.39s/it]\u001b[A\n",
            " 78% 312/400 [15:02<02:08,  1.46s/it]\u001b[A\n",
            " 78% 313/400 [15:03<02:10,  1.50s/it]\u001b[A\n",
            " 78% 314/400 [15:05<02:10,  1.51s/it]\u001b[A\n",
            " 79% 315/400 [15:07<02:09,  1.52s/it]\u001b[A\n",
            " 79% 316/400 [15:08<02:00,  1.43s/it]\u001b[A\n",
            " 79% 317/400 [15:09<02:04,  1.49s/it]\u001b[A\n",
            " 80% 318/400 [15:11<02:04,  1.51s/it]\u001b[A\n",
            " 80% 319/400 [15:13<02:12,  1.63s/it]\u001b[A\n",
            " 80% 320/400 [15:15<02:17,  1.72s/it]\u001b[A\n",
            " 80% 321/400 [15:16<01:59,  1.51s/it]\u001b[A\n",
            " 80% 322/400 [15:17<01:54,  1.47s/it]\u001b[A\n",
            " 81% 323/400 [15:23<03:34,  2.78s/it]\u001b[A\n",
            " 81% 324/400 [15:24<02:47,  2.21s/it]\u001b[A\n",
            " 81% 325/400 [15:25<02:18,  1.84s/it]\u001b[A\n",
            " 82% 326/400 [15:27<02:12,  1.80s/it]\u001b[A\n",
            " 82% 327/400 [15:28<02:06,  1.74s/it]\u001b[A\n",
            " 82% 328/400 [15:29<01:55,  1.60s/it]\u001b[A\n",
            " 82% 329/400 [15:31<01:46,  1.50s/it]\u001b[A\n",
            " 82% 330/400 [15:32<01:37,  1.40s/it]\u001b[A\n",
            " 83% 331/400 [15:33<01:35,  1.39s/it]\u001b[A\n",
            " 83% 332/400 [15:39<03:06,  2.74s/it]\u001b[A\n",
            " 83% 333/400 [15:45<04:07,  3.70s/it]\u001b[A\n",
            " 84% 334/400 [15:46<03:15,  2.97s/it]\u001b[A\n",
            " 84% 335/400 [15:48<02:42,  2.50s/it]\u001b[A\n",
            " 84% 336/400 [15:49<02:18,  2.16s/it]\u001b[A\n",
            " 84% 337/400 [15:50<01:57,  1.86s/it]\u001b[A\n",
            " 84% 338/400 [15:52<01:45,  1.71s/it]\u001b[A\n",
            " 85% 339/400 [15:53<01:35,  1.56s/it]\u001b[A\n",
            " 85% 340/400 [15:54<01:32,  1.54s/it]\u001b[A\n",
            " 85% 341/400 [15:56<01:29,  1.52s/it]\u001b[A\n",
            " 86% 342/400 [15:57<01:27,  1.51s/it]\u001b[A\n",
            " 86% 343/400 [15:58<01:19,  1.40s/it]\u001b[A\n",
            " 86% 344/400 [16:00<01:19,  1.42s/it]\u001b[A\n",
            " 86% 345/400 [16:02<01:23,  1.52s/it]\u001b[A\n",
            " 86% 346/400 [16:03<01:26,  1.60s/it]\u001b[A\n",
            " 87% 347/400 [16:05<01:22,  1.56s/it]\u001b[A\n",
            " 87% 348/400 [16:06<01:15,  1.46s/it]\u001b[A\n",
            " 87% 349/400 [16:07<01:10,  1.39s/it]\u001b[A\n",
            " 88% 350/400 [16:09<01:14,  1.49s/it]\u001b[A\n",
            " 88% 351/400 [16:10<01:09,  1.42s/it]\u001b[A\n",
            " 88% 352/400 [16:16<02:13,  2.79s/it]\u001b[A\n",
            " 88% 353/400 [16:18<01:49,  2.33s/it]\u001b[A\n",
            " 88% 354/400 [16:19<01:32,  2.01s/it]\u001b[A\n",
            " 89% 355/400 [16:20<01:22,  1.82s/it]\u001b[A\n",
            " 89% 356/400 [16:22<01:15,  1.72s/it]\u001b[A\n",
            " 89% 357/400 [16:23<01:12,  1.69s/it]\u001b[A\n",
            " 90% 358/400 [16:25<01:11,  1.70s/it]\u001b[A\n",
            " 90% 359/400 [16:27<01:13,  1.80s/it]\u001b[A\n",
            " 90% 360/400 [16:28<01:03,  1.59s/it]\u001b[A\n",
            " 90% 361/400 [16:34<01:53,  2.90s/it]\u001b[A\n",
            " 90% 362/400 [16:36<01:38,  2.60s/it]\u001b[A\n",
            " 91% 363/400 [16:38<01:30,  2.44s/it]\u001b[A\n",
            " 91% 364/400 [16:44<02:07,  3.55s/it]\u001b[A\n",
            " 91% 365/400 [16:50<02:29,  4.27s/it]\u001b[A\n",
            " 92% 366/400 [16:52<01:56,  3.43s/it]\u001b[A\n",
            " 92% 367/400 [16:53<01:35,  2.90s/it]\u001b[A\n",
            " 92% 368/400 [16:55<01:23,  2.61s/it]\u001b[A\n",
            " 92% 369/400 [16:57<01:13,  2.38s/it]\u001b[A\n",
            " 92% 370/400 [16:59<01:05,  2.19s/it]\u001b[A\n",
            " 93% 371/400 [17:01<01:00,  2.10s/it]\u001b[A\n",
            " 93% 372/400 [17:03<00:56,  2.00s/it]\u001b[A\n",
            " 93% 373/400 [17:09<01:26,  3.22s/it]\u001b[A\n",
            " 94% 374/400 [17:15<01:46,  4.09s/it]\u001b[A\n",
            " 94% 375/400 [17:21<01:56,  4.67s/it]\u001b[A\n",
            " 94% 376/400 [17:27<02:01,  5.07s/it]\u001b[A\n",
            " 94% 377/400 [17:28<01:33,  4.07s/it]\u001b[A\n",
            " 94% 378/400 [17:34<01:41,  4.61s/it]\u001b[A\n",
            " 95% 379/400 [17:37<01:21,  3.90s/it]\u001b[A\n",
            " 95% 380/400 [17:43<01:31,  4.60s/it]\u001b[A\n",
            " 95% 381/400 [17:49<01:34,  4.99s/it]\u001b[A\n",
            " 96% 382/400 [17:50<01:08,  3.82s/it]\u001b[A\n",
            " 96% 383/400 [17:51<00:53,  3.16s/it]\u001b[A\n",
            " 96% 384/400 [17:53<00:43,  2.70s/it]\u001b[A\n",
            " 96% 385/400 [17:54<00:34,  2.28s/it]\u001b[A\n",
            " 96% 386/400 [17:57<00:32,  2.34s/it]\u001b[A\n",
            " 97% 387/400 [17:58<00:25,  2.00s/it]\u001b[A\n",
            " 97% 388/400 [17:59<00:21,  1.82s/it]\u001b[A\n",
            " 97% 389/400 [18:01<00:17,  1.60s/it]\u001b[A\n",
            " 98% 390/400 [18:02<00:15,  1.52s/it]\u001b[A\n",
            " 98% 391/400 [18:03<00:12,  1.37s/it]\u001b[A\n",
            " 98% 392/400 [18:04<00:10,  1.32s/it]\u001b[A\n",
            " 98% 393/400 [18:05<00:08,  1.25s/it]\u001b[A\n",
            " 98% 394/400 [18:07<00:08,  1.40s/it]\u001b[A\n",
            " 99% 395/400 [18:09<00:07,  1.52s/it]\u001b[A\n",
            " 99% 396/400 [18:10<00:05,  1.49s/it]\u001b[A\n",
            " 99% 397/400 [18:12<00:04,  1.52s/it]\u001b[A\n",
            "100% 398/400 [18:13<00:03,  1.57s/it]\u001b[A\n",
            "100% 399/400 [18:14<00:01,  1.37s/it]\u001b[A\n",
            "                                      \n",
            "\u001b[A{'eval_loss': 0.44078460335731506, 'eval_rouge1': 52.0316, 'eval_rouge2': 36.6042, 'eval_rougeL': 51.7875, 'eval_rougeLsum': 51.7518, 'eval_bleu': 70.4287, 'eval_gen_len': 47.0438, 'eval_runtime': 1120.6283, 'eval_samples_per_second': 1.428, 'eval_steps_per_second': 0.357, 'epoch': 2.0}\n",
            " 40% 600/1500 [24:34<08:37,  1.74it/s]\n",
            "100% 400/400 [18:39<00:00,  1.22s/it]\u001b[A\n",
            "                                     \u001b[ASaving model checkpoint to pegasus_model_full/checkpoint-600\n",
            "Configuration saved in pegasus_model_full/checkpoint-600/config.json\n",
            "Configuration saved in pegasus_model_full/checkpoint-600/generation_config.json\n",
            "Model weights saved in pegasus_model_full/checkpoint-600/pytorch_model.bin\n",
            "tokenizer config file saved in pegasus_model_full/checkpoint-600/tokenizer_config.json\n",
            "Special tokens file saved in pegasus_model_full/checkpoint-600/special_tokens_map.json\n",
            "{'loss': 0.5085, 'learning_rate': 1.7e-05, 'epoch': 2.17}\n",
            "{'loss': 0.559, 'learning_rate': 1.6e-05, 'epoch': 2.33}\n",
            "{'loss': 0.5454, 'learning_rate': 1.5e-05, 'epoch': 2.5}\n",
            "{'loss': 0.4866, 'learning_rate': 1.4e-05, 'epoch': 2.67}\n",
            "{'loss': 0.5616, 'learning_rate': 1.3000000000000001e-05, 'epoch': 2.83}\n",
            "{'loss': 0.5382, 'learning_rate': 1.2e-05, 'epoch': 3.0}\n",
            " 60% 900/1500 [27:41<05:31,  1.81it/s]Saving model checkpoint to pegasus_model_full/checkpoint-900\n",
            "Configuration saved in pegasus_model_full/checkpoint-900/config.json\n",
            "Configuration saved in pegasus_model_full/checkpoint-900/generation_config.json\n",
            "Model weights saved in pegasus_model_full/checkpoint-900/pytorch_model.bin\n",
            "tokenizer config file saved in pegasus_model_full/checkpoint-900/tokenizer_config.json\n",
            "Special tokens file saved in pegasus_model_full/checkpoint-900/special_tokens_map.json\n",
            "{'loss': 0.4742, 'learning_rate': 1.1e-05, 'epoch': 3.17}\n",
            "{'loss': 0.5127, 'learning_rate': 9.999999999999999e-06, 'epoch': 3.33}\n",
            "{'loss': 0.5217, 'learning_rate': 9e-06, 'epoch': 3.5}\n",
            "{'loss': 0.5516, 'learning_rate': 8e-06, 'epoch': 3.67}\n",
            "{'loss': 0.5148, 'learning_rate': 7e-06, 'epoch': 3.83}\n",
            "{'loss': 0.4722, 'learning_rate': 6e-06, 'epoch': 4.0}\n",
            " 80% 1200/1500 [30:48<02:46,  1.80it/s]***** Running Evaluation *****\n",
            "  Num examples = 1600\n",
            "  Batch size = 4\n",
            "\n",
            "  0% 0/400 [00:00<?, ?it/s]\u001b[A\n",
            "  0% 2/400 [00:01<04:08,  1.60it/s]\u001b[A\n",
            "  1% 3/400 [00:02<06:38,  1.00s/it]\u001b[A\n",
            "  1% 4/400 [00:04<07:47,  1.18s/it]\u001b[A\n",
            "  1% 5/400 [00:05<08:39,  1.32s/it]\u001b[A\n",
            "  2% 6/400 [00:07<08:55,  1.36s/it]\u001b[A\n",
            "  2% 7/400 [00:08<09:10,  1.40s/it]\u001b[A\n",
            "  2% 8/400 [00:10<09:46,  1.50s/it]\u001b[A\n",
            "  2% 9/400 [00:12<10:23,  1.59s/it]\u001b[A\n",
            "  2% 10/400 [00:13<10:01,  1.54s/it]\u001b[A\n",
            "  3% 11/400 [00:15<11:07,  1.71s/it]\u001b[A\n",
            "  3% 12/400 [00:18<12:06,  1.87s/it]\u001b[A\n",
            "  3% 13/400 [00:20<12:38,  1.96s/it]\u001b[A\n",
            "  4% 14/400 [00:22<13:21,  2.08s/it]\u001b[A\n",
            "  4% 15/400 [00:24<14:00,  2.18s/it]\u001b[A\n",
            "  4% 16/400 [00:26<12:54,  2.02s/it]\u001b[A\n",
            "  4% 17/400 [00:28<12:29,  1.96s/it]\u001b[A\n",
            "  4% 18/400 [00:30<12:22,  1.94s/it]\u001b[A\n",
            "  5% 19/400 [00:32<13:23,  2.11s/it]\u001b[A\n",
            "  5% 20/400 [00:35<14:05,  2.22s/it]\u001b[A\n",
            "  5% 21/400 [00:36<11:47,  1.87s/it]\u001b[A\n",
            "  6% 22/400 [00:38<12:12,  1.94s/it]\u001b[A\n",
            "  6% 23/400 [00:39<10:21,  1.65s/it]\u001b[A\n",
            "  6% 24/400 [00:40<10:08,  1.62s/it]\u001b[A\n",
            "  6% 25/400 [00:46<18:07,  2.90s/it]\u001b[A\n",
            "  6% 26/400 [00:49<17:00,  2.73s/it]\u001b[A\n",
            "  7% 27/400 [00:51<16:02,  2.58s/it]\u001b[A\n",
            "  7% 28/400 [00:52<13:45,  2.22s/it]\u001b[A\n",
            "  7% 29/400 [00:54<13:00,  2.10s/it]\u001b[A\n",
            "  8% 30/400 [00:56<11:56,  1.94s/it]\u001b[A\n",
            "  8% 31/400 [00:57<10:39,  1.73s/it]\u001b[A\n",
            "  8% 32/400 [00:58<10:06,  1.65s/it]\u001b[A\n",
            "  8% 33/400 [01:00<09:53,  1.62s/it]\u001b[A\n",
            "  8% 34/400 [01:01<09:14,  1.51s/it]\u001b[A\n",
            "  9% 35/400 [01:03<09:28,  1.56s/it]\u001b[A\n",
            "  9% 36/400 [01:04<09:21,  1.54s/it]\u001b[A\n",
            "  9% 37/400 [01:06<09:15,  1.53s/it]\u001b[A\n",
            " 10% 38/400 [01:08<09:35,  1.59s/it]\u001b[A\n",
            " 10% 39/400 [01:14<17:30,  2.91s/it]\u001b[A\n",
            " 10% 40/400 [01:16<16:06,  2.69s/it]\u001b[A\n",
            " 10% 41/400 [01:18<14:55,  2.49s/it]\u001b[A\n",
            " 10% 42/400 [01:20<13:46,  2.31s/it]\u001b[A\n",
            " 11% 43/400 [01:21<12:04,  2.03s/it]\u001b[A\n",
            " 11% 44/400 [01:23<12:29,  2.11s/it]\u001b[A\n",
            " 11% 45/400 [01:27<15:59,  2.70s/it]\u001b[A\n",
            " 12% 46/400 [01:30<15:01,  2.55s/it]\u001b[A\n",
            " 12% 47/400 [01:32<13:50,  2.35s/it]\u001b[A\n",
            " 12% 48/400 [01:33<12:32,  2.14s/it]\u001b[A\n",
            " 12% 49/400 [01:35<12:05,  2.07s/it]\u001b[A\n",
            " 12% 50/400 [01:37<11:59,  2.06s/it]\u001b[A\n",
            " 13% 51/400 [01:39<11:07,  1.91s/it]\u001b[A\n",
            " 13% 52/400 [01:45<18:04,  3.12s/it]\u001b[A\n",
            " 13% 53/400 [01:47<16:25,  2.84s/it]\u001b[A\n",
            " 14% 54/400 [01:49<14:33,  2.53s/it]\u001b[A\n",
            " 14% 55/400 [01:50<13:22,  2.33s/it]\u001b[A\n",
            " 14% 56/400 [01:53<12:56,  2.26s/it]\u001b[A\n",
            " 14% 57/400 [01:54<11:56,  2.09s/it]\u001b[A\n",
            " 14% 58/400 [01:57<12:15,  2.15s/it]\u001b[A\n",
            " 15% 59/400 [02:00<14:31,  2.56s/it]\u001b[A\n",
            " 15% 60/400 [02:06<20:08,  3.56s/it]\u001b[A\n",
            " 15% 61/400 [02:12<24:05,  4.26s/it]\u001b[A\n",
            " 16% 62/400 [02:14<20:25,  3.63s/it]\u001b[A\n",
            " 16% 63/400 [02:16<17:56,  3.19s/it]\u001b[A\n",
            " 16% 64/400 [02:18<14:56,  2.67s/it]\u001b[A\n",
            " 16% 65/400 [02:24<20:19,  3.64s/it]\u001b[A\n",
            " 16% 66/400 [02:25<17:12,  3.09s/it]\u001b[A\n",
            " 17% 67/400 [02:28<15:45,  2.84s/it]\u001b[A\n",
            " 17% 68/400 [02:30<14:47,  2.67s/it]\u001b[A\n",
            " 17% 69/400 [02:32<13:57,  2.53s/it]\u001b[A\n",
            " 18% 70/400 [02:34<13:23,  2.44s/it]\u001b[A\n",
            " 18% 71/400 [02:36<11:43,  2.14s/it]\u001b[A\n",
            " 18% 72/400 [02:38<11:58,  2.19s/it]\u001b[A\n",
            " 18% 73/400 [02:44<18:07,  3.33s/it]\u001b[A\n",
            " 18% 74/400 [02:46<15:10,  2.79s/it]\u001b[A\n",
            " 19% 75/400 [02:47<12:49,  2.37s/it]\u001b[A\n",
            " 19% 76/400 [02:49<11:54,  2.20s/it]\u001b[A\n",
            " 19% 77/400 [02:51<12:00,  2.23s/it]\u001b[A\n",
            " 20% 78/400 [02:53<12:01,  2.24s/it]\u001b[A\n",
            " 20% 79/400 [02:59<18:10,  3.40s/it]\u001b[A\n",
            " 20% 80/400 [03:00<13:42,  2.57s/it]\u001b[A\n",
            " 20% 81/400 [03:02<13:12,  2.48s/it]\u001b[A\n",
            " 20% 82/400 [03:04<11:41,  2.21s/it]\u001b[A\n",
            " 21% 83/400 [03:07<12:34,  2.38s/it]\u001b[A\n",
            " 21% 84/400 [03:09<13:04,  2.48s/it]\u001b[A\n",
            " 21% 85/400 [03:11<11:36,  2.21s/it]\u001b[A\n",
            " 22% 86/400 [03:13<11:38,  2.22s/it]\u001b[A\n",
            " 22% 87/400 [03:15<10:24,  2.00s/it]\u001b[A\n",
            " 22% 88/400 [03:16<09:30,  1.83s/it]\u001b[A\n",
            " 22% 89/400 [03:18<09:03,  1.75s/it]\u001b[A\n",
            " 22% 90/400 [03:20<09:28,  1.84s/it]\u001b[A\n",
            " 23% 91/400 [03:26<15:45,  3.06s/it]\u001b[A\n",
            " 23% 92/400 [03:27<13:33,  2.64s/it]\u001b[A\n",
            " 23% 93/400 [03:29<11:34,  2.26s/it]\u001b[A\n",
            " 24% 94/400 [03:35<17:12,  3.38s/it]\u001b[A\n",
            " 24% 95/400 [03:41<21:07,  4.16s/it]\u001b[A\n",
            " 24% 96/400 [03:43<17:36,  3.48s/it]\u001b[A\n",
            " 24% 97/400 [03:44<14:49,  2.94s/it]\u001b[A\n",
            " 24% 98/400 [03:47<14:16,  2.83s/it]\u001b[A\n",
            " 25% 99/400 [03:53<19:01,  3.79s/it]\u001b[A\n",
            " 25% 100/400 [03:54<14:36,  2.92s/it]\u001b[A\n",
            " 25% 101/400 [04:00<19:51,  3.99s/it]\u001b[A\n",
            " 26% 102/400 [04:07<23:30,  4.73s/it]\u001b[A\n",
            " 26% 103/400 [04:07<17:07,  3.46s/it]\u001b[A\n",
            " 26% 104/400 [04:08<12:39,  2.57s/it]\u001b[A\n",
            " 26% 105/400 [04:08<09:32,  1.94s/it]\u001b[A\n",
            " 26% 106/400 [04:14<15:18,  3.12s/it]\u001b[A\n",
            " 27% 107/400 [04:14<11:23,  2.33s/it]\u001b[A\n",
            " 27% 108/400 [04:15<08:36,  1.77s/it]\u001b[A\n",
            " 27% 109/400 [04:15<06:46,  1.40s/it]\u001b[A\n",
            " 28% 110/400 [04:16<05:29,  1.13s/it]\u001b[A\n",
            " 28% 111/400 [04:22<12:27,  2.59s/it]\u001b[A\n",
            " 28% 112/400 [04:28<17:20,  3.61s/it]\u001b[A\n",
            " 28% 113/400 [04:34<20:46,  4.34s/it]\u001b[A\n",
            " 28% 114/400 [04:40<23:02,  4.83s/it]\u001b[A\n",
            " 29% 115/400 [04:46<25:17,  5.32s/it]\u001b[A\n",
            " 29% 116/400 [04:53<26:15,  5.55s/it]\u001b[A\n",
            " 29% 117/400 [04:53<19:04,  4.04s/it]\u001b[A\n",
            " 30% 118/400 [04:54<14:06,  3.00s/it]\u001b[A\n",
            " 30% 119/400 [04:54<10:29,  2.24s/it]\u001b[A\n",
            " 30% 120/400 [05:00<15:36,  3.34s/it]\u001b[A\n",
            " 30% 121/400 [05:06<19:36,  4.22s/it]\u001b[A\n",
            " 30% 122/400 [05:12<21:47,  4.70s/it]\u001b[A\n",
            " 31% 123/400 [05:18<23:37,  5.12s/it]\u001b[A\n",
            " 31% 124/400 [05:19<17:04,  3.71s/it]\u001b[A\n",
            " 31% 125/400 [05:19<12:38,  2.76s/it]\u001b[A\n",
            " 32% 126/400 [05:20<09:31,  2.09s/it]\u001b[A\n",
            " 32% 127/400 [05:20<07:22,  1.62s/it]\u001b[A\n",
            " 32% 128/400 [05:21<06:36,  1.46s/it]\u001b[A\n",
            " 32% 129/400 [05:22<05:17,  1.17s/it]\u001b[A\n",
            " 32% 130/400 [05:22<04:26,  1.01it/s]\u001b[A\n",
            " 33% 131/400 [05:29<11:24,  2.54s/it]\u001b[A\n",
            " 33% 132/400 [05:35<16:04,  3.60s/it]\u001b[A\n",
            " 33% 133/400 [05:41<19:15,  4.33s/it]\u001b[A\n",
            " 34% 134/400 [05:41<14:07,  3.19s/it]\u001b[A\n",
            " 34% 135/400 [05:42<10:53,  2.46s/it]\u001b[A\n",
            " 34% 136/400 [05:42<08:17,  1.88s/it]\u001b[A\n",
            " 34% 137/400 [05:43<06:28,  1.48s/it]\u001b[A\n",
            " 34% 138/400 [05:49<12:18,  2.82s/it]\u001b[A\n",
            " 35% 139/400 [05:55<16:40,  3.83s/it]\u001b[A\n",
            " 35% 140/400 [05:56<13:02,  3.01s/it]\u001b[A\n",
            " 35% 141/400 [05:57<10:31,  2.44s/it]\u001b[A\n",
            " 36% 142/400 [05:58<08:01,  1.87s/it]\u001b[A\n",
            " 36% 143/400 [06:04<13:09,  3.07s/it]\u001b[A\n",
            " 36% 144/400 [06:10<16:40,  3.91s/it]\u001b[A\n",
            " 36% 145/400 [06:10<12:24,  2.92s/it]\u001b[A\n",
            " 36% 146/400 [06:16<16:08,  3.81s/it]\u001b[A\n",
            " 37% 147/400 [06:22<18:41,  4.43s/it]\u001b[A\n",
            " 37% 148/400 [06:28<20:54,  4.98s/it]\u001b[A\n",
            " 37% 149/400 [06:29<15:17,  3.66s/it]\u001b[A\n",
            " 38% 150/400 [06:35<18:04,  4.34s/it]\u001b[A\n",
            " 38% 151/400 [06:41<20:31,  4.95s/it]\u001b[A\n",
            " 38% 152/400 [06:47<21:46,  5.27s/it]\u001b[A\n",
            " 38% 153/400 [06:48<15:51,  3.85s/it]\u001b[A\n",
            " 38% 154/400 [06:48<11:56,  2.91s/it]\u001b[A\n",
            " 39% 155/400 [06:49<09:11,  2.25s/it]\u001b[A\n",
            " 39% 156/400 [06:55<13:49,  3.40s/it]\u001b[A\n",
            " 39% 157/400 [06:56<10:25,  2.57s/it]\u001b[A\n",
            " 40% 158/400 [06:56<08:02,  2.00s/it]\u001b[A\n",
            " 40% 159/400 [06:57<06:27,  1.61s/it]\u001b[A\n",
            " 40% 160/400 [07:03<12:03,  3.01s/it]\u001b[A\n",
            " 40% 161/400 [07:04<09:10,  2.30s/it]\u001b[A\n",
            " 40% 162/400 [07:05<07:50,  1.98s/it]\u001b[A\n",
            " 41% 163/400 [07:07<06:53,  1.75s/it]\u001b[A\n",
            " 41% 164/400 [07:12<11:44,  2.98s/it]\u001b[A\n",
            " 41% 165/400 [07:18<15:06,  3.86s/it]\u001b[A\n",
            " 42% 166/400 [07:24<17:25,  4.47s/it]\u001b[A\n",
            " 42% 167/400 [07:30<19:24,  5.00s/it]\u001b[A\n",
            " 42% 168/400 [07:31<14:27,  3.74s/it]\u001b[A\n",
            " 42% 169/400 [07:32<10:59,  2.85s/it]\u001b[A\n",
            " 42% 170/400 [07:38<14:37,  3.81s/it]\u001b[A\n",
            " 43% 171/400 [07:39<11:38,  3.05s/it]\u001b[A\n",
            " 43% 172/400 [07:41<09:44,  2.56s/it]\u001b[A\n",
            " 43% 173/400 [07:42<07:41,  2.03s/it]\u001b[A\n",
            " 44% 174/400 [07:43<06:37,  1.76s/it]\u001b[A\n",
            " 44% 175/400 [07:49<11:39,  3.11s/it]\u001b[A\n",
            " 44% 176/400 [07:49<08:38,  2.32s/it]\u001b[A\n",
            " 44% 177/400 [07:50<06:51,  1.85s/it]\u001b[A\n",
            " 44% 178/400 [07:51<05:44,  1.55s/it]\u001b[A\n",
            " 45% 179/400 [07:52<04:58,  1.35s/it]\u001b[A\n",
            " 45% 180/400 [07:58<10:08,  2.76s/it]\u001b[A\n",
            " 45% 181/400 [08:04<13:30,  3.70s/it]\u001b[A\n",
            " 46% 182/400 [08:10<16:27,  4.53s/it]\u001b[A\n",
            " 46% 183/400 [08:11<11:57,  3.31s/it]\u001b[A\n",
            " 46% 184/400 [08:11<08:51,  2.46s/it]\u001b[A\n",
            " 46% 185/400 [08:17<12:40,  3.54s/it]\u001b[A\n",
            " 46% 186/400 [08:18<09:40,  2.71s/it]\u001b[A\n",
            " 47% 187/400 [08:24<13:13,  3.72s/it]\u001b[A\n",
            " 47% 188/400 [08:30<15:24,  4.36s/it]\u001b[A\n",
            " 47% 189/400 [08:36<17:10,  4.89s/it]\u001b[A\n",
            " 48% 190/400 [08:37<12:44,  3.64s/it]\u001b[A\n",
            " 48% 191/400 [08:43<14:59,  4.30s/it]\u001b[A\n",
            " 48% 192/400 [08:43<10:56,  3.16s/it]\u001b[A\n",
            " 48% 193/400 [08:49<13:41,  3.97s/it]\u001b[A\n",
            " 48% 194/400 [08:50<10:29,  3.06s/it]\u001b[A\n",
            " 49% 195/400 [08:51<07:54,  2.31s/it]\u001b[A\n",
            " 49% 196/400 [08:51<06:06,  1.80s/it]\u001b[A\n",
            " 49% 197/400 [08:52<04:51,  1.44s/it]\u001b[A\n",
            " 50% 198/400 [08:52<04:03,  1.20s/it]\u001b[A\n",
            " 50% 199/400 [08:59<08:55,  2.67s/it]\u001b[A\n",
            " 50% 200/400 [09:05<12:29,  3.75s/it]\u001b[A\n",
            " 50% 201/400 [09:07<10:38,  3.21s/it]\u001b[A\n",
            " 50% 202/400 [09:08<08:49,  2.68s/it]\u001b[A\n",
            " 51% 203/400 [09:10<07:47,  2.37s/it]\u001b[A\n",
            " 51% 204/400 [09:12<07:06,  2.18s/it]\u001b[A\n",
            " 51% 205/400 [09:13<06:31,  2.01s/it]\u001b[A\n",
            " 52% 206/400 [09:15<06:00,  1.86s/it]\u001b[A\n",
            " 52% 207/400 [09:16<05:54,  1.84s/it]\u001b[A\n",
            " 52% 208/400 [09:19<06:13,  1.95s/it]\u001b[A\n",
            " 52% 209/400 [09:21<06:26,  2.03s/it]\u001b[A\n",
            " 52% 210/400 [09:23<06:05,  1.92s/it]\u001b[A\n",
            " 53% 211/400 [09:25<06:19,  2.01s/it]\u001b[A\n",
            " 53% 212/400 [09:27<06:42,  2.14s/it]\u001b[A\n",
            " 53% 213/400 [09:33<10:13,  3.28s/it]\u001b[A\n",
            " 54% 214/400 [09:36<09:41,  3.13s/it]\u001b[A\n",
            " 54% 215/400 [09:39<09:13,  2.99s/it]\u001b[A\n",
            " 54% 216/400 [09:40<08:05,  2.64s/it]\u001b[A\n",
            " 54% 217/400 [09:43<07:51,  2.57s/it]\u001b[A\n",
            " 55% 218/400 [09:45<07:42,  2.54s/it]\u001b[A\n",
            " 55% 219/400 [09:48<08:01,  2.66s/it]\u001b[A\n",
            " 55% 220/400 [09:51<08:09,  2.72s/it]\u001b[A\n",
            " 55% 221/400 [09:53<07:02,  2.36s/it]\u001b[A\n",
            " 56% 222/400 [09:54<06:21,  2.14s/it]\u001b[A\n",
            " 56% 223/400 [10:00<09:39,  3.28s/it]\u001b[A\n",
            " 56% 224/400 [10:06<12:04,  4.11s/it]\u001b[A\n",
            " 56% 225/400 [10:12<13:41,  4.69s/it]\u001b[A\n",
            " 56% 226/400 [10:15<11:34,  3.99s/it]\u001b[A\n",
            " 57% 227/400 [10:17<10:02,  3.48s/it]\u001b[A\n",
            " 57% 228/400 [10:18<08:17,  2.89s/it]\u001b[A\n",
            " 57% 229/400 [10:20<07:24,  2.60s/it]\u001b[A\n",
            " 57% 230/400 [10:22<06:22,  2.25s/it]\u001b[A\n",
            " 58% 231/400 [10:24<05:54,  2.10s/it]\u001b[A\n",
            " 58% 232/400 [10:30<09:12,  3.29s/it]\u001b[A\n",
            " 58% 233/400 [10:36<11:21,  4.08s/it]\u001b[A\n",
            " 58% 234/400 [10:41<12:47,  4.63s/it]\u001b[A\n",
            " 59% 235/400 [10:43<10:28,  3.81s/it]\u001b[A\n",
            " 59% 236/400 [10:45<08:42,  3.19s/it]\u001b[A\n",
            " 59% 237/400 [10:51<10:56,  4.02s/it]\u001b[A\n",
            " 60% 238/400 [10:57<12:25,  4.60s/it]\u001b[A\n",
            " 60% 239/400 [10:59<10:06,  3.76s/it]\u001b[A\n",
            " 60% 240/400 [11:02<09:19,  3.50s/it]\u001b[A\n",
            " 60% 241/400 [11:06<09:38,  3.64s/it]\u001b[A\n",
            " 60% 242/400 [11:09<09:03,  3.44s/it]\u001b[A\n",
            " 61% 243/400 [11:10<07:36,  2.90s/it]\u001b[A\n",
            " 61% 244/400 [11:13<07:22,  2.84s/it]\u001b[A\n",
            " 61% 245/400 [11:16<07:14,  2.80s/it]\u001b[A\n",
            " 62% 246/400 [11:18<07:08,  2.78s/it]\u001b[A\n",
            " 62% 247/400 [11:21<07:01,  2.75s/it]\u001b[A\n",
            " 62% 248/400 [11:23<06:20,  2.50s/it]\u001b[A\n",
            " 62% 249/400 [11:25<05:59,  2.38s/it]\u001b[A\n",
            " 62% 250/400 [11:28<06:09,  2.46s/it]\u001b[A\n",
            " 63% 251/400 [11:30<05:38,  2.27s/it]\u001b[A\n",
            " 63% 252/400 [11:36<08:23,  3.40s/it]\u001b[A\n",
            " 63% 253/400 [11:38<07:54,  3.23s/it]\u001b[A\n",
            " 64% 254/400 [11:41<07:23,  3.04s/it]\u001b[A\n",
            " 64% 255/400 [11:44<07:01,  2.91s/it]\u001b[A\n",
            " 64% 256/400 [11:46<06:20,  2.64s/it]\u001b[A\n",
            " 64% 257/400 [11:48<05:46,  2.42s/it]\u001b[A\n",
            " 64% 258/400 [11:51<06:14,  2.64s/it]\u001b[A\n",
            " 65% 259/400 [11:54<06:31,  2.77s/it]\u001b[A\n",
            " 65% 260/400 [12:00<08:43,  3.74s/it]\u001b[A\n",
            " 65% 261/400 [12:06<10:13,  4.41s/it]\u001b[A\n",
            " 66% 262/400 [12:08<08:51,  3.85s/it]\u001b[A\n",
            " 66% 263/400 [12:11<08:14,  3.61s/it]\u001b[A\n",
            " 66% 264/400 [12:17<09:47,  4.32s/it]\u001b[A\n",
            " 66% 265/400 [12:20<08:27,  3.76s/it]\u001b[A\n",
            " 66% 266/400 [12:22<07:12,  3.23s/it]\u001b[A\n",
            " 67% 267/400 [12:26<07:33,  3.41s/it]\u001b[A\n",
            " 67% 268/400 [12:30<08:15,  3.75s/it]\u001b[A\n",
            " 67% 269/400 [12:33<07:18,  3.34s/it]\u001b[A\n",
            " 68% 270/400 [12:39<08:59,  4.15s/it]\u001b[A\n",
            " 68% 271/400 [12:41<07:43,  3.59s/it]\u001b[A\n",
            " 68% 272/400 [12:43<07:00,  3.28s/it]\u001b[A\n",
            " 68% 273/400 [12:50<08:42,  4.11s/it]\u001b[A\n",
            " 68% 274/400 [12:55<09:46,  4.66s/it]\u001b[A\n",
            " 69% 275/400 [13:02<10:41,  5.13s/it]\u001b[A\n",
            " 69% 276/400 [13:08<11:09,  5.40s/it]\u001b[A\n",
            " 69% 277/400 [13:11<09:31,  4.65s/it]\u001b[A\n",
            " 70% 278/400 [13:13<08:08,  4.00s/it]\u001b[A\n",
            " 70% 279/400 [13:16<07:25,  3.68s/it]\u001b[A\n",
            " 70% 280/400 [13:22<08:53,  4.44s/it]\u001b[A\n",
            " 70% 281/400 [13:28<09:43,  4.90s/it]\u001b[A\n",
            " 70% 282/400 [13:30<07:56,  4.04s/it]\u001b[A\n",
            " 71% 283/400 [13:34<07:37,  3.91s/it]\u001b[A\n",
            " 71% 284/400 [13:38<07:37,  3.94s/it]\u001b[A\n",
            " 71% 285/400 [13:40<06:21,  3.31s/it]\u001b[A\n",
            " 72% 286/400 [13:43<06:09,  3.24s/it]\u001b[A\n",
            " 72% 287/400 [13:45<05:22,  2.86s/it]\u001b[A\n",
            " 72% 288/400 [13:47<04:50,  2.59s/it]\u001b[A\n",
            " 72% 289/400 [13:48<04:12,  2.27s/it]\u001b[A\n",
            " 72% 290/400 [13:54<06:11,  3.38s/it]\u001b[A\n",
            " 73% 291/400 [14:00<07:30,  4.13s/it]\u001b[A\n",
            " 73% 292/400 [14:02<06:10,  3.43s/it]\u001b[A\n",
            " 73% 293/400 [14:04<05:11,  2.91s/it]\u001b[A\n",
            " 74% 294/400 [14:06<04:54,  2.78s/it]\u001b[A\n",
            " 74% 295/400 [14:09<04:41,  2.68s/it]\u001b[A\n",
            " 74% 296/400 [14:11<04:21,  2.51s/it]\u001b[A\n",
            " 74% 297/400 [14:13<04:03,  2.36s/it]\u001b[A\n",
            " 74% 298/400 [14:15<04:10,  2.46s/it]\u001b[A\n",
            " 75% 299/400 [14:20<05:26,  3.23s/it]\u001b[A\n",
            " 75% 300/400 [14:22<04:22,  2.63s/it]\u001b[A\n",
            " 75% 301/400 [14:23<03:37,  2.19s/it]\u001b[A\n",
            " 76% 302/400 [14:24<03:01,  1.85s/it]\u001b[A\n",
            " 76% 303/400 [14:25<02:34,  1.59s/it]\u001b[A\n",
            " 76% 304/400 [14:26<02:18,  1.45s/it]\u001b[A\n",
            " 76% 305/400 [14:27<02:13,  1.40s/it]\u001b[A\n",
            " 76% 306/400 [14:28<02:04,  1.33s/it]\u001b[A\n",
            " 77% 307/400 [14:29<01:56,  1.26s/it]\u001b[A\n",
            " 77% 308/400 [14:31<01:56,  1.26s/it]\u001b[A\n",
            " 77% 309/400 [14:32<01:54,  1.25s/it]\u001b[A\n",
            " 78% 310/400 [14:33<01:49,  1.22s/it]\u001b[A\n",
            " 78% 311/400 [14:35<02:00,  1.35s/it]\u001b[A\n",
            " 78% 312/400 [14:36<02:06,  1.43s/it]\u001b[A\n",
            " 78% 313/400 [14:38<02:07,  1.47s/it]\u001b[A\n",
            " 78% 314/400 [14:39<02:06,  1.47s/it]\u001b[A\n",
            " 79% 315/400 [14:41<02:05,  1.48s/it]\u001b[A\n",
            " 79% 316/400 [14:42<01:56,  1.38s/it]\u001b[A\n",
            " 79% 317/400 [14:44<02:00,  1.45s/it]\u001b[A\n",
            " 80% 318/400 [14:45<02:02,  1.49s/it]\u001b[A\n",
            " 80% 319/400 [14:47<02:09,  1.60s/it]\u001b[A\n",
            " 80% 320/400 [14:49<02:14,  1.68s/it]\u001b[A\n",
            " 80% 321/400 [14:50<01:57,  1.49s/it]\u001b[A\n",
            " 80% 322/400 [14:51<01:52,  1.44s/it]\u001b[A\n",
            " 81% 323/400 [14:57<03:32,  2.77s/it]\u001b[A\n",
            " 81% 324/400 [15:03<04:41,  3.70s/it]\u001b[A\n",
            " 81% 325/400 [15:04<03:35,  2.88s/it]\u001b[A\n",
            " 82% 326/400 [15:06<03:05,  2.51s/it]\u001b[A\n",
            " 82% 327/400 [15:07<02:42,  2.22s/it]\u001b[A\n",
            " 82% 328/400 [15:08<02:17,  1.92s/it]\u001b[A\n",
            " 82% 329/400 [15:10<02:00,  1.70s/it]\u001b[A\n",
            " 82% 330/400 [15:11<01:47,  1.54s/it]\u001b[A\n",
            " 83% 331/400 [15:12<01:40,  1.46s/it]\u001b[A\n",
            " 83% 332/400 [15:18<03:09,  2.79s/it]\u001b[A\n",
            " 83% 333/400 [15:24<04:09,  3.72s/it]\u001b[A\n",
            " 84% 334/400 [15:25<03:15,  2.97s/it]\u001b[A\n",
            " 84% 335/400 [15:26<02:41,  2.48s/it]\u001b[A\n",
            " 84% 336/400 [15:28<02:17,  2.15s/it]\u001b[A\n",
            " 84% 337/400 [15:29<01:55,  1.83s/it]\u001b[A\n",
            " 84% 338/400 [15:35<03:09,  3.06s/it]\u001b[A\n",
            " 85% 339/400 [15:36<02:32,  2.49s/it]\u001b[A\n",
            " 85% 340/400 [15:37<02:09,  2.16s/it]\u001b[A\n",
            " 85% 341/400 [15:39<01:53,  1.93s/it]\u001b[A\n",
            " 86% 342/400 [15:40<01:42,  1.77s/it]\u001b[A\n",
            " 86% 343/400 [15:41<01:29,  1.56s/it]\u001b[A\n",
            " 86% 344/400 [15:43<01:26,  1.54s/it]\u001b[A\n",
            " 86% 345/400 [15:44<01:26,  1.58s/it]\u001b[A\n",
            " 86% 346/400 [15:46<01:27,  1.62s/it]\u001b[A\n",
            " 87% 347/400 [15:47<01:21,  1.54s/it]\u001b[A\n",
            " 87% 348/400 [15:49<01:14,  1.43s/it]\u001b[A\n",
            " 87% 349/400 [15:50<01:11,  1.41s/it]\u001b[A\n",
            " 88% 350/400 [15:52<01:14,  1.49s/it]\u001b[A\n",
            " 88% 351/400 [15:53<01:07,  1.38s/it]\u001b[A\n",
            " 88% 352/400 [15:59<02:13,  2.78s/it]\u001b[A\n",
            " 88% 353/400 [16:00<01:48,  2.32s/it]\u001b[A\n",
            " 88% 354/400 [16:01<01:31,  1.99s/it]\u001b[A\n",
            " 89% 355/400 [16:03<01:20,  1.79s/it]\u001b[A\n",
            " 89% 356/400 [16:04<01:14,  1.70s/it]\u001b[A\n",
            " 89% 357/400 [16:06<01:10,  1.65s/it]\u001b[A\n",
            " 90% 358/400 [16:07<01:11,  1.69s/it]\u001b[A\n",
            " 90% 359/400 [16:09<01:11,  1.75s/it]\u001b[A\n",
            " 90% 360/400 [16:10<01:01,  1.54s/it]\u001b[A\n",
            " 90% 361/400 [16:16<01:50,  2.84s/it]\u001b[A\n",
            " 90% 362/400 [16:18<01:36,  2.55s/it]\u001b[A\n",
            " 91% 363/400 [16:20<01:28,  2.40s/it]\u001b[A\n",
            " 91% 364/400 [16:26<02:04,  3.46s/it]\u001b[A\n",
            " 91% 365/400 [16:27<01:36,  2.75s/it]\u001b[A\n",
            " 92% 366/400 [16:29<01:18,  2.32s/it]\u001b[A\n",
            " 92% 367/400 [16:30<01:09,  2.10s/it]\u001b[A\n",
            " 92% 368/400 [16:32<01:04,  2.03s/it]\u001b[A\n",
            " 92% 369/400 [16:34<01:00,  1.96s/it]\u001b[A\n",
            " 92% 370/400 [16:36<00:57,  1.90s/it]\u001b[A\n",
            " 93% 371/400 [16:37<00:54,  1.88s/it]\u001b[A\n",
            " 93% 372/400 [16:39<00:51,  1.84s/it]\u001b[A\n",
            " 93% 373/400 [16:45<01:22,  3.07s/it]\u001b[A\n",
            " 94% 374/400 [16:51<01:41,  3.90s/it]\u001b[A\n",
            " 94% 375/400 [16:57<01:53,  4.53s/it]\u001b[A\n",
            " 94% 376/400 [17:03<01:58,  4.95s/it]\u001b[A\n",
            " 94% 377/400 [17:05<01:31,  3.99s/it]\u001b[A\n",
            " 94% 378/400 [17:06<01:12,  3.28s/it]\u001b[A\n",
            " 95% 379/400 [17:08<01:01,  2.94s/it]\u001b[A\n",
            " 95% 380/400 [17:15<01:18,  3.92s/it]\u001b[A\n",
            " 95% 381/400 [17:20<01:25,  4.52s/it]\u001b[A\n",
            " 96% 382/400 [17:22<01:02,  3.48s/it]\u001b[A\n",
            " 96% 383/400 [17:23<00:49,  2.91s/it]\u001b[A\n",
            " 96% 384/400 [17:25<00:40,  2.50s/it]\u001b[A\n",
            " 96% 385/400 [17:26<00:31,  2.12s/it]\u001b[A\n",
            " 96% 386/400 [17:28<00:30,  2.16s/it]\u001b[A\n",
            " 97% 387/400 [17:29<00:24,  1.85s/it]\u001b[A\n",
            " 97% 388/400 [17:31<00:20,  1.71s/it]\u001b[A\n",
            " 97% 389/400 [17:32<00:16,  1.52s/it]\u001b[A\n",
            " 98% 390/400 [17:33<00:14,  1.47s/it]\u001b[A\n",
            " 98% 391/400 [17:39<00:25,  2.79s/it]\u001b[A\n",
            " 98% 392/400 [17:40<00:18,  2.31s/it]\u001b[A\n",
            " 98% 393/400 [17:41<00:13,  1.93s/it]\u001b[A\n",
            " 98% 394/400 [17:43<00:11,  1.86s/it]\u001b[A\n",
            " 99% 395/400 [17:45<00:09,  1.81s/it]\u001b[A\n",
            " 99% 396/400 [17:46<00:06,  1.69s/it]\u001b[A\n",
            " 99% 397/400 [17:48<00:04,  1.64s/it]\u001b[A\n",
            "100% 398/400 [17:49<00:03,  1.64s/it]\u001b[A\n",
            "100% 399/400 [17:50<00:01,  1.46s/it]\u001b[A\n",
            "                                       \n",
            "\u001b[A{'eval_loss': 0.4262450039386749, 'eval_rouge1': 52.2744, 'eval_rouge2': 37.1198, 'eval_rougeL': 52.0032, 'eval_rougeLsum': 52.0106, 'eval_bleu': 71.6628, 'eval_gen_len': 46.5912, 'eval_runtime': 1095.8752, 'eval_samples_per_second': 1.46, 'eval_steps_per_second': 0.365, 'epoch': 4.0}\n",
            " 80% 1200/1500 [49:04<02:46,  1.80it/s]\n",
            "100% 400/400 [18:14<00:00,  1.33s/it]\u001b[A\n",
            "                                     \u001b[ASaving model checkpoint to pegasus_model_full/checkpoint-1200\n",
            "Configuration saved in pegasus_model_full/checkpoint-1200/config.json\n",
            "Configuration saved in pegasus_model_full/checkpoint-1200/generation_config.json\n",
            "Model weights saved in pegasus_model_full/checkpoint-1200/pytorch_model.bin\n",
            "tokenizer config file saved in pegasus_model_full/checkpoint-1200/tokenizer_config.json\n",
            "Special tokens file saved in pegasus_model_full/checkpoint-1200/special_tokens_map.json\n",
            "{'loss': 0.5148, 'learning_rate': 4.9999999999999996e-06, 'epoch': 4.17}\n",
            "{'loss': 0.5178, 'learning_rate': 4e-06, 'epoch': 4.33}\n",
            "{'loss': 0.5022, 'learning_rate': 3e-06, 'epoch': 4.5}\n",
            "{'loss': 0.4626, 'learning_rate': 2e-06, 'epoch': 4.67}\n",
            "{'loss': 0.4971, 'learning_rate': 1e-06, 'epoch': 4.83}\n",
            "{'loss': 0.4772, 'learning_rate': 0.0, 'epoch': 5.0}\n",
            "100% 1500/1500 [52:10<00:00,  1.73it/s]Saving model checkpoint to pegasus_model_full/checkpoint-1500\n",
            "Configuration saved in pegasus_model_full/checkpoint-1500/config.json\n",
            "Configuration saved in pegasus_model_full/checkpoint-1500/generation_config.json\n",
            "Model weights saved in pegasus_model_full/checkpoint-1500/pytorch_model.bin\n",
            "tokenizer config file saved in pegasus_model_full/checkpoint-1500/tokenizer_config.json\n",
            "Special tokens file saved in pegasus_model_full/checkpoint-1500/special_tokens_map.json\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "{'train_runtime': 3156.907, 'train_samples_per_second': 7.602, 'train_steps_per_second': 0.475, 'train_loss': 0.6105319379170736, 'epoch': 5.0}\n",
            "100% 1500/1500 [52:27<00:00,  2.10s/it]\n",
            "Saving model checkpoint to pegasus_model_full/\n",
            "Configuration saved in pegasus_model_full/config.json\n",
            "Configuration saved in pegasus_model_full/generation_config.json\n",
            "Model weights saved in pegasus_model_full/pytorch_model.bin\n",
            "tokenizer config file saved in pegasus_model_full/tokenizer_config.json\n",
            "Special tokens file saved in pegasus_model_full/special_tokens_map.json\n",
            "***** train metrics *****\n",
            "  epoch                    =        5.0\n",
            "  train_loss               =     0.6105\n",
            "  train_runtime            = 0:52:36.90\n",
            "  train_samples            =       4800\n",
            "  train_samples_per_second =      7.602\n",
            "  train_steps_per_second   =      0.475\n",
            "05/08/2023 22:43:05 - INFO - __main__ -   *** Evaluate ***\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1600\n",
            "  Batch size = 4\n",
            "100% 400/400 [13:19<00:00,  2.00s/it]\n",
            "***** eval metrics *****\n",
            "  epoch                   =        5.0\n",
            "  eval_bleu               =    71.6916\n",
            "  eval_gen_len            =    45.0281\n",
            "  eval_loss               =     0.4272\n",
            "  eval_rouge1             =     52.544\n",
            "  eval_rouge2             =    37.1305\n",
            "  eval_rougeL             =    52.2806\n",
            "  eval_rougeLsum          =    52.2931\n",
            "  eval_runtime            = 0:13:20.73\n",
            "  eval_samples            =       1600\n",
            "  eval_samples_per_second =      1.998\n",
            "  eval_steps_per_second   =        0.5\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                      eval/bleu ▁██\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                   eval/gen_len █▆▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                      eval/loss █▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                    eval/rouge1 ▁▄█\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                    eval/rouge2 ▁██\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                    eval/rougeL ▁▄█\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                 eval/rougeLsum ▁▄█\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                   eval/runtime █▇▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        eval/samples_per_second ▁▁█\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/steps_per_second ▁▁█\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                    train/epoch ▁▁▁▂▂▂▂▃▃▃▃▄▄▄▄▄▅▅▅▅▆▆▆▆▇▇▇▇▇█████\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:              train/global_step ▁▁▁▂▂▂▂▃▃▃▃▄▄▄▄▄▅▅▅▅▆▆▆▆▇▇▇▇▇█████\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            train/learning_rate ███▇▇▇▇▆▆▆▆▅▅▅▅▄▄▄▄▃▃▃▃▂▂▂▂▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                     train/loss █▅▅▃▃▃▃▂▂▂▂▁▁▂▂▁▂▂▁▁▁▂▁▁▁▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               train/total_flos ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               train/train_loss ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            train/train_runtime ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: train/train_samples_per_second ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   train/train_steps_per_second ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                      eval/bleu 71.6916\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                   eval/gen_len 45.0281\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                      eval/loss 0.42721\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                    eval/rouge1 52.544\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                    eval/rouge2 37.1305\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                    eval/rougeL 52.2806\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                 eval/rougeLsum 52.2931\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                   eval/runtime 800.7331\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        eval/samples_per_second 1.998\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/steps_per_second 0.5\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                    train/epoch 5.0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:              train/global_step 1500\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            train/learning_rate 0.0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                     train/loss 0.4772\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               train/total_flos 5213767648149504.0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               train/train_loss 0.61053\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            train/train_runtime 3156.907\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: train/train_samples_per_second 7.602\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   train/train_steps_per_second 0.475\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /content/iterater/code/IteraTeR_ACL2022/model/generation/wandb/offline-run-20230508_215030-jlua8l41\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20230508_215030-jlua8l41/logs\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'with open(\"/content/output-fully-multilingual-pegasus-10epochs.txt\", \"r\") as file:\\n    contents = file.read()\\n    print(contents)'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 46
        }
      ],
      "source": [
        "# #training model\n",
        "# %%time\n",
        "!mv /content/cs678-cp1-cp2/edit_generation/multilingual/pegasus_fullysup_multilingual_train.sh /content/iterater/code/IteraTeR_ACL2022/model/generation\n",
        "%cd /content/iterater/code/IteraTeR_ACL2022/model/generation\n",
        "!sh pegasus_fullysup_multilingual_train.sh\n",
        "\n",
        "\"\"\"with open(\"/content/output-fully-multilingual-pegasus-10epochs.txt\", \"r\") as file:\n",
        "    contents = file.read()\n",
        "    print(contents)\"\"\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "245bc530-004f-488d-ea0f-d76ae424e911",
        "id": "W7i2NBWuuFKh"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Errno 2] No such file or directory: '/content/iterater/code/model/generation'\n",
            "/content/iterater/code/IteraTeR_ACL2022/model/generation\n",
            "2023-05-08 22:56:38.339947: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "  0% 0/1440 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1313: UserWarning: Using `max_length`'s default (256) to control the generation length. This behaviour is deprecated and will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "100% 1440/1440 [37:57<00:00,  1.58s/it]\n",
            "100% 1440/1440 [00:11<00:00, 125.40it/s]\n",
            "100% 1440/1440 [00:12<00:00, 116.61it/s]\n",
            "BLEU     : 0.24154555775384126\n",
            "ROUGE     : {'rouge1': 27.80156463913007, 'rouge2': 19.961063631651243, 'rougeL': 27.46477192821768, 'rougeLsum': 27.5146708714897}\n",
            "SARI: 18.079465281471837, KEEP: 0.26554936817718044, ADD: 0.00043437928824687096, DELETE: 0.2764002109787272\n",
            "CPU times: user 12.6 s, sys: 2.59 s, total: 15.2 s\n",
            "Wall time: 38min 49s\n"
          ]
        }
      ],
      "source": [
        "#printing metrics\n",
        "%%time\n",
        "%cd /content/iterater/code/IteraTeR_ACL2022/model/generation\n",
        "!python3 pegasus_inference_and_metrics.py --checkpoint pegasus_model_full --reference /content/cs678-cp1-cp2/multi_data/fully_multi/test.json --output pegasus_sent_output_full"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y-DyGnBJlM8s"
      },
      "source": [
        "#### Model 2.2.2 mT5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JToRri0mlM8t"
      },
      "source": [
        "##### Zero Shot\n",
        "\n",
        "train: english human_sent_level>train.json\n",
        "\n",
        "dev: english human_sent_level>dev.json\n",
        "\n",
        "test: multilingual human_sent_level>test.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "acVrJsmVk6Ar",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be57b30a-bf1d-48bb-8f6a-d864ac972922"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/iterater/code/IteraTeR_ACL2022/model/generation\n",
            "+ export TOKENIZERS_PARALLELISM=false\n",
            "+ PYTHON=python3\n",
            "+ git clone https://github.com/huggingface/transformers\n",
            "fatal: destination path 'transformers' already exists and is not an empty directory.\n",
            "+ cp run_summarization.py ./transformers/examples/pytorch/summarization/\n",
            "+ TRAIN_SCRIPT=./transformers/examples/pytorch/summarization/run_summarization.py\n",
            "+ TRAIN=/content/iterater/dataset/IteraTeR/human_sent_level/train.json\n",
            "+ VALID=/content/iterater/dataset/IteraTeR/human_sent_level/dev.json\n",
            "+ OUTPUT=mT5_model/\n",
            "+ sha1sum ./transformers/examples/pytorch/summarization/run_summarization.py\n",
            "1a98b8a4f2cf13523ec0e86d2094d61c4c53c7c1  ./transformers/examples/pytorch/summarization/run_summarization.py\n",
            "+ python3 ./transformers/examples/pytorch/summarization/run_summarization.py --model_name_or_path google/mt5-base --do_train --do_eval --train_file /content/iterater/dataset/IteraTeR/human_sent_level/train.json --validation_file /content/iterater/dataset/IteraTeR/human_sent_level/dev.json --per_device_train_batch_size=4 --per_device_eval_batch_size=4 --num_train_epochs 5 --gradient_accumulation_steps 4 --evaluation_strategy steps --eval_steps 200 --save_steps 100 --predict_with_generate --logging_steps 50 --output_dir mT5_model/ --overwrite_output_dir --text_column before_sent_with_intent --summary_column after_sent --learning_rate 3e-5\n",
            "2023-05-07 01:27:33.795251: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2023-05-07 01:27:33.855009: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-05-07 01:27:34.993809: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "05/07/2023 01:27:41 - WARNING - __main__ -   Process rank: -1, device: cuda:0, n_gpu: 1distributed training: False, 16-bits training: False\n",
            "05/07/2023 01:27:41 - INFO - __main__ -   Training/evaluation parameters Seq2SeqTrainingArguments(\n",
            "_n_gpu=1,\n",
            "adafactor=False,\n",
            "adam_beta1=0.9,\n",
            "adam_beta2=0.999,\n",
            "adam_epsilon=1e-08,\n",
            "auto_find_batch_size=False,\n",
            "bf16=False,\n",
            "bf16_full_eval=False,\n",
            "data_seed=None,\n",
            "dataloader_drop_last=False,\n",
            "dataloader_num_workers=0,\n",
            "dataloader_pin_memory=True,\n",
            "ddp_bucket_cap_mb=None,\n",
            "ddp_find_unused_parameters=None,\n",
            "ddp_timeout=1800,\n",
            "debug=[],\n",
            "deepspeed=None,\n",
            "disable_tqdm=False,\n",
            "do_eval=True,\n",
            "do_predict=False,\n",
            "do_train=True,\n",
            "eval_accumulation_steps=None,\n",
            "eval_delay=0,\n",
            "eval_steps=200,\n",
            "evaluation_strategy=steps,\n",
            "fp16=False,\n",
            "fp16_backend=auto,\n",
            "fp16_full_eval=False,\n",
            "fp16_opt_level=O1,\n",
            "fsdp=[],\n",
            "fsdp_config={'fsdp_min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},\n",
            "fsdp_min_num_params=0,\n",
            "fsdp_transformer_layer_cls_to_wrap=None,\n",
            "full_determinism=False,\n",
            "generation_config=None,\n",
            "generation_max_length=None,\n",
            "generation_num_beams=None,\n",
            "gradient_accumulation_steps=4,\n",
            "gradient_checkpointing=False,\n",
            "greater_is_better=None,\n",
            "group_by_length=False,\n",
            "half_precision_backend=auto,\n",
            "hub_model_id=None,\n",
            "hub_private_repo=False,\n",
            "hub_strategy=every_save,\n",
            "hub_token=<HUB_TOKEN>,\n",
            "ignore_data_skip=False,\n",
            "include_inputs_for_metrics=False,\n",
            "jit_mode_eval=False,\n",
            "label_names=None,\n",
            "label_smoothing_factor=0.0,\n",
            "learning_rate=3e-05,\n",
            "length_column_name=length,\n",
            "load_best_model_at_end=False,\n",
            "local_rank=-1,\n",
            "log_level=passive,\n",
            "log_level_replica=warning,\n",
            "log_on_each_node=True,\n",
            "logging_dir=mT5_model/runs/May07_01-27-39_cd731d4125ca,\n",
            "logging_first_step=False,\n",
            "logging_nan_inf_filter=True,\n",
            "logging_steps=50,\n",
            "logging_strategy=steps,\n",
            "lr_scheduler_type=linear,\n",
            "max_grad_norm=1.0,\n",
            "max_steps=-1,\n",
            "metric_for_best_model=None,\n",
            "mp_parameters=,\n",
            "no_cuda=False,\n",
            "num_train_epochs=5.0,\n",
            "optim=adamw_hf,\n",
            "optim_args=None,\n",
            "output_dir=mT5_model/,\n",
            "overwrite_output_dir=True,\n",
            "past_index=-1,\n",
            "per_device_eval_batch_size=4,\n",
            "per_device_train_batch_size=4,\n",
            "predict_with_generate=True,\n",
            "prediction_loss_only=False,\n",
            "push_to_hub=False,\n",
            "push_to_hub_model_id=None,\n",
            "push_to_hub_organization=None,\n",
            "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
            "ray_scope=last,\n",
            "remove_unused_columns=True,\n",
            "report_to=['tensorboard', 'wandb'],\n",
            "resume_from_checkpoint=None,\n",
            "run_name=mT5_model/,\n",
            "save_on_each_node=False,\n",
            "save_safetensors=False,\n",
            "save_steps=100,\n",
            "save_strategy=steps,\n",
            "save_total_limit=None,\n",
            "seed=42,\n",
            "sharded_ddp=[],\n",
            "skip_memory_metrics=True,\n",
            "sortish_sampler=False,\n",
            "tf32=None,\n",
            "torch_compile=False,\n",
            "torch_compile_backend=None,\n",
            "torch_compile_mode=None,\n",
            "torchdynamo=None,\n",
            "tpu_metrics_debug=False,\n",
            "tpu_num_cores=None,\n",
            "use_ipex=False,\n",
            "use_legacy_prediction_loop=False,\n",
            "use_mps_device=False,\n",
            "warmup_ratio=0.0,\n",
            "warmup_steps=0,\n",
            "weight_decay=0.0,\n",
            "xpu_backend=None,\n",
            ")\n",
            "05/07/2023 01:27:41 - INFO - __main__ -   Seq2SeqTrainingArguments(\n",
            "_n_gpu=1,\n",
            "adafactor=False,\n",
            "adam_beta1=0.9,\n",
            "adam_beta2=0.999,\n",
            "adam_epsilon=1e-08,\n",
            "auto_find_batch_size=False,\n",
            "bf16=False,\n",
            "bf16_full_eval=False,\n",
            "data_seed=None,\n",
            "dataloader_drop_last=False,\n",
            "dataloader_num_workers=0,\n",
            "dataloader_pin_memory=True,\n",
            "ddp_bucket_cap_mb=None,\n",
            "ddp_find_unused_parameters=None,\n",
            "ddp_timeout=1800,\n",
            "debug=[],\n",
            "deepspeed=None,\n",
            "disable_tqdm=False,\n",
            "do_eval=True,\n",
            "do_predict=False,\n",
            "do_train=True,\n",
            "eval_accumulation_steps=None,\n",
            "eval_delay=0,\n",
            "eval_steps=200,\n",
            "evaluation_strategy=steps,\n",
            "fp16=False,\n",
            "fp16_backend=auto,\n",
            "fp16_full_eval=False,\n",
            "fp16_opt_level=O1,\n",
            "fsdp=[],\n",
            "fsdp_config={'fsdp_min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},\n",
            "fsdp_min_num_params=0,\n",
            "fsdp_transformer_layer_cls_to_wrap=None,\n",
            "full_determinism=False,\n",
            "generation_config=None,\n",
            "generation_max_length=None,\n",
            "generation_num_beams=None,\n",
            "gradient_accumulation_steps=4,\n",
            "gradient_checkpointing=False,\n",
            "greater_is_better=None,\n",
            "group_by_length=False,\n",
            "half_precision_backend=auto,\n",
            "hub_model_id=None,\n",
            "hub_private_repo=False,\n",
            "hub_strategy=every_save,\n",
            "hub_token=<HUB_TOKEN>,\n",
            "ignore_data_skip=False,\n",
            "include_inputs_for_metrics=False,\n",
            "jit_mode_eval=False,\n",
            "label_names=None,\n",
            "label_smoothing_factor=0.0,\n",
            "learning_rate=3e-05,\n",
            "length_column_name=length,\n",
            "load_best_model_at_end=False,\n",
            "local_rank=-1,\n",
            "log_level=passive,\n",
            "log_level_replica=warning,\n",
            "log_on_each_node=True,\n",
            "logging_dir=mT5_model/runs/May07_01-27-39_cd731d4125ca,\n",
            "logging_first_step=False,\n",
            "logging_nan_inf_filter=True,\n",
            "logging_steps=50,\n",
            "logging_strategy=steps,\n",
            "lr_scheduler_type=linear,\n",
            "max_grad_norm=1.0,\n",
            "max_steps=-1,\n",
            "metric_for_best_model=None,\n",
            "mp_parameters=,\n",
            "no_cuda=False,\n",
            "num_train_epochs=5.0,\n",
            "optim=adamw_hf,\n",
            "optim_args=None,\n",
            "output_dir=mT5_model/,\n",
            "overwrite_output_dir=True,\n",
            "past_index=-1,\n",
            "per_device_eval_batch_size=4,\n",
            "per_device_train_batch_size=4,\n",
            "predict_with_generate=True,\n",
            "prediction_loss_only=False,\n",
            "push_to_hub=False,\n",
            "push_to_hub_model_id=None,\n",
            "push_to_hub_organization=None,\n",
            "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
            "ray_scope=last,\n",
            "remove_unused_columns=True,\n",
            "report_to=['tensorboard', 'wandb'],\n",
            "resume_from_checkpoint=None,\n",
            "run_name=mT5_model/,\n",
            "save_on_each_node=False,\n",
            "save_safetensors=False,\n",
            "save_steps=100,\n",
            "save_strategy=steps,\n",
            "save_total_limit=None,\n",
            "seed=42,\n",
            "sharded_ddp=[],\n",
            "skip_memory_metrics=True,\n",
            "sortish_sampler=False,\n",
            "tf32=None,\n",
            "torch_compile=False,\n",
            "torch_compile_backend=None,\n",
            "torch_compile_mode=None,\n",
            "torchdynamo=None,\n",
            "tpu_metrics_debug=False,\n",
            "tpu_num_cores=None,\n",
            "use_ipex=False,\n",
            "use_legacy_prediction_loop=False,\n",
            "use_mps_device=False,\n",
            "warmup_ratio=0.0,\n",
            "warmup_steps=0,\n",
            "weight_decay=0.0,\n",
            "xpu_backend=None,\n",
            ")\n",
            "05/07/2023 01:27:41 - INFO - __main__ -   42\n",
            "05/07/2023 01:27:41 - WARNING - datasets.builder -   Using custom data configuration default-60588ff345f515eb\n",
            "Downloading and preparing dataset json/default to /root/.cache/huggingface/datasets/json/default-60588ff345f515eb/0.0.0/ac0ca5f5289a6cf108e706efcf040422dbbfa8e658dee6a819f20d76bb84d26b...\n",
            "100% 2/2 [00:00<00:00, 11066.77it/s]\n",
            "100% 2/2 [00:00<00:00, 1626.64it/s]\n",
            "Dataset json downloaded and prepared to /root/.cache/huggingface/datasets/json/default-60588ff345f515eb/0.0.0/ac0ca5f5289a6cf108e706efcf040422dbbfa8e658dee6a819f20d76bb84d26b. Subsequent calls will reuse this data.\n",
            "100% 2/2 [00:00<00:00, 362.25it/s]\n",
            "Downloading (…)lve/main/config.json: 100% 702/702 [00:00<00:00, 3.61MB/s]\n",
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--google--mt5-base/snapshots/2eb15465c5dd7f72a8f7984306ad05ebc3dd1e1f/config.json\n",
            "Model config MT5Config {\n",
            "  \"_name_or_path\": \"google/mt5-base\",\n",
            "  \"architectures\": [\n",
            "    \"MT5ForConditionalGeneration\"\n",
            "  ],\n",
            "  \"d_ff\": 2048,\n",
            "  \"d_kv\": 64,\n",
            "  \"d_model\": 768,\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"dense_act_fn\": \"gelu_new\",\n",
            "  \"dropout_rate\": 0.1,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"feed_forward_proj\": \"gated-gelu\",\n",
            "  \"initializer_factor\": 1.0,\n",
            "  \"is_encoder_decoder\": true,\n",
            "  \"is_gated_act\": true,\n",
            "  \"layer_norm_epsilon\": 1e-06,\n",
            "  \"model_type\": \"mt5\",\n",
            "  \"num_decoder_layers\": 12,\n",
            "  \"num_heads\": 12,\n",
            "  \"num_layers\": 12,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"relative_attention_max_distance\": 128,\n",
            "  \"relative_attention_num_buckets\": 32,\n",
            "  \"tie_word_embeddings\": false,\n",
            "  \"tokenizer_class\": \"T5Tokenizer\",\n",
            "  \"transformers_version\": \"4.28.1\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 250112\n",
            "}\n",
            "\n",
            "Downloading (…)okenizer_config.json: 100% 376/376 [00:00<00:00, 2.75MB/s]\n",
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--google--mt5-base/snapshots/2eb15465c5dd7f72a8f7984306ad05ebc3dd1e1f/config.json\n",
            "Model config MT5Config {\n",
            "  \"_name_or_path\": \"google/mt5-base\",\n",
            "  \"architectures\": [\n",
            "    \"MT5ForConditionalGeneration\"\n",
            "  ],\n",
            "  \"d_ff\": 2048,\n",
            "  \"d_kv\": 64,\n",
            "  \"d_model\": 768,\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"dense_act_fn\": \"gelu_new\",\n",
            "  \"dropout_rate\": 0.1,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"feed_forward_proj\": \"gated-gelu\",\n",
            "  \"initializer_factor\": 1.0,\n",
            "  \"is_encoder_decoder\": true,\n",
            "  \"is_gated_act\": true,\n",
            "  \"layer_norm_epsilon\": 1e-06,\n",
            "  \"model_type\": \"mt5\",\n",
            "  \"num_decoder_layers\": 12,\n",
            "  \"num_heads\": 12,\n",
            "  \"num_layers\": 12,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"relative_attention_max_distance\": 128,\n",
            "  \"relative_attention_num_buckets\": 32,\n",
            "  \"tie_word_embeddings\": false,\n",
            "  \"tokenizer_class\": \"T5Tokenizer\",\n",
            "  \"transformers_version\": \"4.28.1\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 250112\n",
            "}\n",
            "\n",
            "Downloading (…)ve/main/spiece.model: 100% 4.31M/4.31M [00:00<00:00, 45.4MB/s]\n",
            "Downloading (…)cial_tokens_map.json: 100% 65.0/65.0 [00:00<00:00, 464kB/s]\n",
            "loading file spiece.model from cache at /root/.cache/huggingface/hub/models--google--mt5-base/snapshots/2eb15465c5dd7f72a8f7984306ad05ebc3dd1e1f/spiece.model\n",
            "loading file tokenizer.json from cache at None\n",
            "loading file added_tokens.json from cache at None\n",
            "loading file special_tokens_map.json from cache at /root/.cache/huggingface/hub/models--google--mt5-base/snapshots/2eb15465c5dd7f72a8f7984306ad05ebc3dd1e1f/special_tokens_map.json\n",
            "loading file tokenizer_config.json from cache at /root/.cache/huggingface/hub/models--google--mt5-base/snapshots/2eb15465c5dd7f72a8f7984306ad05ebc3dd1e1f/tokenizer_config.json\n",
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--google--mt5-base/snapshots/2eb15465c5dd7f72a8f7984306ad05ebc3dd1e1f/config.json\n",
            "Model config MT5Config {\n",
            "  \"_name_or_path\": \"google/mt5-base\",\n",
            "  \"architectures\": [\n",
            "    \"MT5ForConditionalGeneration\"\n",
            "  ],\n",
            "  \"d_ff\": 2048,\n",
            "  \"d_kv\": 64,\n",
            "  \"d_model\": 768,\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"dense_act_fn\": \"gelu_new\",\n",
            "  \"dropout_rate\": 0.1,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"feed_forward_proj\": \"gated-gelu\",\n",
            "  \"initializer_factor\": 1.0,\n",
            "  \"is_encoder_decoder\": true,\n",
            "  \"is_gated_act\": true,\n",
            "  \"layer_norm_epsilon\": 1e-06,\n",
            "  \"model_type\": \"mt5\",\n",
            "  \"num_decoder_layers\": 12,\n",
            "  \"num_heads\": 12,\n",
            "  \"num_layers\": 12,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"relative_attention_max_distance\": 128,\n",
            "  \"relative_attention_num_buckets\": 32,\n",
            "  \"tie_word_embeddings\": false,\n",
            "  \"tokenizer_class\": \"T5Tokenizer\",\n",
            "  \"transformers_version\": \"4.28.1\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 250112\n",
            "}\n",
            "\n",
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--google--mt5-base/snapshots/2eb15465c5dd7f72a8f7984306ad05ebc3dd1e1f/config.json\n",
            "Model config MT5Config {\n",
            "  \"_name_or_path\": \"google/mt5-base\",\n",
            "  \"architectures\": [\n",
            "    \"MT5ForConditionalGeneration\"\n",
            "  ],\n",
            "  \"d_ff\": 2048,\n",
            "  \"d_kv\": 64,\n",
            "  \"d_model\": 768,\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"dense_act_fn\": \"gelu_new\",\n",
            "  \"dropout_rate\": 0.1,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"feed_forward_proj\": \"gated-gelu\",\n",
            "  \"initializer_factor\": 1.0,\n",
            "  \"is_encoder_decoder\": true,\n",
            "  \"is_gated_act\": true,\n",
            "  \"layer_norm_epsilon\": 1e-06,\n",
            "  \"model_type\": \"mt5\",\n",
            "  \"num_decoder_layers\": 12,\n",
            "  \"num_heads\": 12,\n",
            "  \"num_layers\": 12,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"relative_attention_max_distance\": 128,\n",
            "  \"relative_attention_num_buckets\": 32,\n",
            "  \"tie_word_embeddings\": false,\n",
            "  \"tokenizer_class\": \"T5Tokenizer\",\n",
            "  \"transformers_version\": \"4.28.1\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 250112\n",
            "}\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/convert_slow_tokenizer.py:454: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
            "  warnings.warn(\n",
            "Assigning ['<clarity>', '<fluency>', '<coherence>', '<style>', '<meaning-changed>'] to the additional_special_tokens key of the tokenizer\n",
            "Downloading pytorch_model.bin: 100% 2.33G/2.33G [00:21<00:00, 111MB/s]\n",
            "loading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--google--mt5-base/snapshots/2eb15465c5dd7f72a8f7984306ad05ebc3dd1e1f/pytorch_model.bin\n",
            "Generate config GenerationConfig {\n",
            "  \"_from_model_config\": true,\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"transformers_version\": \"4.28.1\"\n",
            "}\n",
            "\n",
            "All model checkpoint weights were used when initializing MT5ForConditionalGeneration.\n",
            "\n",
            "All the weights of MT5ForConditionalGeneration were initialized from the model checkpoint at google/mt5-base.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use MT5ForConditionalGeneration for predictions without further training.\n",
            "Downloading (…)neration_config.json: 100% 147/147 [00:00<00:00, 1.04MB/s]\n",
            "loading configuration file generation_config.json from cache at /root/.cache/huggingface/hub/models--google--mt5-base/snapshots/2eb15465c5dd7f72a8f7984306ad05ebc3dd1e1f/generation_config.json\n",
            "Generate config GenerationConfig {\n",
            "  \"_from_model_config\": true,\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"transformers_version\": \"4.28.1\"\n",
            "}\n",
            "\n",
            "05/07/2023 01:28:18 - WARNING - datasets.fingerprint -   Parameter 'function'=<function main.<locals>.preprocess_function at 0x7fc4c9286320> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.\n",
            "Running tokenizer on train dataset:   0% 0/4 [00:00<?, ?ba/s]/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:3596: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
            "  warnings.warn(\n",
            "Running tokenizer on train dataset: 100% 4/4 [00:01<00:00,  3.65ba/s]\n",
            "Running tokenizer on validation dataset: 100% 1/1 [00:00<00:00,  7.34ba/s]\n",
            "Downloading: 5.60kB [00:00, 2.89MB/s]       \n",
            "Downloading: 6.06kB [00:00, 2.69MB/s]       \n",
            "Downloading: 4.07kB [00:00, 2.40MB/s]       \n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "***** Running training *****\n",
            "  Num examples = 3,254\n",
            "  Num Epochs = 5\n",
            "  Instantaneous batch size per device = 4\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
            "  Gradient Accumulation steps = 4\n",
            "  Total optimization steps = 1,015\n",
            "  Number of trainable parameters = 582,390,528\n",
            "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (1) Create a W&B account\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (2) Use an existing W&B account\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (3) Don't visualize my results\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Enter your choice: 2\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You chose 'Use an existing W&B account'\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.15.2\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/iterater/code/IteraTeR_ACL2022/model/generation/wandb/run-20230507_012833-kdzlhzhq\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mquiet-microwave-15\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/cs678/huggingface\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/cs678/huggingface/runs/kdzlhzhq\u001b[0m\n",
            "  0% 0/1015 [00:00<?, ?it/s]You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
            "{'loss': 13.5739, 'learning_rate': 2.8522167487684728e-05, 'epoch': 0.25}\n",
            "{'loss': 8.6768, 'learning_rate': 2.7044334975369458e-05, 'epoch': 0.49}\n",
            " 10% 100/1015 [00:54<07:26,  2.05it/s]Saving model checkpoint to mT5_model/checkpoint-100\n",
            "Configuration saved in mT5_model/checkpoint-100/config.json\n",
            "Configuration saved in mT5_model/checkpoint-100/generation_config.json\n",
            "Model weights saved in mT5_model/checkpoint-100/pytorch_model.bin\n",
            "tokenizer config file saved in mT5_model/checkpoint-100/tokenizer_config.json\n",
            "Special tokens file saved in mT5_model/checkpoint-100/special_tokens_map.json\n",
            "Copy vocab file to mT5_model/checkpoint-100/spiece.model\n",
            "{'loss': 3.6573, 'learning_rate': 2.5566502463054188e-05, 'epoch': 0.74}\n",
            "{'loss': 1.916, 'learning_rate': 2.408866995073892e-05, 'epoch': 0.98}\n",
            " 20% 200/1015 [02:02<06:43,  2.02it/s]***** Running Evaluation *****\n",
            "  Num examples = 400\n",
            "  Batch size = 4\n",
            "Generate config GenerationConfig {\n",
            "  \"_from_model_config\": true,\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"transformers_version\": \"4.28.1\"\n",
            "}\n",
            "\n",
            "\n",
            "  0% 0/100 [00:00<?, ?it/s]\u001b[A\n",
            "  2% 2/100 [00:00<00:19,  4.93it/s]\u001b[A\n",
            "  3% 3/100 [00:00<00:28,  3.44it/s]\u001b[A\n",
            "  4% 4/100 [00:01<00:32,  2.97it/s]\u001b[A\n",
            "  5% 5/100 [00:01<00:34,  2.77it/s]\u001b[A\n",
            "  6% 6/100 [00:02<00:35,  2.64it/s]\u001b[A\n",
            "  7% 7/100 [00:02<00:36,  2.57it/s]\u001b[A\n",
            "  8% 8/100 [00:02<00:36,  2.53it/s]\u001b[A\n",
            "  9% 9/100 [00:03<00:36,  2.50it/s]\u001b[A\n",
            " 10% 10/100 [00:03<00:36,  2.49it/s]\u001b[A\n",
            " 11% 11/100 [00:04<00:35,  2.48it/s]\u001b[A\n",
            " 12% 12/100 [00:04<00:36,  2.44it/s]\u001b[A\n",
            " 13% 13/100 [00:04<00:35,  2.43it/s]\u001b[A\n",
            " 14% 14/100 [00:05<00:35,  2.45it/s]\u001b[A\n",
            " 15% 15/100 [00:05<00:34,  2.45it/s]\u001b[A\n",
            " 16% 16/100 [00:06<00:34,  2.45it/s]\u001b[A\n",
            " 17% 17/100 [00:06<00:33,  2.45it/s]\u001b[A\n",
            " 18% 18/100 [00:06<00:33,  2.45it/s]\u001b[A\n",
            " 19% 19/100 [00:07<00:33,  2.45it/s]\u001b[A\n",
            " 20% 20/100 [00:07<00:32,  2.47it/s]\u001b[A\n",
            " 21% 21/100 [00:08<00:31,  2.47it/s]\u001b[A\n",
            " 22% 22/100 [00:08<00:31,  2.47it/s]\u001b[A\n",
            " 23% 23/100 [00:08<00:31,  2.48it/s]\u001b[A\n",
            " 24% 24/100 [00:09<00:30,  2.48it/s]\u001b[A\n",
            " 25% 25/100 [00:09<00:30,  2.47it/s]\u001b[A\n",
            " 26% 26/100 [00:10<00:30,  2.46it/s]\u001b[A\n",
            " 27% 27/100 [00:10<00:29,  2.47it/s]\u001b[A\n",
            " 28% 28/100 [00:11<00:29,  2.47it/s]\u001b[A\n",
            " 29% 29/100 [00:11<00:28,  2.45it/s]\u001b[A\n",
            " 30% 30/100 [00:11<00:28,  2.44it/s]\u001b[A\n",
            " 31% 31/100 [00:12<00:28,  2.44it/s]\u001b[A\n",
            " 32% 32/100 [00:12<00:27,  2.45it/s]\u001b[A\n",
            " 33% 33/100 [00:13<00:27,  2.46it/s]\u001b[A\n",
            " 34% 34/100 [00:13<00:26,  2.46it/s]\u001b[A\n",
            " 35% 35/100 [00:13<00:26,  2.46it/s]\u001b[A\n",
            " 36% 36/100 [00:14<00:26,  2.45it/s]\u001b[A\n",
            " 37% 37/100 [00:14<00:25,  2.46it/s]\u001b[A\n",
            " 38% 38/100 [00:15<00:25,  2.46it/s]\u001b[A\n",
            " 39% 39/100 [00:15<00:24,  2.46it/s]\u001b[A\n",
            " 40% 40/100 [00:15<00:24,  2.44it/s]\u001b[A\n",
            " 41% 41/100 [00:16<00:24,  2.44it/s]\u001b[A\n",
            " 42% 42/100 [00:16<00:23,  2.42it/s]\u001b[A\n",
            " 43% 43/100 [00:17<00:23,  2.42it/s]\u001b[A\n",
            " 44% 44/100 [00:17<00:23,  2.42it/s]\u001b[A\n",
            " 45% 45/100 [00:17<00:22,  2.42it/s]\u001b[A\n",
            " 46% 46/100 [00:18<00:22,  2.42it/s]\u001b[A\n",
            " 47% 47/100 [00:18<00:21,  2.42it/s]\u001b[A\n",
            " 48% 48/100 [00:19<00:21,  2.42it/s]\u001b[A\n",
            " 49% 49/100 [00:19<00:20,  2.43it/s]\u001b[A\n",
            " 50% 50/100 [00:20<00:20,  2.44it/s]\u001b[A\n",
            " 51% 51/100 [00:20<00:20,  2.44it/s]\u001b[A\n",
            " 52% 52/100 [00:20<00:19,  2.44it/s]\u001b[A\n",
            " 53% 53/100 [00:21<00:19,  2.45it/s]\u001b[A\n",
            " 54% 54/100 [00:21<00:18,  2.46it/s]\u001b[A\n",
            " 55% 55/100 [00:22<00:18,  2.46it/s]\u001b[A\n",
            " 56% 56/100 [00:22<00:17,  2.45it/s]\u001b[A\n",
            " 57% 57/100 [00:22<00:17,  2.45it/s]\u001b[A\n",
            " 58% 58/100 [00:23<00:17,  2.43it/s]\u001b[A\n",
            " 59% 59/100 [00:23<00:17,  2.41it/s]\u001b[A\n",
            " 60% 60/100 [00:24<00:16,  2.41it/s]\u001b[A\n",
            " 61% 61/100 [00:24<00:16,  2.41it/s]\u001b[A\n",
            " 62% 62/100 [00:24<00:15,  2.41it/s]\u001b[A\n",
            " 63% 63/100 [00:25<00:15,  2.42it/s]\u001b[A\n",
            " 64% 64/100 [00:25<00:14,  2.43it/s]\u001b[A\n",
            " 65% 65/100 [00:26<00:14,  2.44it/s]\u001b[A\n",
            " 66% 66/100 [00:26<00:13,  2.44it/s]\u001b[A\n",
            " 67% 67/100 [00:27<00:13,  2.46it/s]\u001b[A\n",
            " 68% 68/100 [00:27<00:13,  2.43it/s]\u001b[A\n",
            " 69% 69/100 [00:27<00:12,  2.44it/s]\u001b[A\n",
            " 70% 70/100 [00:28<00:12,  2.44it/s]\u001b[A\n",
            " 71% 71/100 [00:28<00:11,  2.44it/s]\u001b[A\n",
            " 72% 72/100 [00:29<00:11,  2.45it/s]\u001b[A\n",
            " 73% 73/100 [00:29<00:11,  2.45it/s]\u001b[A\n",
            " 74% 74/100 [00:29<00:10,  2.45it/s]\u001b[A\n",
            " 75% 75/100 [00:30<00:10,  2.45it/s]\u001b[A\n",
            " 76% 76/100 [00:30<00:09,  2.44it/s]\u001b[A\n",
            " 77% 77/100 [00:31<00:09,  2.44it/s]\u001b[A\n",
            " 78% 78/100 [00:31<00:08,  2.45it/s]\u001b[A\n",
            " 79% 79/100 [00:31<00:08,  2.44it/s]\u001b[A\n",
            " 80% 80/100 [00:32<00:08,  2.44it/s]\u001b[A\n",
            " 81% 81/100 [00:32<00:07,  2.44it/s]\u001b[A\n",
            " 82% 82/100 [00:33<00:07,  2.41it/s]\u001b[A\n",
            " 83% 83/100 [00:33<00:07,  2.41it/s]\u001b[A\n",
            " 84% 84/100 [00:34<00:06,  2.41it/s]\u001b[A\n",
            " 85% 85/100 [00:34<00:06,  2.43it/s]\u001b[A\n",
            " 86% 86/100 [00:34<00:05,  2.42it/s]\u001b[A\n",
            " 87% 87/100 [00:35<00:05,  2.42it/s]\u001b[A\n",
            " 88% 88/100 [00:35<00:04,  2.42it/s]\u001b[A\n",
            " 89% 89/100 [00:36<00:04,  2.44it/s]\u001b[A\n",
            " 90% 90/100 [00:36<00:04,  2.43it/s]\u001b[A\n",
            " 91% 91/100 [00:36<00:03,  2.44it/s]\u001b[A\n",
            " 92% 92/100 [00:37<00:03,  2.45it/s]\u001b[A\n",
            " 93% 93/100 [00:37<00:02,  2.45it/s]\u001b[A\n",
            " 94% 94/100 [00:38<00:02,  2.44it/s]\u001b[A\n",
            " 95% 95/100 [00:38<00:02,  2.44it/s]\u001b[A\n",
            " 96% 96/100 [00:38<00:01,  2.44it/s]\u001b[A\n",
            " 97% 97/100 [00:39<00:01,  2.42it/s]\u001b[A\n",
            " 98% 98/100 [00:39<00:00,  2.43it/s]\u001b[A\n",
            " 99% 99/100 [00:40<00:00,  2.45it/s]\u001b[A\n",
            "                                      \n",
            "\u001b[A{'eval_loss': 0.9844945669174194, 'eval_rouge1': 45.6802, 'eval_rouge2': 40.8404, 'eval_rougeL': 45.0594, 'eval_rougeLsum': 45.0942, 'eval_bleu': 15.9572, 'eval_gen_len': 17.41, 'eval_runtime': 50.6097, 'eval_samples_per_second': 7.904, 'eval_steps_per_second': 1.976, 'epoch': 0.98}\n",
            " 20% 200/1015 [02:53<06:43,  2.02it/s]\n",
            "100% 100/100 [00:48<00:00,  2.47it/s]\u001b[A\n",
            "                                     \u001b[ASaving model checkpoint to mT5_model/checkpoint-200\n",
            "Configuration saved in mT5_model/checkpoint-200/config.json\n",
            "Configuration saved in mT5_model/checkpoint-200/generation_config.json\n",
            "Model weights saved in mT5_model/checkpoint-200/pytorch_model.bin\n",
            "tokenizer config file saved in mT5_model/checkpoint-200/tokenizer_config.json\n",
            "Special tokens file saved in mT5_model/checkpoint-200/special_tokens_map.json\n",
            "Copy vocab file to mT5_model/checkpoint-200/spiece.model\n",
            "{'loss': 1.5303, 'learning_rate': 2.2610837438423645e-05, 'epoch': 1.23}\n",
            "{'loss': 1.3974, 'learning_rate': 2.1133004926108376e-05, 'epoch': 1.47}\n",
            " 30% 300/1015 [04:01<06:04,  1.96it/s]Saving model checkpoint to mT5_model/checkpoint-300\n",
            "Configuration saved in mT5_model/checkpoint-300/config.json\n",
            "Configuration saved in mT5_model/checkpoint-300/generation_config.json\n",
            "Model weights saved in mT5_model/checkpoint-300/pytorch_model.bin\n",
            "tokenizer config file saved in mT5_model/checkpoint-300/tokenizer_config.json\n",
            "Special tokens file saved in mT5_model/checkpoint-300/special_tokens_map.json\n",
            "Copy vocab file to mT5_model/checkpoint-300/spiece.model\n",
            "{'loss': 1.3647, 'learning_rate': 1.9655172413793102e-05, 'epoch': 1.72}\n",
            "{'loss': 1.2211, 'learning_rate': 1.8177339901477833e-05, 'epoch': 1.97}\n",
            " 39% 400/1015 [05:10<05:14,  1.95it/s]***** Running Evaluation *****\n",
            "  Num examples = 400\n",
            "  Batch size = 4\n",
            "\n",
            "  0% 0/100 [00:00<?, ?it/s]\u001b[A\n",
            "  2% 2/100 [00:00<00:20,  4.78it/s]\u001b[A\n",
            "  3% 3/100 [00:00<00:28,  3.42it/s]\u001b[A\n",
            "  4% 4/100 [00:01<00:32,  3.00it/s]\u001b[A\n",
            "  5% 5/100 [00:01<00:34,  2.77it/s]\u001b[A\n",
            "  6% 6/100 [00:02<00:35,  2.62it/s]\u001b[A\n",
            "  7% 7/100 [00:02<00:36,  2.56it/s]\u001b[A\n",
            "  8% 8/100 [00:02<00:36,  2.52it/s]\u001b[A\n",
            "  9% 9/100 [00:03<00:36,  2.48it/s]\u001b[A\n",
            " 10% 10/100 [00:03<00:36,  2.47it/s]\u001b[A\n",
            " 11% 11/100 [00:04<00:36,  2.46it/s]\u001b[A\n",
            " 12% 12/100 [00:04<00:36,  2.42it/s]\u001b[A\n",
            " 13% 13/100 [00:04<00:35,  2.43it/s]\u001b[A\n",
            " 14% 14/100 [00:05<00:35,  2.44it/s]\u001b[A\n",
            " 15% 15/100 [00:05<00:34,  2.46it/s]\u001b[A\n",
            " 16% 16/100 [00:06<00:34,  2.47it/s]\u001b[A\n",
            " 17% 17/100 [00:06<00:33,  2.46it/s]\u001b[A\n",
            " 18% 18/100 [00:06<00:33,  2.47it/s]\u001b[A\n",
            " 19% 19/100 [00:07<00:32,  2.48it/s]\u001b[A\n",
            " 20% 20/100 [00:07<00:32,  2.47it/s]\u001b[A\n",
            " 21% 21/100 [00:08<00:31,  2.47it/s]\u001b[A\n",
            " 22% 22/100 [00:08<00:31,  2.46it/s]\u001b[A\n",
            " 23% 23/100 [00:09<00:31,  2.46it/s]\u001b[A\n",
            " 24% 24/100 [00:09<00:30,  2.45it/s]\u001b[A\n",
            " 25% 25/100 [00:09<00:30,  2.45it/s]\u001b[A\n",
            " 26% 26/100 [00:10<00:30,  2.44it/s]\u001b[A\n",
            " 27% 27/100 [00:10<00:29,  2.45it/s]\u001b[A\n",
            " 28% 28/100 [00:11<00:29,  2.46it/s]\u001b[A\n",
            " 29% 29/100 [00:11<00:28,  2.45it/s]\u001b[A\n",
            " 30% 30/100 [00:11<00:28,  2.45it/s]\u001b[A\n",
            " 31% 31/100 [00:12<00:28,  2.45it/s]\u001b[A\n",
            " 32% 32/100 [00:12<00:27,  2.45it/s]\u001b[A\n",
            " 33% 33/100 [00:13<00:27,  2.44it/s]\u001b[A\n",
            " 34% 34/100 [00:13<00:26,  2.45it/s]\u001b[A\n",
            " 35% 35/100 [00:13<00:26,  2.45it/s]\u001b[A\n",
            " 36% 36/100 [00:14<00:26,  2.46it/s]\u001b[A\n",
            " 37% 37/100 [00:14<00:25,  2.45it/s]\u001b[A\n",
            " 38% 38/100 [00:15<00:25,  2.45it/s]\u001b[A\n",
            " 39% 39/100 [00:15<00:25,  2.44it/s]\u001b[A\n",
            " 40% 40/100 [00:15<00:24,  2.43it/s]\u001b[A\n",
            " 41% 41/100 [00:16<00:24,  2.43it/s]\u001b[A\n",
            " 42% 42/100 [00:16<00:24,  2.41it/s]\u001b[A\n",
            " 43% 43/100 [00:17<00:23,  2.41it/s]\u001b[A\n",
            " 44% 44/100 [00:17<00:23,  2.39it/s]\u001b[A\n",
            " 45% 45/100 [00:18<00:23,  2.38it/s]\u001b[A\n",
            " 46% 46/100 [00:18<00:22,  2.38it/s]\u001b[A\n",
            " 47% 47/100 [00:18<00:22,  2.39it/s]\u001b[A\n",
            " 48% 48/100 [00:19<00:21,  2.40it/s]\u001b[A\n",
            " 49% 49/100 [00:19<00:21,  2.41it/s]\u001b[A\n",
            " 50% 50/100 [00:20<00:20,  2.43it/s]\u001b[A\n",
            " 51% 51/100 [00:20<00:19,  2.45it/s]\u001b[A\n",
            " 52% 52/100 [00:20<00:19,  2.46it/s]\u001b[A\n",
            " 53% 53/100 [00:21<00:19,  2.45it/s]\u001b[A\n",
            " 54% 54/100 [00:21<00:18,  2.44it/s]\u001b[A\n",
            " 55% 55/100 [00:22<00:18,  2.42it/s]\u001b[A\n",
            " 56% 56/100 [00:22<00:18,  2.43it/s]\u001b[A\n",
            " 57% 57/100 [00:22<00:17,  2.43it/s]\u001b[A\n",
            " 58% 58/100 [00:23<00:17,  2.43it/s]\u001b[A\n",
            " 59% 59/100 [00:23<00:16,  2.43it/s]\u001b[A\n",
            " 60% 60/100 [00:24<00:16,  2.43it/s]\u001b[A\n",
            " 61% 61/100 [00:24<00:15,  2.44it/s]\u001b[A\n",
            " 62% 62/100 [00:25<00:15,  2.42it/s]\u001b[A\n",
            " 63% 63/100 [00:25<00:15,  2.41it/s]\u001b[A\n",
            " 64% 64/100 [00:25<00:14,  2.41it/s]\u001b[A\n",
            " 65% 65/100 [00:26<00:14,  2.43it/s]\u001b[A\n",
            " 66% 66/100 [00:26<00:14,  2.43it/s]\u001b[A\n",
            " 67% 67/100 [00:27<00:13,  2.43it/s]\u001b[A\n",
            " 68% 68/100 [00:27<00:13,  2.41it/s]\u001b[A\n",
            " 69% 69/100 [00:27<00:12,  2.39it/s]\u001b[A\n",
            " 70% 70/100 [00:28<00:12,  2.39it/s]\u001b[A\n",
            " 71% 71/100 [00:28<00:12,  2.39it/s]\u001b[A\n",
            " 72% 72/100 [00:29<00:11,  2.38it/s]\u001b[A\n",
            " 73% 73/100 [00:29<00:11,  2.37it/s]\u001b[A\n",
            " 74% 74/100 [00:30<00:10,  2.38it/s]\u001b[A\n",
            " 75% 75/100 [00:30<00:10,  2.40it/s]\u001b[A\n",
            " 76% 76/100 [00:30<00:09,  2.41it/s]\u001b[A\n",
            " 77% 77/100 [00:31<00:09,  2.42it/s]\u001b[A\n",
            " 78% 78/100 [00:31<00:09,  2.42it/s]\u001b[A\n",
            " 79% 79/100 [00:32<00:08,  2.42it/s]\u001b[A\n",
            " 80% 80/100 [00:32<00:08,  2.43it/s]\u001b[A\n",
            " 81% 81/100 [00:32<00:07,  2.43it/s]\u001b[A\n",
            " 82% 82/100 [00:33<00:07,  2.44it/s]\u001b[A\n",
            " 83% 83/100 [00:33<00:06,  2.43it/s]\u001b[A\n",
            " 84% 84/100 [00:34<00:06,  2.43it/s]\u001b[A\n",
            " 85% 85/100 [00:34<00:06,  2.44it/s]\u001b[A\n",
            " 86% 86/100 [00:34<00:05,  2.45it/s]\u001b[A\n",
            " 87% 87/100 [00:35<00:05,  2.45it/s]\u001b[A\n",
            " 88% 88/100 [00:35<00:04,  2.46it/s]\u001b[A\n",
            " 89% 89/100 [00:36<00:04,  2.46it/s]\u001b[A\n",
            " 90% 90/100 [00:36<00:04,  2.46it/s]\u001b[A\n",
            " 91% 91/100 [00:37<00:03,  2.45it/s]\u001b[A\n",
            " 92% 92/100 [00:37<00:03,  2.46it/s]\u001b[A\n",
            " 93% 93/100 [00:37<00:02,  2.46it/s]\u001b[A\n",
            " 94% 94/100 [00:38<00:02,  2.45it/s]\u001b[A\n",
            " 95% 95/100 [00:38<00:02,  2.45it/s]\u001b[A\n",
            " 96% 96/100 [00:39<00:01,  2.45it/s]\u001b[A\n",
            " 97% 97/100 [00:39<00:01,  2.44it/s]\u001b[A\n",
            " 98% 98/100 [00:39<00:00,  2.44it/s]\u001b[A\n",
            " 99% 99/100 [00:40<00:00,  2.43it/s]\u001b[A\n",
            "                                      \n",
            "\u001b[A{'eval_loss': 0.7824210524559021, 'eval_rouge1': 50.4029, 'eval_rouge2': 45.7095, 'eval_rougeL': 49.95, 'eval_rougeLsum': 49.9266, 'eval_bleu': 19.8858, 'eval_gen_len': 18.725, 'eval_runtime': 49.0885, 'eval_samples_per_second': 8.149, 'eval_steps_per_second': 2.037, 'epoch': 1.97}\n",
            " 39% 400/1015 [05:59<05:14,  1.95it/s]\n",
            "100% 100/100 [00:48<00:00,  2.44it/s]\u001b[A\n",
            "                                     \u001b[ASaving model checkpoint to mT5_model/checkpoint-400\n",
            "Configuration saved in mT5_model/checkpoint-400/config.json\n",
            "Configuration saved in mT5_model/checkpoint-400/generation_config.json\n",
            "Model weights saved in mT5_model/checkpoint-400/pytorch_model.bin\n",
            "tokenizer config file saved in mT5_model/checkpoint-400/tokenizer_config.json\n",
            "Special tokens file saved in mT5_model/checkpoint-400/special_tokens_map.json\n",
            "Copy vocab file to mT5_model/checkpoint-400/spiece.model\n",
            "{'loss': 1.2321, 'learning_rate': 1.6699507389162563e-05, 'epoch': 2.21}\n",
            "{'loss': 1.1999, 'learning_rate': 1.5221674876847293e-05, 'epoch': 2.46}\n",
            " 49% 500/1015 [07:07<04:30,  1.90it/s]Saving model checkpoint to mT5_model/checkpoint-500\n",
            "Configuration saved in mT5_model/checkpoint-500/config.json\n",
            "Configuration saved in mT5_model/checkpoint-500/generation_config.json\n",
            "Model weights saved in mT5_model/checkpoint-500/pytorch_model.bin\n",
            "tokenizer config file saved in mT5_model/checkpoint-500/tokenizer_config.json\n",
            "Special tokens file saved in mT5_model/checkpoint-500/special_tokens_map.json\n",
            "Copy vocab file to mT5_model/checkpoint-500/spiece.model\n",
            "{'loss': 1.1406, 'learning_rate': 1.374384236453202e-05, 'epoch': 2.7}\n",
            "{'loss': 1.1057, 'learning_rate': 1.2266009852216749e-05, 'epoch': 2.95}\n",
            " 59% 600/1015 [08:16<03:26,  2.01it/s]***** Running Evaluation *****\n",
            "  Num examples = 400\n",
            "  Batch size = 4\n",
            "\n",
            "  0% 0/100 [00:00<?, ?it/s]\u001b[A\n",
            "  2% 2/100 [00:00<00:19,  4.96it/s]\u001b[A\n",
            "  3% 3/100 [00:00<00:27,  3.50it/s]\u001b[A\n",
            "  4% 4/100 [00:01<00:31,  3.02it/s]\u001b[A\n",
            "  5% 5/100 [00:01<00:34,  2.77it/s]\u001b[A\n",
            "  6% 6/100 [00:02<00:35,  2.64it/s]\u001b[A\n",
            "  7% 7/100 [00:02<00:36,  2.58it/s]\u001b[A\n",
            "  8% 8/100 [00:02<00:36,  2.53it/s]\u001b[A\n",
            "  9% 9/100 [00:03<00:36,  2.50it/s]\u001b[A\n",
            " 10% 10/100 [00:03<00:36,  2.49it/s]\u001b[A\n",
            " 11% 11/100 [00:04<00:35,  2.49it/s]\u001b[A\n",
            " 12% 12/100 [00:04<00:35,  2.46it/s]\u001b[A\n",
            " 13% 13/100 [00:04<00:35,  2.44it/s]\u001b[A\n",
            " 14% 14/100 [00:05<00:35,  2.44it/s]\u001b[A\n",
            " 15% 15/100 [00:05<00:34,  2.43it/s]\u001b[A\n",
            " 16% 16/100 [00:06<00:34,  2.44it/s]\u001b[A\n",
            " 17% 17/100 [00:06<00:34,  2.43it/s]\u001b[A\n",
            " 18% 18/100 [00:06<00:33,  2.43it/s]\u001b[A\n",
            " 19% 19/100 [00:07<00:33,  2.42it/s]\u001b[A\n",
            " 20% 20/100 [00:07<00:33,  2.42it/s]\u001b[A\n",
            " 21% 21/100 [00:08<00:32,  2.44it/s]\u001b[A\n",
            " 22% 22/100 [00:08<00:32,  2.43it/s]\u001b[A\n",
            " 23% 23/100 [00:09<00:31,  2.43it/s]\u001b[A\n",
            " 24% 24/100 [00:09<00:31,  2.43it/s]\u001b[A\n",
            " 25% 25/100 [00:09<00:30,  2.42it/s]\u001b[A\n",
            " 26% 26/100 [00:10<00:30,  2.42it/s]\u001b[A\n",
            " 27% 27/100 [00:10<00:30,  2.41it/s]\u001b[A\n",
            " 28% 28/100 [00:11<00:30,  2.40it/s]\u001b[A\n",
            " 29% 29/100 [00:11<00:29,  2.38it/s]\u001b[A\n",
            " 30% 30/100 [00:11<00:29,  2.39it/s]\u001b[A\n",
            " 31% 31/100 [00:12<00:28,  2.39it/s]\u001b[A\n",
            " 32% 32/100 [00:12<00:28,  2.40it/s]\u001b[A\n",
            " 33% 33/100 [00:13<00:27,  2.43it/s]\u001b[A\n",
            " 34% 34/100 [00:13<00:26,  2.45it/s]\u001b[A\n",
            " 35% 35/100 [00:14<00:26,  2.45it/s]\u001b[A\n",
            " 36% 36/100 [00:14<00:26,  2.45it/s]\u001b[A\n",
            " 37% 37/100 [00:14<00:25,  2.44it/s]\u001b[A\n",
            " 38% 38/100 [00:15<00:25,  2.44it/s]\u001b[A\n",
            " 39% 39/100 [00:15<00:25,  2.44it/s]\u001b[A\n",
            " 40% 40/100 [00:16<00:24,  2.44it/s]\u001b[A\n",
            " 41% 41/100 [00:16<00:24,  2.44it/s]\u001b[A\n",
            " 42% 42/100 [00:16<00:23,  2.44it/s]\u001b[A\n",
            " 43% 43/100 [00:17<00:23,  2.44it/s]\u001b[A\n",
            " 44% 44/100 [00:17<00:23,  2.43it/s]\u001b[A\n",
            " 45% 45/100 [00:18<00:22,  2.43it/s]\u001b[A\n",
            " 46% 46/100 [00:18<00:22,  2.43it/s]\u001b[A\n",
            " 47% 47/100 [00:18<00:21,  2.44it/s]\u001b[A\n",
            " 48% 48/100 [00:19<00:21,  2.45it/s]\u001b[A\n",
            " 49% 49/100 [00:19<00:20,  2.44it/s]\u001b[A\n",
            " 50% 50/100 [00:20<00:20,  2.45it/s]\u001b[A\n",
            " 51% 51/100 [00:20<00:19,  2.46it/s]\u001b[A\n",
            " 52% 52/100 [00:20<00:19,  2.46it/s]\u001b[A\n",
            " 53% 53/100 [00:21<00:19,  2.46it/s]\u001b[A\n",
            " 54% 54/100 [00:21<00:18,  2.45it/s]\u001b[A\n",
            " 55% 55/100 [00:22<00:18,  2.45it/s]\u001b[A\n",
            " 56% 56/100 [00:22<00:17,  2.45it/s]\u001b[A\n",
            " 57% 57/100 [00:22<00:17,  2.45it/s]\u001b[A\n",
            " 58% 58/100 [00:23<00:17,  2.42it/s]\u001b[A\n",
            " 59% 59/100 [00:23<00:16,  2.42it/s]\u001b[A\n",
            " 60% 60/100 [00:24<00:16,  2.42it/s]\u001b[A\n",
            " 61% 61/100 [00:24<00:16,  2.43it/s]\u001b[A\n",
            " 62% 62/100 [00:25<00:15,  2.44it/s]\u001b[A\n",
            " 63% 63/100 [00:25<00:15,  2.44it/s]\u001b[A\n",
            " 64% 64/100 [00:25<00:14,  2.45it/s]\u001b[A\n",
            " 65% 65/100 [00:26<00:14,  2.45it/s]\u001b[A\n",
            " 66% 66/100 [00:26<00:13,  2.45it/s]\u001b[A\n",
            " 67% 67/100 [00:27<00:13,  2.45it/s]\u001b[A\n",
            " 68% 68/100 [00:27<00:13,  2.42it/s]\u001b[A\n",
            " 69% 69/100 [00:27<00:12,  2.42it/s]\u001b[A\n",
            " 70% 70/100 [00:28<00:12,  2.45it/s]\u001b[A\n",
            " 71% 71/100 [00:28<00:11,  2.46it/s]\u001b[A\n",
            " 72% 72/100 [00:29<00:11,  2.46it/s]\u001b[A\n",
            " 73% 73/100 [00:29<00:10,  2.47it/s]\u001b[A\n",
            " 74% 74/100 [00:29<00:10,  2.46it/s]\u001b[A\n",
            " 75% 75/100 [00:30<00:10,  2.44it/s]\u001b[A\n",
            " 76% 76/100 [00:30<00:09,  2.45it/s]\u001b[A\n",
            " 77% 77/100 [00:31<00:09,  2.45it/s]\u001b[A\n",
            " 78% 78/100 [00:31<00:09,  2.44it/s]\u001b[A\n",
            " 79% 79/100 [00:32<00:08,  2.44it/s]\u001b[A\n",
            " 80% 80/100 [00:32<00:08,  2.45it/s]\u001b[A\n",
            " 81% 81/100 [00:32<00:07,  2.45it/s]\u001b[A\n",
            " 82% 82/100 [00:33<00:07,  2.45it/s]\u001b[A\n",
            " 83% 83/100 [00:33<00:06,  2.43it/s]\u001b[A\n",
            " 84% 84/100 [00:34<00:06,  2.44it/s]\u001b[A\n",
            " 85% 85/100 [00:34<00:06,  2.44it/s]\u001b[A\n",
            " 86% 86/100 [00:34<00:05,  2.45it/s]\u001b[A\n",
            " 87% 87/100 [00:35<00:05,  2.46it/s]\u001b[A\n",
            " 88% 88/100 [00:35<00:04,  2.46it/s]\u001b[A\n",
            " 89% 89/100 [00:36<00:04,  2.47it/s]\u001b[A\n",
            " 90% 90/100 [00:36<00:04,  2.46it/s]\u001b[A\n",
            " 91% 91/100 [00:36<00:03,  2.46it/s]\u001b[A\n",
            " 92% 92/100 [00:37<00:03,  2.46it/s]\u001b[A\n",
            " 93% 93/100 [00:37<00:02,  2.46it/s]\u001b[A\n",
            " 94% 94/100 [00:38<00:02,  2.45it/s]\u001b[A\n",
            " 95% 95/100 [00:38<00:02,  2.45it/s]\u001b[A\n",
            " 96% 96/100 [00:38<00:01,  2.46it/s]\u001b[A\n",
            " 97% 97/100 [00:39<00:01,  2.46it/s]\u001b[A\n",
            " 98% 98/100 [00:39<00:00,  2.44it/s]\u001b[A\n",
            " 99% 99/100 [00:40<00:00,  2.45it/s]\u001b[A\n",
            "                                      \n",
            "\u001b[A{'eval_loss': 0.718906044960022, 'eval_rouge1': 54.8619, 'eval_rouge2': 48.7442, 'eval_rougeL': 53.2632, 'eval_rougeLsum': 53.4311, 'eval_bleu': 15.5354, 'eval_gen_len': 18.65, 'eval_runtime': 48.668, 'eval_samples_per_second': 8.219, 'eval_steps_per_second': 2.055, 'epoch': 2.95}\n",
            " 59% 600/1015 [09:05<03:26,  2.01it/s]\n",
            "100% 100/100 [00:48<00:00,  2.47it/s]\u001b[A\n",
            "                                     \u001b[ASaving model checkpoint to mT5_model/checkpoint-600\n",
            "Configuration saved in mT5_model/checkpoint-600/config.json\n",
            "Configuration saved in mT5_model/checkpoint-600/generation_config.json\n",
            "Model weights saved in mT5_model/checkpoint-600/pytorch_model.bin\n",
            "tokenizer config file saved in mT5_model/checkpoint-600/tokenizer_config.json\n",
            "Special tokens file saved in mT5_model/checkpoint-600/special_tokens_map.json\n",
            "Copy vocab file to mT5_model/checkpoint-600/spiece.model\n",
            "{'loss': 1.0144, 'learning_rate': 1.0788177339901479e-05, 'epoch': 3.19}\n",
            "{'loss': 1.0972, 'learning_rate': 9.310344827586207e-06, 'epoch': 3.44}\n",
            " 69% 700/1015 [10:13<02:43,  1.93it/s]Saving model checkpoint to mT5_model/checkpoint-700\n",
            "Configuration saved in mT5_model/checkpoint-700/config.json\n",
            "Configuration saved in mT5_model/checkpoint-700/generation_config.json\n",
            "Model weights saved in mT5_model/checkpoint-700/pytorch_model.bin\n",
            "tokenizer config file saved in mT5_model/checkpoint-700/tokenizer_config.json\n",
            "Special tokens file saved in mT5_model/checkpoint-700/special_tokens_map.json\n",
            "Copy vocab file to mT5_model/checkpoint-700/spiece.model\n",
            "{'loss': 1.1087, 'learning_rate': 7.832512315270936e-06, 'epoch': 3.69}\n",
            "{'loss': 1.0791, 'learning_rate': 6.354679802955665e-06, 'epoch': 3.93}\n",
            " 79% 800/1015 [11:21<01:47,  1.99it/s]***** Running Evaluation *****\n",
            "  Num examples = 400\n",
            "  Batch size = 4\n",
            "\n",
            "  0% 0/100 [00:00<?, ?it/s]\u001b[A\n",
            "  2% 2/100 [00:00<00:20,  4.79it/s]\u001b[A\n",
            "  3% 3/100 [00:00<00:28,  3.45it/s]\u001b[A\n",
            "  4% 4/100 [00:01<00:32,  3.00it/s]\u001b[A\n",
            "  5% 5/100 [00:01<00:34,  2.78it/s]\u001b[A\n",
            "  6% 6/100 [00:02<00:35,  2.65it/s]\u001b[A\n",
            "  7% 7/100 [00:02<00:36,  2.58it/s]\u001b[A\n",
            "  8% 8/100 [00:02<00:36,  2.54it/s]\u001b[A\n",
            "  9% 9/100 [00:03<00:36,  2.51it/s]\u001b[A\n",
            " 10% 10/100 [00:03<00:36,  2.49it/s]\u001b[A\n",
            " 11% 11/100 [00:04<00:35,  2.48it/s]\u001b[A\n",
            " 12% 12/100 [00:04<00:35,  2.45it/s]\u001b[A\n",
            " 13% 13/100 [00:04<00:35,  2.43it/s]\u001b[A\n",
            " 14% 14/100 [00:05<00:35,  2.41it/s]\u001b[A\n",
            " 15% 15/100 [00:05<00:35,  2.42it/s]\u001b[A\n",
            " 16% 16/100 [00:06<00:34,  2.41it/s]\u001b[A\n",
            " 17% 17/100 [00:06<00:34,  2.40it/s]\u001b[A\n",
            " 18% 18/100 [00:07<00:34,  2.40it/s]\u001b[A\n",
            " 19% 19/100 [00:07<00:33,  2.41it/s]\u001b[A\n",
            " 20% 20/100 [00:07<00:33,  2.42it/s]\u001b[A\n",
            " 21% 21/100 [00:08<00:32,  2.44it/s]\u001b[A\n",
            " 22% 22/100 [00:08<00:31,  2.45it/s]\u001b[A\n",
            " 23% 23/100 [00:09<00:31,  2.46it/s]\u001b[A\n",
            " 24% 24/100 [00:09<00:30,  2.46it/s]\u001b[A\n",
            " 25% 25/100 [00:09<00:30,  2.46it/s]\u001b[A\n",
            " 26% 26/100 [00:10<00:30,  2.46it/s]\u001b[A\n",
            " 27% 27/100 [00:10<00:29,  2.46it/s]\u001b[A\n",
            " 28% 28/100 [00:11<00:29,  2.45it/s]\u001b[A\n",
            " 29% 29/100 [00:11<00:29,  2.44it/s]\u001b[A\n",
            " 30% 30/100 [00:11<00:28,  2.45it/s]\u001b[A\n",
            " 31% 31/100 [00:12<00:28,  2.45it/s]\u001b[A\n",
            " 32% 32/100 [00:12<00:27,  2.45it/s]\u001b[A\n",
            " 33% 33/100 [00:13<00:27,  2.45it/s]\u001b[A\n",
            " 34% 34/100 [00:13<00:26,  2.46it/s]\u001b[A\n",
            " 35% 35/100 [00:13<00:26,  2.46it/s]\u001b[A\n",
            " 36% 36/100 [00:14<00:26,  2.45it/s]\u001b[A\n",
            " 37% 37/100 [00:14<00:25,  2.46it/s]\u001b[A\n",
            " 38% 38/100 [00:15<00:25,  2.46it/s]\u001b[A\n",
            " 39% 39/100 [00:15<00:24,  2.44it/s]\u001b[A\n",
            " 40% 40/100 [00:15<00:24,  2.44it/s]\u001b[A\n",
            " 41% 41/100 [00:16<00:24,  2.44it/s]\u001b[A\n",
            " 42% 42/100 [00:16<00:23,  2.43it/s]\u001b[A\n",
            " 43% 43/100 [00:17<00:23,  2.42it/s]\u001b[A\n",
            " 44% 44/100 [00:17<00:23,  2.42it/s]\u001b[A\n",
            " 45% 45/100 [00:18<00:22,  2.41it/s]\u001b[A\n",
            " 46% 46/100 [00:18<00:22,  2.40it/s]\u001b[A\n",
            " 47% 47/100 [00:18<00:22,  2.41it/s]\u001b[A\n",
            " 48% 48/100 [00:19<00:21,  2.41it/s]\u001b[A\n",
            " 49% 49/100 [00:19<00:21,  2.40it/s]\u001b[A\n",
            " 50% 50/100 [00:20<00:21,  2.37it/s]\u001b[A\n",
            " 51% 51/100 [00:20<00:20,  2.39it/s]\u001b[A\n",
            " 52% 52/100 [00:20<00:19,  2.41it/s]\u001b[A\n",
            " 53% 53/100 [00:21<00:19,  2.42it/s]\u001b[A\n",
            " 54% 54/100 [00:21<00:18,  2.43it/s]\u001b[A\n",
            " 55% 55/100 [00:22<00:18,  2.44it/s]\u001b[A\n",
            " 56% 56/100 [00:22<00:18,  2.44it/s]\u001b[A\n",
            " 57% 57/100 [00:23<00:17,  2.45it/s]\u001b[A\n",
            " 58% 58/100 [00:23<00:17,  2.45it/s]\u001b[A\n",
            " 59% 59/100 [00:23<00:16,  2.45it/s]\u001b[A\n",
            " 60% 60/100 [00:24<00:16,  2.46it/s]\u001b[A\n",
            " 61% 61/100 [00:24<00:15,  2.45it/s]\u001b[A\n",
            " 62% 62/100 [00:25<00:15,  2.46it/s]\u001b[A\n",
            " 63% 63/100 [00:25<00:15,  2.46it/s]\u001b[A\n",
            " 64% 64/100 [00:25<00:14,  2.46it/s]\u001b[A\n",
            " 65% 65/100 [00:26<00:14,  2.46it/s]\u001b[A\n",
            " 66% 66/100 [00:26<00:13,  2.46it/s]\u001b[A\n",
            " 67% 67/100 [00:27<00:13,  2.46it/s]\u001b[A\n",
            " 68% 68/100 [00:27<00:13,  2.43it/s]\u001b[A\n",
            " 69% 69/100 [00:27<00:12,  2.43it/s]\u001b[A\n",
            " 70% 70/100 [00:28<00:12,  2.44it/s]\u001b[A\n",
            " 71% 71/100 [00:28<00:11,  2.45it/s]\u001b[A\n",
            " 72% 72/100 [00:29<00:11,  2.45it/s]\u001b[A\n",
            " 73% 73/100 [00:29<00:11,  2.45it/s]\u001b[A\n",
            " 74% 74/100 [00:29<00:10,  2.45it/s]\u001b[A\n",
            " 75% 75/100 [00:30<00:10,  2.42it/s]\u001b[A\n",
            " 76% 76/100 [00:30<00:09,  2.43it/s]\u001b[A\n",
            " 77% 77/100 [00:31<00:09,  2.43it/s]\u001b[A\n",
            " 78% 78/100 [00:31<00:09,  2.44it/s]\u001b[A\n",
            " 79% 79/100 [00:32<00:08,  2.43it/s]\u001b[A\n",
            " 80% 80/100 [00:32<00:08,  2.43it/s]\u001b[A\n",
            " 81% 81/100 [00:32<00:07,  2.42it/s]\u001b[A\n",
            " 82% 82/100 [00:33<00:07,  2.42it/s]\u001b[A\n",
            " 83% 83/100 [00:33<00:07,  2.42it/s]\u001b[A\n",
            " 84% 84/100 [00:34<00:06,  2.42it/s]\u001b[A\n",
            " 85% 85/100 [00:34<00:06,  2.44it/s]\u001b[A\n",
            " 86% 86/100 [00:34<00:05,  2.44it/s]\u001b[A\n",
            " 87% 87/100 [00:35<00:05,  2.45it/s]\u001b[A\n",
            " 88% 88/100 [00:35<00:04,  2.47it/s]\u001b[A\n",
            " 89% 89/100 [00:36<00:04,  2.48it/s]\u001b[A\n",
            " 90% 90/100 [00:36<00:04,  2.47it/s]\u001b[A\n",
            " 91% 91/100 [00:36<00:03,  2.46it/s]\u001b[A\n",
            " 92% 92/100 [00:37<00:03,  2.47it/s]\u001b[A\n",
            " 93% 93/100 [00:37<00:02,  2.46it/s]\u001b[A\n",
            " 94% 94/100 [00:38<00:02,  2.46it/s]\u001b[A\n",
            " 95% 95/100 [00:38<00:02,  2.46it/s]\u001b[A\n",
            " 96% 96/100 [00:38<00:01,  2.45it/s]\u001b[A\n",
            " 97% 97/100 [00:39<00:01,  2.44it/s]\u001b[A\n",
            " 98% 98/100 [00:39<00:00,  2.44it/s]\u001b[A\n",
            " 99% 99/100 [00:40<00:00,  2.45it/s]\u001b[A\n",
            "                                      \n",
            "\u001b[A{'eval_loss': 0.6868060827255249, 'eval_rouge1': 55.4021, 'eval_rouge2': 49.307, 'eval_rougeL': 53.7391, 'eval_rougeLsum': 53.8756, 'eval_bleu': 16.1073, 'eval_gen_len': 18.7075, 'eval_runtime': 48.7507, 'eval_samples_per_second': 8.205, 'eval_steps_per_second': 2.051, 'epoch': 3.93}\n",
            " 79% 800/1015 [12:10<01:47,  1.99it/s]\n",
            "100% 100/100 [00:48<00:00,  2.44it/s]\u001b[A\n",
            "                                     \u001b[ASaving model checkpoint to mT5_model/checkpoint-800\n",
            "Configuration saved in mT5_model/checkpoint-800/config.json\n",
            "Configuration saved in mT5_model/checkpoint-800/generation_config.json\n",
            "Model weights saved in mT5_model/checkpoint-800/pytorch_model.bin\n",
            "tokenizer config file saved in mT5_model/checkpoint-800/tokenizer_config.json\n",
            "Special tokens file saved in mT5_model/checkpoint-800/special_tokens_map.json\n",
            "Copy vocab file to mT5_model/checkpoint-800/spiece.model\n",
            "{'loss': 1.0911, 'learning_rate': 4.876847290640394e-06, 'epoch': 4.18}\n",
            "{'loss': 1.1018, 'learning_rate': 3.3990147783251234e-06, 'epoch': 4.42}\n",
            " 89% 900/1015 [13:19<00:56,  2.03it/s]Saving model checkpoint to mT5_model/checkpoint-900\n",
            "Configuration saved in mT5_model/checkpoint-900/config.json\n",
            "Configuration saved in mT5_model/checkpoint-900/generation_config.json\n",
            "Model weights saved in mT5_model/checkpoint-900/pytorch_model.bin\n",
            "tokenizer config file saved in mT5_model/checkpoint-900/tokenizer_config.json\n",
            "Special tokens file saved in mT5_model/checkpoint-900/special_tokens_map.json\n",
            "Copy vocab file to mT5_model/checkpoint-900/spiece.model\n",
            "{'loss': 0.9724, 'learning_rate': 1.9211822660098524e-06, 'epoch': 4.67}\n",
            "{'loss': 1.0806, 'learning_rate': 4.4334975369458127e-07, 'epoch': 4.91}\n",
            " 99% 1000/1015 [14:27<00:07,  1.97it/s]***** Running Evaluation *****\n",
            "  Num examples = 400\n",
            "  Batch size = 4\n",
            "\n",
            "  0% 0/100 [00:00<?, ?it/s]\u001b[A\n",
            "  2% 2/100 [00:00<00:20,  4.85it/s]\u001b[A\n",
            "  3% 3/100 [00:00<00:28,  3.43it/s]\u001b[A\n",
            "  4% 4/100 [00:01<00:32,  2.96it/s]\u001b[A\n",
            "  5% 5/100 [00:01<00:34,  2.75it/s]\u001b[A\n",
            "  6% 6/100 [00:02<00:36,  2.61it/s]\u001b[A\n",
            "  7% 7/100 [00:02<00:36,  2.56it/s]\u001b[A\n",
            "  8% 8/100 [00:02<00:36,  2.52it/s]\u001b[A\n",
            "  9% 9/100 [00:03<00:36,  2.50it/s]\u001b[A\n",
            " 10% 10/100 [00:03<00:36,  2.49it/s]\u001b[A\n",
            " 11% 11/100 [00:04<00:35,  2.48it/s]\u001b[A\n",
            " 12% 12/100 [00:04<00:35,  2.46it/s]\u001b[A\n",
            " 13% 13/100 [00:04<00:35,  2.45it/s]\u001b[A\n",
            " 14% 14/100 [00:05<00:34,  2.46it/s]\u001b[A\n",
            " 15% 15/100 [00:05<00:34,  2.47it/s]\u001b[A\n",
            " 16% 16/100 [00:06<00:34,  2.46it/s]\u001b[A\n",
            " 17% 17/100 [00:06<00:33,  2.45it/s]\u001b[A\n",
            " 18% 18/100 [00:06<00:33,  2.43it/s]\u001b[A\n",
            " 19% 19/100 [00:07<00:33,  2.43it/s]\u001b[A\n",
            " 20% 20/100 [00:07<00:32,  2.45it/s]\u001b[A\n",
            " 21% 21/100 [00:08<00:32,  2.46it/s]\u001b[A\n",
            " 22% 22/100 [00:08<00:31,  2.46it/s]\u001b[A\n",
            " 23% 23/100 [00:09<00:31,  2.46it/s]\u001b[A\n",
            " 24% 24/100 [00:09<00:30,  2.47it/s]\u001b[A\n",
            " 25% 25/100 [00:09<00:30,  2.47it/s]\u001b[A\n",
            " 26% 26/100 [00:10<00:30,  2.46it/s]\u001b[A\n",
            " 27% 27/100 [00:10<00:29,  2.46it/s]\u001b[A\n",
            " 28% 28/100 [00:11<00:29,  2.45it/s]\u001b[A\n",
            " 29% 29/100 [00:11<00:29,  2.44it/s]\u001b[A\n",
            " 30% 30/100 [00:11<00:28,  2.44it/s]\u001b[A\n",
            " 31% 31/100 [00:12<00:28,  2.45it/s]\u001b[A\n",
            " 32% 32/100 [00:12<00:27,  2.44it/s]\u001b[A\n",
            " 33% 33/100 [00:13<00:27,  2.43it/s]\u001b[A\n",
            " 34% 34/100 [00:13<00:27,  2.44it/s]\u001b[A\n",
            " 35% 35/100 [00:13<00:26,  2.43it/s]\u001b[A\n",
            " 36% 36/100 [00:14<00:26,  2.43it/s]\u001b[A\n",
            " 37% 37/100 [00:14<00:25,  2.43it/s]\u001b[A\n",
            " 38% 38/100 [00:15<00:25,  2.43it/s]\u001b[A\n",
            " 39% 39/100 [00:15<00:25,  2.42it/s]\u001b[A\n",
            " 40% 40/100 [00:15<00:24,  2.43it/s]\u001b[A\n",
            " 41% 41/100 [00:16<00:24,  2.44it/s]\u001b[A\n",
            " 42% 42/100 [00:16<00:23,  2.46it/s]\u001b[A\n",
            " 43% 43/100 [00:17<00:23,  2.46it/s]\u001b[A\n",
            " 44% 44/100 [00:17<00:22,  2.46it/s]\u001b[A\n",
            " 45% 45/100 [00:18<00:22,  2.43it/s]\u001b[A\n",
            " 46% 46/100 [00:18<00:22,  2.44it/s]\u001b[A\n",
            " 47% 47/100 [00:18<00:21,  2.44it/s]\u001b[A\n",
            " 48% 48/100 [00:19<00:21,  2.44it/s]\u001b[A\n",
            " 49% 49/100 [00:19<00:20,  2.45it/s]\u001b[A\n",
            " 50% 50/100 [00:20<00:20,  2.45it/s]\u001b[A\n",
            " 51% 51/100 [00:20<00:19,  2.45it/s]\u001b[A\n",
            " 52% 52/100 [00:20<00:19,  2.46it/s]\u001b[A\n",
            " 53% 53/100 [00:21<00:19,  2.46it/s]\u001b[A\n",
            " 54% 54/100 [00:21<00:18,  2.45it/s]\u001b[A\n",
            " 55% 55/100 [00:22<00:18,  2.45it/s]\u001b[A\n",
            " 56% 56/100 [00:22<00:17,  2.45it/s]\u001b[A\n",
            " 57% 57/100 [00:22<00:17,  2.45it/s]\u001b[A\n",
            " 58% 58/100 [00:23<00:17,  2.45it/s]\u001b[A\n",
            " 59% 59/100 [00:23<00:16,  2.45it/s]\u001b[A\n",
            " 60% 60/100 [00:24<00:16,  2.45it/s]\u001b[A\n",
            " 61% 61/100 [00:24<00:15,  2.46it/s]\u001b[A\n",
            " 62% 62/100 [00:24<00:15,  2.45it/s]\u001b[A\n",
            " 63% 63/100 [00:25<00:15,  2.45it/s]\u001b[A\n",
            " 64% 64/100 [00:25<00:14,  2.46it/s]\u001b[A\n",
            " 65% 65/100 [00:26<00:14,  2.44it/s]\u001b[A\n",
            " 66% 66/100 [00:26<00:13,  2.44it/s]\u001b[A\n",
            " 67% 67/100 [00:27<00:13,  2.44it/s]\u001b[A\n",
            " 68% 68/100 [00:27<00:13,  2.42it/s]\u001b[A\n",
            " 69% 69/100 [00:27<00:12,  2.42it/s]\u001b[A\n",
            " 70% 70/100 [00:28<00:12,  2.43it/s]\u001b[A\n",
            " 71% 71/100 [00:28<00:11,  2.44it/s]\u001b[A\n",
            " 72% 72/100 [00:29<00:11,  2.44it/s]\u001b[A\n",
            " 73% 73/100 [00:29<00:11,  2.44it/s]\u001b[A\n",
            " 74% 74/100 [00:29<00:10,  2.43it/s]\u001b[A\n",
            " 75% 75/100 [00:30<00:10,  2.44it/s]\u001b[A\n",
            " 76% 76/100 [00:30<00:09,  2.44it/s]\u001b[A\n",
            " 77% 77/100 [00:31<00:09,  2.44it/s]\u001b[A\n",
            " 78% 78/100 [00:31<00:09,  2.43it/s]\u001b[A\n",
            " 79% 79/100 [00:31<00:08,  2.43it/s]\u001b[A\n",
            " 80% 80/100 [00:32<00:08,  2.46it/s]\u001b[A\n",
            " 81% 81/100 [00:32<00:07,  2.46it/s]\u001b[A\n",
            " 82% 82/100 [00:33<00:07,  2.46it/s]\u001b[A\n",
            " 83% 83/100 [00:33<00:06,  2.45it/s]\u001b[A\n",
            " 84% 84/100 [00:33<00:06,  2.44it/s]\u001b[A\n",
            " 85% 85/100 [00:34<00:06,  2.46it/s]\u001b[A\n",
            " 86% 86/100 [00:34<00:05,  2.46it/s]\u001b[A\n",
            " 87% 87/100 [00:35<00:05,  2.46it/s]\u001b[A\n",
            " 88% 88/100 [00:35<00:04,  2.46it/s]\u001b[A\n",
            " 89% 89/100 [00:36<00:04,  2.45it/s]\u001b[A\n",
            " 90% 90/100 [00:36<00:04,  2.46it/s]\u001b[A\n",
            " 91% 91/100 [00:36<00:03,  2.45it/s]\u001b[A\n",
            " 92% 92/100 [00:37<00:03,  2.45it/s]\u001b[A\n",
            " 93% 93/100 [00:37<00:02,  2.46it/s]\u001b[A\n",
            " 94% 94/100 [00:38<00:02,  2.46it/s]\u001b[A\n",
            " 95% 95/100 [00:38<00:02,  2.45it/s]\u001b[A\n",
            " 96% 96/100 [00:38<00:01,  2.46it/s]\u001b[A\n",
            " 97% 97/100 [00:39<00:01,  2.47it/s]\u001b[A\n",
            " 98% 98/100 [00:39<00:00,  2.47it/s]\u001b[A\n",
            " 99% 99/100 [00:40<00:00,  2.48it/s]\u001b[A\n",
            "                                       \n",
            "\u001b[A{'eval_loss': 0.6802536249160767, 'eval_rouge1': 55.3329, 'eval_rouge2': 49.4433, 'eval_rougeL': 53.8402, 'eval_rougeLsum': 53.9912, 'eval_bleu': 16.196, 'eval_gen_len': 18.7225, 'eval_runtime': 48.622, 'eval_samples_per_second': 8.227, 'eval_steps_per_second': 2.057, 'epoch': 4.91}\n",
            " 99% 1000/1015 [15:15<00:07,  1.97it/s]\n",
            "100% 100/100 [00:48<00:00,  2.49it/s]\u001b[A\n",
            "                                     \u001b[ASaving model checkpoint to mT5_model/checkpoint-1000\n",
            "Configuration saved in mT5_model/checkpoint-1000/config.json\n",
            "Configuration saved in mT5_model/checkpoint-1000/generation_config.json\n",
            "Model weights saved in mT5_model/checkpoint-1000/pytorch_model.bin\n",
            "tokenizer config file saved in mT5_model/checkpoint-1000/tokenizer_config.json\n",
            "Special tokens file saved in mT5_model/checkpoint-1000/special_tokens_map.json\n",
            "Copy vocab file to mT5_model/checkpoint-1000/spiece.model\n",
            "100% 1015/1015 [15:40<00:00,  1.54it/s]\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "{'train_runtime': 952.4858, 'train_samples_per_second': 17.082, 'train_steps_per_second': 1.066, 'train_loss': 2.307605571464952, 'epoch': 4.99}\n",
            "100% 1015/1015 [15:40<00:00,  1.08it/s]\n",
            "Saving model checkpoint to mT5_model/\n",
            "Configuration saved in mT5_model/config.json\n",
            "Configuration saved in mT5_model/generation_config.json\n",
            "Model weights saved in mT5_model/pytorch_model.bin\n",
            "tokenizer config file saved in mT5_model/tokenizer_config.json\n",
            "Special tokens file saved in mT5_model/special_tokens_map.json\n",
            "Copy vocab file to mT5_model/spiece.model\n",
            "***** train metrics *****\n",
            "  epoch                    =       4.99\n",
            "  train_loss               =     2.3076\n",
            "  train_runtime            = 0:15:52.48\n",
            "  train_samples            =       3254\n",
            "  train_samples_per_second =     17.082\n",
            "  train_steps_per_second   =      1.066\n",
            "05/07/2023 01:44:19 - INFO - __main__ -   *** Evaluate ***\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 400\n",
            "  Batch size = 4\n",
            "100% 100/100 [02:06<00:00,  1.53s/it]Traceback (most recent call last):\n",
            "  File \"/content/iterater/code/IteraTeR_ACL2022/model/generation/./transformers/examples/pytorch/summarization/run_summarization.py\", line 633, in <module>\n",
            "    main()\n",
            "  File \"/content/iterater/code/IteraTeR_ACL2022/model/generation/./transformers/examples/pytorch/summarization/run_summarization.py\", line 575, in main\n",
            "    metrics = trainer.evaluate(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/transformers/trainer_seq2seq.py\", line 159, in evaluate\n",
            "    return super().evaluate(eval_dataset, ignore_keys=ignore_keys, metric_key_prefix=metric_key_prefix)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\", line 2993, in evaluate\n",
            "    output = eval_loop(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\", line 3281, in evaluation_loop\n",
            "    metrics = self.compute_metrics(EvalPrediction(predictions=all_preds, label_ids=all_labels))\n",
            "  File \"/content/iterater/code/IteraTeR_ACL2022/model/generation/./transformers/examples/pytorch/summarization/run_summarization.py\", line 510, in compute_metrics\n",
            "    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py\", line 3446, in batch_decode\n",
            "    return [\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py\", line 3447, in <listcomp>\n",
            "    self.decode(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py\", line 3486, in decode\n",
            "    return self._decode(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_fast.py\", line 549, in _decode\n",
            "    text = self._tokenizer.decode(token_ids, skip_special_tokens=skip_special_tokens)\n",
            "OverflowError: out of range integral type conversion attempted\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/iterater/code/IteraTeR_ACL2022/model/generation/./transformers/examples/pytorch/summarization/run_summarization.py\", line 633, in <module>\n",
            "    main()\n",
            "  File \"/content/iterater/code/IteraTeR_ACL2022/model/generation/./transformers/examples/pytorch/summarization/run_summarization.py\", line 575, in main\n",
            "    metrics = trainer.evaluate(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/transformers/trainer_seq2seq.py\", line 159, in evaluate\n",
            "    return super().evaluate(eval_dataset, ignore_keys=ignore_keys, metric_key_prefix=metric_key_prefix)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\", line 2993, in evaluate\n",
            "    output = eval_loop(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\", line 3281, in evaluation_loop\n",
            "    metrics = self.compute_metrics(EvalPrediction(predictions=all_preds, label_ids=all_labels))\n",
            "  File \"/content/iterater/code/IteraTeR_ACL2022/model/generation/./transformers/examples/pytorch/summarization/run_summarization.py\", line 510, in compute_metrics\n",
            "    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py\", line 3446, in batch_decode\n",
            "    return [\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py\", line 3447, in <listcomp>\n",
            "    self.decode(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py\", line 3486, in decode\n",
            "    return self._decode(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_fast.py\", line 549, in _decode\n",
            "    text = self._tokenizer.decode(token_ids, skip_special_tokens=skip_special_tokens)\n",
            "OverflowError: out of range integral type conversion attempted\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[31m(failed 1).\u001b[0m Press Control-C to abort syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                      eval/bleu ▂█▁▂▂\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                   eval/gen_len ▁████\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                      eval/loss █▃▂▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                    eval/rouge1 ▁▄███\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                    eval/rouge2 ▁▅▇██\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                    eval/rougeL ▁▅███\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                 eval/rougeLsum ▁▅███\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                   eval/runtime █▃▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        eval/samples_per_second ▁▆███\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/steps_per_second ▁▆█▇█\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                    train/epoch ▁▁▂▂▂▂▃▃▄▄▄▄▅▅▅▅▆▆▆▆▇▇████\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:              train/global_step ▁▁▂▂▂▂▃▃▄▄▄▄▅▅▅▅▆▆▆▆▇▇████\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            train/learning_rate ██▇▇▇▆▆▅▅▅▄▄▄▃▃▂▂▂▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                     train/loss █▅▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               train/total_flos ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               train/train_loss ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            train/train_runtime ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: train/train_samples_per_second ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   train/train_steps_per_second ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                      eval/bleu 16.196\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                   eval/gen_len 18.7225\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                      eval/loss 0.68025\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                    eval/rouge1 55.3329\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                    eval/rouge2 49.4433\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                    eval/rougeL 53.8402\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                 eval/rougeLsum 53.9912\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                   eval/runtime 48.622\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        eval/samples_per_second 8.227\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/steps_per_second 2.057\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                    train/epoch 4.99\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:              train/global_step 1015\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            train/learning_rate 0.0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                     train/loss 1.0806\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               train/total_flos 3129790475381760.0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               train/train_loss 2.30761\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            train/train_runtime 952.4858\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: train/train_samples_per_second 17.082\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   train/train_steps_per_second 1.066\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mquiet-microwave-15\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/cs678/huggingface/runs/kdzlhzhq\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20230507_012833-kdzlhzhq/logs\u001b[0m\n",
            "CPU times: user 8 s, sys: 1.4 s, total: 9.4 s\n",
            "Wall time: 19min 6s\n"
          ]
        }
      ],
      "source": [
        "#training model\n",
        "%%time\n",
        "%cd /content/iterater/code/IteraTeR_ACL2022/model/generation\n",
        "!sh mT5_zeroshot_multilingual_train.sh"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "44d18e0c-ad50-4496-9fd2-c0a53c42f9d0",
        "id": "0G5RKLjJoRrD"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/iterater/code/IteraTeR_ACL2022/model/generation\n",
            "2023-05-07 02:54:03.225859: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2023-05-07 02:54:03.286307: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-05-07 02:54:04.377949: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "  0% 0/1440 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1313: UserWarning: Using `max_length`'s default (20) to control the generation length. This behaviour is deprecated and will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "100% 1440/1440 [07:54<00:00,  3.03it/s]\n",
            "100% 1440/1440 [00:10<00:00, 137.71it/s]\n",
            " 37% 531/1440 [00:04<00:05, 161.68it/s]"
          ]
        }
      ],
      "source": [
        "#printing metrics\n",
        "%%time\n",
        "%cd /content/iterater/code/IteraTeR_ACL2022/model/generation\n",
        "!python3 mT5_inference_and_metrics.py --checkpoint mT5_model --reference /content/cs678-cp1-cp2/multi_data/zeroshot_multi/test.json --output mt5_zeroshot_sent_output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4LyOyb-mlM8t"
      },
      "source": [
        "##### Fully Supervised Training\n",
        "\n",
        "train: multilingual human_sent_level>train.json\n",
        "\n",
        "dev: multilingual human_sent_level>dev.json\n",
        "\n",
        "test: multilingual human_sent_level>test.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "00371190-d938-467f-eee6-18f2c2dde602",
        "id": "djp3Lw5QobcQ"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/iterater/code/IteraTeR_ACL2022/model/generation\n",
            "+ export TOKENIZERS_PARALLELISM=false\n",
            "+ PYTHON=python3\n",
            "+ git clone https://github.com/huggingface/transformers\n",
            "fatal: destination path 'transformers' already exists and is not an empty directory.\n",
            "+ cp run_summarization.py ./transformers/examples/pytorch/summarization/\n",
            "+ TRAIN_SCRIPT=./transformers/examples/pytorch/summarization/run_summarization.py\n",
            "+ TRAIN=/content/cs678-cp1-cp2/multi_data/fully_multi/train.json\n",
            "+ VALID=/content/cs678-cp1-cp2/multi_data/fully_multi/dev.json\n",
            "+ OUTPUT=mT5_model_full/\n",
            "+ sha1sum ./transformers/examples/pytorch/summarization/run_summarization.py\n",
            "1a98b8a4f2cf13523ec0e86d2094d61c4c53c7c1  ./transformers/examples/pytorch/summarization/run_summarization.py\n",
            "+ python3 ./transformers/examples/pytorch/summarization/run_summarization.py --model_name_or_path google/mt5-base --do_train --do_eval --train_file /content/cs678-cp1-cp2/multi_data/fully_multi/train.json --validation_file /content/cs678-cp1-cp2/multi_data/fully_multi/dev.json --per_device_train_batch_size=4 --per_device_eval_batch_size=4 --num_train_epochs 5 --gradient_accumulation_steps 4 --evaluation_strategy steps --eval_steps 200 --save_steps 100 --predict_with_generate --logging_steps 50 --output_dir mT5_model_full/ --overwrite_output_dir --text_column before_sent_with_intent --summary_column after_sent --learning_rate 3e-5\n",
            "2023-05-07 03:06:25.384399: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2023-05-07 03:06:25.443822: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-05-07 03:06:26.591523: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "05/07/2023 03:06:33 - WARNING - __main__ -   Process rank: -1, device: cuda:0, n_gpu: 1distributed training: False, 16-bits training: False\n",
            "05/07/2023 03:06:33 - INFO - __main__ -   Training/evaluation parameters Seq2SeqTrainingArguments(\n",
            "_n_gpu=1,\n",
            "adafactor=False,\n",
            "adam_beta1=0.9,\n",
            "adam_beta2=0.999,\n",
            "adam_epsilon=1e-08,\n",
            "auto_find_batch_size=False,\n",
            "bf16=False,\n",
            "bf16_full_eval=False,\n",
            "data_seed=None,\n",
            "dataloader_drop_last=False,\n",
            "dataloader_num_workers=0,\n",
            "dataloader_pin_memory=True,\n",
            "ddp_bucket_cap_mb=None,\n",
            "ddp_find_unused_parameters=None,\n",
            "ddp_timeout=1800,\n",
            "debug=[],\n",
            "deepspeed=None,\n",
            "disable_tqdm=False,\n",
            "do_eval=True,\n",
            "do_predict=False,\n",
            "do_train=True,\n",
            "eval_accumulation_steps=None,\n",
            "eval_delay=0,\n",
            "eval_steps=200,\n",
            "evaluation_strategy=steps,\n",
            "fp16=False,\n",
            "fp16_backend=auto,\n",
            "fp16_full_eval=False,\n",
            "fp16_opt_level=O1,\n",
            "fsdp=[],\n",
            "fsdp_config={'fsdp_min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},\n",
            "fsdp_min_num_params=0,\n",
            "fsdp_transformer_layer_cls_to_wrap=None,\n",
            "full_determinism=False,\n",
            "generation_config=None,\n",
            "generation_max_length=None,\n",
            "generation_num_beams=None,\n",
            "gradient_accumulation_steps=4,\n",
            "gradient_checkpointing=False,\n",
            "greater_is_better=None,\n",
            "group_by_length=False,\n",
            "half_precision_backend=auto,\n",
            "hub_model_id=None,\n",
            "hub_private_repo=False,\n",
            "hub_strategy=every_save,\n",
            "hub_token=<HUB_TOKEN>,\n",
            "ignore_data_skip=False,\n",
            "include_inputs_for_metrics=False,\n",
            "jit_mode_eval=False,\n",
            "label_names=None,\n",
            "label_smoothing_factor=0.0,\n",
            "learning_rate=3e-05,\n",
            "length_column_name=length,\n",
            "load_best_model_at_end=False,\n",
            "local_rank=-1,\n",
            "log_level=passive,\n",
            "log_level_replica=warning,\n",
            "log_on_each_node=True,\n",
            "logging_dir=mT5_model_full/runs/May07_03-06-31_cd731d4125ca,\n",
            "logging_first_step=False,\n",
            "logging_nan_inf_filter=True,\n",
            "logging_steps=50,\n",
            "logging_strategy=steps,\n",
            "lr_scheduler_type=linear,\n",
            "max_grad_norm=1.0,\n",
            "max_steps=-1,\n",
            "metric_for_best_model=None,\n",
            "mp_parameters=,\n",
            "no_cuda=False,\n",
            "num_train_epochs=5.0,\n",
            "optim=adamw_hf,\n",
            "optim_args=None,\n",
            "output_dir=mT5_model_full/,\n",
            "overwrite_output_dir=True,\n",
            "past_index=-1,\n",
            "per_device_eval_batch_size=4,\n",
            "per_device_train_batch_size=4,\n",
            "predict_with_generate=True,\n",
            "prediction_loss_only=False,\n",
            "push_to_hub=False,\n",
            "push_to_hub_model_id=None,\n",
            "push_to_hub_organization=None,\n",
            "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
            "ray_scope=last,\n",
            "remove_unused_columns=True,\n",
            "report_to=['tensorboard', 'wandb'],\n",
            "resume_from_checkpoint=None,\n",
            "run_name=mT5_model_full/,\n",
            "save_on_each_node=False,\n",
            "save_safetensors=False,\n",
            "save_steps=100,\n",
            "save_strategy=steps,\n",
            "save_total_limit=None,\n",
            "seed=42,\n",
            "sharded_ddp=[],\n",
            "skip_memory_metrics=True,\n",
            "sortish_sampler=False,\n",
            "tf32=None,\n",
            "torch_compile=False,\n",
            "torch_compile_backend=None,\n",
            "torch_compile_mode=None,\n",
            "torchdynamo=None,\n",
            "tpu_metrics_debug=False,\n",
            "tpu_num_cores=None,\n",
            "use_ipex=False,\n",
            "use_legacy_prediction_loop=False,\n",
            "use_mps_device=False,\n",
            "warmup_ratio=0.0,\n",
            "warmup_steps=0,\n",
            "weight_decay=0.0,\n",
            "xpu_backend=None,\n",
            ")\n",
            "05/07/2023 03:06:33 - INFO - __main__ -   Seq2SeqTrainingArguments(\n",
            "_n_gpu=1,\n",
            "adafactor=False,\n",
            "adam_beta1=0.9,\n",
            "adam_beta2=0.999,\n",
            "adam_epsilon=1e-08,\n",
            "auto_find_batch_size=False,\n",
            "bf16=False,\n",
            "bf16_full_eval=False,\n",
            "data_seed=None,\n",
            "dataloader_drop_last=False,\n",
            "dataloader_num_workers=0,\n",
            "dataloader_pin_memory=True,\n",
            "ddp_bucket_cap_mb=None,\n",
            "ddp_find_unused_parameters=None,\n",
            "ddp_timeout=1800,\n",
            "debug=[],\n",
            "deepspeed=None,\n",
            "disable_tqdm=False,\n",
            "do_eval=True,\n",
            "do_predict=False,\n",
            "do_train=True,\n",
            "eval_accumulation_steps=None,\n",
            "eval_delay=0,\n",
            "eval_steps=200,\n",
            "evaluation_strategy=steps,\n",
            "fp16=False,\n",
            "fp16_backend=auto,\n",
            "fp16_full_eval=False,\n",
            "fp16_opt_level=O1,\n",
            "fsdp=[],\n",
            "fsdp_config={'fsdp_min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},\n",
            "fsdp_min_num_params=0,\n",
            "fsdp_transformer_layer_cls_to_wrap=None,\n",
            "full_determinism=False,\n",
            "generation_config=None,\n",
            "generation_max_length=None,\n",
            "generation_num_beams=None,\n",
            "gradient_accumulation_steps=4,\n",
            "gradient_checkpointing=False,\n",
            "greater_is_better=None,\n",
            "group_by_length=False,\n",
            "half_precision_backend=auto,\n",
            "hub_model_id=None,\n",
            "hub_private_repo=False,\n",
            "hub_strategy=every_save,\n",
            "hub_token=<HUB_TOKEN>,\n",
            "ignore_data_skip=False,\n",
            "include_inputs_for_metrics=False,\n",
            "jit_mode_eval=False,\n",
            "label_names=None,\n",
            "label_smoothing_factor=0.0,\n",
            "learning_rate=3e-05,\n",
            "length_column_name=length,\n",
            "load_best_model_at_end=False,\n",
            "local_rank=-1,\n",
            "log_level=passive,\n",
            "log_level_replica=warning,\n",
            "log_on_each_node=True,\n",
            "logging_dir=mT5_model_full/runs/May07_03-06-31_cd731d4125ca,\n",
            "logging_first_step=False,\n",
            "logging_nan_inf_filter=True,\n",
            "logging_steps=50,\n",
            "logging_strategy=steps,\n",
            "lr_scheduler_type=linear,\n",
            "max_grad_norm=1.0,\n",
            "max_steps=-1,\n",
            "metric_for_best_model=None,\n",
            "mp_parameters=,\n",
            "no_cuda=False,\n",
            "num_train_epochs=5.0,\n",
            "optim=adamw_hf,\n",
            "optim_args=None,\n",
            "output_dir=mT5_model_full/,\n",
            "overwrite_output_dir=True,\n",
            "past_index=-1,\n",
            "per_device_eval_batch_size=4,\n",
            "per_device_train_batch_size=4,\n",
            "predict_with_generate=True,\n",
            "prediction_loss_only=False,\n",
            "push_to_hub=False,\n",
            "push_to_hub_model_id=None,\n",
            "push_to_hub_organization=None,\n",
            "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
            "ray_scope=last,\n",
            "remove_unused_columns=True,\n",
            "report_to=['tensorboard', 'wandb'],\n",
            "resume_from_checkpoint=None,\n",
            "run_name=mT5_model_full/,\n",
            "save_on_each_node=False,\n",
            "save_safetensors=False,\n",
            "save_steps=100,\n",
            "save_strategy=steps,\n",
            "save_total_limit=None,\n",
            "seed=42,\n",
            "sharded_ddp=[],\n",
            "skip_memory_metrics=True,\n",
            "sortish_sampler=False,\n",
            "tf32=None,\n",
            "torch_compile=False,\n",
            "torch_compile_backend=None,\n",
            "torch_compile_mode=None,\n",
            "torchdynamo=None,\n",
            "tpu_metrics_debug=False,\n",
            "tpu_num_cores=None,\n",
            "use_ipex=False,\n",
            "use_legacy_prediction_loop=False,\n",
            "use_mps_device=False,\n",
            "warmup_ratio=0.0,\n",
            "warmup_steps=0,\n",
            "weight_decay=0.0,\n",
            "xpu_backend=None,\n",
            ")\n",
            "05/07/2023 03:06:33 - INFO - __main__ -   42\n",
            "05/07/2023 03:06:33 - WARNING - datasets.builder -   Using custom data configuration default-4759fca39f4c7cff\n",
            "05/07/2023 03:06:33 - WARNING - datasets.builder -   Reusing dataset json (/root/.cache/huggingface/datasets/json/default-4759fca39f4c7cff/0.0.0/ac0ca5f5289a6cf108e706efcf040422dbbfa8e658dee6a819f20d76bb84d26b)\n",
            "100% 2/2 [00:00<00:00, 650.94it/s]\n",
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--google--mt5-base/snapshots/2eb15465c5dd7f72a8f7984306ad05ebc3dd1e1f/config.json\n",
            "Model config MT5Config {\n",
            "  \"_name_or_path\": \"google/mt5-base\",\n",
            "  \"architectures\": [\n",
            "    \"MT5ForConditionalGeneration\"\n",
            "  ],\n",
            "  \"d_ff\": 2048,\n",
            "  \"d_kv\": 64,\n",
            "  \"d_model\": 768,\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"dense_act_fn\": \"gelu_new\",\n",
            "  \"dropout_rate\": 0.1,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"feed_forward_proj\": \"gated-gelu\",\n",
            "  \"initializer_factor\": 1.0,\n",
            "  \"is_encoder_decoder\": true,\n",
            "  \"is_gated_act\": true,\n",
            "  \"layer_norm_epsilon\": 1e-06,\n",
            "  \"model_type\": \"mt5\",\n",
            "  \"num_decoder_layers\": 12,\n",
            "  \"num_heads\": 12,\n",
            "  \"num_layers\": 12,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"relative_attention_max_distance\": 128,\n",
            "  \"relative_attention_num_buckets\": 32,\n",
            "  \"tie_word_embeddings\": false,\n",
            "  \"tokenizer_class\": \"T5Tokenizer\",\n",
            "  \"transformers_version\": \"4.28.1\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 250112\n",
            "}\n",
            "\n",
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--google--mt5-base/snapshots/2eb15465c5dd7f72a8f7984306ad05ebc3dd1e1f/config.json\n",
            "Model config MT5Config {\n",
            "  \"_name_or_path\": \"google/mt5-base\",\n",
            "  \"architectures\": [\n",
            "    \"MT5ForConditionalGeneration\"\n",
            "  ],\n",
            "  \"d_ff\": 2048,\n",
            "  \"d_kv\": 64,\n",
            "  \"d_model\": 768,\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"dense_act_fn\": \"gelu_new\",\n",
            "  \"dropout_rate\": 0.1,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"feed_forward_proj\": \"gated-gelu\",\n",
            "  \"initializer_factor\": 1.0,\n",
            "  \"is_encoder_decoder\": true,\n",
            "  \"is_gated_act\": true,\n",
            "  \"layer_norm_epsilon\": 1e-06,\n",
            "  \"model_type\": \"mt5\",\n",
            "  \"num_decoder_layers\": 12,\n",
            "  \"num_heads\": 12,\n",
            "  \"num_layers\": 12,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"relative_attention_max_distance\": 128,\n",
            "  \"relative_attention_num_buckets\": 32,\n",
            "  \"tie_word_embeddings\": false,\n",
            "  \"tokenizer_class\": \"T5Tokenizer\",\n",
            "  \"transformers_version\": \"4.28.1\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 250112\n",
            "}\n",
            "\n",
            "loading file spiece.model from cache at /root/.cache/huggingface/hub/models--google--mt5-base/snapshots/2eb15465c5dd7f72a8f7984306ad05ebc3dd1e1f/spiece.model\n",
            "loading file tokenizer.json from cache at None\n",
            "loading file added_tokens.json from cache at None\n",
            "loading file special_tokens_map.json from cache at /root/.cache/huggingface/hub/models--google--mt5-base/snapshots/2eb15465c5dd7f72a8f7984306ad05ebc3dd1e1f/special_tokens_map.json\n",
            "loading file tokenizer_config.json from cache at /root/.cache/huggingface/hub/models--google--mt5-base/snapshots/2eb15465c5dd7f72a8f7984306ad05ebc3dd1e1f/tokenizer_config.json\n",
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--google--mt5-base/snapshots/2eb15465c5dd7f72a8f7984306ad05ebc3dd1e1f/config.json\n",
            "Model config MT5Config {\n",
            "  \"_name_or_path\": \"google/mt5-base\",\n",
            "  \"architectures\": [\n",
            "    \"MT5ForConditionalGeneration\"\n",
            "  ],\n",
            "  \"d_ff\": 2048,\n",
            "  \"d_kv\": 64,\n",
            "  \"d_model\": 768,\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"dense_act_fn\": \"gelu_new\",\n",
            "  \"dropout_rate\": 0.1,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"feed_forward_proj\": \"gated-gelu\",\n",
            "  \"initializer_factor\": 1.0,\n",
            "  \"is_encoder_decoder\": true,\n",
            "  \"is_gated_act\": true,\n",
            "  \"layer_norm_epsilon\": 1e-06,\n",
            "  \"model_type\": \"mt5\",\n",
            "  \"num_decoder_layers\": 12,\n",
            "  \"num_heads\": 12,\n",
            "  \"num_layers\": 12,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"relative_attention_max_distance\": 128,\n",
            "  \"relative_attention_num_buckets\": 32,\n",
            "  \"tie_word_embeddings\": false,\n",
            "  \"tokenizer_class\": \"T5Tokenizer\",\n",
            "  \"transformers_version\": \"4.28.1\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 250112\n",
            "}\n",
            "\n",
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--google--mt5-base/snapshots/2eb15465c5dd7f72a8f7984306ad05ebc3dd1e1f/config.json\n",
            "Model config MT5Config {\n",
            "  \"_name_or_path\": \"google/mt5-base\",\n",
            "  \"architectures\": [\n",
            "    \"MT5ForConditionalGeneration\"\n",
            "  ],\n",
            "  \"d_ff\": 2048,\n",
            "  \"d_kv\": 64,\n",
            "  \"d_model\": 768,\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"dense_act_fn\": \"gelu_new\",\n",
            "  \"dropout_rate\": 0.1,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"feed_forward_proj\": \"gated-gelu\",\n",
            "  \"initializer_factor\": 1.0,\n",
            "  \"is_encoder_decoder\": true,\n",
            "  \"is_gated_act\": true,\n",
            "  \"layer_norm_epsilon\": 1e-06,\n",
            "  \"model_type\": \"mt5\",\n",
            "  \"num_decoder_layers\": 12,\n",
            "  \"num_heads\": 12,\n",
            "  \"num_layers\": 12,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"relative_attention_max_distance\": 128,\n",
            "  \"relative_attention_num_buckets\": 32,\n",
            "  \"tie_word_embeddings\": false,\n",
            "  \"tokenizer_class\": \"T5Tokenizer\",\n",
            "  \"transformers_version\": \"4.28.1\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 250112\n",
            "}\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/convert_slow_tokenizer.py:454: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
            "  warnings.warn(\n",
            "Assigning ['<clarity>', '<fluency>', '<coherence>', '<style>', '<meaning-changed>'] to the additional_special_tokens key of the tokenizer\n",
            "loading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--google--mt5-base/snapshots/2eb15465c5dd7f72a8f7984306ad05ebc3dd1e1f/pytorch_model.bin\n",
            "Generate config GenerationConfig {\n",
            "  \"_from_model_config\": true,\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"transformers_version\": \"4.28.1\"\n",
            "}\n",
            "\n",
            "All model checkpoint weights were used when initializing MT5ForConditionalGeneration.\n",
            "\n",
            "All the weights of MT5ForConditionalGeneration were initialized from the model checkpoint at google/mt5-base.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use MT5ForConditionalGeneration for predictions without further training.\n",
            "loading configuration file generation_config.json from cache at /root/.cache/huggingface/hub/models--google--mt5-base/snapshots/2eb15465c5dd7f72a8f7984306ad05ebc3dd1e1f/generation_config.json\n",
            "Generate config GenerationConfig {\n",
            "  \"_from_model_config\": true,\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"transformers_version\": \"4.28.1\"\n",
            "}\n",
            "\n",
            "05/07/2023 03:06:47 - WARNING - datasets.fingerprint -   Parameter 'function'=<function main.<locals>.preprocess_function at 0x7f8e82e2de10> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.\n",
            "05/07/2023 03:06:47 - WARNING - datasets.arrow_dataset -   Loading cached processed dataset at /root/.cache/huggingface/datasets/json/default-4759fca39f4c7cff/0.0.0/ac0ca5f5289a6cf108e706efcf040422dbbfa8e658dee6a819f20d76bb84d26b/cache-1c80317fa3b1799d.arrow\n",
            "05/07/2023 03:06:47 - WARNING - datasets.arrow_dataset -   Loading cached processed dataset at /root/.cache/huggingface/datasets/json/default-4759fca39f4c7cff/0.0.0/ac0ca5f5289a6cf108e706efcf040422dbbfa8e658dee6a819f20d76bb84d26b/cache-bdd640fb06671ad1.arrow\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "***** Running training *****\n",
            "  Num examples = 4,800\n",
            "  Num Epochs = 5\n",
            "  Instantaneous batch size per device = 4\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
            "  Gradient Accumulation steps = 4\n",
            "  Total optimization steps = 1,500\n",
            "  Number of trainable parameters = 582,390,528\n",
            "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mwilliamdavid825\u001b[0m (\u001b[33mcs678\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.15.2\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/iterater/code/IteraTeR_ACL2022/model/generation/wandb/run-20230507_030650-8s6yf44b\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33msmooth-valley-17\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/cs678/huggingface\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/cs678/huggingface/runs/8s6yf44b\u001b[0m\n",
            "  0% 0/1500 [00:00<?, ?it/s]You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
            "{'loss': 12.6621, 'learning_rate': 2.9e-05, 'epoch': 0.17}\n",
            "{'loss': 7.9746, 'learning_rate': 2.8e-05, 'epoch': 0.33}\n",
            "  7% 100/1500 [00:50<11:33,  2.02it/s]Saving model checkpoint to mT5_model_full/checkpoint-100\n",
            "Configuration saved in mT5_model_full/checkpoint-100/config.json\n",
            "Configuration saved in mT5_model_full/checkpoint-100/generation_config.json\n",
            "Model weights saved in mT5_model_full/checkpoint-100/pytorch_model.bin\n",
            "tokenizer config file saved in mT5_model_full/checkpoint-100/tokenizer_config.json\n",
            "Special tokens file saved in mT5_model_full/checkpoint-100/special_tokens_map.json\n",
            "Copy vocab file to mT5_model_full/checkpoint-100/spiece.model\n",
            "{'loss': 4.8177, 'learning_rate': 2.7000000000000002e-05, 'epoch': 0.5}\n",
            "{'loss': 2.8676, 'learning_rate': 2.6000000000000002e-05, 'epoch': 0.67}\n",
            " 13% 200/1500 [01:57<10:42,  2.02it/s]***** Running Evaluation *****\n",
            "  Num examples = 1600\n",
            "  Batch size = 4\n",
            "Generate config GenerationConfig {\n",
            "  \"_from_model_config\": true,\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"transformers_version\": \"4.28.1\"\n",
            "}\n",
            "\n",
            "\n",
            "  0% 0/400 [00:00<?, ?it/s]\u001b[A\n",
            "  0% 2/400 [00:00<01:19,  5.00it/s]\u001b[A\n",
            "  1% 3/400 [00:00<01:52,  3.53it/s]\u001b[A\n",
            "  1% 4/400 [00:01<02:09,  3.05it/s]\u001b[A\n",
            "  1% 5/400 [00:01<02:19,  2.83it/s]\u001b[A\n",
            "  2% 6/400 [00:02<02:26,  2.69it/s]\u001b[A\n",
            "  2% 7/400 [00:02<02:30,  2.61it/s]\u001b[A\n",
            "  2% 8/400 [00:02<02:33,  2.56it/s]\u001b[A\n",
            "  2% 9/400 [00:03<02:34,  2.52it/s]\u001b[A\n",
            "  2% 10/400 [00:03<02:35,  2.50it/s]\u001b[A\n",
            "  3% 11/400 [00:04<02:37,  2.48it/s]\u001b[A\n",
            "  3% 12/400 [00:04<02:36,  2.47it/s]\u001b[A\n",
            "  3% 13/400 [00:04<02:36,  2.47it/s]\u001b[A\n",
            "  4% 14/400 [00:05<02:36,  2.47it/s]\u001b[A\n",
            "  4% 15/400 [00:05<02:35,  2.47it/s]\u001b[A\n",
            "  4% 16/400 [00:06<02:35,  2.47it/s]\u001b[A\n",
            "  4% 17/400 [00:06<02:34,  2.47it/s]\u001b[A\n",
            "  4% 18/400 [00:06<02:34,  2.47it/s]\u001b[A\n",
            "  5% 19/400 [00:07<02:34,  2.47it/s]\u001b[A\n",
            "  5% 20/400 [00:07<02:34,  2.47it/s]\u001b[A\n",
            "  5% 21/400 [00:08<02:32,  2.48it/s]\u001b[A\n",
            "  6% 22/400 [00:08<02:35,  2.43it/s]\u001b[A\n",
            "  6% 23/400 [00:08<02:38,  2.37it/s]\u001b[A\n",
            "  6% 24/400 [00:09<02:35,  2.41it/s]\u001b[A\n",
            "  6% 25/400 [00:09<02:34,  2.42it/s]\u001b[A\n",
            "  6% 26/400 [00:10<02:34,  2.43it/s]\u001b[A\n",
            "  7% 27/400 [00:10<02:33,  2.42it/s]\u001b[A\n",
            "  7% 28/400 [00:11<02:31,  2.45it/s]\u001b[A\n",
            "  7% 29/400 [00:11<02:30,  2.47it/s]\u001b[A\n",
            "  8% 30/400 [00:11<02:28,  2.49it/s]\u001b[A\n",
            "  8% 31/400 [00:12<02:27,  2.50it/s]\u001b[A\n",
            "  8% 32/400 [00:12<02:27,  2.50it/s]\u001b[A\n",
            "  8% 33/400 [00:12<02:27,  2.50it/s]\u001b[A\n",
            "  8% 34/400 [00:13<02:27,  2.48it/s]\u001b[A\n",
            "  9% 35/400 [00:13<02:27,  2.47it/s]\u001b[A\n",
            "  9% 36/400 [00:14<02:27,  2.47it/s]\u001b[A\n",
            "  9% 37/400 [00:14<02:28,  2.45it/s]\u001b[A\n",
            " 10% 38/400 [00:15<02:27,  2.45it/s]\u001b[A\n",
            " 10% 39/400 [00:15<02:26,  2.46it/s]\u001b[A\n",
            " 10% 40/400 [00:15<02:25,  2.47it/s]\u001b[A\n",
            " 10% 41/400 [00:16<02:25,  2.48it/s]\u001b[A\n",
            " 10% 42/400 [00:16<02:24,  2.48it/s]\u001b[A\n",
            " 11% 43/400 [00:17<02:23,  2.49it/s]\u001b[A\n",
            " 11% 44/400 [00:17<02:23,  2.49it/s]\u001b[A\n",
            " 11% 45/400 [00:17<02:22,  2.49it/s]\u001b[A\n",
            " 12% 46/400 [00:18<02:22,  2.49it/s]\u001b[A\n",
            " 12% 47/400 [00:18<02:21,  2.49it/s]\u001b[A\n",
            " 12% 48/400 [00:19<02:21,  2.48it/s]\u001b[A\n",
            " 12% 49/400 [00:19<02:20,  2.49it/s]\u001b[A\n",
            " 12% 50/400 [00:19<02:20,  2.49it/s]\u001b[A\n",
            " 13% 51/400 [00:20<02:19,  2.50it/s]\u001b[A\n",
            " 13% 52/400 [00:20<02:14,  2.59it/s]\u001b[A\n",
            " 13% 53/400 [00:21<02:16,  2.55it/s]\u001b[A\n",
            " 14% 54/400 [00:21<02:17,  2.52it/s]\u001b[A\n",
            " 14% 55/400 [00:21<02:17,  2.50it/s]\u001b[A\n",
            " 14% 56/400 [00:22<02:17,  2.50it/s]\u001b[A\n",
            " 14% 57/400 [00:22<02:16,  2.51it/s]\u001b[A\n",
            " 14% 58/400 [00:23<02:17,  2.49it/s]\u001b[A\n",
            " 15% 59/400 [00:23<02:19,  2.44it/s]\u001b[A\n",
            " 15% 60/400 [00:23<02:11,  2.60it/s]\u001b[A\n",
            " 15% 61/400 [00:24<02:12,  2.57it/s]\u001b[A\n",
            " 16% 62/400 [00:24<02:12,  2.54it/s]\u001b[A\n",
            " 16% 63/400 [00:25<02:14,  2.51it/s]\u001b[A\n",
            " 16% 64/400 [00:25<02:15,  2.49it/s]\u001b[A\n",
            " 16% 65/400 [00:25<01:56,  2.87it/s]\u001b[A\n",
            " 16% 66/400 [00:26<02:03,  2.71it/s]\u001b[A\n",
            " 17% 67/400 [00:26<02:06,  2.64it/s]\u001b[A\n",
            " 17% 68/400 [00:26<02:08,  2.58it/s]\u001b[A\n",
            " 17% 69/400 [00:27<02:07,  2.59it/s]\u001b[A\n",
            " 18% 70/400 [00:27<02:08,  2.56it/s]\u001b[A\n",
            " 18% 71/400 [00:28<02:09,  2.54it/s]\u001b[A\n",
            " 18% 72/400 [00:28<02:09,  2.53it/s]\u001b[A\n",
            " 18% 73/400 [00:28<02:10,  2.51it/s]\u001b[A\n",
            " 18% 74/400 [00:29<01:52,  2.90it/s]\u001b[A\n",
            " 19% 75/400 [00:29<01:57,  2.76it/s]\u001b[A\n",
            " 19% 76/400 [00:29<02:01,  2.66it/s]\u001b[A\n",
            " 19% 77/400 [00:30<02:03,  2.61it/s]\u001b[A\n",
            " 20% 78/400 [00:30<01:58,  2.73it/s]\u001b[A\n",
            " 20% 79/400 [00:30<01:54,  2.79it/s]\u001b[A\n",
            " 20% 80/400 [00:31<01:45,  3.02it/s]\u001b[A\n",
            " 20% 81/400 [00:31<01:52,  2.83it/s]\u001b[A\n",
            " 20% 82/400 [00:32<01:57,  2.72it/s]\u001b[A\n",
            " 21% 83/400 [00:32<02:00,  2.64it/s]\u001b[A\n",
            " 21% 84/400 [00:32<02:02,  2.58it/s]\u001b[A\n",
            " 21% 85/400 [00:33<02:03,  2.54it/s]\u001b[A\n",
            " 22% 86/400 [00:33<01:50,  2.84it/s]\u001b[A\n",
            " 22% 87/400 [00:33<01:55,  2.72it/s]\u001b[A\n",
            " 22% 88/400 [00:34<01:57,  2.65it/s]\u001b[A\n",
            " 22% 89/400 [00:34<01:59,  2.59it/s]\u001b[A\n",
            " 22% 90/400 [00:35<02:01,  2.56it/s]\u001b[A\n",
            " 23% 91/400 [00:35<02:02,  2.52it/s]\u001b[A\n",
            " 23% 92/400 [00:35<02:02,  2.51it/s]\u001b[A\n",
            " 23% 93/400 [00:36<02:02,  2.50it/s]\u001b[A\n",
            " 24% 94/400 [00:36<02:02,  2.49it/s]\u001b[A\n",
            " 24% 95/400 [00:37<02:03,  2.47it/s]\u001b[A\n",
            " 24% 96/400 [00:37<02:03,  2.47it/s]\u001b[A\n",
            " 24% 97/400 [00:37<02:02,  2.47it/s]\u001b[A\n",
            " 24% 98/400 [00:38<02:02,  2.47it/s]\u001b[A\n",
            " 25% 99/400 [00:38<02:01,  2.48it/s]\u001b[A\n",
            " 25% 100/400 [00:39<02:00,  2.49it/s]\u001b[A\n",
            " 25% 101/400 [00:39<02:00,  2.48it/s]\u001b[A\n",
            " 26% 102/400 [00:39<01:49,  2.72it/s]\u001b[A\n",
            " 26% 103/400 [00:40<01:52,  2.64it/s]\u001b[A\n",
            " 26% 104/400 [00:40<01:54,  2.59it/s]\u001b[A\n",
            " 26% 105/400 [00:41<01:51,  2.65it/s]\u001b[A\n",
            " 26% 106/400 [00:41<01:52,  2.62it/s]\u001b[A\n",
            " 27% 107/400 [00:41<01:58,  2.48it/s]\u001b[A\n",
            " 27% 108/400 [00:42<01:57,  2.48it/s]\u001b[A\n",
            " 27% 109/400 [00:42<01:52,  2.58it/s]\u001b[A\n",
            " 28% 110/400 [00:42<01:48,  2.67it/s]\u001b[A\n",
            " 28% 111/400 [00:43<01:34,  3.04it/s]\u001b[A\n",
            " 28% 112/400 [00:43<01:41,  2.85it/s]\u001b[A\n",
            " 28% 113/400 [00:43<01:45,  2.73it/s]\u001b[A\n",
            " 28% 114/400 [00:44<01:26,  3.29it/s]\u001b[A\n",
            " 29% 115/400 [00:44<01:34,  3.02it/s]\u001b[A\n",
            " 29% 116/400 [00:44<01:39,  2.85it/s]\u001b[A\n",
            " 29% 117/400 [00:45<01:44,  2.71it/s]\u001b[A\n",
            " 30% 118/400 [00:45<01:46,  2.64it/s]\u001b[A\n",
            " 30% 119/400 [00:46<01:47,  2.62it/s]\u001b[A\n",
            " 30% 120/400 [00:46<01:48,  2.57it/s]\u001b[A\n",
            " 30% 121/400 [00:46<01:44,  2.66it/s]\u001b[A\n",
            " 30% 122/400 [00:47<01:46,  2.61it/s]\u001b[A\n",
            " 31% 123/400 [00:47<01:47,  2.58it/s]\u001b[A\n",
            " 31% 124/400 [00:47<01:23,  3.31it/s]\u001b[A\n",
            " 31% 125/400 [00:48<01:25,  3.22it/s]\u001b[A\n",
            " 32% 126/400 [00:48<01:32,  2.97it/s]\u001b[A\n",
            " 32% 127/400 [00:48<01:37,  2.81it/s]\u001b[A\n",
            " 32% 128/400 [00:49<01:32,  2.93it/s]\u001b[A\n",
            " 32% 129/400 [00:49<01:37,  2.78it/s]\u001b[A\n",
            " 32% 130/400 [00:50<01:40,  2.69it/s]\u001b[A\n",
            " 33% 131/400 [00:50<01:29,  3.01it/s]\u001b[A\n",
            " 33% 132/400 [00:50<01:31,  2.93it/s]\u001b[A\n",
            " 33% 133/400 [00:51<01:36,  2.77it/s]\u001b[A\n",
            " 34% 134/400 [00:51<01:38,  2.69it/s]\u001b[A\n",
            " 34% 135/400 [00:51<01:41,  2.62it/s]\u001b[A\n",
            " 34% 136/400 [00:52<01:42,  2.57it/s]\u001b[A\n",
            " 34% 137/400 [00:52<01:43,  2.55it/s]\u001b[A\n",
            " 34% 138/400 [00:53<01:43,  2.53it/s]\u001b[A\n",
            " 35% 139/400 [00:53<01:43,  2.52it/s]\u001b[A\n",
            " 35% 140/400 [00:53<01:43,  2.50it/s]\u001b[A\n",
            " 35% 141/400 [00:54<01:44,  2.48it/s]\u001b[A\n",
            " 36% 142/400 [00:54<01:45,  2.44it/s]\u001b[A\n",
            " 36% 143/400 [00:55<01:42,  2.51it/s]\u001b[A\n",
            " 36% 144/400 [00:55<01:40,  2.54it/s]\u001b[A\n",
            " 36% 145/400 [00:55<01:41,  2.51it/s]\u001b[A\n",
            " 36% 146/400 [00:56<01:42,  2.47it/s]\u001b[A\n",
            " 37% 147/400 [00:56<01:42,  2.47it/s]\u001b[A\n",
            " 37% 148/400 [00:57<01:37,  2.57it/s]\u001b[A\n",
            " 37% 149/400 [00:57<01:38,  2.55it/s]\u001b[A\n",
            " 38% 150/400 [00:57<01:38,  2.54it/s]\u001b[A\n",
            " 38% 151/400 [00:58<01:29,  2.77it/s]\u001b[A\n",
            " 38% 152/400 [00:58<01:32,  2.68it/s]\u001b[A\n",
            " 38% 153/400 [00:58<01:34,  2.62it/s]\u001b[A\n",
            " 38% 154/400 [00:59<01:35,  2.59it/s]\u001b[A\n",
            " 39% 155/400 [00:59<01:36,  2.54it/s]\u001b[A\n",
            " 39% 156/400 [01:00<01:35,  2.55it/s]\u001b[A\n",
            " 39% 157/400 [01:00<01:35,  2.54it/s]\u001b[A\n",
            " 40% 158/400 [01:00<01:35,  2.52it/s]\u001b[A\n",
            " 40% 159/400 [01:01<01:35,  2.51it/s]\u001b[A\n",
            " 40% 160/400 [01:01<01:35,  2.51it/s]\u001b[A\n",
            " 40% 161/400 [01:02<01:35,  2.51it/s]\u001b[A\n",
            " 40% 162/400 [01:02<01:35,  2.50it/s]\u001b[A\n",
            " 41% 163/400 [01:02<01:35,  2.49it/s]\u001b[A\n",
            " 41% 164/400 [01:03<01:34,  2.49it/s]\u001b[A\n",
            " 41% 165/400 [01:03<01:35,  2.46it/s]\u001b[A\n",
            " 42% 166/400 [01:04<01:35,  2.46it/s]\u001b[A\n",
            " 42% 167/400 [01:04<01:34,  2.46it/s]\u001b[A\n",
            " 42% 168/400 [01:04<01:34,  2.47it/s]\u001b[A\n",
            " 42% 169/400 [01:05<01:33,  2.47it/s]\u001b[A\n",
            " 42% 170/400 [01:05<01:21,  2.81it/s]\u001b[A\n",
            " 43% 171/400 [01:06<01:24,  2.71it/s]\u001b[A\n",
            " 43% 172/400 [01:06<01:26,  2.63it/s]\u001b[A\n",
            " 43% 173/400 [01:06<01:27,  2.59it/s]\u001b[A\n",
            " 44% 174/400 [01:07<01:28,  2.56it/s]\u001b[A\n",
            " 44% 175/400 [01:07<01:29,  2.52it/s]\u001b[A\n",
            " 44% 176/400 [01:08<01:29,  2.51it/s]\u001b[A\n",
            " 44% 177/400 [01:08<01:25,  2.61it/s]\u001b[A\n",
            " 44% 178/400 [01:08<01:27,  2.55it/s]\u001b[A\n",
            " 45% 179/400 [01:09<01:28,  2.51it/s]\u001b[A\n",
            " 45% 180/400 [01:09<01:22,  2.65it/s]\u001b[A\n",
            " 45% 181/400 [01:09<01:24,  2.59it/s]\u001b[A\n",
            " 46% 182/400 [01:10<01:25,  2.56it/s]\u001b[A\n",
            " 46% 183/400 [01:10<01:08,  3.16it/s]\u001b[A\n",
            " 46% 184/400 [01:10<01:00,  3.60it/s]\u001b[A\n",
            " 46% 185/400 [01:11<01:07,  3.17it/s]\u001b[A\n",
            " 46% 186/400 [01:11<01:13,  2.92it/s]\u001b[A\n",
            " 47% 187/400 [01:11<01:17,  2.76it/s]\u001b[A\n",
            " 47% 188/400 [01:12<01:19,  2.67it/s]\u001b[A\n",
            " 47% 189/400 [01:12<01:21,  2.60it/s]\u001b[A\n",
            " 48% 190/400 [01:13<01:18,  2.68it/s]\u001b[A\n",
            " 48% 191/400 [01:13<01:20,  2.59it/s]\u001b[A\n",
            " 48% 192/400 [01:13<01:21,  2.55it/s]\u001b[A\n",
            " 48% 193/400 [01:14<01:22,  2.52it/s]\u001b[A\n",
            " 48% 194/400 [01:14<01:22,  2.49it/s]\u001b[A\n",
            " 49% 195/400 [01:15<01:22,  2.48it/s]\u001b[A\n",
            " 49% 196/400 [01:15<01:17,  2.62it/s]\u001b[A\n",
            " 49% 197/400 [01:15<01:19,  2.54it/s]\u001b[A\n",
            " 50% 198/400 [01:16<01:19,  2.53it/s]\u001b[A\n",
            " 50% 199/400 [01:16<01:12,  2.76it/s]\u001b[A\n",
            " 50% 200/400 [01:16<01:08,  2.90it/s]\u001b[A\n",
            " 50% 201/400 [01:17<01:12,  2.76it/s]\u001b[A\n",
            " 50% 202/400 [01:17<01:13,  2.69it/s]\u001b[A\n",
            " 51% 203/400 [01:18<01:14,  2.64it/s]\u001b[A\n",
            " 51% 204/400 [01:18<01:15,  2.61it/s]\u001b[A\n",
            " 51% 205/400 [01:18<01:15,  2.58it/s]\u001b[A\n",
            " 52% 206/400 [01:19<01:16,  2.55it/s]\u001b[A\n",
            " 52% 207/400 [01:19<01:16,  2.53it/s]\u001b[A\n",
            " 52% 208/400 [01:20<01:16,  2.51it/s]\u001b[A\n",
            " 52% 209/400 [01:20<01:16,  2.51it/s]\u001b[A\n",
            " 52% 210/400 [01:20<01:15,  2.50it/s]\u001b[A\n",
            " 53% 211/400 [01:21<01:15,  2.50it/s]\u001b[A\n",
            " 53% 212/400 [01:21<01:15,  2.49it/s]\u001b[A\n",
            " 53% 213/400 [01:22<01:15,  2.48it/s]\u001b[A\n",
            " 54% 214/400 [01:22<01:14,  2.48it/s]\u001b[A\n",
            " 54% 215/400 [01:22<01:15,  2.46it/s]\u001b[A\n",
            " 54% 216/400 [01:23<01:15,  2.45it/s]\u001b[A\n",
            " 54% 217/400 [01:23<01:15,  2.44it/s]\u001b[A\n",
            " 55% 218/400 [01:24<01:14,  2.43it/s]\u001b[A\n",
            " 55% 219/400 [01:24<01:14,  2.44it/s]\u001b[A\n",
            " 55% 220/400 [01:24<01:14,  2.43it/s]\u001b[A\n",
            " 55% 221/400 [01:25<01:14,  2.41it/s]\u001b[A\n",
            " 56% 222/400 [01:25<01:14,  2.39it/s]\u001b[A\n",
            " 56% 223/400 [01:26<01:10,  2.49it/s]\u001b[A\n",
            " 56% 224/400 [01:26<01:11,  2.47it/s]\u001b[A\n",
            " 56% 225/400 [01:26<01:11,  2.45it/s]\u001b[A\n",
            " 56% 226/400 [01:27<01:11,  2.44it/s]\u001b[A\n",
            " 57% 227/400 [01:27<01:11,  2.43it/s]\u001b[A\n",
            " 57% 228/400 [01:28<01:10,  2.43it/s]\u001b[A\n",
            " 57% 229/400 [01:28<01:09,  2.45it/s]\u001b[A\n",
            " 57% 230/400 [01:29<01:09,  2.45it/s]\u001b[A\n",
            " 58% 231/400 [01:29<01:08,  2.46it/s]\u001b[A\n",
            " 58% 232/400 [01:29<01:08,  2.47it/s]\u001b[A\n",
            " 58% 233/400 [01:30<01:07,  2.46it/s]\u001b[A\n",
            " 58% 234/400 [01:30<01:07,  2.48it/s]\u001b[A\n",
            " 59% 235/400 [01:31<01:06,  2.47it/s]\u001b[A\n",
            " 59% 236/400 [01:31<01:06,  2.48it/s]\u001b[A\n",
            " 59% 237/400 [01:31<01:05,  2.48it/s]\u001b[A\n",
            " 60% 238/400 [01:32<01:05,  2.48it/s]\u001b[A\n",
            " 60% 239/400 [01:32<01:04,  2.49it/s]\u001b[A\n",
            " 60% 240/400 [01:33<01:04,  2.48it/s]\u001b[A\n",
            " 60% 241/400 [01:33<01:04,  2.48it/s]\u001b[A\n",
            " 60% 242/400 [01:33<01:03,  2.49it/s]\u001b[A\n",
            " 61% 243/400 [01:34<01:03,  2.49it/s]\u001b[A\n",
            " 61% 244/400 [01:34<01:02,  2.49it/s]\u001b[A\n",
            " 61% 245/400 [01:35<01:02,  2.48it/s]\u001b[A\n",
            " 62% 246/400 [01:35<01:02,  2.47it/s]\u001b[A\n",
            " 62% 247/400 [01:35<01:02,  2.46it/s]\u001b[A\n",
            " 62% 248/400 [01:36<01:00,  2.53it/s]\u001b[A\n",
            " 62% 249/400 [01:36<01:00,  2.51it/s]\u001b[A\n",
            " 62% 250/400 [01:37<01:00,  2.50it/s]\u001b[A\n",
            " 63% 251/400 [01:37<00:59,  2.49it/s]\u001b[A\n",
            " 63% 252/400 [01:37<00:59,  2.47it/s]\u001b[A\n",
            " 63% 253/400 [01:38<01:00,  2.45it/s]\u001b[A\n",
            " 64% 254/400 [01:38<00:59,  2.44it/s]\u001b[A\n",
            " 64% 255/400 [01:39<00:59,  2.42it/s]\u001b[A\n",
            " 64% 256/400 [01:39<00:59,  2.43it/s]\u001b[A\n",
            " 64% 257/400 [01:39<00:59,  2.42it/s]\u001b[A\n",
            " 64% 258/400 [01:40<00:58,  2.42it/s]\u001b[A\n",
            " 65% 259/400 [01:40<00:58,  2.40it/s]\u001b[A\n",
            " 65% 260/400 [01:41<00:58,  2.41it/s]\u001b[A\n",
            " 65% 261/400 [01:41<00:57,  2.42it/s]\u001b[A\n",
            " 66% 262/400 [01:42<00:57,  2.41it/s]\u001b[A\n",
            " 66% 263/400 [01:42<00:57,  2.40it/s]\u001b[A\n",
            " 66% 264/400 [01:42<00:56,  2.41it/s]\u001b[A\n",
            " 66% 265/400 [01:43<00:55,  2.43it/s]\u001b[A\n",
            " 66% 266/400 [01:43<00:54,  2.45it/s]\u001b[A\n",
            " 67% 267/400 [01:44<00:54,  2.46it/s]\u001b[A\n",
            " 67% 268/400 [01:44<00:54,  2.44it/s]\u001b[A\n",
            " 67% 269/400 [01:44<00:53,  2.45it/s]\u001b[A\n",
            " 68% 270/400 [01:45<00:53,  2.45it/s]\u001b[A\n",
            " 68% 271/400 [01:45<00:52,  2.46it/s]\u001b[A\n",
            " 68% 272/400 [01:46<00:52,  2.46it/s]\u001b[A\n",
            " 68% 273/400 [01:46<00:51,  2.46it/s]\u001b[A\n",
            " 68% 274/400 [01:46<00:44,  2.81it/s]\u001b[A\n",
            " 69% 275/400 [01:47<00:46,  2.69it/s]\u001b[A\n",
            " 69% 276/400 [01:47<00:47,  2.62it/s]\u001b[A\n",
            " 69% 277/400 [01:47<00:47,  2.56it/s]\u001b[A\n",
            " 70% 278/400 [01:48<00:47,  2.55it/s]\u001b[A\n",
            " 70% 279/400 [01:48<00:47,  2.53it/s]\u001b[A\n",
            " 70% 280/400 [01:49<00:47,  2.51it/s]\u001b[A\n",
            " 70% 281/400 [01:49<00:47,  2.49it/s]\u001b[A\n",
            " 70% 282/400 [01:49<00:47,  2.48it/s]\u001b[A\n",
            " 71% 283/400 [01:50<00:47,  2.47it/s]\u001b[A\n",
            " 71% 284/400 [01:50<00:47,  2.45it/s]\u001b[A\n",
            " 71% 285/400 [01:51<00:46,  2.46it/s]\u001b[A\n",
            " 72% 286/400 [01:51<00:46,  2.46it/s]\u001b[A\n",
            " 72% 287/400 [01:52<00:45,  2.47it/s]\u001b[A\n",
            " 72% 288/400 [01:52<00:44,  2.49it/s]\u001b[A\n",
            " 72% 289/400 [01:52<00:44,  2.50it/s]\u001b[A\n",
            " 72% 290/400 [01:53<00:44,  2.49it/s]\u001b[A\n",
            " 73% 291/400 [01:53<00:44,  2.46it/s]\u001b[A\n",
            " 73% 292/400 [01:54<00:44,  2.44it/s]\u001b[A\n",
            " 73% 293/400 [01:54<00:43,  2.44it/s]\u001b[A\n",
            " 74% 294/400 [01:54<00:43,  2.42it/s]\u001b[A\n",
            " 74% 295/400 [01:55<00:43,  2.42it/s]\u001b[A\n",
            " 74% 296/400 [01:55<00:40,  2.55it/s]\u001b[A\n",
            " 74% 297/400 [01:56<00:41,  2.50it/s]\u001b[A\n",
            " 74% 298/400 [01:56<00:41,  2.45it/s]\u001b[A\n",
            " 75% 299/400 [01:56<00:41,  2.41it/s]\u001b[A\n",
            " 75% 300/400 [01:57<00:39,  2.56it/s]\u001b[A\n",
            " 75% 301/400 [01:57<00:39,  2.50it/s]\u001b[A\n",
            " 76% 302/400 [01:58<00:39,  2.48it/s]\u001b[A\n",
            " 76% 303/400 [01:58<00:39,  2.47it/s]\u001b[A\n",
            " 76% 304/400 [01:58<00:38,  2.47it/s]\u001b[A\n",
            " 76% 305/400 [01:59<00:38,  2.48it/s]\u001b[A\n",
            " 76% 306/400 [01:59<00:37,  2.48it/s]\u001b[A\n",
            " 77% 307/400 [02:00<00:37,  2.48it/s]\u001b[A\n",
            " 77% 308/400 [02:00<00:37,  2.48it/s]\u001b[A\n",
            " 77% 309/400 [02:00<00:36,  2.47it/s]\u001b[A\n",
            " 78% 310/400 [02:01<00:36,  2.48it/s]\u001b[A\n",
            " 78% 311/400 [02:01<00:36,  2.47it/s]\u001b[A\n",
            " 78% 312/400 [02:02<00:35,  2.47it/s]\u001b[A\n",
            " 78% 313/400 [02:02<00:35,  2.47it/s]\u001b[A\n",
            " 78% 314/400 [02:02<00:35,  2.46it/s]\u001b[A\n",
            " 79% 315/400 [02:03<00:34,  2.46it/s]\u001b[A\n",
            " 79% 316/400 [02:03<00:34,  2.46it/s]\u001b[A\n",
            " 79% 317/400 [02:04<00:33,  2.46it/s]\u001b[A\n",
            " 80% 318/400 [02:04<00:33,  2.46it/s]\u001b[A\n",
            " 80% 319/400 [02:04<00:32,  2.47it/s]\u001b[A\n",
            " 80% 320/400 [02:05<00:32,  2.47it/s]\u001b[A\n",
            " 80% 321/400 [02:05<00:31,  2.48it/s]\u001b[A\n",
            " 80% 322/400 [02:06<00:31,  2.48it/s]\u001b[A\n",
            " 81% 323/400 [02:06<00:29,  2.63it/s]\u001b[A\n",
            " 81% 324/400 [02:06<00:24,  3.07it/s]\u001b[A\n",
            " 81% 325/400 [02:06<00:23,  3.20it/s]\u001b[A\n",
            " 82% 326/400 [02:07<00:25,  2.93it/s]\u001b[A\n",
            " 82% 327/400 [02:07<00:26,  2.78it/s]\u001b[A\n",
            " 82% 328/400 [02:08<00:26,  2.75it/s]\u001b[A\n",
            " 82% 329/400 [02:08<00:26,  2.64it/s]\u001b[A\n",
            " 82% 330/400 [02:08<00:27,  2.57it/s]\u001b[A\n",
            " 83% 331/400 [02:09<00:27,  2.51it/s]\u001b[A\n",
            " 83% 332/400 [02:09<00:27,  2.47it/s]\u001b[A\n",
            " 83% 333/400 [02:10<00:27,  2.46it/s]\u001b[A\n",
            " 84% 334/400 [02:10<00:25,  2.63it/s]\u001b[A\n",
            " 84% 335/400 [02:10<00:25,  2.57it/s]\u001b[A\n",
            " 84% 336/400 [02:11<00:25,  2.53it/s]\u001b[A\n",
            " 84% 337/400 [02:11<00:25,  2.50it/s]\u001b[A\n",
            " 84% 338/400 [02:12<00:25,  2.47it/s]\u001b[A\n",
            " 85% 339/400 [02:12<00:25,  2.44it/s]\u001b[A\n",
            " 85% 340/400 [02:13<00:24,  2.41it/s]\u001b[A\n",
            " 85% 341/400 [02:13<00:24,  2.40it/s]\u001b[A\n",
            " 86% 342/400 [02:13<00:24,  2.40it/s]\u001b[A\n",
            " 86% 343/400 [02:14<00:23,  2.41it/s]\u001b[A\n",
            " 86% 344/400 [02:14<00:23,  2.43it/s]\u001b[A\n",
            " 86% 345/400 [02:15<00:22,  2.45it/s]\u001b[A\n",
            " 86% 346/400 [02:15<00:21,  2.46it/s]\u001b[A\n",
            " 87% 347/400 [02:15<00:21,  2.48it/s]\u001b[A\n",
            " 87% 348/400 [02:16<00:20,  2.48it/s]\u001b[A\n",
            " 87% 349/400 [02:16<00:20,  2.49it/s]\u001b[A\n",
            " 88% 350/400 [02:17<00:20,  2.48it/s]\u001b[A\n",
            " 88% 351/400 [02:17<00:19,  2.47it/s]\u001b[A\n",
            " 88% 352/400 [02:17<00:19,  2.48it/s]\u001b[A\n",
            " 88% 353/400 [02:18<00:18,  2.48it/s]\u001b[A\n",
            " 88% 354/400 [02:18<00:18,  2.49it/s]\u001b[A\n",
            " 89% 355/400 [02:19<00:18,  2.49it/s]\u001b[A\n",
            " 89% 356/400 [02:19<00:17,  2.49it/s]\u001b[A\n",
            " 89% 357/400 [02:19<00:17,  2.49it/s]\u001b[A\n",
            " 90% 358/400 [02:20<00:16,  2.48it/s]\u001b[A\n",
            " 90% 359/400 [02:20<00:16,  2.49it/s]\u001b[A\n",
            " 90% 360/400 [02:21<00:16,  2.50it/s]\u001b[A\n",
            " 90% 361/400 [02:21<00:15,  2.50it/s]\u001b[A\n",
            " 90% 362/400 [02:21<00:15,  2.49it/s]\u001b[A\n",
            " 91% 363/400 [02:22<00:14,  2.48it/s]\u001b[A\n",
            " 91% 364/400 [02:22<00:14,  2.49it/s]\u001b[A\n",
            " 91% 365/400 [02:22<00:11,  2.93it/s]\u001b[A\n",
            " 92% 366/400 [02:23<00:12,  2.77it/s]\u001b[A\n",
            " 92% 367/400 [02:23<00:11,  2.83it/s]\u001b[A\n",
            " 92% 368/400 [02:24<00:11,  2.71it/s]\u001b[A\n",
            " 92% 369/400 [02:24<00:11,  2.63it/s]\u001b[A\n",
            " 92% 370/400 [02:24<00:11,  2.59it/s]\u001b[A\n",
            " 93% 371/400 [02:25<00:11,  2.54it/s]\u001b[A\n",
            " 93% 372/400 [02:25<00:11,  2.51it/s]\u001b[A\n",
            " 93% 373/400 [02:26<00:10,  2.49it/s]\u001b[A\n",
            " 94% 374/400 [02:26<00:09,  2.73it/s]\u001b[A\n",
            " 94% 375/400 [02:26<00:09,  2.65it/s]\u001b[A\n",
            " 94% 376/400 [02:27<00:09,  2.58it/s]\u001b[A\n",
            " 94% 377/400 [02:27<00:09,  2.52it/s]\u001b[A\n",
            " 94% 378/400 [02:28<00:08,  2.48it/s]\u001b[A\n",
            " 95% 379/400 [02:28<00:08,  2.47it/s]\u001b[A\n",
            " 95% 380/400 [02:28<00:08,  2.47it/s]\u001b[A\n",
            " 95% 381/400 [02:29<00:07,  2.48it/s]\u001b[A\n",
            " 96% 382/400 [02:29<00:07,  2.48it/s]\u001b[A\n",
            " 96% 383/400 [02:30<00:06,  2.47it/s]\u001b[A\n",
            " 96% 384/400 [02:30<00:06,  2.48it/s]\u001b[A\n",
            " 96% 385/400 [02:30<00:06,  2.48it/s]\u001b[A\n",
            " 96% 386/400 [02:31<00:05,  2.50it/s]\u001b[A\n",
            " 97% 387/400 [02:31<00:05,  2.49it/s]\u001b[A\n",
            " 97% 388/400 [02:32<00:04,  2.48it/s]\u001b[A\n",
            " 97% 389/400 [02:32<00:04,  2.47it/s]\u001b[A\n",
            " 98% 390/400 [02:32<00:04,  2.46it/s]\u001b[A\n",
            " 98% 391/400 [02:33<00:03,  2.48it/s]\u001b[A\n",
            " 98% 392/400 [02:33<00:03,  2.49it/s]\u001b[A\n",
            " 98% 393/400 [02:34<00:02,  2.49it/s]\u001b[A\n",
            " 98% 394/400 [02:34<00:02,  2.49it/s]\u001b[A\n",
            " 99% 395/400 [02:34<00:02,  2.48it/s]\u001b[A\n",
            " 99% 396/400 [02:35<00:01,  2.48it/s]\u001b[A\n",
            " 99% 397/400 [02:35<00:01,  2.47it/s]\u001b[A\n",
            "100% 398/400 [02:36<00:00,  2.48it/s]\u001b[A\n",
            "100% 399/400 [02:36<00:00,  2.58it/s]\u001b[A\n",
            "                                      \n",
            "\u001b[A{'eval_loss': 1.4914401769638062, 'eval_rouge1': 14.3702, 'eval_rouge2': 8.5198, 'eval_rougeL': 14.0521, 'eval_rougeLsum': 14.0432, 'eval_bleu': 7.8056, 'eval_gen_len': 15.1244, 'eval_runtime': 183.9956, 'eval_samples_per_second': 8.696, 'eval_steps_per_second': 2.174, 'epoch': 0.67}\n",
            " 13% 200/1500 [05:01<10:42,  2.02it/s]\n",
            "100% 400/400 [03:03<00:00,  2.55it/s]\u001b[A\n",
            "                                     \u001b[ASaving model checkpoint to mT5_model_full/checkpoint-200\n",
            "Configuration saved in mT5_model_full/checkpoint-200/config.json\n",
            "Configuration saved in mT5_model_full/checkpoint-200/generation_config.json\n",
            "Model weights saved in mT5_model_full/checkpoint-200/pytorch_model.bin\n",
            "tokenizer config file saved in mT5_model_full/checkpoint-200/tokenizer_config.json\n",
            "Special tokens file saved in mT5_model_full/checkpoint-200/special_tokens_map.json\n",
            "Copy vocab file to mT5_model_full/checkpoint-200/spiece.model\n",
            "{'loss': 2.2535, 'learning_rate': 2.5e-05, 'epoch': 0.83}\n",
            "{'loss': 1.998, 'learning_rate': 2.4e-05, 'epoch': 1.0}\n",
            " 20% 300/1500 [06:09<09:51,  2.03it/s]Saving model checkpoint to mT5_model_full/checkpoint-300\n",
            "Configuration saved in mT5_model_full/checkpoint-300/config.json\n",
            "Configuration saved in mT5_model_full/checkpoint-300/generation_config.json\n",
            "Model weights saved in mT5_model_full/checkpoint-300/pytorch_model.bin\n",
            "tokenizer config file saved in mT5_model_full/checkpoint-300/tokenizer_config.json\n",
            "Special tokens file saved in mT5_model_full/checkpoint-300/special_tokens_map.json\n",
            "Copy vocab file to mT5_model_full/checkpoint-300/spiece.model\n",
            "{'loss': 1.8798, 'learning_rate': 2.3000000000000003e-05, 'epoch': 1.17}\n",
            "{'loss': 1.7055, 'learning_rate': 2.2e-05, 'epoch': 1.33}\n",
            " 27% 400/1500 [07:16<09:10,  2.00it/s]***** Running Evaluation *****\n",
            "  Num examples = 1600\n",
            "  Batch size = 4\n",
            "\n",
            "  0% 0/400 [00:00<?, ?it/s]\u001b[A\n",
            "  0% 2/400 [00:00<01:19,  4.98it/s]\u001b[A\n",
            "  1% 3/400 [00:00<01:52,  3.52it/s]\u001b[A\n",
            "  1% 4/400 [00:01<02:10,  3.02it/s]\u001b[A\n",
            "  1% 5/400 [00:01<02:20,  2.80it/s]\u001b[A\n",
            "  2% 6/400 [00:02<02:27,  2.67it/s]\u001b[A\n",
            "  2% 7/400 [00:02<02:31,  2.59it/s]\u001b[A\n",
            "  2% 8/400 [00:02<02:33,  2.55it/s]\u001b[A\n",
            "  2% 9/400 [00:03<02:35,  2.51it/s]\u001b[A\n",
            "  2% 10/400 [00:03<02:36,  2.50it/s]\u001b[A\n",
            "  3% 11/400 [00:04<02:37,  2.47it/s]\u001b[A\n",
            "  3% 12/400 [00:04<02:37,  2.46it/s]\u001b[A\n",
            "  3% 13/400 [00:04<02:37,  2.46it/s]\u001b[A\n",
            "  4% 14/400 [00:05<02:37,  2.46it/s]\u001b[A\n",
            "  4% 15/400 [00:05<02:36,  2.45it/s]\u001b[A\n",
            "  4% 16/400 [00:06<02:37,  2.44it/s]\u001b[A\n",
            "  4% 17/400 [00:06<02:37,  2.44it/s]\u001b[A\n",
            "  4% 18/400 [00:06<02:36,  2.45it/s]\u001b[A\n",
            "  5% 19/400 [00:07<02:36,  2.44it/s]\u001b[A\n",
            "  5% 20/400 [00:07<02:35,  2.45it/s]\u001b[A\n",
            "  5% 21/400 [00:08<02:34,  2.45it/s]\u001b[A\n",
            "  6% 22/400 [00:08<02:35,  2.43it/s]\u001b[A\n",
            "  6% 23/400 [00:09<02:35,  2.42it/s]\u001b[A\n",
            "  6% 24/400 [00:09<02:35,  2.42it/s]\u001b[A\n",
            "  6% 25/400 [00:09<02:34,  2.42it/s]\u001b[A\n",
            "  6% 26/400 [00:10<02:35,  2.41it/s]\u001b[A\n",
            "  7% 27/400 [00:10<02:35,  2.41it/s]\u001b[A\n",
            "  7% 28/400 [00:11<02:34,  2.41it/s]\u001b[A\n",
            "  7% 29/400 [00:11<02:33,  2.41it/s]\u001b[A\n",
            "  8% 30/400 [00:11<02:33,  2.42it/s]\u001b[A\n",
            "  8% 31/400 [00:12<02:33,  2.41it/s]\u001b[A\n",
            "  8% 32/400 [00:12<02:32,  2.41it/s]\u001b[A\n",
            "  8% 33/400 [00:13<02:32,  2.41it/s]\u001b[A\n",
            "  8% 34/400 [00:13<02:31,  2.42it/s]\u001b[A\n",
            "  9% 35/400 [00:13<02:31,  2.41it/s]\u001b[A\n",
            "  9% 36/400 [00:14<02:30,  2.42it/s]\u001b[A\n",
            "  9% 37/400 [00:14<02:29,  2.42it/s]\u001b[A\n",
            " 10% 38/400 [00:15<02:30,  2.41it/s]\u001b[A\n",
            " 10% 39/400 [00:15<02:28,  2.43it/s]\u001b[A\n",
            " 10% 40/400 [00:16<02:27,  2.44it/s]\u001b[A\n",
            " 10% 41/400 [00:16<02:27,  2.43it/s]\u001b[A\n",
            " 10% 42/400 [00:16<02:26,  2.44it/s]\u001b[A\n",
            " 11% 43/400 [00:17<02:26,  2.44it/s]\u001b[A\n",
            " 11% 44/400 [00:17<02:25,  2.44it/s]\u001b[A\n",
            " 11% 45/400 [00:18<02:25,  2.44it/s]\u001b[A\n",
            " 12% 46/400 [00:18<02:24,  2.46it/s]\u001b[A\n",
            " 12% 47/400 [00:18<02:23,  2.47it/s]\u001b[A\n",
            " 12% 48/400 [00:19<02:23,  2.46it/s]\u001b[A\n",
            " 12% 49/400 [00:19<02:22,  2.46it/s]\u001b[A\n",
            " 12% 50/400 [00:20<02:22,  2.46it/s]\u001b[A\n",
            " 13% 51/400 [00:20<02:22,  2.45it/s]\u001b[A\n",
            " 13% 52/400 [00:20<02:21,  2.45it/s]\u001b[A\n",
            " 13% 53/400 [00:21<02:20,  2.46it/s]\u001b[A\n",
            " 14% 54/400 [00:21<02:20,  2.46it/s]\u001b[A\n",
            " 14% 55/400 [00:22<02:20,  2.46it/s]\u001b[A\n",
            " 14% 56/400 [00:22<02:21,  2.44it/s]\u001b[A\n",
            " 14% 57/400 [00:22<02:20,  2.45it/s]\u001b[A\n",
            " 14% 58/400 [00:23<02:19,  2.45it/s]\u001b[A\n",
            " 15% 59/400 [00:23<02:19,  2.44it/s]\u001b[A\n",
            " 15% 60/400 [00:24<02:20,  2.42it/s]\u001b[A\n",
            " 15% 61/400 [00:24<02:21,  2.39it/s]\u001b[A\n",
            " 16% 62/400 [00:25<02:21,  2.38it/s]\u001b[A\n",
            " 16% 63/400 [00:25<02:21,  2.38it/s]\u001b[A\n",
            " 16% 64/400 [00:25<02:21,  2.38it/s]\u001b[A\n",
            " 16% 65/400 [00:26<02:21,  2.37it/s]\u001b[A\n",
            " 16% 66/400 [00:26<02:23,  2.33it/s]\u001b[A\n",
            " 17% 67/400 [00:27<02:21,  2.35it/s]\u001b[A\n",
            " 17% 68/400 [00:27<02:21,  2.34it/s]\u001b[A\n",
            " 17% 69/400 [00:28<02:20,  2.35it/s]\u001b[A\n",
            " 18% 70/400 [00:28<02:19,  2.37it/s]\u001b[A\n",
            " 18% 71/400 [00:28<02:18,  2.37it/s]\u001b[A\n",
            " 18% 72/400 [00:29<02:17,  2.39it/s]\u001b[A\n",
            " 18% 73/400 [00:29<02:15,  2.41it/s]\u001b[A\n",
            " 18% 74/400 [00:30<02:14,  2.42it/s]\u001b[A\n",
            " 19% 75/400 [00:30<02:13,  2.43it/s]\u001b[A\n",
            " 19% 76/400 [00:30<02:13,  2.43it/s]\u001b[A\n",
            " 19% 77/400 [00:31<02:12,  2.45it/s]\u001b[A\n",
            " 20% 78/400 [00:31<02:11,  2.45it/s]\u001b[A\n",
            " 20% 79/400 [00:32<02:11,  2.44it/s]\u001b[A\n",
            " 20% 80/400 [00:32<02:07,  2.52it/s]\u001b[A\n",
            " 20% 81/400 [00:32<02:08,  2.49it/s]\u001b[A\n",
            " 20% 82/400 [00:33<02:07,  2.49it/s]\u001b[A\n",
            " 21% 83/400 [00:33<02:08,  2.46it/s]\u001b[A\n",
            " 21% 84/400 [00:34<02:08,  2.46it/s]\u001b[A\n",
            " 21% 85/400 [00:34<02:08,  2.45it/s]\u001b[A\n",
            " 22% 86/400 [00:34<02:08,  2.44it/s]\u001b[A\n",
            " 22% 87/400 [00:35<02:07,  2.45it/s]\u001b[A\n",
            " 22% 88/400 [00:35<02:08,  2.42it/s]\u001b[A\n",
            " 22% 89/400 [00:36<02:07,  2.44it/s]\u001b[A\n",
            " 22% 90/400 [00:36<02:07,  2.43it/s]\u001b[A\n",
            " 23% 91/400 [00:37<02:06,  2.44it/s]\u001b[A\n",
            " 23% 92/400 [00:37<02:05,  2.45it/s]\u001b[A\n",
            " 23% 93/400 [00:37<02:05,  2.45it/s]\u001b[A\n",
            " 24% 94/400 [00:38<02:04,  2.45it/s]\u001b[A\n",
            " 24% 95/400 [00:38<02:04,  2.45it/s]\u001b[A\n",
            " 24% 96/400 [00:39<02:04,  2.45it/s]\u001b[A\n",
            " 24% 97/400 [00:39<02:03,  2.44it/s]\u001b[A\n",
            " 24% 98/400 [00:39<02:03,  2.44it/s]\u001b[A\n",
            " 25% 99/400 [00:40<02:03,  2.44it/s]\u001b[A\n",
            " 25% 100/400 [00:40<02:03,  2.43it/s]\u001b[A\n",
            " 25% 101/400 [00:41<02:03,  2.43it/s]\u001b[A\n",
            " 26% 102/400 [00:41<02:02,  2.43it/s]\u001b[A\n",
            " 26% 103/400 [00:41<02:02,  2.43it/s]\u001b[A\n",
            " 26% 104/400 [00:42<02:02,  2.42it/s]\u001b[A\n",
            " 26% 105/400 [00:42<02:01,  2.42it/s]\u001b[A\n",
            " 26% 106/400 [00:43<02:01,  2.41it/s]\u001b[A\n",
            " 27% 107/400 [00:43<02:01,  2.42it/s]\u001b[A\n",
            " 27% 108/400 [00:44<02:00,  2.42it/s]\u001b[A\n",
            " 27% 109/400 [00:44<01:59,  2.43it/s]\u001b[A\n",
            " 28% 110/400 [00:44<01:57,  2.46it/s]\u001b[A\n",
            " 28% 111/400 [00:45<01:57,  2.45it/s]\u001b[A\n",
            " 28% 112/400 [00:45<01:58,  2.43it/s]\u001b[A\n",
            " 28% 113/400 [00:46<01:58,  2.41it/s]\u001b[A\n",
            " 28% 114/400 [00:46<01:58,  2.41it/s]\u001b[A\n",
            " 29% 115/400 [00:46<01:57,  2.43it/s]\u001b[A\n",
            " 29% 116/400 [00:47<01:56,  2.43it/s]\u001b[A\n",
            " 29% 117/400 [00:47<01:55,  2.45it/s]\u001b[A\n",
            " 30% 118/400 [00:48<01:55,  2.45it/s]\u001b[A\n",
            " 30% 119/400 [00:48<01:54,  2.46it/s]\u001b[A\n",
            " 30% 120/400 [00:48<01:54,  2.45it/s]\u001b[A\n",
            " 30% 121/400 [00:49<01:53,  2.46it/s]\u001b[A\n",
            " 30% 122/400 [00:49<01:51,  2.49it/s]\u001b[A\n",
            " 31% 123/400 [00:50<01:52,  2.47it/s]\u001b[A\n",
            " 31% 124/400 [00:50<01:51,  2.48it/s]\u001b[A\n",
            " 31% 125/400 [00:50<01:50,  2.49it/s]\u001b[A\n",
            " 32% 126/400 [00:51<01:50,  2.49it/s]\u001b[A\n",
            " 32% 127/400 [00:51<01:50,  2.48it/s]\u001b[A\n",
            " 32% 128/400 [00:52<01:49,  2.47it/s]\u001b[A\n",
            " 32% 129/400 [00:52<01:49,  2.47it/s]\u001b[A\n",
            " 32% 130/400 [00:52<01:49,  2.47it/s]\u001b[A\n",
            " 33% 131/400 [00:53<01:48,  2.48it/s]\u001b[A\n",
            " 33% 132/400 [00:53<01:48,  2.47it/s]\u001b[A\n",
            " 33% 133/400 [00:54<01:49,  2.44it/s]\u001b[A\n",
            " 34% 134/400 [00:54<01:49,  2.42it/s]\u001b[A\n",
            " 34% 135/400 [00:55<01:50,  2.40it/s]\u001b[A\n",
            " 34% 136/400 [00:55<01:50,  2.38it/s]\u001b[A\n",
            " 34% 137/400 [00:55<01:50,  2.37it/s]\u001b[A\n",
            " 34% 138/400 [00:56<01:50,  2.37it/s]\u001b[A\n",
            " 35% 139/400 [00:56<01:49,  2.39it/s]\u001b[A\n",
            " 35% 140/400 [00:57<01:48,  2.39it/s]\u001b[A\n",
            " 35% 141/400 [00:57<01:48,  2.39it/s]\u001b[A\n",
            " 36% 142/400 [00:57<01:47,  2.40it/s]\u001b[A\n",
            " 36% 143/400 [00:58<01:46,  2.41it/s]\u001b[A\n",
            " 36% 144/400 [00:58<01:46,  2.41it/s]\u001b[A\n",
            " 36% 145/400 [00:59<01:45,  2.41it/s]\u001b[A\n",
            " 36% 146/400 [00:59<01:44,  2.43it/s]\u001b[A\n",
            " 37% 147/400 [01:00<01:43,  2.45it/s]\u001b[A\n",
            " 37% 148/400 [01:00<01:41,  2.47it/s]\u001b[A\n",
            " 37% 149/400 [01:00<01:41,  2.47it/s]\u001b[A\n",
            " 38% 150/400 [01:01<01:41,  2.47it/s]\u001b[A\n",
            " 38% 151/400 [01:01<01:37,  2.54it/s]\u001b[A\n",
            " 38% 152/400 [01:01<01:38,  2.53it/s]\u001b[A\n",
            " 38% 153/400 [01:02<01:38,  2.50it/s]\u001b[A\n",
            " 38% 154/400 [01:02<01:38,  2.50it/s]\u001b[A\n",
            " 39% 155/400 [01:03<01:38,  2.49it/s]\u001b[A\n",
            " 39% 156/400 [01:03<01:38,  2.48it/s]\u001b[A\n",
            " 39% 157/400 [01:04<01:38,  2.48it/s]\u001b[A\n",
            " 40% 158/400 [01:04<01:37,  2.47it/s]\u001b[A\n",
            " 40% 159/400 [01:04<01:37,  2.47it/s]\u001b[A\n",
            " 40% 160/400 [01:05<01:37,  2.47it/s]\u001b[A\n",
            " 40% 161/400 [01:05<01:36,  2.46it/s]\u001b[A\n",
            " 40% 162/400 [01:06<01:37,  2.45it/s]\u001b[A\n",
            " 41% 163/400 [01:06<01:36,  2.45it/s]\u001b[A\n",
            " 41% 164/400 [01:06<01:35,  2.46it/s]\u001b[A\n",
            " 41% 165/400 [01:07<01:35,  2.45it/s]\u001b[A\n",
            " 42% 166/400 [01:07<01:35,  2.45it/s]\u001b[A\n",
            " 42% 167/400 [01:08<01:34,  2.46it/s]\u001b[A\n",
            " 42% 168/400 [01:08<01:34,  2.46it/s]\u001b[A\n",
            " 42% 169/400 [01:08<01:33,  2.46it/s]\u001b[A\n",
            " 42% 170/400 [01:09<01:33,  2.46it/s]\u001b[A\n",
            " 43% 171/400 [01:09<01:33,  2.44it/s]\u001b[A\n",
            " 43% 172/400 [01:10<01:34,  2.41it/s]\u001b[A\n",
            " 43% 173/400 [01:10<01:34,  2.40it/s]\u001b[A\n",
            " 44% 174/400 [01:10<01:34,  2.39it/s]\u001b[A\n",
            " 44% 175/400 [01:11<01:33,  2.40it/s]\u001b[A\n",
            " 44% 176/400 [01:11<01:33,  2.40it/s]\u001b[A\n",
            " 44% 177/400 [01:12<01:32,  2.40it/s]\u001b[A\n",
            " 44% 178/400 [01:12<01:32,  2.40it/s]\u001b[A\n",
            " 45% 179/400 [01:13<01:32,  2.40it/s]\u001b[A\n",
            " 45% 180/400 [01:13<01:31,  2.41it/s]\u001b[A\n",
            " 45% 181/400 [01:13<01:31,  2.40it/s]\u001b[A\n",
            " 46% 182/400 [01:14<01:30,  2.40it/s]\u001b[A\n",
            " 46% 183/400 [01:14<01:30,  2.41it/s]\u001b[A\n",
            " 46% 184/400 [01:15<01:29,  2.43it/s]\u001b[A\n",
            " 46% 185/400 [01:15<01:28,  2.44it/s]\u001b[A\n",
            " 46% 186/400 [01:15<01:27,  2.45it/s]\u001b[A\n",
            " 47% 187/400 [01:16<01:27,  2.45it/s]\u001b[A\n",
            " 47% 188/400 [01:16<01:27,  2.44it/s]\u001b[A\n",
            " 47% 189/400 [01:17<01:26,  2.44it/s]\u001b[A\n",
            " 48% 190/400 [01:17<01:25,  2.45it/s]\u001b[A\n",
            " 48% 191/400 [01:17<01:25,  2.45it/s]\u001b[A\n",
            " 48% 192/400 [01:18<01:24,  2.47it/s]\u001b[A\n",
            " 48% 193/400 [01:18<01:23,  2.48it/s]\u001b[A\n",
            " 48% 194/400 [01:19<01:23,  2.46it/s]\u001b[A\n",
            " 49% 195/400 [01:19<01:23,  2.46it/s]\u001b[A\n",
            " 49% 196/400 [01:20<01:23,  2.45it/s]\u001b[A\n",
            " 49% 197/400 [01:20<01:22,  2.46it/s]\u001b[A\n",
            " 50% 198/400 [01:20<01:21,  2.47it/s]\u001b[A\n",
            " 50% 199/400 [01:21<01:21,  2.48it/s]\u001b[A\n",
            " 50% 200/400 [01:21<01:14,  2.67it/s]\u001b[A\n",
            " 50% 201/400 [01:21<01:16,  2.59it/s]\u001b[A\n",
            " 50% 202/400 [01:22<01:18,  2.53it/s]\u001b[A\n",
            " 51% 203/400 [01:22<01:19,  2.49it/s]\u001b[A\n",
            " 51% 204/400 [01:23<01:19,  2.47it/s]\u001b[A\n",
            " 51% 205/400 [01:23<01:19,  2.46it/s]\u001b[A\n",
            " 52% 206/400 [01:24<01:18,  2.46it/s]\u001b[A\n",
            " 52% 207/400 [01:24<01:18,  2.46it/s]\u001b[A\n",
            " 52% 208/400 [01:24<01:18,  2.44it/s]\u001b[A\n",
            " 52% 209/400 [01:25<01:18,  2.43it/s]\u001b[A\n",
            " 52% 210/400 [01:25<01:18,  2.43it/s]\u001b[A\n",
            " 53% 211/400 [01:26<01:18,  2.39it/s]\u001b[A\n",
            " 53% 212/400 [01:26<01:18,  2.39it/s]\u001b[A\n",
            " 53% 213/400 [01:26<01:18,  2.38it/s]\u001b[A\n",
            " 54% 214/400 [01:27<01:18,  2.38it/s]\u001b[A\n",
            " 54% 215/400 [01:27<01:18,  2.37it/s]\u001b[A\n",
            " 54% 216/400 [01:28<01:17,  2.39it/s]\u001b[A\n",
            " 54% 217/400 [01:28<01:16,  2.39it/s]\u001b[A\n",
            " 55% 218/400 [01:29<01:16,  2.39it/s]\u001b[A\n",
            " 55% 219/400 [01:29<01:15,  2.41it/s]\u001b[A\n",
            " 55% 220/400 [01:29<01:14,  2.42it/s]\u001b[A\n",
            " 55% 221/400 [01:30<01:13,  2.44it/s]\u001b[A\n",
            " 56% 222/400 [01:30<01:12,  2.45it/s]\u001b[A\n",
            " 56% 223/400 [01:31<01:12,  2.43it/s]\u001b[A\n",
            " 56% 224/400 [01:31<01:11,  2.45it/s]\u001b[A\n",
            " 56% 225/400 [01:31<01:10,  2.47it/s]\u001b[A\n",
            " 56% 226/400 [01:32<01:10,  2.46it/s]\u001b[A\n",
            " 57% 227/400 [01:32<01:10,  2.44it/s]\u001b[A\n",
            " 57% 228/400 [01:33<01:10,  2.44it/s]\u001b[A\n",
            " 57% 229/400 [01:33<01:10,  2.44it/s]\u001b[A\n",
            " 57% 230/400 [01:33<01:09,  2.44it/s]\u001b[A\n",
            " 58% 231/400 [01:34<01:09,  2.44it/s]\u001b[A\n",
            " 58% 232/400 [01:34<01:08,  2.44it/s]\u001b[A\n",
            " 58% 233/400 [01:35<01:08,  2.44it/s]\u001b[A\n",
            " 58% 234/400 [01:35<01:07,  2.46it/s]\u001b[A\n",
            " 59% 235/400 [01:35<01:07,  2.45it/s]\u001b[A\n",
            " 59% 236/400 [01:36<01:06,  2.46it/s]\u001b[A\n",
            " 59% 237/400 [01:36<01:06,  2.46it/s]\u001b[A\n",
            " 60% 238/400 [01:37<01:06,  2.45it/s]\u001b[A\n",
            " 60% 239/400 [01:37<01:05,  2.46it/s]\u001b[A\n",
            " 60% 240/400 [01:38<01:05,  2.45it/s]\u001b[A\n",
            " 60% 241/400 [01:38<01:04,  2.45it/s]\u001b[A\n",
            " 60% 242/400 [01:38<01:04,  2.45it/s]\u001b[A\n",
            " 61% 243/400 [01:39<01:04,  2.42it/s]\u001b[A\n",
            " 61% 244/400 [01:39<01:04,  2.42it/s]\u001b[A\n",
            " 61% 245/400 [01:40<01:04,  2.40it/s]\u001b[A\n",
            " 62% 246/400 [01:40<01:04,  2.39it/s]\u001b[A\n",
            " 62% 247/400 [01:40<01:03,  2.40it/s]\u001b[A\n",
            " 62% 248/400 [01:41<01:03,  2.41it/s]\u001b[A\n",
            " 62% 249/400 [01:41<01:02,  2.42it/s]\u001b[A\n",
            " 62% 250/400 [01:42<01:01,  2.42it/s]\u001b[A\n",
            " 63% 251/400 [01:42<01:01,  2.43it/s]\u001b[A\n",
            " 63% 252/400 [01:42<01:01,  2.42it/s]\u001b[A\n",
            " 63% 253/400 [01:43<01:00,  2.42it/s]\u001b[A\n",
            " 64% 254/400 [01:43<01:00,  2.41it/s]\u001b[A\n",
            " 64% 255/400 [01:44<01:00,  2.39it/s]\u001b[A\n",
            " 64% 256/400 [01:44<00:59,  2.40it/s]\u001b[A\n",
            " 64% 257/400 [01:45<00:59,  2.40it/s]\u001b[A\n",
            " 64% 258/400 [01:45<00:59,  2.40it/s]\u001b[A\n",
            " 65% 259/400 [01:45<00:58,  2.40it/s]\u001b[A\n",
            " 65% 260/400 [01:46<00:57,  2.42it/s]\u001b[A\n",
            " 65% 261/400 [01:46<00:57,  2.43it/s]\u001b[A\n",
            " 66% 262/400 [01:47<00:56,  2.44it/s]\u001b[A\n",
            " 66% 263/400 [01:47<00:56,  2.43it/s]\u001b[A\n",
            " 66% 264/400 [01:47<00:55,  2.44it/s]\u001b[A\n",
            " 66% 265/400 [01:48<00:55,  2.42it/s]\u001b[A\n",
            " 66% 266/400 [01:48<00:55,  2.42it/s]\u001b[A\n",
            " 67% 267/400 [01:49<00:54,  2.43it/s]\u001b[A\n",
            " 67% 268/400 [01:49<00:54,  2.42it/s]\u001b[A\n",
            " 67% 269/400 [01:50<00:53,  2.44it/s]\u001b[A\n",
            " 68% 270/400 [01:50<00:53,  2.45it/s]\u001b[A\n",
            " 68% 271/400 [01:50<00:52,  2.45it/s]\u001b[A\n",
            " 68% 272/400 [01:51<00:52,  2.45it/s]\u001b[A\n",
            " 68% 273/400 [01:51<00:51,  2.45it/s]\u001b[A\n",
            " 68% 274/400 [01:52<00:51,  2.44it/s]\u001b[A\n",
            " 69% 275/400 [01:52<00:51,  2.43it/s]\u001b[A\n",
            " 69% 276/400 [01:52<00:50,  2.44it/s]\u001b[A\n",
            " 69% 277/400 [01:53<00:50,  2.45it/s]\u001b[A\n",
            " 70% 278/400 [01:53<00:49,  2.45it/s]\u001b[A\n",
            " 70% 279/400 [01:54<00:49,  2.43it/s]\u001b[A\n",
            " 70% 280/400 [01:54<00:49,  2.41it/s]\u001b[A\n",
            " 70% 281/400 [01:54<00:49,  2.40it/s]\u001b[A\n",
            " 70% 282/400 [01:55<00:49,  2.37it/s]\u001b[A\n",
            " 71% 283/400 [01:55<00:50,  2.33it/s]\u001b[A\n",
            " 71% 284/400 [01:56<00:50,  2.31it/s]\u001b[A\n",
            " 71% 285/400 [01:56<00:49,  2.33it/s]\u001b[A\n",
            " 72% 286/400 [01:57<00:48,  2.34it/s]\u001b[A\n",
            " 72% 287/400 [01:57<00:47,  2.36it/s]\u001b[A\n",
            " 72% 288/400 [01:57<00:47,  2.36it/s]\u001b[A\n",
            " 72% 289/400 [01:58<00:46,  2.38it/s]\u001b[A\n",
            " 72% 290/400 [01:58<00:46,  2.38it/s]\u001b[A\n",
            " 73% 291/400 [01:59<00:45,  2.38it/s]\u001b[A\n",
            " 73% 292/400 [01:59<00:45,  2.37it/s]\u001b[A\n",
            " 73% 293/400 [02:00<00:45,  2.37it/s]\u001b[A\n",
            " 74% 294/400 [02:00<00:44,  2.37it/s]\u001b[A\n",
            " 74% 295/400 [02:00<00:43,  2.39it/s]\u001b[A\n",
            " 74% 296/400 [02:01<00:43,  2.41it/s]\u001b[A\n",
            " 74% 297/400 [02:01<00:42,  2.41it/s]\u001b[A\n",
            " 74% 298/400 [02:02<00:42,  2.42it/s]\u001b[A\n",
            " 75% 299/400 [02:02<00:41,  2.44it/s]\u001b[A\n",
            " 75% 300/400 [02:02<00:40,  2.45it/s]\u001b[A\n",
            " 75% 301/400 [02:03<00:40,  2.44it/s]\u001b[A\n",
            " 76% 302/400 [02:03<00:40,  2.44it/s]\u001b[A\n",
            " 76% 303/400 [02:04<00:39,  2.44it/s]\u001b[A\n",
            " 76% 304/400 [02:04<00:39,  2.45it/s]\u001b[A\n",
            " 76% 305/400 [02:04<00:38,  2.45it/s]\u001b[A\n",
            " 76% 306/400 [02:05<00:38,  2.45it/s]\u001b[A\n",
            " 77% 307/400 [02:05<00:37,  2.45it/s]\u001b[A\n",
            " 77% 308/400 [02:06<00:37,  2.44it/s]\u001b[A\n",
            " 77% 309/400 [02:06<00:37,  2.44it/s]\u001b[A\n",
            " 78% 310/400 [02:07<00:36,  2.44it/s]\u001b[A\n",
            " 78% 311/400 [02:07<00:36,  2.44it/s]\u001b[A\n",
            " 78% 312/400 [02:07<00:36,  2.44it/s]\u001b[A\n",
            " 78% 313/400 [02:08<00:35,  2.43it/s]\u001b[A\n",
            " 78% 314/400 [02:08<00:35,  2.43it/s]\u001b[A\n",
            " 79% 315/400 [02:09<00:34,  2.44it/s]\u001b[A\n",
            " 79% 316/400 [02:09<00:34,  2.45it/s]\u001b[A\n",
            " 79% 317/400 [02:09<00:34,  2.44it/s]\u001b[A\n",
            " 80% 318/400 [02:10<00:33,  2.43it/s]\u001b[A\n",
            " 80% 319/400 [02:10<00:33,  2.42it/s]\u001b[A\n",
            " 80% 320/400 [02:11<00:33,  2.40it/s]\u001b[A\n",
            " 80% 321/400 [02:11<00:32,  2.40it/s]\u001b[A\n",
            " 80% 322/400 [02:11<00:32,  2.41it/s]\u001b[A\n",
            " 81% 323/400 [02:12<00:31,  2.42it/s]\u001b[A\n",
            " 81% 324/400 [02:12<00:31,  2.43it/s]\u001b[A\n",
            " 81% 325/400 [02:13<00:30,  2.42it/s]\u001b[A\n",
            " 82% 326/400 [02:13<00:30,  2.41it/s]\u001b[A\n",
            " 82% 327/400 [02:14<00:30,  2.40it/s]\u001b[A\n",
            " 82% 328/400 [02:14<00:29,  2.41it/s]\u001b[A\n",
            " 82% 329/400 [02:14<00:29,  2.41it/s]\u001b[A\n",
            " 82% 330/400 [02:15<00:28,  2.42it/s]\u001b[A\n",
            " 83% 331/400 [02:15<00:28,  2.42it/s]\u001b[A\n",
            " 83% 332/400 [02:16<00:27,  2.44it/s]\u001b[A\n",
            " 83% 333/400 [02:16<00:27,  2.45it/s]\u001b[A\n",
            " 84% 334/400 [02:16<00:26,  2.46it/s]\u001b[A\n",
            " 84% 335/400 [02:17<00:26,  2.46it/s]\u001b[A\n",
            " 84% 336/400 [02:17<00:25,  2.47it/s]\u001b[A\n",
            " 84% 337/400 [02:18<00:25,  2.46it/s]\u001b[A\n",
            " 84% 338/400 [02:18<00:25,  2.47it/s]\u001b[A\n",
            " 85% 339/400 [02:18<00:24,  2.47it/s]\u001b[A\n",
            " 85% 340/400 [02:19<00:24,  2.46it/s]\u001b[A\n",
            " 85% 341/400 [02:19<00:23,  2.47it/s]\u001b[A\n",
            " 86% 342/400 [02:20<00:23,  2.46it/s]\u001b[A\n",
            " 86% 343/400 [02:20<00:23,  2.46it/s]\u001b[A\n",
            " 86% 344/400 [02:20<00:22,  2.47it/s]\u001b[A\n",
            " 86% 345/400 [02:21<00:22,  2.46it/s]\u001b[A\n",
            " 86% 346/400 [02:21<00:21,  2.46it/s]\u001b[A\n",
            " 87% 347/400 [02:22<00:21,  2.46it/s]\u001b[A\n",
            " 87% 348/400 [02:22<00:21,  2.46it/s]\u001b[A\n",
            " 87% 349/400 [02:22<00:20,  2.46it/s]\u001b[A\n",
            " 88% 350/400 [02:23<00:20,  2.46it/s]\u001b[A\n",
            " 88% 351/400 [02:23<00:19,  2.47it/s]\u001b[A\n",
            " 88% 352/400 [02:24<00:19,  2.47it/s]\u001b[A\n",
            " 88% 353/400 [02:24<00:19,  2.47it/s]\u001b[A\n",
            " 88% 354/400 [02:25<00:18,  2.47it/s]\u001b[A\n",
            " 89% 355/400 [02:25<00:18,  2.47it/s]\u001b[A\n",
            " 89% 356/400 [02:25<00:17,  2.47it/s]\u001b[A\n",
            " 89% 357/400 [02:26<00:17,  2.46it/s]\u001b[A\n",
            " 90% 358/400 [02:26<00:17,  2.44it/s]\u001b[A\n",
            " 90% 359/400 [02:27<00:16,  2.43it/s]\u001b[A\n",
            " 90% 360/400 [02:27<00:16,  2.43it/s]\u001b[A\n",
            " 90% 361/400 [02:27<00:16,  2.43it/s]\u001b[A\n",
            " 90% 362/400 [02:28<00:15,  2.42it/s]\u001b[A\n",
            " 91% 363/400 [02:28<00:15,  2.39it/s]\u001b[A\n",
            " 91% 364/400 [02:29<00:14,  2.40it/s]\u001b[A\n",
            " 91% 365/400 [02:29<00:14,  2.43it/s]\u001b[A\n",
            " 92% 366/400 [02:29<00:14,  2.43it/s]\u001b[A\n",
            " 92% 367/400 [02:30<00:13,  2.43it/s]\u001b[A\n",
            " 92% 368/400 [02:30<00:13,  2.44it/s]\u001b[A\n",
            " 92% 369/400 [02:31<00:12,  2.44it/s]\u001b[A\n",
            " 92% 370/400 [02:31<00:12,  2.45it/s]\u001b[A\n",
            " 93% 371/400 [02:31<00:11,  2.45it/s]\u001b[A\n",
            " 93% 372/400 [02:32<00:11,  2.45it/s]\u001b[A\n",
            " 93% 373/400 [02:32<00:11,  2.45it/s]\u001b[A\n",
            " 94% 374/400 [02:33<00:10,  2.45it/s]\u001b[A\n",
            " 94% 375/400 [02:33<00:10,  2.45it/s]\u001b[A\n",
            " 94% 376/400 [02:34<00:09,  2.45it/s]\u001b[A\n",
            " 94% 377/400 [02:34<00:09,  2.45it/s]\u001b[A\n",
            " 94% 378/400 [02:34<00:08,  2.46it/s]\u001b[A\n",
            " 95% 379/400 [02:35<00:08,  2.45it/s]\u001b[A\n",
            " 95% 380/400 [02:35<00:08,  2.47it/s]\u001b[A\n",
            " 95% 381/400 [02:36<00:07,  2.47it/s]\u001b[A\n",
            " 96% 382/400 [02:36<00:07,  2.47it/s]\u001b[A\n",
            " 96% 383/400 [02:36<00:06,  2.47it/s]\u001b[A\n",
            " 96% 384/400 [02:37<00:06,  2.47it/s]\u001b[A\n",
            " 96% 385/400 [02:37<00:06,  2.47it/s]\u001b[A\n",
            " 96% 386/400 [02:38<00:05,  2.46it/s]\u001b[A\n",
            " 97% 387/400 [02:38<00:05,  2.45it/s]\u001b[A\n",
            " 97% 388/400 [02:38<00:04,  2.46it/s]\u001b[A\n",
            " 97% 389/400 [02:39<00:04,  2.47it/s]\u001b[A\n",
            " 98% 390/400 [02:39<00:04,  2.46it/s]\u001b[A\n",
            " 98% 391/400 [02:40<00:03,  2.46it/s]\u001b[A\n",
            " 98% 392/400 [02:40<00:03,  2.46it/s]\u001b[A\n",
            " 98% 393/400 [02:40<00:02,  2.46it/s]\u001b[A\n",
            " 98% 394/400 [02:41<00:02,  2.45it/s]\u001b[A\n",
            " 99% 395/400 [02:41<00:02,  2.42it/s]\u001b[A\n",
            " 99% 396/400 [02:42<00:01,  2.42it/s]\u001b[A\n",
            " 99% 397/400 [02:42<00:01,  2.43it/s]\u001b[A\n",
            "100% 398/400 [02:43<00:00,  2.44it/s]\u001b[A\n",
            "100% 399/400 [02:43<00:00,  2.44it/s]\u001b[A\n",
            "                                      \n",
            "\u001b[A{'eval_loss': 1.2044764757156372, 'eval_rouge1': 22.9488, 'eval_rouge2': 14.9406, 'eval_rougeL': 22.7227, 'eval_rougeLsum': 22.7309, 'eval_bleu': 13.249, 'eval_gen_len': 18.3744, 'eval_runtime': 190.3292, 'eval_samples_per_second': 8.406, 'eval_steps_per_second': 2.102, 'epoch': 1.33}\n",
            " 27% 400/1500 [10:26<09:10,  2.00it/s]\n",
            "100% 400/400 [03:09<00:00,  2.45it/s]\u001b[A\n",
            "                                     \u001b[ASaving model checkpoint to mT5_model_full/checkpoint-400\n",
            "Configuration saved in mT5_model_full/checkpoint-400/config.json\n",
            "Configuration saved in mT5_model_full/checkpoint-400/generation_config.json\n",
            "Model weights saved in mT5_model_full/checkpoint-400/pytorch_model.bin\n",
            "tokenizer config file saved in mT5_model_full/checkpoint-400/tokenizer_config.json\n",
            "Special tokens file saved in mT5_model_full/checkpoint-400/special_tokens_map.json\n",
            "Copy vocab file to mT5_model_full/checkpoint-400/spiece.model\n",
            "{'loss': 1.8004, 'learning_rate': 2.1e-05, 'epoch': 1.5}\n",
            "{'loss': 1.6643, 'learning_rate': 1.9999999999999998e-05, 'epoch': 1.67}\n",
            " 33% 500/1500 [11:35<08:36,  1.94it/s]Saving model checkpoint to mT5_model_full/checkpoint-500\n",
            "Configuration saved in mT5_model_full/checkpoint-500/config.json\n",
            "Configuration saved in mT5_model_full/checkpoint-500/generation_config.json\n",
            "Model weights saved in mT5_model_full/checkpoint-500/pytorch_model.bin\n",
            "tokenizer config file saved in mT5_model_full/checkpoint-500/tokenizer_config.json\n",
            "Special tokens file saved in mT5_model_full/checkpoint-500/special_tokens_map.json\n",
            "Copy vocab file to mT5_model_full/checkpoint-500/spiece.model\n",
            "{'loss': 1.6482, 'learning_rate': 1.9e-05, 'epoch': 1.83}\n",
            "{'loss': 1.5055, 'learning_rate': 1.8e-05, 'epoch': 2.0}\n",
            " 40% 600/1500 [12:44<07:31,  1.99it/s]***** Running Evaluation *****\n",
            "  Num examples = 1600\n",
            "  Batch size = 4\n",
            "\n",
            "  0% 0/400 [00:00<?, ?it/s]\u001b[A\n",
            "  0% 2/400 [00:00<01:19,  5.03it/s]\u001b[A\n",
            "  1% 3/400 [00:00<01:52,  3.53it/s]\u001b[A\n",
            "  1% 4/400 [00:01<02:09,  3.06it/s]\u001b[A\n",
            "  1% 5/400 [00:01<02:19,  2.84it/s]\u001b[A\n",
            "  2% 6/400 [00:02<02:26,  2.69it/s]\u001b[A\n",
            "  2% 7/400 [00:02<02:31,  2.59it/s]\u001b[A\n",
            "  2% 8/400 [00:02<02:33,  2.55it/s]\u001b[A\n",
            "  2% 9/400 [00:03<02:35,  2.52it/s]\u001b[A\n",
            "  2% 10/400 [00:03<02:36,  2.50it/s]\u001b[A\n",
            "  3% 11/400 [00:04<02:36,  2.48it/s]\u001b[A\n",
            "  3% 12/400 [00:04<02:37,  2.47it/s]\u001b[A\n",
            "  3% 13/400 [00:04<02:36,  2.47it/s]\u001b[A\n",
            "  4% 14/400 [00:05<02:37,  2.45it/s]\u001b[A\n",
            "  4% 15/400 [00:05<02:37,  2.44it/s]\u001b[A\n",
            "  4% 16/400 [00:06<02:37,  2.44it/s]\u001b[A\n",
            "  4% 17/400 [00:06<02:37,  2.44it/s]\u001b[A\n",
            "  4% 18/400 [00:06<02:35,  2.46it/s]\u001b[A\n",
            "  5% 19/400 [00:07<02:34,  2.46it/s]\u001b[A\n",
            "  5% 20/400 [00:07<02:34,  2.47it/s]\u001b[A\n",
            "  5% 21/400 [00:08<02:33,  2.48it/s]\u001b[A\n",
            "  6% 22/400 [00:08<02:33,  2.47it/s]\u001b[A\n",
            "  6% 23/400 [00:08<02:32,  2.47it/s]\u001b[A\n",
            "  6% 24/400 [00:09<02:31,  2.48it/s]\u001b[A\n",
            "  6% 25/400 [00:09<02:30,  2.49it/s]\u001b[A\n",
            "  6% 26/400 [00:10<02:30,  2.48it/s]\u001b[A\n",
            "  7% 27/400 [00:10<02:30,  2.48it/s]\u001b[A\n",
            "  7% 28/400 [00:10<02:28,  2.50it/s]\u001b[A\n",
            "  7% 29/400 [00:11<02:28,  2.50it/s]\u001b[A\n",
            "  8% 30/400 [00:11<02:27,  2.50it/s]\u001b[A\n",
            "  8% 31/400 [00:12<02:28,  2.48it/s]\u001b[A\n",
            "  8% 32/400 [00:12<02:27,  2.49it/s]\u001b[A\n",
            "  8% 33/400 [00:12<02:28,  2.48it/s]\u001b[A\n",
            "  8% 34/400 [00:13<02:27,  2.48it/s]\u001b[A\n",
            "  9% 35/400 [00:13<02:26,  2.50it/s]\u001b[A\n",
            "  9% 36/400 [00:14<02:25,  2.49it/s]\u001b[A\n",
            "  9% 37/400 [00:14<02:24,  2.51it/s]\u001b[A\n",
            " 10% 38/400 [00:14<02:24,  2.51it/s]\u001b[A\n",
            " 10% 39/400 [00:15<02:23,  2.52it/s]\u001b[A\n",
            " 10% 40/400 [00:15<02:22,  2.53it/s]\u001b[A\n",
            " 10% 41/400 [00:16<02:22,  2.51it/s]\u001b[A\n",
            " 10% 42/400 [00:16<02:23,  2.50it/s]\u001b[A\n",
            " 11% 43/400 [00:16<02:22,  2.51it/s]\u001b[A\n",
            " 11% 44/400 [00:17<02:23,  2.48it/s]\u001b[A\n",
            " 11% 45/400 [00:17<02:24,  2.46it/s]\u001b[A\n",
            " 12% 46/400 [00:18<02:24,  2.45it/s]\u001b[A\n",
            " 12% 47/400 [00:18<02:24,  2.44it/s]\u001b[A\n",
            " 12% 48/400 [00:19<02:24,  2.43it/s]\u001b[A\n",
            " 12% 49/400 [00:19<02:24,  2.43it/s]\u001b[A\n",
            " 12% 50/400 [00:19<02:25,  2.40it/s]\u001b[A\n",
            " 13% 51/400 [00:20<02:25,  2.40it/s]\u001b[A\n",
            " 13% 52/400 [00:20<02:24,  2.41it/s]\u001b[A\n",
            " 13% 53/400 [00:21<02:24,  2.41it/s]\u001b[A\n",
            " 14% 54/400 [00:21<02:24,  2.40it/s]\u001b[A\n",
            " 14% 55/400 [00:21<02:23,  2.40it/s]\u001b[A\n",
            " 14% 56/400 [00:22<02:23,  2.40it/s]\u001b[A\n",
            " 14% 57/400 [00:22<02:22,  2.41it/s]\u001b[A\n",
            " 14% 58/400 [00:23<02:20,  2.43it/s]\u001b[A\n",
            " 15% 59/400 [00:23<02:19,  2.45it/s]\u001b[A\n",
            " 15% 60/400 [00:23<02:17,  2.47it/s]\u001b[A\n",
            " 15% 61/400 [00:24<02:17,  2.47it/s]\u001b[A\n",
            " 16% 62/400 [00:24<02:16,  2.48it/s]\u001b[A\n",
            " 16% 63/400 [00:25<02:16,  2.47it/s]\u001b[A\n",
            " 16% 64/400 [00:25<02:15,  2.48it/s]\u001b[A\n",
            " 16% 65/400 [00:25<02:14,  2.49it/s]\u001b[A\n",
            " 16% 66/400 [00:26<02:14,  2.48it/s]\u001b[A\n",
            " 17% 67/400 [00:26<02:14,  2.48it/s]\u001b[A\n",
            " 17% 68/400 [00:27<02:14,  2.46it/s]\u001b[A\n",
            " 17% 69/400 [00:27<02:14,  2.46it/s]\u001b[A\n",
            " 18% 70/400 [00:28<02:14,  2.45it/s]\u001b[A\n",
            " 18% 71/400 [00:28<02:14,  2.45it/s]\u001b[A\n",
            " 18% 72/400 [00:28<02:13,  2.45it/s]\u001b[A\n",
            " 18% 73/400 [00:29<02:12,  2.47it/s]\u001b[A\n",
            " 18% 74/400 [00:29<02:11,  2.47it/s]\u001b[A\n",
            " 19% 75/400 [00:30<02:11,  2.48it/s]\u001b[A\n",
            " 19% 76/400 [00:30<02:11,  2.46it/s]\u001b[A\n",
            " 19% 77/400 [00:30<02:10,  2.47it/s]\u001b[A\n",
            " 20% 78/400 [00:31<02:10,  2.47it/s]\u001b[A\n",
            " 20% 79/400 [00:31<02:09,  2.47it/s]\u001b[A\n",
            " 20% 80/400 [00:32<02:08,  2.49it/s]\u001b[A\n",
            " 20% 81/400 [00:32<02:08,  2.48it/s]\u001b[A\n",
            " 20% 82/400 [00:32<02:08,  2.47it/s]\u001b[A\n",
            " 21% 83/400 [00:33<02:08,  2.47it/s]\u001b[A\n",
            " 21% 84/400 [00:33<02:07,  2.47it/s]\u001b[A\n",
            " 21% 85/400 [00:34<02:07,  2.48it/s]\u001b[A\n",
            " 22% 86/400 [00:34<02:07,  2.47it/s]\u001b[A\n",
            " 22% 87/400 [00:34<02:06,  2.47it/s]\u001b[A\n",
            " 22% 88/400 [00:35<02:08,  2.42it/s]\u001b[A\n",
            " 22% 89/400 [00:35<02:11,  2.37it/s]\u001b[A\n",
            " 22% 90/400 [00:36<02:09,  2.39it/s]\u001b[A\n",
            " 23% 91/400 [00:36<02:08,  2.40it/s]\u001b[A\n",
            " 23% 92/400 [00:36<02:07,  2.42it/s]\u001b[A\n",
            " 23% 93/400 [00:37<02:05,  2.44it/s]\u001b[A\n",
            " 24% 94/400 [00:37<02:05,  2.44it/s]\u001b[A\n",
            " 24% 95/400 [00:38<02:04,  2.45it/s]\u001b[A\n",
            " 24% 96/400 [00:38<02:03,  2.46it/s]\u001b[A\n",
            " 24% 97/400 [00:39<02:02,  2.47it/s]\u001b[A\n",
            " 24% 98/400 [00:39<02:02,  2.46it/s]\u001b[A\n",
            " 25% 99/400 [00:39<02:01,  2.47it/s]\u001b[A\n",
            " 25% 100/400 [00:40<02:00,  2.48it/s]\u001b[A\n",
            " 25% 101/400 [00:40<02:00,  2.49it/s]\u001b[A\n",
            " 26% 102/400 [00:41<01:59,  2.50it/s]\u001b[A\n",
            " 26% 103/400 [00:41<01:58,  2.50it/s]\u001b[A\n",
            " 26% 104/400 [00:41<01:58,  2.50it/s]\u001b[A\n",
            " 26% 105/400 [00:42<01:58,  2.50it/s]\u001b[A\n",
            " 26% 106/400 [00:42<01:57,  2.51it/s]\u001b[A\n",
            " 27% 107/400 [00:42<01:56,  2.52it/s]\u001b[A\n",
            " 27% 108/400 [00:43<01:55,  2.52it/s]\u001b[A\n",
            " 27% 109/400 [00:43<01:56,  2.51it/s]\u001b[A\n",
            " 28% 110/400 [00:44<01:55,  2.51it/s]\u001b[A\n",
            " 28% 111/400 [00:44<01:55,  2.50it/s]\u001b[A\n",
            " 28% 112/400 [00:44<01:55,  2.49it/s]\u001b[A\n",
            " 28% 113/400 [00:45<01:54,  2.50it/s]\u001b[A\n",
            " 28% 114/400 [00:45<01:54,  2.49it/s]\u001b[A\n",
            " 29% 115/400 [00:46<01:54,  2.49it/s]\u001b[A\n",
            " 29% 116/400 [00:46<01:53,  2.49it/s]\u001b[A\n",
            " 29% 117/400 [00:47<01:54,  2.47it/s]\u001b[A\n",
            " 30% 118/400 [00:47<01:53,  2.48it/s]\u001b[A\n",
            " 30% 119/400 [00:47<01:53,  2.49it/s]\u001b[A\n",
            " 30% 120/400 [00:48<01:53,  2.46it/s]\u001b[A\n",
            " 30% 121/400 [00:48<01:53,  2.45it/s]\u001b[A\n",
            " 30% 122/400 [00:49<01:53,  2.44it/s]\u001b[A\n",
            " 31% 123/400 [00:49<01:53,  2.43it/s]\u001b[A\n",
            " 31% 124/400 [00:49<01:53,  2.44it/s]\u001b[A\n",
            " 31% 125/400 [00:50<01:53,  2.43it/s]\u001b[A\n",
            " 32% 126/400 [00:50<01:53,  2.42it/s]\u001b[A\n",
            " 32% 127/400 [00:51<01:52,  2.42it/s]\u001b[A\n",
            " 32% 128/400 [00:51<01:52,  2.42it/s]\u001b[A\n",
            " 32% 129/400 [00:51<01:52,  2.41it/s]\u001b[A\n",
            " 32% 130/400 [00:52<01:53,  2.39it/s]\u001b[A\n",
            " 33% 131/400 [00:52<01:52,  2.40it/s]\u001b[A\n",
            " 33% 132/400 [00:53<01:50,  2.42it/s]\u001b[A\n",
            " 33% 133/400 [00:53<01:49,  2.44it/s]\u001b[A\n",
            " 34% 134/400 [00:53<01:47,  2.46it/s]\u001b[A\n",
            " 34% 135/400 [00:54<01:47,  2.47it/s]\u001b[A\n",
            " 34% 136/400 [00:54<01:46,  2.49it/s]\u001b[A\n",
            " 34% 137/400 [00:55<01:46,  2.48it/s]\u001b[A\n",
            " 34% 138/400 [00:55<01:45,  2.49it/s]\u001b[A\n",
            " 35% 139/400 [00:55<01:44,  2.50it/s]\u001b[A\n",
            " 35% 140/400 [00:56<01:44,  2.50it/s]\u001b[A\n",
            " 35% 141/400 [00:56<01:43,  2.51it/s]\u001b[A\n",
            " 36% 142/400 [00:57<01:43,  2.50it/s]\u001b[A\n",
            " 36% 143/400 [00:57<01:43,  2.49it/s]\u001b[A\n",
            " 36% 144/400 [00:58<01:43,  2.48it/s]\u001b[A\n",
            " 36% 145/400 [00:58<01:42,  2.49it/s]\u001b[A\n",
            " 36% 146/400 [00:58<01:42,  2.49it/s]\u001b[A\n",
            " 37% 147/400 [00:59<01:41,  2.49it/s]\u001b[A\n",
            " 37% 148/400 [00:59<01:40,  2.50it/s]\u001b[A\n",
            " 37% 149/400 [01:00<01:40,  2.50it/s]\u001b[A\n",
            " 38% 150/400 [01:00<01:40,  2.50it/s]\u001b[A\n",
            " 38% 151/400 [01:00<01:39,  2.50it/s]\u001b[A\n",
            " 38% 152/400 [01:01<01:39,  2.50it/s]\u001b[A\n",
            " 38% 153/400 [01:01<01:38,  2.50it/s]\u001b[A\n",
            " 38% 154/400 [01:02<01:38,  2.50it/s]\u001b[A\n",
            " 39% 155/400 [01:02<01:38,  2.50it/s]\u001b[A\n",
            " 39% 156/400 [01:02<01:37,  2.50it/s]\u001b[A\n",
            " 39% 157/400 [01:03<01:38,  2.48it/s]\u001b[A\n",
            " 40% 158/400 [01:03<01:38,  2.46it/s]\u001b[A\n",
            " 40% 159/400 [01:04<01:38,  2.44it/s]\u001b[A\n",
            " 40% 160/400 [01:04<01:38,  2.45it/s]\u001b[A\n",
            " 40% 161/400 [01:04<01:39,  2.40it/s]\u001b[A\n",
            " 40% 162/400 [01:05<01:39,  2.39it/s]\u001b[A\n",
            " 41% 163/400 [01:05<01:38,  2.40it/s]\u001b[A\n",
            " 41% 164/400 [01:06<01:38,  2.40it/s]\u001b[A\n",
            " 41% 165/400 [01:06<01:37,  2.41it/s]\u001b[A\n",
            " 42% 166/400 [01:06<01:37,  2.40it/s]\u001b[A\n",
            " 42% 167/400 [01:07<01:36,  2.41it/s]\u001b[A\n",
            " 42% 168/400 [01:07<01:36,  2.41it/s]\u001b[A\n",
            " 42% 169/400 [01:08<01:35,  2.42it/s]\u001b[A\n",
            " 42% 170/400 [01:08<01:34,  2.43it/s]\u001b[A\n",
            " 43% 171/400 [01:09<01:33,  2.44it/s]\u001b[A\n",
            " 43% 172/400 [01:09<01:32,  2.45it/s]\u001b[A\n",
            " 43% 173/400 [01:09<01:32,  2.47it/s]\u001b[A\n",
            " 44% 174/400 [01:10<01:31,  2.46it/s]\u001b[A\n",
            " 44% 175/400 [01:10<01:31,  2.47it/s]\u001b[A\n",
            " 44% 176/400 [01:11<01:30,  2.48it/s]\u001b[A\n",
            " 44% 177/400 [01:11<01:29,  2.48it/s]\u001b[A\n",
            " 44% 178/400 [01:11<01:29,  2.49it/s]\u001b[A\n",
            " 45% 179/400 [01:12<01:29,  2.48it/s]\u001b[A\n",
            " 45% 180/400 [01:12<01:28,  2.49it/s]\u001b[A\n",
            " 45% 181/400 [01:13<01:28,  2.49it/s]\u001b[A\n",
            " 46% 182/400 [01:13<01:27,  2.49it/s]\u001b[A\n",
            " 46% 183/400 [01:13<01:26,  2.50it/s]\u001b[A\n",
            " 46% 184/400 [01:14<01:26,  2.50it/s]\u001b[A\n",
            " 46% 185/400 [01:14<01:25,  2.51it/s]\u001b[A\n",
            " 46% 186/400 [01:15<01:25,  2.52it/s]\u001b[A\n",
            " 47% 187/400 [01:15<01:24,  2.51it/s]\u001b[A\n",
            " 47% 188/400 [01:15<01:24,  2.50it/s]\u001b[A\n",
            " 47% 189/400 [01:16<01:24,  2.50it/s]\u001b[A\n",
            " 48% 190/400 [01:16<01:23,  2.50it/s]\u001b[A\n",
            " 48% 191/400 [01:17<01:23,  2.50it/s]\u001b[A\n",
            " 48% 192/400 [01:17<01:23,  2.50it/s]\u001b[A\n",
            " 48% 193/400 [01:17<01:22,  2.50it/s]\u001b[A\n",
            " 48% 194/400 [01:18<01:22,  2.49it/s]\u001b[A\n",
            " 49% 195/400 [01:18<01:23,  2.45it/s]\u001b[A\n",
            " 49% 196/400 [01:19<01:23,  2.44it/s]\u001b[A\n",
            " 49% 197/400 [01:19<01:23,  2.43it/s]\u001b[A\n",
            " 50% 198/400 [01:19<01:23,  2.43it/s]\u001b[A\n",
            " 50% 199/400 [01:20<01:22,  2.42it/s]\u001b[A\n",
            " 50% 200/400 [01:20<01:22,  2.43it/s]\u001b[A\n",
            " 50% 201/400 [01:21<01:22,  2.41it/s]\u001b[A\n",
            " 50% 202/400 [01:21<01:22,  2.40it/s]\u001b[A\n",
            " 51% 203/400 [01:21<01:21,  2.40it/s]\u001b[A\n",
            " 51% 204/400 [01:22<01:21,  2.41it/s]\u001b[A\n",
            " 51% 205/400 [01:22<01:20,  2.42it/s]\u001b[A\n",
            " 52% 206/400 [01:23<01:20,  2.42it/s]\u001b[A\n",
            " 52% 207/400 [01:23<01:19,  2.43it/s]\u001b[A\n",
            " 52% 208/400 [01:24<01:18,  2.44it/s]\u001b[A\n",
            " 52% 209/400 [01:24<01:17,  2.45it/s]\u001b[A\n",
            " 52% 210/400 [01:24<01:17,  2.46it/s]\u001b[A\n",
            " 53% 211/400 [01:25<01:17,  2.45it/s]\u001b[A\n",
            " 53% 212/400 [01:25<01:16,  2.47it/s]\u001b[A\n",
            " 53% 213/400 [01:26<01:15,  2.46it/s]\u001b[A\n",
            " 54% 214/400 [01:26<01:15,  2.46it/s]\u001b[A\n",
            " 54% 215/400 [01:26<01:15,  2.44it/s]\u001b[A\n",
            " 54% 216/400 [01:27<01:15,  2.43it/s]\u001b[A\n",
            " 54% 217/400 [01:27<01:15,  2.42it/s]\u001b[A\n",
            " 55% 218/400 [01:28<01:15,  2.40it/s]\u001b[A\n",
            " 55% 219/400 [01:28<01:15,  2.41it/s]\u001b[A\n",
            " 55% 220/400 [01:28<01:14,  2.42it/s]\u001b[A\n",
            " 55% 221/400 [01:29<01:13,  2.44it/s]\u001b[A\n",
            " 56% 222/400 [01:29<01:12,  2.45it/s]\u001b[A\n",
            " 56% 223/400 [01:30<01:11,  2.46it/s]\u001b[A\n",
            " 56% 224/400 [01:30<01:11,  2.47it/s]\u001b[A\n",
            " 56% 225/400 [01:30<01:10,  2.47it/s]\u001b[A\n",
            " 56% 226/400 [01:31<01:10,  2.47it/s]\u001b[A\n",
            " 57% 227/400 [01:31<01:10,  2.46it/s]\u001b[A\n",
            " 57% 228/400 [01:32<01:09,  2.46it/s]\u001b[A\n",
            " 57% 229/400 [01:32<01:09,  2.47it/s]\u001b[A\n",
            " 57% 230/400 [01:32<01:08,  2.48it/s]\u001b[A\n",
            " 58% 231/400 [01:33<01:08,  2.45it/s]\u001b[A\n",
            " 58% 232/400 [01:33<01:09,  2.42it/s]\u001b[A\n",
            " 58% 233/400 [01:34<01:09,  2.41it/s]\u001b[A\n",
            " 58% 234/400 [01:34<01:10,  2.37it/s]\u001b[A\n",
            " 59% 235/400 [01:35<01:10,  2.34it/s]\u001b[A\n",
            " 59% 236/400 [01:35<01:11,  2.30it/s]\u001b[A\n",
            " 59% 237/400 [01:36<01:11,  2.28it/s]\u001b[A\n",
            " 60% 238/400 [01:36<01:09,  2.33it/s]\u001b[A\n",
            " 60% 239/400 [01:36<01:07,  2.37it/s]\u001b[A\n",
            " 60% 240/400 [01:37<01:07,  2.39it/s]\u001b[A\n",
            " 60% 241/400 [01:37<01:06,  2.40it/s]\u001b[A\n",
            " 60% 242/400 [01:38<01:05,  2.42it/s]\u001b[A\n",
            " 61% 243/400 [01:38<01:04,  2.43it/s]\u001b[A\n",
            " 61% 244/400 [01:38<01:03,  2.44it/s]\u001b[A\n",
            " 61% 245/400 [01:39<01:03,  2.45it/s]\u001b[A\n",
            " 62% 246/400 [01:39<01:02,  2.45it/s]\u001b[A\n",
            " 62% 247/400 [01:40<01:01,  2.47it/s]\u001b[A\n",
            " 62% 248/400 [01:40<01:01,  2.47it/s]\u001b[A\n",
            " 62% 249/400 [01:40<01:00,  2.48it/s]\u001b[A\n",
            " 62% 250/400 [01:41<01:00,  2.48it/s]\u001b[A\n",
            " 63% 251/400 [01:41<00:59,  2.49it/s]\u001b[A\n",
            " 63% 252/400 [01:42<00:59,  2.48it/s]\u001b[A\n",
            " 63% 253/400 [01:42<00:59,  2.48it/s]\u001b[A\n",
            " 64% 254/400 [01:42<00:58,  2.48it/s]\u001b[A\n",
            " 64% 255/400 [01:43<00:58,  2.48it/s]\u001b[A\n",
            " 64% 256/400 [01:43<00:57,  2.48it/s]\u001b[A\n",
            " 64% 257/400 [01:44<00:57,  2.48it/s]\u001b[A\n",
            " 64% 258/400 [01:44<00:57,  2.46it/s]\u001b[A\n",
            " 65% 259/400 [01:44<00:57,  2.46it/s]\u001b[A\n",
            " 65% 260/400 [01:45<00:56,  2.48it/s]\u001b[A\n",
            " 65% 261/400 [01:45<00:55,  2.49it/s]\u001b[A\n",
            " 66% 262/400 [01:46<00:55,  2.49it/s]\u001b[A\n",
            " 66% 263/400 [01:46<00:55,  2.47it/s]\u001b[A\n",
            " 66% 264/400 [01:46<00:54,  2.48it/s]\u001b[A\n",
            " 66% 265/400 [01:47<00:54,  2.48it/s]\u001b[A\n",
            " 66% 266/400 [01:47<00:54,  2.47it/s]\u001b[A\n",
            " 67% 267/400 [01:48<00:54,  2.44it/s]\u001b[A\n",
            " 67% 268/400 [01:48<00:54,  2.42it/s]\u001b[A\n",
            " 67% 269/400 [01:49<00:54,  2.42it/s]\u001b[A\n",
            " 68% 270/400 [01:49<00:53,  2.42it/s]\u001b[A\n",
            " 68% 271/400 [01:49<00:53,  2.41it/s]\u001b[A\n",
            " 68% 272/400 [01:50<00:53,  2.41it/s]\u001b[A\n",
            " 68% 273/400 [01:50<00:52,  2.40it/s]\u001b[A\n",
            " 68% 274/400 [01:51<00:52,  2.40it/s]\u001b[A\n",
            " 69% 275/400 [01:51<00:51,  2.40it/s]\u001b[A\n",
            " 69% 276/400 [01:51<00:51,  2.42it/s]\u001b[A\n",
            " 69% 277/400 [01:52<00:51,  2.40it/s]\u001b[A\n",
            " 70% 278/400 [01:52<00:50,  2.40it/s]\u001b[A\n",
            " 70% 279/400 [01:53<00:50,  2.41it/s]\u001b[A\n",
            " 70% 280/400 [01:53<00:48,  2.47it/s]\u001b[A\n",
            " 70% 281/400 [01:53<00:48,  2.48it/s]\u001b[A\n",
            " 70% 282/400 [01:54<00:47,  2.47it/s]\u001b[A\n",
            " 71% 283/400 [01:54<00:47,  2.47it/s]\u001b[A\n",
            " 71% 284/400 [01:55<00:47,  2.47it/s]\u001b[A\n",
            " 71% 285/400 [01:55<00:46,  2.47it/s]\u001b[A\n",
            " 72% 286/400 [01:55<00:46,  2.47it/s]\u001b[A\n",
            " 72% 287/400 [01:56<00:45,  2.47it/s]\u001b[A\n",
            " 72% 288/400 [01:56<00:45,  2.45it/s]\u001b[A\n",
            " 72% 289/400 [01:57<00:45,  2.46it/s]\u001b[A\n",
            " 72% 290/400 [01:57<00:44,  2.46it/s]\u001b[A\n",
            " 73% 291/400 [01:58<00:44,  2.45it/s]\u001b[A\n",
            " 73% 292/400 [01:58<00:43,  2.47it/s]\u001b[A\n",
            " 73% 293/400 [01:58<00:43,  2.48it/s]\u001b[A\n",
            " 74% 294/400 [01:59<00:42,  2.48it/s]\u001b[A\n",
            " 74% 295/400 [01:59<00:42,  2.47it/s]\u001b[A\n",
            " 74% 296/400 [02:00<00:42,  2.47it/s]\u001b[A\n",
            " 74% 297/400 [02:00<00:41,  2.48it/s]\u001b[A\n",
            " 74% 298/400 [02:00<00:41,  2.49it/s]\u001b[A\n",
            " 75% 299/400 [02:01<00:40,  2.49it/s]\u001b[A\n",
            " 75% 300/400 [02:01<00:40,  2.50it/s]\u001b[A\n",
            " 75% 301/400 [02:02<00:39,  2.49it/s]\u001b[A\n",
            " 76% 302/400 [02:02<00:39,  2.49it/s]\u001b[A\n",
            " 76% 303/400 [02:02<00:39,  2.48it/s]\u001b[A\n",
            " 76% 304/400 [02:03<00:38,  2.48it/s]\u001b[A\n",
            " 76% 305/400 [02:03<00:38,  2.48it/s]\u001b[A\n",
            " 76% 306/400 [02:04<00:38,  2.46it/s]\u001b[A\n",
            " 77% 307/400 [02:04<00:37,  2.46it/s]\u001b[A\n",
            " 77% 308/400 [02:04<00:37,  2.46it/s]\u001b[A\n",
            " 77% 309/400 [02:05<00:37,  2.45it/s]\u001b[A\n",
            " 78% 310/400 [02:05<00:36,  2.44it/s]\u001b[A\n",
            " 78% 311/400 [02:06<00:36,  2.43it/s]\u001b[A\n",
            " 78% 312/400 [02:06<00:36,  2.43it/s]\u001b[A\n",
            " 78% 313/400 [02:06<00:35,  2.43it/s]\u001b[A\n",
            " 78% 314/400 [02:07<00:35,  2.43it/s]\u001b[A\n",
            " 79% 315/400 [02:07<00:34,  2.44it/s]\u001b[A\n",
            " 79% 316/400 [02:08<00:34,  2.45it/s]\u001b[A\n",
            " 79% 317/400 [02:08<00:33,  2.46it/s]\u001b[A\n",
            " 80% 318/400 [02:08<00:33,  2.46it/s]\u001b[A\n",
            " 80% 319/400 [02:09<00:32,  2.47it/s]\u001b[A\n",
            " 80% 320/400 [02:09<00:32,  2.47it/s]\u001b[A\n",
            " 80% 321/400 [02:10<00:31,  2.48it/s]\u001b[A\n",
            " 80% 322/400 [02:10<00:31,  2.49it/s]\u001b[A\n",
            " 81% 323/400 [02:10<00:31,  2.48it/s]\u001b[A\n",
            " 81% 324/400 [02:11<00:30,  2.49it/s]\u001b[A\n",
            " 81% 325/400 [02:11<00:30,  2.49it/s]\u001b[A\n",
            " 82% 326/400 [02:12<00:29,  2.48it/s]\u001b[A\n",
            " 82% 327/400 [02:12<00:29,  2.49it/s]\u001b[A\n",
            " 82% 328/400 [02:13<00:28,  2.50it/s]\u001b[A\n",
            " 82% 329/400 [02:13<00:28,  2.49it/s]\u001b[A\n",
            " 82% 330/400 [02:13<00:28,  2.48it/s]\u001b[A\n",
            " 83% 331/400 [02:14<00:27,  2.49it/s]\u001b[A\n",
            " 83% 332/400 [02:14<00:27,  2.50it/s]\u001b[A\n",
            " 83% 333/400 [02:15<00:26,  2.51it/s]\u001b[A\n",
            " 84% 334/400 [02:15<00:26,  2.50it/s]\u001b[A\n",
            " 84% 335/400 [02:15<00:26,  2.49it/s]\u001b[A\n",
            " 84% 336/400 [02:16<00:25,  2.48it/s]\u001b[A\n",
            " 84% 337/400 [02:16<00:25,  2.48it/s]\u001b[A\n",
            " 84% 338/400 [02:17<00:25,  2.47it/s]\u001b[A\n",
            " 85% 339/400 [02:17<00:24,  2.47it/s]\u001b[A\n",
            " 85% 340/400 [02:17<00:24,  2.44it/s]\u001b[A\n",
            " 85% 341/400 [02:18<00:24,  2.42it/s]\u001b[A\n",
            " 86% 342/400 [02:18<00:24,  2.41it/s]\u001b[A\n",
            " 86% 343/400 [02:19<00:23,  2.40it/s]\u001b[A\n",
            " 86% 344/400 [02:19<00:23,  2.41it/s]\u001b[A\n",
            " 86% 345/400 [02:19<00:23,  2.39it/s]\u001b[A\n",
            " 86% 346/400 [02:20<00:22,  2.36it/s]\u001b[A\n",
            " 87% 347/400 [02:20<00:22,  2.39it/s]\u001b[A\n",
            " 87% 348/400 [02:21<00:21,  2.41it/s]\u001b[A\n",
            " 87% 349/400 [02:21<00:21,  2.42it/s]\u001b[A\n",
            " 88% 350/400 [02:22<00:20,  2.42it/s]\u001b[A\n",
            " 88% 351/400 [02:22<00:20,  2.43it/s]\u001b[A\n",
            " 88% 352/400 [02:22<00:19,  2.46it/s]\u001b[A\n",
            " 88% 353/400 [02:23<00:19,  2.47it/s]\u001b[A\n",
            " 88% 354/400 [02:23<00:18,  2.49it/s]\u001b[A\n",
            " 89% 355/400 [02:24<00:18,  2.50it/s]\u001b[A\n",
            " 89% 356/400 [02:24<00:17,  2.49it/s]\u001b[A\n",
            " 89% 357/400 [02:24<00:17,  2.48it/s]\u001b[A\n",
            " 90% 358/400 [02:25<00:17,  2.47it/s]\u001b[A\n",
            " 90% 359/400 [02:25<00:16,  2.48it/s]\u001b[A\n",
            " 90% 360/400 [02:26<00:16,  2.48it/s]\u001b[A\n",
            " 90% 361/400 [02:26<00:15,  2.46it/s]\u001b[A\n",
            " 90% 362/400 [02:26<00:15,  2.45it/s]\u001b[A\n",
            " 91% 363/400 [02:27<00:15,  2.43it/s]\u001b[A\n",
            " 91% 364/400 [02:27<00:14,  2.43it/s]\u001b[A\n",
            " 91% 365/400 [02:28<00:14,  2.42it/s]\u001b[A\n",
            " 92% 366/400 [02:28<00:14,  2.42it/s]\u001b[A\n",
            " 92% 367/400 [02:28<00:13,  2.42it/s]\u001b[A\n",
            " 92% 368/400 [02:29<00:13,  2.40it/s]\u001b[A\n",
            " 92% 369/400 [02:29<00:12,  2.42it/s]\u001b[A\n",
            " 92% 370/400 [02:30<00:12,  2.43it/s]\u001b[A\n",
            " 93% 371/400 [02:30<00:11,  2.44it/s]\u001b[A\n",
            " 93% 372/400 [02:30<00:11,  2.44it/s]\u001b[A\n",
            " 93% 373/400 [02:31<00:11,  2.44it/s]\u001b[A\n",
            " 94% 374/400 [02:31<00:10,  2.45it/s]\u001b[A\n",
            " 94% 375/400 [02:32<00:10,  2.46it/s]\u001b[A\n",
            " 94% 376/400 [02:32<00:09,  2.44it/s]\u001b[A\n",
            " 94% 377/400 [02:33<00:09,  2.45it/s]\u001b[A\n",
            " 94% 378/400 [02:33<00:09,  2.44it/s]\u001b[A\n",
            " 95% 379/400 [02:33<00:08,  2.42it/s]\u001b[A\n",
            " 95% 380/400 [02:34<00:08,  2.42it/s]\u001b[A\n",
            " 95% 381/400 [02:34<00:07,  2.43it/s]\u001b[A\n",
            " 96% 382/400 [02:35<00:07,  2.43it/s]\u001b[A\n",
            " 96% 383/400 [02:35<00:07,  2.42it/s]\u001b[A\n",
            " 96% 384/400 [02:35<00:06,  2.42it/s]\u001b[A\n",
            " 96% 385/400 [02:36<00:06,  2.42it/s]\u001b[A\n",
            " 96% 386/400 [02:36<00:05,  2.42it/s]\u001b[A\n",
            " 97% 387/400 [02:37<00:05,  2.43it/s]\u001b[A\n",
            " 97% 388/400 [02:37<00:04,  2.45it/s]\u001b[A\n",
            " 97% 389/400 [02:37<00:04,  2.46it/s]\u001b[A\n",
            " 98% 390/400 [02:38<00:04,  2.46it/s]\u001b[A\n",
            " 98% 391/400 [02:38<00:03,  2.46it/s]\u001b[A\n",
            " 98% 392/400 [02:39<00:03,  2.46it/s]\u001b[A\n",
            " 98% 393/400 [02:39<00:02,  2.47it/s]\u001b[A\n",
            " 98% 394/400 [02:39<00:02,  2.47it/s]\u001b[A\n",
            " 99% 395/400 [02:40<00:02,  2.47it/s]\u001b[A\n",
            " 99% 396/400 [02:40<00:01,  2.47it/s]\u001b[A\n",
            " 99% 397/400 [02:41<00:01,  2.46it/s]\u001b[A\n",
            "100% 398/400 [02:41<00:00,  2.46it/s]\u001b[A\n",
            "100% 399/400 [02:42<00:00,  2.46it/s]\u001b[A\n",
            "                                      \n",
            "\u001b[A{'eval_loss': 1.0836395025253296, 'eval_rouge1': 28.8174, 'eval_rouge2': 18.0089, 'eval_rougeL': 28.5749, 'eval_rougeLsum': 28.5946, 'eval_bleu': 9.9136, 'eval_gen_len': 18.2019, 'eval_runtime': 188.0517, 'eval_samples_per_second': 8.508, 'eval_steps_per_second': 2.127, 'epoch': 2.0}\n",
            " 40% 600/1500 [15:52<07:31,  1.99it/s]\n",
            "100% 400/400 [03:07<00:00,  2.47it/s]\u001b[A\n",
            "                                     \u001b[ASaving model checkpoint to mT5_model_full/checkpoint-600\n",
            "Configuration saved in mT5_model_full/checkpoint-600/config.json\n",
            "Configuration saved in mT5_model_full/checkpoint-600/generation_config.json\n",
            "Model weights saved in mT5_model_full/checkpoint-600/pytorch_model.bin\n",
            "tokenizer config file saved in mT5_model_full/checkpoint-600/tokenizer_config.json\n",
            "Special tokens file saved in mT5_model_full/checkpoint-600/special_tokens_map.json\n",
            "Copy vocab file to mT5_model_full/checkpoint-600/spiece.model\n",
            "{'loss': 1.5421, 'learning_rate': 1.7e-05, 'epoch': 2.17}\n",
            "{'loss': 1.5058, 'learning_rate': 1.6e-05, 'epoch': 2.33}\n",
            " 47% 700/1500 [17:00<06:40,  2.00it/s]Saving model checkpoint to mT5_model_full/checkpoint-700\n",
            "Configuration saved in mT5_model_full/checkpoint-700/config.json\n",
            "Configuration saved in mT5_model_full/checkpoint-700/generation_config.json\n",
            "Model weights saved in mT5_model_full/checkpoint-700/pytorch_model.bin\n",
            "tokenizer config file saved in mT5_model_full/checkpoint-700/tokenizer_config.json\n",
            "Special tokens file saved in mT5_model_full/checkpoint-700/special_tokens_map.json\n",
            "Copy vocab file to mT5_model_full/checkpoint-700/spiece.model\n",
            "{'loss': 1.4699, 'learning_rate': 1.5e-05, 'epoch': 2.5}\n",
            "{'loss': 1.4455, 'learning_rate': 1.4e-05, 'epoch': 2.67}\n",
            " 53% 800/1500 [18:08<05:50,  2.00it/s]***** Running Evaluation *****\n",
            "  Num examples = 1600\n",
            "  Batch size = 4\n",
            "\n",
            "  0% 0/400 [00:00<?, ?it/s]\u001b[A\n",
            "  0% 2/400 [00:00<01:20,  4.93it/s]\u001b[A\n",
            "  1% 3/400 [00:00<01:53,  3.49it/s]\u001b[A\n",
            "  1% 4/400 [00:01<02:11,  3.01it/s]\u001b[A\n",
            "  1% 5/400 [00:01<02:21,  2.80it/s]\u001b[A\n",
            "  2% 6/400 [00:02<02:27,  2.67it/s]\u001b[A\n",
            "  2% 7/400 [00:02<02:32,  2.57it/s]\u001b[A\n",
            "  2% 8/400 [00:02<02:35,  2.52it/s]\u001b[A\n",
            "  2% 9/400 [00:03<02:37,  2.49it/s]\u001b[A\n",
            "  2% 10/400 [00:03<02:38,  2.46it/s]\u001b[A\n",
            "  3% 11/400 [00:04<02:39,  2.44it/s]\u001b[A\n",
            "  3% 12/400 [00:04<02:39,  2.43it/s]\u001b[A\n",
            "  3% 13/400 [00:04<02:38,  2.44it/s]\u001b[A\n",
            "  4% 14/400 [00:05<02:37,  2.45it/s]\u001b[A\n",
            "  4% 15/400 [00:05<02:37,  2.45it/s]\u001b[A\n",
            "  4% 16/400 [00:06<02:37,  2.44it/s]\u001b[A\n",
            "  4% 17/400 [00:06<02:36,  2.45it/s]\u001b[A\n",
            "  4% 18/400 [00:06<02:35,  2.46it/s]\u001b[A\n",
            "  5% 19/400 [00:07<02:33,  2.49it/s]\u001b[A\n",
            "  5% 20/400 [00:07<02:32,  2.49it/s]\u001b[A\n",
            "  5% 21/400 [00:08<02:33,  2.48it/s]\u001b[A\n",
            "  6% 22/400 [00:08<02:39,  2.37it/s]\u001b[A\n",
            "  6% 23/400 [00:09<02:37,  2.40it/s]\u001b[A\n",
            "  6% 24/400 [00:09<02:35,  2.41it/s]\u001b[A\n",
            "  6% 25/400 [00:09<02:34,  2.43it/s]\u001b[A\n",
            "  6% 26/400 [00:10<02:34,  2.43it/s]\u001b[A\n",
            "  7% 27/400 [00:10<02:33,  2.43it/s]\u001b[A\n",
            "  7% 28/400 [00:11<02:32,  2.44it/s]\u001b[A\n",
            "  7% 29/400 [00:11<02:31,  2.45it/s]\u001b[A\n",
            "  8% 30/400 [00:11<02:31,  2.44it/s]\u001b[A\n",
            "  8% 31/400 [00:12<02:30,  2.44it/s]\u001b[A\n",
            "  8% 32/400 [00:12<02:29,  2.45it/s]\u001b[A\n",
            "  8% 33/400 [00:13<02:29,  2.45it/s]\u001b[A\n",
            "  8% 34/400 [00:13<02:28,  2.46it/s]\u001b[A\n",
            "  9% 35/400 [00:13<02:28,  2.45it/s]\u001b[A\n",
            "  9% 36/400 [00:14<02:28,  2.45it/s]\u001b[A\n",
            "  9% 37/400 [00:14<02:27,  2.46it/s]\u001b[A\n",
            " 10% 38/400 [00:15<02:28,  2.45it/s]\u001b[A\n",
            " 10% 39/400 [00:15<02:27,  2.45it/s]\u001b[A\n",
            " 10% 40/400 [00:15<02:26,  2.45it/s]\u001b[A\n",
            " 10% 41/400 [00:16<02:26,  2.46it/s]\u001b[A\n",
            " 10% 42/400 [00:16<02:25,  2.46it/s]\u001b[A\n",
            " 11% 43/400 [00:17<02:24,  2.47it/s]\u001b[A\n",
            " 11% 44/400 [00:17<02:24,  2.47it/s]\u001b[A\n",
            " 11% 45/400 [00:17<02:23,  2.47it/s]\u001b[A\n",
            " 12% 46/400 [00:18<02:23,  2.47it/s]\u001b[A\n",
            " 12% 47/400 [00:18<02:23,  2.46it/s]\u001b[A\n",
            " 12% 48/400 [00:19<02:22,  2.47it/s]\u001b[A\n",
            " 12% 49/400 [00:19<02:21,  2.47it/s]\u001b[A\n",
            " 12% 50/400 [00:20<02:21,  2.47it/s]\u001b[A\n",
            " 13% 51/400 [00:20<02:22,  2.46it/s]\u001b[A\n",
            " 13% 52/400 [00:20<02:22,  2.44it/s]\u001b[A\n",
            " 13% 53/400 [00:21<02:23,  2.43it/s]\u001b[A\n",
            " 14% 54/400 [00:21<02:23,  2.41it/s]\u001b[A\n",
            " 14% 55/400 [00:22<02:23,  2.40it/s]\u001b[A\n",
            " 14% 56/400 [00:22<02:24,  2.39it/s]\u001b[A\n",
            " 14% 57/400 [00:22<02:24,  2.38it/s]\u001b[A\n",
            " 14% 58/400 [00:23<02:23,  2.38it/s]\u001b[A\n",
            " 15% 59/400 [00:23<02:24,  2.36it/s]\u001b[A\n",
            " 15% 60/400 [00:24<02:22,  2.38it/s]\u001b[A\n",
            " 15% 61/400 [00:24<02:22,  2.39it/s]\u001b[A\n",
            " 16% 62/400 [00:25<02:22,  2.38it/s]\u001b[A\n",
            " 16% 63/400 [00:25<02:20,  2.40it/s]\u001b[A\n",
            " 16% 64/400 [00:25<02:18,  2.42it/s]\u001b[A\n",
            " 16% 65/400 [00:26<02:17,  2.43it/s]\u001b[A\n",
            " 16% 66/400 [00:26<02:16,  2.44it/s]\u001b[A\n",
            " 17% 67/400 [00:27<02:16,  2.45it/s]\u001b[A\n",
            " 17% 68/400 [00:27<02:15,  2.45it/s]\u001b[A\n",
            " 17% 69/400 [00:27<02:15,  2.45it/s]\u001b[A\n",
            " 18% 70/400 [00:28<02:14,  2.46it/s]\u001b[A\n",
            " 18% 71/400 [00:28<02:13,  2.47it/s]\u001b[A\n",
            " 18% 72/400 [00:29<02:13,  2.46it/s]\u001b[A\n",
            " 18% 73/400 [00:29<02:13,  2.45it/s]\u001b[A\n",
            " 18% 74/400 [00:29<02:12,  2.46it/s]\u001b[A\n",
            " 19% 75/400 [00:30<02:11,  2.48it/s]\u001b[A\n",
            " 19% 76/400 [00:30<02:11,  2.47it/s]\u001b[A\n",
            " 19% 77/400 [00:31<02:11,  2.46it/s]\u001b[A\n",
            " 20% 78/400 [00:31<02:10,  2.46it/s]\u001b[A\n",
            " 20% 79/400 [00:31<02:10,  2.46it/s]\u001b[A\n",
            " 20% 80/400 [00:32<02:08,  2.48it/s]\u001b[A\n",
            " 20% 81/400 [00:32<02:08,  2.48it/s]\u001b[A\n",
            " 20% 82/400 [00:33<02:08,  2.47it/s]\u001b[A\n",
            " 21% 83/400 [00:33<02:08,  2.47it/s]\u001b[A\n",
            " 21% 84/400 [00:33<02:08,  2.46it/s]\u001b[A\n",
            " 21% 85/400 [00:34<02:07,  2.46it/s]\u001b[A\n",
            " 22% 86/400 [00:34<02:07,  2.46it/s]\u001b[A\n",
            " 22% 87/400 [00:35<02:07,  2.45it/s]\u001b[A\n",
            " 22% 88/400 [00:35<02:08,  2.43it/s]\u001b[A\n",
            " 22% 89/400 [00:36<02:08,  2.42it/s]\u001b[A\n",
            " 22% 90/400 [00:36<02:07,  2.43it/s]\u001b[A\n",
            " 23% 91/400 [00:36<02:07,  2.42it/s]\u001b[A\n",
            " 23% 92/400 [00:37<02:07,  2.42it/s]\u001b[A\n",
            " 23% 93/400 [00:37<02:07,  2.41it/s]\u001b[A\n",
            " 24% 94/400 [00:38<02:11,  2.32it/s]\u001b[A\n",
            " 24% 95/400 [00:38<02:09,  2.35it/s]\u001b[A\n",
            " 24% 97/400 [00:39<01:45,  2.88it/s]\u001b[A\n",
            " 24% 98/400 [00:39<01:50,  2.74it/s]\u001b[A\n",
            " 25% 99/400 [00:39<01:53,  2.65it/s]\u001b[A\n",
            " 25% 100/400 [00:40<01:55,  2.61it/s]\u001b[A\n",
            " 25% 101/400 [00:40<01:55,  2.58it/s]\u001b[A\n",
            " 26% 102/400 [00:41<01:57,  2.54it/s]\u001b[A\n",
            " 26% 103/400 [00:41<01:57,  2.53it/s]\u001b[A\n",
            " 26% 104/400 [00:41<01:57,  2.52it/s]\u001b[A\n",
            " 26% 105/400 [00:42<01:57,  2.52it/s]\u001b[A\n",
            " 26% 106/400 [00:42<01:56,  2.51it/s]\u001b[A\n",
            " 27% 107/400 [00:43<01:57,  2.49it/s]\u001b[A\n",
            " 27% 108/400 [00:43<01:57,  2.49it/s]\u001b[A\n",
            " 27% 109/400 [00:43<01:57,  2.48it/s]\u001b[A\n",
            " 28% 110/400 [00:44<01:56,  2.49it/s]\u001b[A\n",
            " 28% 111/400 [00:44<01:56,  2.49it/s]\u001b[A\n",
            " 28% 112/400 [00:45<01:56,  2.47it/s]\u001b[A\n",
            " 28% 113/400 [00:45<01:55,  2.48it/s]\u001b[A\n",
            " 28% 114/400 [00:45<01:55,  2.48it/s]\u001b[A\n",
            " 29% 115/400 [00:46<01:54,  2.49it/s]\u001b[A\n",
            " 29% 116/400 [00:46<01:53,  2.49it/s]\u001b[A\n",
            " 29% 117/400 [00:47<01:54,  2.46it/s]\u001b[A\n",
            " 30% 118/400 [00:47<01:54,  2.46it/s]\u001b[A\n",
            " 30% 119/400 [00:47<01:53,  2.47it/s]\u001b[A\n",
            " 30% 120/400 [00:48<01:52,  2.48it/s]\u001b[A\n",
            " 30% 121/400 [00:48<01:52,  2.49it/s]\u001b[A\n",
            " 30% 122/400 [00:49<01:51,  2.49it/s]\u001b[A\n",
            " 31% 123/400 [00:49<01:50,  2.50it/s]\u001b[A\n",
            " 31% 124/400 [00:49<01:51,  2.48it/s]\u001b[A\n",
            " 31% 125/400 [00:50<01:51,  2.46it/s]\u001b[A\n",
            " 32% 126/400 [00:50<01:51,  2.45it/s]\u001b[A\n",
            " 32% 127/400 [00:51<01:51,  2.44it/s]\u001b[A\n",
            " 32% 128/400 [00:51<01:51,  2.43it/s]\u001b[A\n",
            " 32% 129/400 [00:52<01:51,  2.43it/s]\u001b[A\n",
            " 32% 130/400 [00:52<01:51,  2.41it/s]\u001b[A\n",
            " 33% 131/400 [00:52<01:51,  2.41it/s]\u001b[A\n",
            " 33% 132/400 [00:53<01:50,  2.42it/s]\u001b[A\n",
            " 33% 133/400 [00:53<01:50,  2.42it/s]\u001b[A\n",
            " 34% 134/400 [00:54<01:49,  2.42it/s]\u001b[A\n",
            " 34% 135/400 [00:54<01:49,  2.43it/s]\u001b[A\n",
            " 34% 136/400 [00:54<01:48,  2.43it/s]\u001b[A\n",
            " 34% 137/400 [00:55<01:47,  2.45it/s]\u001b[A\n",
            " 34% 138/400 [00:55<01:47,  2.45it/s]\u001b[A\n",
            " 35% 139/400 [00:56<01:46,  2.45it/s]\u001b[A\n",
            " 35% 140/400 [00:56<01:45,  2.46it/s]\u001b[A\n",
            " 35% 141/400 [00:56<01:45,  2.46it/s]\u001b[A\n",
            " 36% 142/400 [00:57<01:44,  2.47it/s]\u001b[A\n",
            " 36% 143/400 [00:57<01:43,  2.48it/s]\u001b[A\n",
            " 36% 144/400 [00:58<01:43,  2.46it/s]\u001b[A\n",
            " 36% 145/400 [00:58<01:43,  2.46it/s]\u001b[A\n",
            " 36% 146/400 [00:59<01:43,  2.45it/s]\u001b[A\n",
            " 37% 147/400 [00:59<01:43,  2.45it/s]\u001b[A\n",
            " 37% 148/400 [00:59<01:42,  2.46it/s]\u001b[A\n",
            " 37% 149/400 [01:00<01:42,  2.46it/s]\u001b[A\n",
            " 38% 150/400 [01:00<01:41,  2.47it/s]\u001b[A\n",
            " 38% 151/400 [01:01<01:40,  2.48it/s]\u001b[A\n",
            " 38% 152/400 [01:01<01:40,  2.47it/s]\u001b[A\n",
            " 38% 153/400 [01:01<01:39,  2.47it/s]\u001b[A\n",
            " 38% 154/400 [01:02<01:39,  2.46it/s]\u001b[A\n",
            " 39% 155/400 [01:02<01:40,  2.45it/s]\u001b[A\n",
            " 39% 156/400 [01:03<01:40,  2.44it/s]\u001b[A\n",
            " 39% 157/400 [01:03<01:40,  2.43it/s]\u001b[A\n",
            " 40% 158/400 [01:03<01:39,  2.43it/s]\u001b[A\n",
            " 40% 159/400 [01:04<01:39,  2.42it/s]\u001b[A\n",
            " 40% 160/400 [01:04<01:38,  2.43it/s]\u001b[A\n",
            " 40% 161/400 [01:05<01:38,  2.42it/s]\u001b[A\n",
            " 40% 162/400 [01:05<01:38,  2.41it/s]\u001b[A\n",
            " 41% 163/400 [01:05<01:38,  2.41it/s]\u001b[A\n",
            " 41% 164/400 [01:06<01:38,  2.40it/s]\u001b[A\n",
            " 41% 165/400 [01:06<01:37,  2.40it/s]\u001b[A\n",
            " 42% 166/400 [01:07<01:36,  2.41it/s]\u001b[A\n",
            " 42% 167/400 [01:07<01:36,  2.42it/s]\u001b[A\n",
            " 42% 168/400 [01:08<01:36,  2.41it/s]\u001b[A\n",
            " 42% 169/400 [01:08<01:36,  2.39it/s]\u001b[A\n",
            " 42% 170/400 [01:08<01:35,  2.40it/s]\u001b[A\n",
            " 43% 171/400 [01:09<01:35,  2.40it/s]\u001b[A\n",
            " 43% 172/400 [01:09<01:34,  2.41it/s]\u001b[A\n",
            " 43% 173/400 [01:10<01:34,  2.40it/s]\u001b[A\n",
            " 44% 174/400 [01:10<01:33,  2.42it/s]\u001b[A\n",
            " 44% 175/400 [01:10<01:32,  2.44it/s]\u001b[A\n",
            " 44% 176/400 [01:11<01:31,  2.44it/s]\u001b[A\n",
            " 44% 177/400 [01:11<01:30,  2.45it/s]\u001b[A\n",
            " 44% 178/400 [01:12<01:30,  2.45it/s]\u001b[A\n",
            " 45% 179/400 [01:12<01:29,  2.46it/s]\u001b[A\n",
            " 45% 180/400 [01:12<01:29,  2.47it/s]\u001b[A\n",
            " 45% 181/400 [01:13<01:28,  2.47it/s]\u001b[A\n",
            " 46% 182/400 [01:13<01:28,  2.48it/s]\u001b[A\n",
            " 46% 183/400 [01:14<01:27,  2.48it/s]\u001b[A\n",
            " 46% 184/400 [01:14<01:27,  2.47it/s]\u001b[A\n",
            " 46% 185/400 [01:15<01:27,  2.46it/s]\u001b[A\n",
            " 46% 186/400 [01:15<01:26,  2.47it/s]\u001b[A\n",
            " 47% 187/400 [01:15<01:26,  2.46it/s]\u001b[A\n",
            " 47% 188/400 [01:16<01:26,  2.45it/s]\u001b[A\n",
            " 47% 189/400 [01:16<01:25,  2.45it/s]\u001b[A\n",
            " 48% 190/400 [01:17<01:25,  2.45it/s]\u001b[A\n",
            " 48% 191/400 [01:17<01:25,  2.45it/s]\u001b[A\n",
            " 48% 192/400 [01:17<01:24,  2.45it/s]\u001b[A\n",
            " 48% 193/400 [01:18<01:24,  2.46it/s]\u001b[A\n",
            " 48% 194/400 [01:18<01:23,  2.46it/s]\u001b[A\n",
            " 49% 195/400 [01:19<01:23,  2.46it/s]\u001b[A\n",
            " 49% 196/400 [01:19<01:23,  2.44it/s]\u001b[A\n",
            " 49% 197/400 [01:19<01:23,  2.42it/s]\u001b[A\n",
            " 50% 198/400 [01:20<01:23,  2.42it/s]\u001b[A\n",
            " 50% 199/400 [01:20<01:22,  2.42it/s]\u001b[A\n",
            " 50% 200/400 [01:21<01:22,  2.42it/s]\u001b[A\n",
            " 50% 201/400 [01:21<01:22,  2.40it/s]\u001b[A\n",
            " 50% 202/400 [01:22<01:23,  2.38it/s]\u001b[A\n",
            " 51% 203/400 [01:22<01:22,  2.39it/s]\u001b[A\n",
            " 51% 204/400 [01:22<01:21,  2.40it/s]\u001b[A\n",
            " 51% 205/400 [01:23<01:21,  2.40it/s]\u001b[A\n",
            " 52% 206/400 [01:23<01:20,  2.40it/s]\u001b[A\n",
            " 52% 207/400 [01:24<01:21,  2.38it/s]\u001b[A\n",
            " 52% 208/400 [01:24<01:20,  2.39it/s]\u001b[A\n",
            " 52% 209/400 [01:24<01:19,  2.41it/s]\u001b[A\n",
            " 52% 210/400 [01:25<01:18,  2.43it/s]\u001b[A\n",
            " 53% 211/400 [01:25<01:17,  2.42it/s]\u001b[A\n",
            " 53% 212/400 [01:26<01:17,  2.43it/s]\u001b[A\n",
            " 53% 213/400 [01:26<01:16,  2.45it/s]\u001b[A\n",
            " 54% 214/400 [01:26<01:15,  2.45it/s]\u001b[A\n",
            " 54% 215/400 [01:27<01:15,  2.45it/s]\u001b[A\n",
            " 54% 216/400 [01:27<01:14,  2.45it/s]\u001b[A\n",
            " 54% 217/400 [01:28<01:14,  2.46it/s]\u001b[A\n",
            " 55% 218/400 [01:28<01:14,  2.46it/s]\u001b[A\n",
            " 55% 219/400 [01:28<01:13,  2.45it/s]\u001b[A\n",
            " 55% 220/400 [01:29<01:14,  2.43it/s]\u001b[A\n",
            " 55% 221/400 [01:29<01:13,  2.45it/s]\u001b[A\n",
            " 56% 222/400 [01:30<01:12,  2.45it/s]\u001b[A\n",
            " 56% 223/400 [01:30<01:11,  2.46it/s]\u001b[A\n",
            " 56% 224/400 [01:31<01:11,  2.47it/s]\u001b[A\n",
            " 56% 225/400 [01:31<01:11,  2.46it/s]\u001b[A\n",
            " 56% 226/400 [01:31<01:11,  2.45it/s]\u001b[A\n",
            " 57% 227/400 [01:32<01:10,  2.44it/s]\u001b[A\n",
            " 57% 228/400 [01:32<01:10,  2.45it/s]\u001b[A\n",
            " 57% 229/400 [01:33<01:09,  2.45it/s]\u001b[A\n",
            " 57% 230/400 [01:33<01:09,  2.46it/s]\u001b[A\n",
            " 58% 231/400 [01:33<01:08,  2.46it/s]\u001b[A\n",
            " 58% 232/400 [01:34<01:08,  2.44it/s]\u001b[A\n",
            " 58% 233/400 [01:34<01:08,  2.43it/s]\u001b[A\n",
            " 58% 234/400 [01:35<01:08,  2.43it/s]\u001b[A\n",
            " 59% 235/400 [01:35<01:08,  2.43it/s]\u001b[A\n",
            " 59% 236/400 [01:35<01:08,  2.41it/s]\u001b[A\n",
            " 59% 237/400 [01:36<01:08,  2.39it/s]\u001b[A\n",
            " 60% 238/400 [01:36<01:07,  2.39it/s]\u001b[A\n",
            " 60% 239/400 [01:37<01:07,  2.39it/s]\u001b[A\n",
            " 60% 240/400 [01:37<01:06,  2.40it/s]\u001b[A\n",
            " 60% 241/400 [01:38<01:05,  2.42it/s]\u001b[A\n",
            " 60% 242/400 [01:38<01:05,  2.42it/s]\u001b[A\n",
            " 61% 243/400 [01:38<01:05,  2.41it/s]\u001b[A\n",
            " 61% 244/400 [01:39<01:04,  2.40it/s]\u001b[A\n",
            " 61% 245/400 [01:39<01:04,  2.41it/s]\u001b[A\n",
            " 62% 246/400 [01:40<01:03,  2.42it/s]\u001b[A\n",
            " 62% 247/400 [01:40<01:02,  2.44it/s]\u001b[A\n",
            " 62% 248/400 [01:40<01:01,  2.46it/s]\u001b[A\n",
            " 62% 249/400 [01:41<01:01,  2.45it/s]\u001b[A\n",
            " 62% 250/400 [01:41<01:01,  2.44it/s]\u001b[A\n",
            " 63% 251/400 [01:42<01:01,  2.42it/s]\u001b[A\n",
            " 63% 252/400 [01:42<01:01,  2.42it/s]\u001b[A\n",
            " 63% 253/400 [01:42<01:00,  2.43it/s]\u001b[A\n",
            " 64% 254/400 [01:43<00:59,  2.44it/s]\u001b[A\n",
            " 64% 255/400 [01:43<00:59,  2.44it/s]\u001b[A\n",
            " 64% 256/400 [01:44<00:58,  2.45it/s]\u001b[A\n",
            " 64% 257/400 [01:44<00:58,  2.46it/s]\u001b[A\n",
            " 64% 258/400 [01:45<00:57,  2.45it/s]\u001b[A\n",
            " 65% 259/400 [01:45<00:57,  2.46it/s]\u001b[A\n",
            " 65% 260/400 [01:45<00:56,  2.46it/s]\u001b[A\n",
            " 65% 261/400 [01:46<00:56,  2.46it/s]\u001b[A\n",
            " 66% 262/400 [01:46<00:56,  2.45it/s]\u001b[A\n",
            " 66% 263/400 [01:47<00:55,  2.45it/s]\u001b[A\n",
            " 66% 264/400 [01:47<00:55,  2.44it/s]\u001b[A\n",
            " 66% 265/400 [01:47<00:55,  2.44it/s]\u001b[A\n",
            " 66% 266/400 [01:48<00:54,  2.44it/s]\u001b[A\n",
            " 67% 267/400 [01:48<00:54,  2.43it/s]\u001b[A\n",
            " 67% 268/400 [01:49<00:54,  2.41it/s]\u001b[A\n",
            " 67% 269/400 [01:49<00:53,  2.43it/s]\u001b[A\n",
            " 68% 270/400 [01:49<00:53,  2.43it/s]\u001b[A\n",
            " 68% 271/400 [01:50<00:53,  2.42it/s]\u001b[A\n",
            " 68% 272/400 [01:50<00:53,  2.39it/s]\u001b[A\n",
            " 68% 273/400 [01:51<00:53,  2.38it/s]\u001b[A\n",
            " 68% 274/400 [01:51<00:53,  2.38it/s]\u001b[A\n",
            " 69% 275/400 [01:52<00:52,  2.39it/s]\u001b[A\n",
            " 69% 276/400 [01:52<00:51,  2.41it/s]\u001b[A\n",
            " 69% 277/400 [01:52<00:50,  2.42it/s]\u001b[A\n",
            " 70% 278/400 [01:53<00:50,  2.42it/s]\u001b[A\n",
            " 70% 279/400 [01:53<00:49,  2.42it/s]\u001b[A\n",
            " 70% 280/400 [01:54<00:48,  2.46it/s]\u001b[A\n",
            " 70% 281/400 [01:54<00:48,  2.44it/s]\u001b[A\n",
            " 70% 282/400 [01:54<00:48,  2.44it/s]\u001b[A\n",
            " 71% 283/400 [01:55<00:47,  2.45it/s]\u001b[A\n",
            " 71% 284/400 [01:55<00:47,  2.45it/s]\u001b[A\n",
            " 71% 285/400 [01:56<00:47,  2.44it/s]\u001b[A\n",
            " 72% 286/400 [01:56<00:46,  2.44it/s]\u001b[A\n",
            " 72% 287/400 [01:56<00:46,  2.44it/s]\u001b[A\n",
            " 72% 288/400 [01:57<00:45,  2.45it/s]\u001b[A\n",
            " 72% 289/400 [01:57<00:45,  2.46it/s]\u001b[A\n",
            " 72% 290/400 [01:58<00:44,  2.47it/s]\u001b[A\n",
            " 73% 291/400 [01:58<00:44,  2.46it/s]\u001b[A\n",
            " 73% 292/400 [01:58<00:43,  2.46it/s]\u001b[A\n",
            " 73% 293/400 [01:59<00:43,  2.45it/s]\u001b[A\n",
            " 74% 294/400 [01:59<00:43,  2.45it/s]\u001b[A\n",
            " 74% 295/400 [02:00<00:42,  2.45it/s]\u001b[A\n",
            " 74% 296/400 [02:00<00:42,  2.46it/s]\u001b[A\n",
            " 74% 297/400 [02:01<00:41,  2.46it/s]\u001b[A\n",
            " 74% 298/400 [02:01<00:41,  2.45it/s]\u001b[A\n",
            " 75% 299/400 [02:01<00:41,  2.44it/s]\u001b[A\n",
            " 75% 300/400 [02:02<00:40,  2.45it/s]\u001b[A\n",
            " 75% 301/400 [02:02<00:40,  2.45it/s]\u001b[A\n",
            " 76% 302/400 [02:03<00:40,  2.44it/s]\u001b[A\n",
            " 76% 303/400 [02:03<00:40,  2.41it/s]\u001b[A\n",
            " 76% 304/400 [02:03<00:40,  2.40it/s]\u001b[A\n",
            " 76% 305/400 [02:04<00:39,  2.38it/s]\u001b[A\n",
            " 76% 306/400 [02:04<00:39,  2.39it/s]\u001b[A\n",
            " 77% 307/400 [02:05<00:38,  2.39it/s]\u001b[A\n",
            " 77% 308/400 [02:05<00:38,  2.40it/s]\u001b[A\n",
            " 77% 309/400 [02:06<00:37,  2.41it/s]\u001b[A\n",
            " 78% 310/400 [02:06<00:37,  2.43it/s]\u001b[A\n",
            " 78% 311/400 [02:06<00:36,  2.43it/s]\u001b[A\n",
            " 78% 312/400 [02:07<00:37,  2.37it/s]\u001b[A\n",
            " 78% 313/400 [02:07<00:36,  2.37it/s]\u001b[A\n",
            " 78% 314/400 [02:08<00:36,  2.39it/s]\u001b[A\n",
            " 79% 315/400 [02:08<00:35,  2.41it/s]\u001b[A\n",
            " 79% 316/400 [02:08<00:34,  2.44it/s]\u001b[A\n",
            " 79% 317/400 [02:09<00:33,  2.46it/s]\u001b[A\n",
            " 80% 318/400 [02:09<00:33,  2.47it/s]\u001b[A\n",
            " 80% 319/400 [02:10<00:32,  2.46it/s]\u001b[A\n",
            " 80% 320/400 [02:10<00:32,  2.47it/s]\u001b[A\n",
            " 80% 321/400 [02:10<00:32,  2.47it/s]\u001b[A\n",
            " 80% 322/400 [02:11<00:31,  2.46it/s]\u001b[A\n",
            " 81% 323/400 [02:11<00:31,  2.47it/s]\u001b[A\n",
            " 81% 324/400 [02:12<00:30,  2.47it/s]\u001b[A\n",
            " 81% 325/400 [02:12<00:30,  2.46it/s]\u001b[A\n",
            " 82% 326/400 [02:12<00:30,  2.46it/s]\u001b[A\n",
            " 82% 327/400 [02:13<00:29,  2.46it/s]\u001b[A\n",
            " 82% 328/400 [02:13<00:29,  2.47it/s]\u001b[A\n",
            " 82% 329/400 [02:14<00:28,  2.45it/s]\u001b[A\n",
            " 82% 330/400 [02:14<00:28,  2.44it/s]\u001b[A\n",
            " 83% 331/400 [02:15<00:28,  2.44it/s]\u001b[A\n",
            " 83% 332/400 [02:15<00:27,  2.44it/s]\u001b[A\n",
            " 83% 333/400 [02:15<00:27,  2.45it/s]\u001b[A\n",
            " 84% 334/400 [02:16<00:26,  2.46it/s]\u001b[A\n",
            " 84% 335/400 [02:16<00:26,  2.46it/s]\u001b[A\n",
            " 84% 336/400 [02:17<00:25,  2.47it/s]\u001b[A\n",
            " 84% 337/400 [02:17<00:25,  2.46it/s]\u001b[A\n",
            " 84% 338/400 [02:17<00:25,  2.47it/s]\u001b[A\n",
            " 85% 339/400 [02:18<00:24,  2.47it/s]\u001b[A\n",
            " 85% 340/400 [02:18<00:24,  2.46it/s]\u001b[A\n",
            " 85% 341/400 [02:19<00:24,  2.46it/s]\u001b[A\n",
            " 86% 342/400 [02:19<00:23,  2.46it/s]\u001b[A\n",
            " 86% 343/400 [02:19<00:23,  2.47it/s]\u001b[A\n",
            " 86% 344/400 [02:20<00:22,  2.46it/s]\u001b[A\n",
            " 86% 345/400 [02:20<00:22,  2.46it/s]\u001b[A\n",
            " 86% 346/400 [02:21<00:22,  2.45it/s]\u001b[A\n",
            " 87% 347/400 [02:21<00:21,  2.45it/s]\u001b[A\n",
            " 87% 348/400 [02:21<00:21,  2.45it/s]\u001b[A\n",
            " 87% 349/400 [02:22<00:20,  2.44it/s]\u001b[A\n",
            " 88% 350/400 [02:22<00:20,  2.42it/s]\u001b[A\n",
            " 88% 351/400 [02:23<00:20,  2.40it/s]\u001b[A\n",
            " 88% 352/400 [02:23<00:19,  2.41it/s]\u001b[A\n",
            " 88% 353/400 [02:23<00:19,  2.42it/s]\u001b[A\n",
            " 88% 354/400 [02:24<00:19,  2.42it/s]\u001b[A\n",
            " 89% 355/400 [02:24<00:18,  2.42it/s]\u001b[A\n",
            " 89% 356/400 [02:25<00:18,  2.44it/s]\u001b[A\n",
            " 89% 357/400 [02:25<00:17,  2.44it/s]\u001b[A\n",
            " 90% 358/400 [02:26<00:17,  2.45it/s]\u001b[A\n",
            " 90% 359/400 [02:26<00:16,  2.46it/s]\u001b[A\n",
            " 90% 360/400 [02:26<00:16,  2.47it/s]\u001b[A\n",
            " 90% 361/400 [02:27<00:15,  2.47it/s]\u001b[A\n",
            " 90% 362/400 [02:27<00:15,  2.46it/s]\u001b[A\n",
            " 91% 363/400 [02:28<00:15,  2.46it/s]\u001b[A\n",
            " 91% 364/400 [02:28<00:14,  2.46it/s]\u001b[A\n",
            " 91% 365/400 [02:28<00:14,  2.45it/s]\u001b[A\n",
            " 92% 366/400 [02:29<00:13,  2.44it/s]\u001b[A\n",
            " 92% 367/400 [02:29<00:13,  2.44it/s]\u001b[A\n",
            " 92% 368/400 [02:30<00:13,  2.45it/s]\u001b[A\n",
            " 92% 369/400 [02:30<00:12,  2.45it/s]\u001b[A\n",
            " 92% 370/400 [02:30<00:12,  2.47it/s]\u001b[A\n",
            " 93% 371/400 [02:31<00:11,  2.49it/s]\u001b[A\n",
            " 93% 372/400 [02:31<00:11,  2.48it/s]\u001b[A\n",
            " 93% 373/400 [02:32<00:10,  2.48it/s]\u001b[A\n",
            " 94% 374/400 [02:32<00:10,  2.49it/s]\u001b[A\n",
            " 94% 375/400 [02:32<00:10,  2.49it/s]\u001b[A\n",
            " 94% 376/400 [02:33<00:09,  2.47it/s]\u001b[A\n",
            " 94% 377/400 [02:33<00:09,  2.46it/s]\u001b[A\n",
            " 94% 378/400 [02:34<00:08,  2.46it/s]\u001b[A\n",
            " 95% 379/400 [02:34<00:08,  2.43it/s]\u001b[A\n",
            " 95% 380/400 [02:34<00:08,  2.42it/s]\u001b[A\n",
            " 95% 381/400 [02:35<00:07,  2.42it/s]\u001b[A\n",
            " 96% 382/400 [02:35<00:07,  2.43it/s]\u001b[A\n",
            " 96% 383/400 [02:36<00:06,  2.45it/s]\u001b[A\n",
            " 96% 384/400 [02:36<00:06,  2.43it/s]\u001b[A\n",
            " 96% 385/400 [02:37<00:06,  2.43it/s]\u001b[A\n",
            " 96% 386/400 [02:37<00:05,  2.43it/s]\u001b[A\n",
            " 97% 387/400 [02:37<00:05,  2.41it/s]\u001b[A\n",
            " 97% 388/400 [02:38<00:04,  2.42it/s]\u001b[A\n",
            " 97% 389/400 [02:38<00:04,  2.44it/s]\u001b[A\n",
            " 98% 390/400 [02:39<00:04,  2.45it/s]\u001b[A\n",
            " 98% 391/400 [02:39<00:03,  2.44it/s]\u001b[A\n",
            " 98% 392/400 [02:39<00:03,  2.45it/s]\u001b[A\n",
            " 98% 393/400 [02:40<00:02,  2.47it/s]\u001b[A\n",
            " 98% 394/400 [02:40<00:02,  2.48it/s]\u001b[A\n",
            " 99% 395/400 [02:41<00:02,  2.47it/s]\u001b[A\n",
            " 99% 396/400 [02:41<00:01,  2.45it/s]\u001b[A\n",
            " 99% 397/400 [02:41<00:01,  2.45it/s]\u001b[A\n",
            "100% 398/400 [02:42<00:00,  2.46it/s]\u001b[A\n",
            "100% 399/400 [02:42<00:00,  2.46it/s]\u001b[A\n",
            "                                      \n",
            "\u001b[A{'eval_loss': 1.0534292459487915, 'eval_rouge1': 29.0117, 'eval_rouge2': 18.0225, 'eval_rougeL': 28.7259, 'eval_rougeLsum': 28.8014, 'eval_bleu': 9.3134, 'eval_gen_len': 18.1881, 'eval_runtime': 188.9225, 'eval_samples_per_second': 8.469, 'eval_steps_per_second': 2.117, 'epoch': 2.67}\n",
            " 53% 800/1500 [21:17<05:50,  2.00it/s]\n",
            "100% 400/400 [03:08<00:00,  2.47it/s]\u001b[A\n",
            "                                     \u001b[ASaving model checkpoint to mT5_model_full/checkpoint-800\n",
            "Configuration saved in mT5_model_full/checkpoint-800/config.json\n",
            "Configuration saved in mT5_model_full/checkpoint-800/generation_config.json\n",
            "Model weights saved in mT5_model_full/checkpoint-800/pytorch_model.bin\n",
            "tokenizer config file saved in mT5_model_full/checkpoint-800/tokenizer_config.json\n",
            "Special tokens file saved in mT5_model_full/checkpoint-800/special_tokens_map.json\n",
            "Copy vocab file to mT5_model_full/checkpoint-800/spiece.model\n",
            "{'loss': 1.5105, 'learning_rate': 1.3000000000000001e-05, 'epoch': 2.83}\n",
            "{'loss': 1.5111, 'learning_rate': 1.2e-05, 'epoch': 3.0}\n",
            " 60% 900/1500 [22:24<04:50,  2.06it/s]Saving model checkpoint to mT5_model_full/checkpoint-900\n",
            "Configuration saved in mT5_model_full/checkpoint-900/config.json\n",
            "Configuration saved in mT5_model_full/checkpoint-900/generation_config.json\n",
            "Model weights saved in mT5_model_full/checkpoint-900/pytorch_model.bin\n",
            "tokenizer config file saved in mT5_model_full/checkpoint-900/tokenizer_config.json\n",
            "Special tokens file saved in mT5_model_full/checkpoint-900/special_tokens_map.json\n",
            "Copy vocab file to mT5_model_full/checkpoint-900/spiece.model\n",
            "{'loss': 1.4116, 'learning_rate': 1.1e-05, 'epoch': 3.17}\n",
            "{'loss': 1.4174, 'learning_rate': 9.999999999999999e-06, 'epoch': 3.33}\n",
            " 67% 1000/1500 [23:32<04:03,  2.05it/s]***** Running Evaluation *****\n",
            "  Num examples = 1600\n",
            "  Batch size = 4\n",
            "\n",
            "  0% 0/400 [00:00<?, ?it/s]\u001b[A\n",
            "  0% 2/400 [00:00<01:21,  4.86it/s]\u001b[A\n",
            "  1% 3/400 [00:00<01:55,  3.45it/s]\u001b[A\n",
            "  1% 4/400 [00:01<02:11,  3.02it/s]\u001b[A\n",
            "  1% 5/400 [00:01<02:21,  2.80it/s]\u001b[A\n",
            "  2% 6/400 [00:02<02:26,  2.68it/s]\u001b[A\n",
            "  2% 7/400 [00:02<02:30,  2.61it/s]\u001b[A\n",
            "  2% 8/400 [00:02<02:33,  2.56it/s]\u001b[A\n",
            "  2% 9/400 [00:03<02:35,  2.52it/s]\u001b[A\n",
            "  2% 10/400 [00:03<02:35,  2.51it/s]\u001b[A\n",
            "  3% 11/400 [00:04<02:36,  2.49it/s]\u001b[A\n",
            "  3% 12/400 [00:04<02:36,  2.49it/s]\u001b[A\n",
            "  3% 13/400 [00:04<02:35,  2.48it/s]\u001b[A\n",
            "  4% 14/400 [00:05<02:35,  2.48it/s]\u001b[A\n",
            "  4% 15/400 [00:05<02:35,  2.47it/s]\u001b[A\n",
            "  4% 16/400 [00:06<02:34,  2.48it/s]\u001b[A\n",
            "  4% 17/400 [00:06<02:34,  2.48it/s]\u001b[A\n",
            "  4% 18/400 [00:06<02:34,  2.47it/s]\u001b[A\n",
            "  5% 19/400 [00:07<02:35,  2.46it/s]\u001b[A\n",
            "  5% 20/400 [00:07<02:36,  2.43it/s]\u001b[A\n",
            "  5% 21/400 [00:08<02:35,  2.44it/s]\u001b[A\n",
            "  6% 22/400 [00:08<02:34,  2.45it/s]\u001b[A\n",
            "  6% 23/400 [00:08<02:33,  2.46it/s]\u001b[A\n",
            "  6% 24/400 [00:09<02:32,  2.47it/s]\u001b[A\n",
            "  6% 25/400 [00:09<02:32,  2.46it/s]\u001b[A\n",
            "  6% 26/400 [00:10<02:32,  2.45it/s]\u001b[A\n",
            "  7% 27/400 [00:10<02:33,  2.43it/s]\u001b[A\n",
            "  7% 28/400 [00:11<02:35,  2.39it/s]\u001b[A\n",
            "  7% 29/400 [00:11<02:35,  2.39it/s]\u001b[A\n",
            "  8% 30/400 [00:11<02:33,  2.41it/s]\u001b[A\n",
            "  8% 31/400 [00:12<02:31,  2.43it/s]\u001b[A\n",
            "  8% 32/400 [00:12<02:30,  2.45it/s]\u001b[A\n",
            "  8% 33/400 [00:13<02:29,  2.46it/s]\u001b[A\n",
            "  8% 34/400 [00:13<02:28,  2.46it/s]\u001b[A\n",
            "  9% 35/400 [00:13<02:28,  2.45it/s]\u001b[A\n",
            "  9% 36/400 [00:14<02:27,  2.46it/s]\u001b[A\n",
            "  9% 37/400 [00:14<02:26,  2.47it/s]\u001b[A\n",
            " 10% 38/400 [00:15<02:26,  2.46it/s]\u001b[A\n",
            " 10% 39/400 [00:15<02:25,  2.47it/s]\u001b[A\n",
            " 10% 40/400 [00:15<02:26,  2.46it/s]\u001b[A\n",
            " 10% 41/400 [00:16<02:26,  2.45it/s]\u001b[A\n",
            " 10% 42/400 [00:16<02:26,  2.44it/s]\u001b[A\n",
            " 11% 43/400 [00:17<02:26,  2.44it/s]\u001b[A\n",
            " 11% 44/400 [00:17<02:25,  2.45it/s]\u001b[A\n",
            " 11% 45/400 [00:17<02:25,  2.44it/s]\u001b[A\n",
            " 12% 46/400 [00:18<02:24,  2.45it/s]\u001b[A\n",
            " 12% 47/400 [00:18<02:23,  2.46it/s]\u001b[A\n",
            " 12% 48/400 [00:19<02:23,  2.45it/s]\u001b[A\n",
            " 12% 49/400 [00:19<02:23,  2.44it/s]\u001b[A\n",
            " 12% 50/400 [00:19<02:23,  2.44it/s]\u001b[A\n",
            " 13% 51/400 [00:20<02:22,  2.44it/s]\u001b[A\n",
            " 13% 52/400 [00:20<02:22,  2.45it/s]\u001b[A\n",
            " 13% 53/400 [00:21<02:21,  2.45it/s]\u001b[A\n",
            " 14% 54/400 [00:21<02:21,  2.44it/s]\u001b[A\n",
            " 14% 55/400 [00:22<02:21,  2.43it/s]\u001b[A\n",
            " 14% 56/400 [00:22<02:22,  2.41it/s]\u001b[A\n",
            " 14% 57/400 [00:22<02:23,  2.40it/s]\u001b[A\n",
            " 14% 58/400 [00:23<02:22,  2.40it/s]\u001b[A\n",
            " 15% 59/400 [00:23<02:22,  2.40it/s]\u001b[A\n",
            " 15% 60/400 [00:24<02:21,  2.40it/s]\u001b[A\n",
            " 15% 61/400 [00:24<02:21,  2.40it/s]\u001b[A\n",
            " 16% 62/400 [00:24<02:20,  2.40it/s]\u001b[A\n",
            " 16% 63/400 [00:25<02:21,  2.39it/s]\u001b[A\n",
            " 16% 64/400 [00:25<02:20,  2.39it/s]\u001b[A\n",
            " 16% 65/400 [00:26<02:20,  2.39it/s]\u001b[A\n",
            " 16% 66/400 [00:26<02:18,  2.41it/s]\u001b[A\n",
            " 17% 67/400 [00:27<02:17,  2.43it/s]\u001b[A\n",
            " 17% 68/400 [00:27<02:15,  2.44it/s]\u001b[A\n",
            " 17% 69/400 [00:27<02:15,  2.44it/s]\u001b[A\n",
            " 18% 70/400 [00:28<02:16,  2.42it/s]\u001b[A\n",
            " 18% 71/400 [00:28<02:15,  2.43it/s]\u001b[A\n",
            " 18% 72/400 [00:29<02:14,  2.45it/s]\u001b[A\n",
            " 18% 73/400 [00:29<02:13,  2.45it/s]\u001b[A\n",
            " 18% 74/400 [00:29<02:13,  2.45it/s]\u001b[A\n",
            " 19% 75/400 [00:30<02:12,  2.46it/s]\u001b[A\n",
            " 19% 76/400 [00:30<02:12,  2.44it/s]\u001b[A\n",
            " 19% 77/400 [00:31<02:13,  2.42it/s]\u001b[A\n",
            " 20% 78/400 [00:31<02:11,  2.44it/s]\u001b[A\n",
            " 20% 79/400 [00:31<02:12,  2.43it/s]\u001b[A\n",
            " 20% 80/400 [00:32<02:09,  2.47it/s]\u001b[A\n",
            " 20% 81/400 [00:32<02:08,  2.47it/s]\u001b[A\n",
            " 20% 82/400 [00:33<02:09,  2.46it/s]\u001b[A\n",
            " 21% 83/400 [00:33<02:09,  2.45it/s]\u001b[A\n",
            " 21% 84/400 [00:33<02:09,  2.45it/s]\u001b[A\n",
            " 21% 85/400 [00:34<02:07,  2.47it/s]\u001b[A\n",
            " 22% 86/400 [00:34<02:07,  2.47it/s]\u001b[A\n",
            " 22% 87/400 [00:35<02:07,  2.46it/s]\u001b[A\n",
            " 22% 88/400 [00:35<02:06,  2.47it/s]\u001b[A\n",
            " 22% 89/400 [00:35<02:05,  2.48it/s]\u001b[A\n",
            " 22% 90/400 [00:36<02:05,  2.47it/s]\u001b[A\n",
            " 23% 91/400 [00:36<02:06,  2.45it/s]\u001b[A\n",
            " 23% 92/400 [00:37<02:06,  2.44it/s]\u001b[A\n",
            " 23% 93/400 [00:37<02:06,  2.43it/s]\u001b[A\n",
            " 24% 94/400 [00:38<02:07,  2.41it/s]\u001b[A\n",
            " 24% 95/400 [00:38<02:07,  2.40it/s]\u001b[A\n",
            " 24% 97/400 [00:39<01:44,  2.90it/s]\u001b[A\n",
            " 24% 98/400 [00:39<01:51,  2.72it/s]\u001b[A\n",
            " 25% 99/400 [00:39<01:54,  2.63it/s]\u001b[A\n",
            " 25% 100/400 [00:40<01:58,  2.54it/s]\u001b[A\n",
            " 25% 101/400 [00:40<01:59,  2.50it/s]\u001b[A\n",
            " 26% 102/400 [00:41<01:59,  2.49it/s]\u001b[A\n",
            " 26% 103/400 [00:41<01:59,  2.49it/s]\u001b[A\n",
            " 26% 104/400 [00:41<01:58,  2.50it/s]\u001b[A\n",
            " 26% 105/400 [00:42<01:57,  2.51it/s]\u001b[A\n",
            " 26% 106/400 [00:42<01:58,  2.49it/s]\u001b[A\n",
            " 27% 107/400 [00:43<01:57,  2.50it/s]\u001b[A\n",
            " 27% 108/400 [00:43<01:56,  2.51it/s]\u001b[A\n",
            " 27% 109/400 [00:43<01:56,  2.51it/s]\u001b[A\n",
            " 28% 110/400 [00:44<01:55,  2.51it/s]\u001b[A\n",
            " 28% 111/400 [00:44<01:55,  2.49it/s]\u001b[A\n",
            " 28% 112/400 [00:45<01:55,  2.49it/s]\u001b[A\n",
            " 28% 113/400 [00:45<01:55,  2.49it/s]\u001b[A\n",
            " 28% 114/400 [00:45<01:55,  2.48it/s]\u001b[A\n",
            " 29% 115/400 [00:46<01:55,  2.46it/s]\u001b[A\n",
            " 29% 116/400 [00:46<01:55,  2.46it/s]\u001b[A\n",
            " 29% 117/400 [00:47<01:54,  2.46it/s]\u001b[A\n",
            " 30% 118/400 [00:47<01:53,  2.47it/s]\u001b[A\n",
            " 30% 119/400 [00:47<01:53,  2.47it/s]\u001b[A\n",
            " 30% 120/400 [00:48<01:52,  2.48it/s]\u001b[A\n",
            " 30% 121/400 [00:48<01:51,  2.49it/s]\u001b[A\n",
            " 30% 122/400 [00:49<01:51,  2.49it/s]\u001b[A\n",
            " 31% 123/400 [00:49<01:51,  2.48it/s]\u001b[A\n",
            " 31% 124/400 [00:49<01:51,  2.48it/s]\u001b[A\n",
            " 31% 125/400 [00:50<01:50,  2.49it/s]\u001b[A\n",
            " 32% 126/400 [00:50<01:49,  2.49it/s]\u001b[A\n",
            " 32% 127/400 [00:51<01:49,  2.49it/s]\u001b[A\n",
            " 32% 128/400 [00:51<01:49,  2.48it/s]\u001b[A\n",
            " 32% 129/400 [00:51<01:49,  2.47it/s]\u001b[A\n",
            " 32% 130/400 [00:52<01:49,  2.47it/s]\u001b[A\n",
            " 33% 131/400 [00:52<01:48,  2.47it/s]\u001b[A\n",
            " 33% 132/400 [00:53<01:48,  2.47it/s]\u001b[A\n",
            " 33% 133/400 [00:53<01:48,  2.47it/s]\u001b[A\n",
            " 34% 134/400 [00:54<01:47,  2.47it/s]\u001b[A\n",
            " 34% 135/400 [00:54<01:47,  2.47it/s]\u001b[A\n",
            " 34% 136/400 [00:54<01:47,  2.46it/s]\u001b[A\n",
            " 34% 137/400 [00:55<01:47,  2.45it/s]\u001b[A\n",
            " 34% 138/400 [00:55<01:46,  2.45it/s]\u001b[A\n",
            " 35% 139/400 [00:56<01:45,  2.47it/s]\u001b[A\n",
            " 35% 140/400 [00:56<01:45,  2.47it/s]\u001b[A\n",
            " 35% 141/400 [00:56<01:44,  2.48it/s]\u001b[A\n",
            " 36% 142/400 [00:57<01:43,  2.48it/s]\u001b[A\n",
            " 36% 143/400 [00:57<01:43,  2.49it/s]\u001b[A\n",
            " 36% 144/400 [00:58<01:43,  2.47it/s]\u001b[A\n",
            " 36% 145/400 [00:58<01:43,  2.47it/s]\u001b[A\n",
            " 36% 146/400 [00:58<01:42,  2.47it/s]\u001b[A\n",
            " 37% 147/400 [00:59<01:42,  2.47it/s]\u001b[A\n",
            " 37% 148/400 [00:59<01:41,  2.48it/s]\u001b[A\n",
            " 37% 149/400 [01:00<01:40,  2.50it/s]\u001b[A\n",
            " 38% 150/400 [01:00<01:39,  2.50it/s]\u001b[A\n",
            " 38% 151/400 [01:00<01:40,  2.49it/s]\u001b[A\n",
            " 38% 152/400 [01:01<01:39,  2.49it/s]\u001b[A\n",
            " 38% 153/400 [01:01<01:39,  2.47it/s]\u001b[A\n",
            " 38% 154/400 [01:02<01:39,  2.48it/s]\u001b[A\n",
            " 39% 155/400 [01:02<01:38,  2.48it/s]\u001b[A\n",
            " 39% 156/400 [01:02<01:38,  2.48it/s]\u001b[A\n",
            " 39% 157/400 [01:03<01:38,  2.46it/s]\u001b[A\n",
            " 40% 158/400 [01:03<01:37,  2.47it/s]\u001b[A\n",
            " 40% 159/400 [01:04<01:37,  2.47it/s]\u001b[A\n",
            " 40% 160/400 [01:04<01:36,  2.48it/s]\u001b[A\n",
            " 40% 161/400 [01:04<01:36,  2.48it/s]\u001b[A\n",
            " 40% 162/400 [01:05<01:36,  2.48it/s]\u001b[A\n",
            " 41% 163/400 [01:05<01:35,  2.48it/s]\u001b[A\n",
            " 41% 164/400 [01:06<01:35,  2.47it/s]\u001b[A\n",
            " 41% 165/400 [01:06<01:35,  2.45it/s]\u001b[A\n",
            " 42% 166/400 [01:06<01:35,  2.45it/s]\u001b[A\n",
            " 42% 167/400 [01:07<01:35,  2.45it/s]\u001b[A\n",
            " 42% 168/400 [01:07<01:35,  2.44it/s]\u001b[A\n",
            " 42% 169/400 [01:08<01:34,  2.44it/s]\u001b[A\n",
            " 42% 170/400 [01:08<01:35,  2.42it/s]\u001b[A\n",
            " 43% 171/400 [01:09<01:35,  2.39it/s]\u001b[A\n",
            " 43% 172/400 [01:09<01:34,  2.40it/s]\u001b[A\n",
            " 43% 173/400 [01:09<01:34,  2.41it/s]\u001b[A\n",
            " 44% 174/400 [01:10<01:33,  2.41it/s]\u001b[A\n",
            " 44% 175/400 [01:10<01:33,  2.42it/s]\u001b[A\n",
            " 44% 176/400 [01:11<01:32,  2.43it/s]\u001b[A\n",
            " 44% 177/400 [01:11<01:30,  2.46it/s]\u001b[A\n",
            " 44% 178/400 [01:11<01:29,  2.47it/s]\u001b[A\n",
            " 45% 179/400 [01:12<01:29,  2.47it/s]\u001b[A\n",
            " 45% 180/400 [01:12<01:28,  2.48it/s]\u001b[A\n",
            " 45% 181/400 [01:13<01:28,  2.48it/s]\u001b[A\n",
            " 46% 182/400 [01:13<01:28,  2.48it/s]\u001b[A\n",
            " 46% 183/400 [01:13<01:27,  2.48it/s]\u001b[A\n",
            " 46% 184/400 [01:14<01:26,  2.48it/s]\u001b[A\n",
            " 46% 185/400 [01:14<01:27,  2.47it/s]\u001b[A\n",
            " 46% 186/400 [01:15<01:26,  2.46it/s]\u001b[A\n",
            " 47% 187/400 [01:15<01:26,  2.47it/s]\u001b[A\n",
            " 47% 188/400 [01:15<01:25,  2.47it/s]\u001b[A\n",
            " 47% 189/400 [01:16<01:25,  2.46it/s]\u001b[A\n",
            " 48% 190/400 [01:16<01:25,  2.46it/s]\u001b[A\n",
            " 48% 191/400 [01:17<01:24,  2.47it/s]\u001b[A\n",
            " 48% 192/400 [01:17<01:24,  2.47it/s]\u001b[A\n",
            " 48% 193/400 [01:17<01:24,  2.46it/s]\u001b[A\n",
            " 48% 194/400 [01:18<01:24,  2.45it/s]\u001b[A\n",
            " 49% 195/400 [01:18<01:23,  2.45it/s]\u001b[A\n",
            " 49% 196/400 [01:19<01:22,  2.46it/s]\u001b[A\n",
            " 49% 197/400 [01:19<01:22,  2.47it/s]\u001b[A\n",
            " 50% 198/400 [01:19<01:21,  2.47it/s]\u001b[A\n",
            " 50% 199/400 [01:20<01:20,  2.48it/s]\u001b[A\n",
            " 50% 200/400 [01:20<01:20,  2.47it/s]\u001b[A\n",
            " 50% 201/400 [01:21<01:21,  2.44it/s]\u001b[A\n",
            " 50% 202/400 [01:21<01:20,  2.44it/s]\u001b[A\n",
            " 51% 203/400 [01:22<01:20,  2.44it/s]\u001b[A\n",
            " 51% 204/400 [01:22<01:20,  2.44it/s]\u001b[A\n",
            " 51% 205/400 [01:22<01:19,  2.44it/s]\u001b[A\n",
            " 52% 206/400 [01:23<01:19,  2.43it/s]\u001b[A\n",
            " 52% 207/400 [01:23<01:20,  2.40it/s]\u001b[A\n",
            " 52% 208/400 [01:24<01:19,  2.41it/s]\u001b[A\n",
            " 52% 209/400 [01:24<01:18,  2.43it/s]\u001b[A\n",
            " 52% 210/400 [01:24<01:18,  2.42it/s]\u001b[A\n",
            " 53% 211/400 [01:25<01:18,  2.42it/s]\u001b[A\n",
            " 53% 212/400 [01:25<01:17,  2.43it/s]\u001b[A\n",
            " 53% 213/400 [01:26<01:16,  2.44it/s]\u001b[A\n",
            " 54% 214/400 [01:26<01:16,  2.44it/s]\u001b[A\n",
            " 54% 215/400 [01:26<01:15,  2.44it/s]\u001b[A\n",
            " 54% 216/400 [01:27<01:15,  2.45it/s]\u001b[A\n",
            " 54% 217/400 [01:27<01:14,  2.45it/s]\u001b[A\n",
            " 55% 218/400 [01:28<01:14,  2.45it/s]\u001b[A\n",
            " 55% 219/400 [01:28<01:14,  2.45it/s]\u001b[A\n",
            " 55% 220/400 [01:29<01:14,  2.43it/s]\u001b[A\n",
            " 55% 221/400 [01:29<01:13,  2.44it/s]\u001b[A\n",
            " 56% 222/400 [01:29<01:12,  2.45it/s]\u001b[A\n",
            " 56% 223/400 [01:30<01:12,  2.46it/s]\u001b[A\n",
            " 56% 224/400 [01:30<01:11,  2.45it/s]\u001b[A\n",
            " 56% 225/400 [01:31<01:11,  2.46it/s]\u001b[A\n",
            " 56% 226/400 [01:31<01:10,  2.46it/s]\u001b[A\n",
            " 57% 227/400 [01:31<01:10,  2.44it/s]\u001b[A\n",
            " 57% 228/400 [01:32<01:10,  2.44it/s]\u001b[A\n",
            " 57% 229/400 [01:32<01:10,  2.44it/s]\u001b[A\n",
            " 57% 230/400 [01:33<01:09,  2.45it/s]\u001b[A\n",
            " 58% 231/400 [01:33<01:08,  2.46it/s]\u001b[A\n",
            " 58% 232/400 [01:33<01:08,  2.47it/s]\u001b[A\n",
            " 58% 233/400 [01:34<01:07,  2.47it/s]\u001b[A\n",
            " 58% 234/400 [01:34<01:07,  2.47it/s]\u001b[A\n",
            " 59% 235/400 [01:35<01:06,  2.48it/s]\u001b[A\n",
            " 59% 236/400 [01:35<01:06,  2.48it/s]\u001b[A\n",
            " 59% 237/400 [01:35<01:06,  2.44it/s]\u001b[A\n",
            " 60% 238/400 [01:36<01:07,  2.41it/s]\u001b[A\n",
            " 60% 239/400 [01:36<01:06,  2.40it/s]\u001b[A\n",
            " 60% 240/400 [01:37<01:06,  2.41it/s]\u001b[A\n",
            " 60% 241/400 [01:37<01:06,  2.39it/s]\u001b[A\n",
            " 60% 242/400 [01:38<01:06,  2.37it/s]\u001b[A\n",
            " 61% 243/400 [01:38<01:06,  2.37it/s]\u001b[A\n",
            " 61% 244/400 [01:38<01:06,  2.34it/s]\u001b[A\n",
            " 61% 245/400 [01:39<01:05,  2.35it/s]\u001b[A\n",
            " 62% 246/400 [01:39<01:05,  2.35it/s]\u001b[A\n",
            " 62% 247/400 [01:40<01:04,  2.37it/s]\u001b[A\n",
            " 62% 248/400 [01:40<01:03,  2.41it/s]\u001b[A\n",
            " 62% 249/400 [01:40<01:02,  2.42it/s]\u001b[A\n",
            " 62% 250/400 [01:41<01:01,  2.43it/s]\u001b[A\n",
            " 63% 251/400 [01:41<01:00,  2.44it/s]\u001b[A\n",
            " 63% 252/400 [01:42<01:00,  2.44it/s]\u001b[A\n",
            " 63% 253/400 [01:42<00:59,  2.45it/s]\u001b[A\n",
            " 64% 254/400 [01:43<00:59,  2.44it/s]\u001b[A\n",
            " 64% 255/400 [01:43<00:59,  2.45it/s]\u001b[A\n",
            " 64% 256/400 [01:43<00:58,  2.46it/s]\u001b[A\n",
            " 64% 257/400 [01:44<00:57,  2.47it/s]\u001b[A\n",
            " 64% 258/400 [01:44<00:57,  2.48it/s]\u001b[A\n",
            " 65% 259/400 [01:45<00:56,  2.47it/s]\u001b[A\n",
            " 65% 260/400 [01:45<00:56,  2.48it/s]\u001b[A\n",
            " 65% 261/400 [01:45<00:56,  2.47it/s]\u001b[A\n",
            " 66% 262/400 [01:46<00:55,  2.47it/s]\u001b[A\n",
            " 66% 263/400 [01:46<00:55,  2.47it/s]\u001b[A\n",
            " 66% 264/400 [01:47<00:55,  2.46it/s]\u001b[A\n",
            " 66% 265/400 [01:47<00:54,  2.46it/s]\u001b[A\n",
            " 66% 266/400 [01:47<00:54,  2.45it/s]\u001b[A\n",
            " 67% 267/400 [01:48<00:54,  2.46it/s]\u001b[A\n",
            " 67% 268/400 [01:48<00:53,  2.47it/s]\u001b[A\n",
            " 67% 269/400 [01:49<00:53,  2.47it/s]\u001b[A\n",
            " 68% 270/400 [01:49<00:52,  2.47it/s]\u001b[A\n",
            " 68% 271/400 [01:49<00:52,  2.47it/s]\u001b[A\n",
            " 68% 272/400 [01:50<00:51,  2.46it/s]\u001b[A\n",
            " 68% 273/400 [01:50<00:52,  2.44it/s]\u001b[A\n",
            " 68% 274/400 [01:51<00:52,  2.42it/s]\u001b[A\n",
            " 69% 275/400 [01:51<00:52,  2.40it/s]\u001b[A\n",
            " 69% 276/400 [01:51<00:51,  2.39it/s]\u001b[A\n",
            " 69% 277/400 [01:52<00:51,  2.39it/s]\u001b[A\n",
            " 70% 278/400 [01:52<00:50,  2.39it/s]\u001b[A\n",
            " 70% 279/400 [01:53<00:50,  2.40it/s]\u001b[A\n",
            " 70% 280/400 [01:53<00:48,  2.45it/s]\u001b[A\n",
            " 70% 281/400 [01:54<00:49,  2.41it/s]\u001b[A\n",
            " 70% 282/400 [01:54<00:48,  2.41it/s]\u001b[A\n",
            " 71% 283/400 [01:54<00:48,  2.41it/s]\u001b[A\n",
            " 71% 284/400 [01:55<00:48,  2.41it/s]\u001b[A\n",
            " 71% 285/400 [01:55<00:47,  2.44it/s]\u001b[A\n",
            " 72% 286/400 [01:56<00:46,  2.45it/s]\u001b[A\n",
            " 72% 287/400 [01:56<00:46,  2.45it/s]\u001b[A\n",
            " 72% 288/400 [01:56<00:45,  2.44it/s]\u001b[A\n",
            " 72% 289/400 [01:57<00:45,  2.45it/s]\u001b[A\n",
            " 72% 290/400 [01:57<00:44,  2.45it/s]\u001b[A\n",
            " 73% 291/400 [01:58<00:44,  2.45it/s]\u001b[A\n",
            " 73% 292/400 [01:58<00:43,  2.46it/s]\u001b[A\n",
            " 73% 293/400 [01:58<00:43,  2.47it/s]\u001b[A\n",
            " 74% 294/400 [01:59<00:42,  2.47it/s]\u001b[A\n",
            " 74% 295/400 [01:59<00:42,  2.47it/s]\u001b[A\n",
            " 74% 296/400 [02:00<00:42,  2.45it/s]\u001b[A\n",
            " 74% 297/400 [02:00<00:42,  2.45it/s]\u001b[A\n",
            " 74% 298/400 [02:00<00:41,  2.45it/s]\u001b[A\n",
            " 75% 299/400 [02:01<00:41,  2.45it/s]\u001b[A\n",
            " 75% 300/400 [02:01<00:40,  2.46it/s]\u001b[A\n",
            " 75% 301/400 [02:02<00:40,  2.46it/s]\u001b[A\n",
            " 76% 302/400 [02:02<00:39,  2.48it/s]\u001b[A\n",
            " 76% 303/400 [02:03<00:39,  2.49it/s]\u001b[A\n",
            " 76% 304/400 [02:03<00:38,  2.46it/s]\u001b[A\n",
            " 76% 305/400 [02:03<00:38,  2.46it/s]\u001b[A\n",
            " 76% 306/400 [02:04<00:38,  2.44it/s]\u001b[A\n",
            " 77% 307/400 [02:04<00:38,  2.45it/s]\u001b[A\n",
            " 77% 308/400 [02:05<00:37,  2.46it/s]\u001b[A\n",
            " 77% 309/400 [02:05<00:37,  2.45it/s]\u001b[A\n",
            " 78% 310/400 [02:05<00:37,  2.43it/s]\u001b[A\n",
            " 78% 311/400 [02:06<00:36,  2.42it/s]\u001b[A\n",
            " 78% 312/400 [02:06<00:36,  2.41it/s]\u001b[A\n",
            " 78% 313/400 [02:07<00:36,  2.35it/s]\u001b[A\n",
            " 78% 314/400 [02:07<00:36,  2.36it/s]\u001b[A\n",
            " 79% 315/400 [02:08<00:35,  2.37it/s]\u001b[A\n",
            " 79% 316/400 [02:08<00:35,  2.37it/s]\u001b[A\n",
            " 79% 317/400 [02:08<00:35,  2.37it/s]\u001b[A\n",
            " 80% 318/400 [02:09<00:34,  2.36it/s]\u001b[A\n",
            " 80% 319/400 [02:09<00:34,  2.36it/s]\u001b[A\n",
            " 80% 320/400 [02:10<00:33,  2.39it/s]\u001b[A\n",
            " 80% 321/400 [02:10<00:32,  2.41it/s]\u001b[A\n",
            " 80% 322/400 [02:10<00:32,  2.43it/s]\u001b[A\n",
            " 81% 323/400 [02:11<00:31,  2.43it/s]\u001b[A\n",
            " 81% 324/400 [02:11<00:31,  2.44it/s]\u001b[A\n",
            " 81% 325/400 [02:12<00:30,  2.45it/s]\u001b[A\n",
            " 82% 326/400 [02:12<00:30,  2.45it/s]\u001b[A\n",
            " 82% 327/400 [02:12<00:29,  2.45it/s]\u001b[A\n",
            " 82% 328/400 [02:13<00:29,  2.46it/s]\u001b[A\n",
            " 82% 329/400 [02:13<00:28,  2.46it/s]\u001b[A\n",
            " 82% 330/400 [02:14<00:28,  2.47it/s]\u001b[A\n",
            " 83% 331/400 [02:14<00:27,  2.47it/s]\u001b[A\n",
            " 83% 332/400 [02:14<00:27,  2.47it/s]\u001b[A\n",
            " 83% 333/400 [02:15<00:27,  2.46it/s]\u001b[A\n",
            " 84% 334/400 [02:15<00:26,  2.47it/s]\u001b[A\n",
            " 84% 335/400 [02:16<00:26,  2.46it/s]\u001b[A\n",
            " 84% 336/400 [02:16<00:25,  2.46it/s]\u001b[A\n",
            " 84% 337/400 [02:17<00:25,  2.47it/s]\u001b[A\n",
            " 84% 338/400 [02:17<00:25,  2.47it/s]\u001b[A\n",
            " 85% 339/400 [02:17<00:24,  2.47it/s]\u001b[A\n",
            " 85% 340/400 [02:18<00:24,  2.48it/s]\u001b[A\n",
            " 85% 341/400 [02:18<00:23,  2.48it/s]\u001b[A\n",
            " 86% 342/400 [02:19<00:23,  2.48it/s]\u001b[A\n",
            " 86% 343/400 [02:19<00:22,  2.48it/s]\u001b[A\n",
            " 86% 344/400 [02:19<00:22,  2.45it/s]\u001b[A\n",
            " 86% 345/400 [02:20<00:22,  2.43it/s]\u001b[A\n",
            " 86% 346/400 [02:20<00:22,  2.40it/s]\u001b[A\n",
            " 87% 347/400 [02:21<00:21,  2.41it/s]\u001b[A\n",
            " 87% 348/400 [02:21<00:21,  2.41it/s]\u001b[A\n",
            " 87% 349/400 [02:21<00:21,  2.40it/s]\u001b[A\n",
            " 88% 350/400 [02:22<00:20,  2.39it/s]\u001b[A\n",
            " 88% 351/400 [02:22<00:20,  2.38it/s]\u001b[A\n",
            " 88% 352/400 [02:23<00:20,  2.38it/s]\u001b[A\n",
            " 88% 353/400 [02:23<00:19,  2.40it/s]\u001b[A\n",
            " 88% 354/400 [02:24<00:19,  2.36it/s]\u001b[A\n",
            " 89% 355/400 [02:24<00:19,  2.30it/s]\u001b[A\n",
            " 89% 356/400 [02:24<00:18,  2.35it/s]\u001b[A\n",
            " 89% 357/400 [02:25<00:18,  2.39it/s]\u001b[A\n",
            " 90% 358/400 [02:25<00:17,  2.40it/s]\u001b[A\n",
            " 90% 359/400 [02:26<00:16,  2.41it/s]\u001b[A\n",
            " 90% 360/400 [02:26<00:16,  2.43it/s]\u001b[A\n",
            " 90% 361/400 [02:26<00:15,  2.44it/s]\u001b[A\n",
            " 90% 362/400 [02:27<00:15,  2.45it/s]\u001b[A\n",
            " 91% 363/400 [02:27<00:15,  2.44it/s]\u001b[A\n",
            " 91% 364/400 [02:28<00:14,  2.45it/s]\u001b[A\n",
            " 91% 365/400 [02:28<00:14,  2.46it/s]\u001b[A\n",
            " 92% 366/400 [02:28<00:13,  2.45it/s]\u001b[A\n",
            " 92% 367/400 [02:29<00:13,  2.46it/s]\u001b[A\n",
            " 92% 368/400 [02:29<00:13,  2.45it/s]\u001b[A\n",
            " 92% 369/400 [02:30<00:12,  2.45it/s]\u001b[A\n",
            " 92% 370/400 [02:30<00:12,  2.45it/s]\u001b[A\n",
            " 93% 371/400 [02:31<00:11,  2.45it/s]\u001b[A\n",
            " 93% 372/400 [02:31<00:11,  2.45it/s]\u001b[A\n",
            " 93% 373/400 [02:31<00:10,  2.46it/s]\u001b[A\n",
            " 94% 374/400 [02:32<00:10,  2.47it/s]\u001b[A\n",
            " 94% 375/400 [02:32<00:10,  2.49it/s]\u001b[A\n",
            " 94% 376/400 [02:33<00:09,  2.46it/s]\u001b[A\n",
            " 94% 377/400 [02:33<00:09,  2.45it/s]\u001b[A\n",
            " 94% 378/400 [02:33<00:08,  2.45it/s]\u001b[A\n",
            " 95% 379/400 [02:34<00:08,  2.45it/s]\u001b[A\n",
            " 95% 380/400 [02:34<00:08,  2.45it/s]\u001b[A\n",
            " 95% 381/400 [02:35<00:07,  2.42it/s]\u001b[A\n",
            " 96% 382/400 [02:35<00:07,  2.43it/s]\u001b[A\n",
            " 96% 383/400 [02:35<00:07,  2.41it/s]\u001b[A\n",
            " 96% 384/400 [02:36<00:06,  2.41it/s]\u001b[A\n",
            " 96% 385/400 [02:36<00:06,  2.41it/s]\u001b[A\n",
            " 96% 386/400 [02:37<00:05,  2.42it/s]\u001b[A\n",
            " 97% 387/400 [02:37<00:05,  2.42it/s]\u001b[A\n",
            " 97% 388/400 [02:38<00:05,  2.38it/s]\u001b[A\n",
            " 97% 389/400 [02:38<00:04,  2.37it/s]\u001b[A\n",
            " 98% 390/400 [02:38<00:04,  2.35it/s]\u001b[A\n",
            " 98% 391/400 [02:39<00:03,  2.35it/s]\u001b[A\n",
            " 98% 392/400 [02:39<00:03,  2.37it/s]\u001b[A\n",
            " 98% 393/400 [02:40<00:02,  2.40it/s]\u001b[A\n",
            " 98% 394/400 [02:40<00:02,  2.41it/s]\u001b[A\n",
            " 99% 395/400 [02:40<00:02,  2.42it/s]\u001b[A\n",
            " 99% 396/400 [02:41<00:01,  2.44it/s]\u001b[A\n",
            " 99% 397/400 [02:41<00:01,  2.43it/s]\u001b[A\n",
            "100% 398/400 [02:42<00:00,  2.45it/s]\u001b[A\n",
            "100% 399/400 [02:42<00:00,  2.46it/s]\u001b[A\n",
            "                                       \n",
            "\u001b[A{'eval_loss': 1.020564079284668, 'eval_rouge1': 28.7764, 'eval_rouge2': 17.8377, 'eval_rougeL': 28.4917, 'eval_rougeLsum': 28.5472, 'eval_bleu': 9.1414, 'eval_gen_len': 18.1444, 'eval_runtime': 188.2685, 'eval_samples_per_second': 8.499, 'eval_steps_per_second': 2.125, 'epoch': 3.33}\n",
            " 67% 1000/1500 [26:40<04:03,  2.05it/s]\n",
            "100% 400/400 [03:07<00:00,  2.47it/s]\u001b[A\n",
            "                                     \u001b[ASaving model checkpoint to mT5_model_full/checkpoint-1000\n",
            "Configuration saved in mT5_model_full/checkpoint-1000/config.json\n",
            "Configuration saved in mT5_model_full/checkpoint-1000/generation_config.json\n",
            "Model weights saved in mT5_model_full/checkpoint-1000/pytorch_model.bin\n",
            "tokenizer config file saved in mT5_model_full/checkpoint-1000/tokenizer_config.json\n",
            "Special tokens file saved in mT5_model_full/checkpoint-1000/special_tokens_map.json\n",
            "Copy vocab file to mT5_model_full/checkpoint-1000/spiece.model\n",
            "{'loss': 1.3941, 'learning_rate': 9e-06, 'epoch': 3.5}\n",
            "{'loss': 1.4751, 'learning_rate': 8e-06, 'epoch': 3.67}\n",
            " 73% 1100/1500 [27:49<03:23,  1.97it/s]Saving model checkpoint to mT5_model_full/checkpoint-1100\n",
            "Configuration saved in mT5_model_full/checkpoint-1100/config.json\n",
            "Configuration saved in mT5_model_full/checkpoint-1100/generation_config.json\n",
            "Model weights saved in mT5_model_full/checkpoint-1100/pytorch_model.bin\n",
            "tokenizer config file saved in mT5_model_full/checkpoint-1100/tokenizer_config.json\n",
            "Special tokens file saved in mT5_model_full/checkpoint-1100/special_tokens_map.json\n",
            "Copy vocab file to mT5_model_full/checkpoint-1100/spiece.model\n",
            "{'loss': 1.4151, 'learning_rate': 7e-06, 'epoch': 3.83}\n",
            "{'loss': 1.3571, 'learning_rate': 6e-06, 'epoch': 4.0}\n",
            " 80% 1200/1500 [28:57<02:31,  1.98it/s]***** Running Evaluation *****\n",
            "  Num examples = 1600\n",
            "  Batch size = 4\n",
            "\n",
            "  0% 0/400 [00:00<?, ?it/s]\u001b[A\n",
            "  0% 2/400 [00:00<01:21,  4.87it/s]\u001b[A\n",
            "  1% 3/400 [00:00<01:56,  3.42it/s]\u001b[A\n",
            "  1% 4/400 [00:01<02:12,  2.98it/s]\u001b[A\n",
            "  1% 5/400 [00:01<02:22,  2.78it/s]\u001b[A\n",
            "  2% 6/400 [00:02<02:28,  2.65it/s]\u001b[A\n",
            "  2% 7/400 [00:02<02:31,  2.59it/s]\u001b[A\n",
            "  2% 8/400 [00:02<02:34,  2.54it/s]\u001b[A\n",
            "  2% 9/400 [00:03<02:36,  2.51it/s]\u001b[A\n",
            "  2% 10/400 [00:03<02:37,  2.48it/s]\u001b[A\n",
            "  3% 11/400 [00:04<02:37,  2.47it/s]\u001b[A\n",
            "  3% 12/400 [00:04<02:37,  2.47it/s]\u001b[A\n",
            "  3% 13/400 [00:04<02:37,  2.46it/s]\u001b[A\n",
            "  4% 14/400 [00:05<02:36,  2.46it/s]\u001b[A\n",
            "  4% 15/400 [00:05<02:37,  2.45it/s]\u001b[A\n",
            "  4% 16/400 [00:06<02:37,  2.45it/s]\u001b[A\n",
            "  4% 17/400 [00:06<02:36,  2.45it/s]\u001b[A\n",
            "  4% 18/400 [00:06<02:36,  2.45it/s]\u001b[A\n",
            "  5% 19/400 [00:07<02:35,  2.44it/s]\u001b[A\n",
            "  5% 20/400 [00:07<02:35,  2.44it/s]\u001b[A\n",
            "  5% 21/400 [00:08<02:35,  2.44it/s]\u001b[A\n",
            "  6% 22/400 [00:08<02:35,  2.43it/s]\u001b[A\n",
            "  6% 23/400 [00:09<02:35,  2.43it/s]\u001b[A\n",
            "  6% 24/400 [00:09<02:35,  2.43it/s]\u001b[A\n",
            "  6% 25/400 [00:09<02:34,  2.43it/s]\u001b[A\n",
            "  6% 26/400 [00:10<02:33,  2.43it/s]\u001b[A\n",
            "  7% 27/400 [00:10<02:34,  2.41it/s]\u001b[A\n",
            "  7% 28/400 [00:11<02:34,  2.41it/s]\u001b[A\n",
            "  7% 29/400 [00:11<02:34,  2.40it/s]\u001b[A\n",
            "  8% 30/400 [00:11<02:33,  2.42it/s]\u001b[A\n",
            "  8% 31/400 [00:12<02:32,  2.43it/s]\u001b[A\n",
            "  8% 32/400 [00:12<02:31,  2.43it/s]\u001b[A\n",
            "  8% 33/400 [00:13<02:31,  2.43it/s]\u001b[A\n",
            "  8% 34/400 [00:13<02:32,  2.40it/s]\u001b[A\n",
            "  9% 35/400 [00:14<02:32,  2.39it/s]\u001b[A\n",
            "  9% 36/400 [00:14<02:32,  2.39it/s]\u001b[A\n",
            "  9% 37/400 [00:14<02:30,  2.41it/s]\u001b[A\n",
            " 10% 38/400 [00:15<02:29,  2.42it/s]\u001b[A\n",
            " 10% 39/400 [00:15<02:28,  2.44it/s]\u001b[A\n",
            " 10% 40/400 [00:16<02:27,  2.44it/s]\u001b[A\n",
            " 10% 41/400 [00:16<02:27,  2.43it/s]\u001b[A\n",
            " 10% 42/400 [00:16<02:28,  2.41it/s]\u001b[A\n",
            " 11% 43/400 [00:17<02:28,  2.41it/s]\u001b[A\n",
            " 11% 44/400 [00:17<02:27,  2.42it/s]\u001b[A\n",
            " 11% 45/400 [00:18<02:27,  2.41it/s]\u001b[A\n",
            " 12% 46/400 [00:18<02:26,  2.42it/s]\u001b[A\n",
            " 12% 47/400 [00:18<02:24,  2.44it/s]\u001b[A\n",
            " 12% 48/400 [00:19<02:23,  2.45it/s]\u001b[A\n",
            " 12% 49/400 [00:19<02:23,  2.45it/s]\u001b[A\n",
            " 12% 50/400 [00:20<02:23,  2.45it/s]\u001b[A\n",
            " 13% 51/400 [00:20<02:22,  2.45it/s]\u001b[A\n",
            " 13% 52/400 [00:20<02:21,  2.45it/s]\u001b[A\n",
            " 13% 53/400 [00:21<02:20,  2.47it/s]\u001b[A\n",
            " 14% 54/400 [00:21<02:20,  2.46it/s]\u001b[A\n",
            " 14% 55/400 [00:22<02:20,  2.46it/s]\u001b[A\n",
            " 14% 56/400 [00:22<02:19,  2.46it/s]\u001b[A\n",
            " 14% 57/400 [00:23<02:19,  2.45it/s]\u001b[A\n",
            " 14% 58/400 [00:23<02:19,  2.45it/s]\u001b[A\n",
            " 15% 59/400 [00:23<02:19,  2.44it/s]\u001b[A\n",
            " 15% 60/400 [00:24<02:19,  2.43it/s]\u001b[A\n",
            " 15% 61/400 [00:24<02:19,  2.44it/s]\u001b[A\n",
            " 16% 62/400 [00:25<02:19,  2.43it/s]\u001b[A\n",
            " 16% 63/400 [00:25<02:19,  2.42it/s]\u001b[A\n",
            " 16% 64/400 [00:25<02:18,  2.42it/s]\u001b[A\n",
            " 16% 65/400 [00:26<02:18,  2.42it/s]\u001b[A\n",
            " 16% 66/400 [00:26<02:17,  2.42it/s]\u001b[A\n",
            " 17% 67/400 [00:27<02:17,  2.43it/s]\u001b[A\n",
            " 17% 68/400 [00:27<02:16,  2.43it/s]\u001b[A\n",
            " 17% 69/400 [00:27<02:14,  2.46it/s]\u001b[A\n",
            " 18% 70/400 [00:28<02:13,  2.47it/s]\u001b[A\n",
            " 18% 71/400 [00:28<02:13,  2.47it/s]\u001b[A\n",
            " 18% 72/400 [00:29<02:12,  2.47it/s]\u001b[A\n",
            " 18% 73/400 [00:29<02:12,  2.47it/s]\u001b[A\n",
            " 18% 74/400 [00:29<02:11,  2.48it/s]\u001b[A\n",
            " 19% 75/400 [00:30<02:11,  2.47it/s]\u001b[A\n",
            " 19% 76/400 [00:30<02:11,  2.47it/s]\u001b[A\n",
            " 19% 77/400 [00:31<02:10,  2.47it/s]\u001b[A\n",
            " 20% 78/400 [00:31<02:09,  2.48it/s]\u001b[A\n",
            " 20% 79/400 [00:31<02:09,  2.48it/s]\u001b[A\n",
            " 20% 80/400 [00:32<02:08,  2.49it/s]\u001b[A\n",
            " 20% 81/400 [00:32<02:07,  2.49it/s]\u001b[A\n",
            " 20% 82/400 [00:33<02:08,  2.48it/s]\u001b[A\n",
            " 21% 83/400 [00:33<02:08,  2.47it/s]\u001b[A\n",
            " 21% 84/400 [00:33<02:08,  2.47it/s]\u001b[A\n",
            " 21% 85/400 [00:34<02:07,  2.46it/s]\u001b[A\n",
            " 22% 86/400 [00:34<02:07,  2.47it/s]\u001b[A\n",
            " 22% 87/400 [00:35<02:06,  2.47it/s]\u001b[A\n",
            " 22% 88/400 [00:35<02:05,  2.48it/s]\u001b[A\n",
            " 22% 89/400 [00:36<02:05,  2.47it/s]\u001b[A\n",
            " 22% 90/400 [00:36<02:05,  2.47it/s]\u001b[A\n",
            " 23% 91/400 [00:36<02:05,  2.46it/s]\u001b[A\n",
            " 23% 92/400 [00:37<02:04,  2.47it/s]\u001b[A\n",
            " 23% 93/400 [00:37<02:04,  2.47it/s]\u001b[A\n",
            " 24% 94/400 [00:38<02:03,  2.47it/s]\u001b[A\n",
            " 24% 95/400 [00:38<02:03,  2.47it/s]\u001b[A\n",
            " 24% 97/400 [00:38<01:40,  3.00it/s]\u001b[A\n",
            " 24% 98/400 [00:39<01:46,  2.84it/s]\u001b[A\n",
            " 25% 99/400 [00:39<01:50,  2.73it/s]\u001b[A\n",
            " 25% 100/400 [00:40<01:52,  2.67it/s]\u001b[A\n",
            " 25% 101/400 [00:40<01:54,  2.61it/s]\u001b[A\n",
            " 26% 102/400 [00:40<01:56,  2.57it/s]\u001b[A\n",
            " 26% 103/400 [00:41<01:57,  2.53it/s]\u001b[A\n",
            " 26% 104/400 [00:41<01:57,  2.51it/s]\u001b[A\n",
            " 26% 105/400 [00:42<01:57,  2.50it/s]\u001b[A\n",
            " 26% 106/400 [00:42<01:57,  2.49it/s]\u001b[A\n",
            " 27% 107/400 [00:43<01:57,  2.49it/s]\u001b[A\n",
            " 27% 108/400 [00:43<01:57,  2.49it/s]\u001b[A\n",
            " 27% 109/400 [00:43<01:57,  2.48it/s]\u001b[A\n",
            " 28% 110/400 [00:44<01:56,  2.49it/s]\u001b[A\n",
            " 28% 111/400 [00:44<01:56,  2.49it/s]\u001b[A\n",
            " 28% 112/400 [00:45<01:55,  2.49it/s]\u001b[A\n",
            " 28% 113/400 [00:45<01:55,  2.49it/s]\u001b[A\n",
            " 28% 114/400 [00:45<01:55,  2.48it/s]\u001b[A\n",
            " 29% 115/400 [00:46<01:55,  2.48it/s]\u001b[A\n",
            " 29% 116/400 [00:46<01:54,  2.48it/s]\u001b[A\n",
            " 29% 117/400 [00:47<01:54,  2.48it/s]\u001b[A\n",
            " 30% 118/400 [00:47<01:53,  2.48it/s]\u001b[A\n",
            " 30% 119/400 [00:47<01:53,  2.48it/s]\u001b[A\n",
            " 30% 120/400 [00:48<01:52,  2.49it/s]\u001b[A\n",
            " 30% 121/400 [00:48<01:51,  2.49it/s]\u001b[A\n",
            " 30% 122/400 [00:49<01:51,  2.50it/s]\u001b[A\n",
            " 31% 123/400 [00:49<01:50,  2.50it/s]\u001b[A\n",
            " 31% 124/400 [00:49<01:50,  2.50it/s]\u001b[A\n",
            " 31% 125/400 [00:50<01:49,  2.51it/s]\u001b[A\n",
            " 32% 126/400 [00:50<01:49,  2.50it/s]\u001b[A\n",
            " 32% 127/400 [00:51<01:49,  2.48it/s]\u001b[A\n",
            " 32% 128/400 [00:51<01:49,  2.49it/s]\u001b[A\n",
            " 32% 129/400 [00:51<01:48,  2.49it/s]\u001b[A\n",
            " 32% 130/400 [00:52<01:48,  2.48it/s]\u001b[A\n",
            " 33% 131/400 [00:52<01:48,  2.48it/s]\u001b[A\n",
            " 33% 132/400 [00:53<01:47,  2.49it/s]\u001b[A\n",
            " 33% 133/400 [00:53<01:47,  2.49it/s]\u001b[A\n",
            " 34% 134/400 [00:53<01:47,  2.48it/s]\u001b[A\n",
            " 34% 135/400 [00:54<01:47,  2.47it/s]\u001b[A\n",
            " 34% 136/400 [00:54<01:47,  2.46it/s]\u001b[A\n",
            " 34% 137/400 [00:55<01:46,  2.47it/s]\u001b[A\n",
            " 34% 138/400 [00:55<01:46,  2.46it/s]\u001b[A\n",
            " 35% 139/400 [00:55<01:45,  2.47it/s]\u001b[A\n",
            " 35% 140/400 [00:56<01:44,  2.48it/s]\u001b[A\n",
            " 35% 141/400 [00:56<01:44,  2.48it/s]\u001b[A\n",
            " 36% 142/400 [00:57<01:44,  2.47it/s]\u001b[A\n",
            " 36% 143/400 [00:57<01:43,  2.48it/s]\u001b[A\n",
            " 36% 144/400 [00:57<01:42,  2.49it/s]\u001b[A\n",
            " 36% 145/400 [00:58<01:42,  2.50it/s]\u001b[A\n",
            " 36% 146/400 [00:58<01:41,  2.49it/s]\u001b[A\n",
            " 37% 147/400 [00:59<01:41,  2.49it/s]\u001b[A\n",
            " 37% 148/400 [00:59<01:41,  2.49it/s]\u001b[A\n",
            " 37% 149/400 [00:59<01:40,  2.49it/s]\u001b[A\n",
            " 38% 150/400 [01:00<01:40,  2.49it/s]\u001b[A\n",
            " 38% 151/400 [01:00<01:39,  2.51it/s]\u001b[A\n",
            " 38% 152/400 [01:01<01:38,  2.51it/s]\u001b[A\n",
            " 38% 153/400 [01:01<01:38,  2.50it/s]\u001b[A\n",
            " 38% 154/400 [01:01<01:38,  2.50it/s]\u001b[A\n",
            " 39% 155/400 [01:02<01:38,  2.49it/s]\u001b[A\n",
            " 39% 156/400 [01:02<01:38,  2.49it/s]\u001b[A\n",
            " 39% 157/400 [01:03<01:38,  2.48it/s]\u001b[A\n",
            " 40% 158/400 [01:03<01:37,  2.48it/s]\u001b[A\n",
            " 40% 159/400 [01:03<01:36,  2.49it/s]\u001b[A\n",
            " 40% 160/400 [01:04<01:36,  2.49it/s]\u001b[A\n",
            " 40% 161/400 [01:04<01:35,  2.49it/s]\u001b[A\n",
            " 40% 162/400 [01:05<01:35,  2.48it/s]\u001b[A\n",
            " 41% 163/400 [01:05<01:35,  2.48it/s]\u001b[A\n",
            " 41% 164/400 [01:05<01:35,  2.48it/s]\u001b[A\n",
            " 41% 165/400 [01:06<01:35,  2.46it/s]\u001b[A\n",
            " 42% 166/400 [01:06<01:34,  2.47it/s]\u001b[A\n",
            " 42% 167/400 [01:07<01:34,  2.47it/s]\u001b[A\n",
            " 42% 168/400 [01:07<01:34,  2.46it/s]\u001b[A\n",
            " 42% 169/400 [01:07<01:33,  2.47it/s]\u001b[A\n",
            " 42% 170/400 [01:08<01:33,  2.47it/s]\u001b[A\n",
            " 43% 171/400 [01:08<01:32,  2.46it/s]\u001b[A\n",
            " 43% 172/400 [01:09<01:32,  2.46it/s]\u001b[A\n",
            " 43% 173/400 [01:09<01:32,  2.46it/s]\u001b[A\n",
            " 44% 174/400 [01:09<01:31,  2.47it/s]\u001b[A\n",
            " 44% 175/400 [01:10<01:31,  2.47it/s]\u001b[A\n",
            " 44% 176/400 [01:10<01:30,  2.47it/s]\u001b[A\n",
            " 44% 177/400 [01:11<01:30,  2.48it/s]\u001b[A\n",
            " 44% 178/400 [01:11<01:29,  2.48it/s]\u001b[A\n",
            " 45% 179/400 [01:12<01:29,  2.48it/s]\u001b[A\n",
            " 45% 180/400 [01:12<01:28,  2.49it/s]\u001b[A\n",
            " 45% 181/400 [01:12<01:28,  2.49it/s]\u001b[A\n",
            " 46% 182/400 [01:13<01:27,  2.49it/s]\u001b[A\n",
            " 46% 183/400 [01:13<01:27,  2.48it/s]\u001b[A\n",
            " 46% 184/400 [01:14<01:28,  2.45it/s]\u001b[A\n",
            " 46% 185/400 [01:14<01:28,  2.43it/s]\u001b[A\n",
            " 46% 186/400 [01:14<01:27,  2.43it/s]\u001b[A\n",
            " 47% 187/400 [01:15<01:27,  2.43it/s]\u001b[A\n",
            " 47% 188/400 [01:15<01:26,  2.44it/s]\u001b[A\n",
            " 47% 189/400 [01:16<01:26,  2.45it/s]\u001b[A\n",
            " 48% 190/400 [01:16<01:26,  2.44it/s]\u001b[A\n",
            " 48% 191/400 [01:16<01:25,  2.45it/s]\u001b[A\n",
            " 48% 192/400 [01:17<01:24,  2.45it/s]\u001b[A\n",
            " 48% 193/400 [01:17<01:24,  2.45it/s]\u001b[A\n",
            " 48% 194/400 [01:18<01:24,  2.45it/s]\u001b[A\n",
            " 49% 195/400 [01:18<01:23,  2.45it/s]\u001b[A\n",
            " 49% 196/400 [01:18<01:23,  2.45it/s]\u001b[A\n",
            " 49% 197/400 [01:19<01:22,  2.45it/s]\u001b[A\n",
            " 50% 198/400 [01:19<01:22,  2.46it/s]\u001b[A\n",
            " 50% 199/400 [01:20<01:21,  2.48it/s]\u001b[A\n",
            " 50% 200/400 [01:20<01:21,  2.47it/s]\u001b[A\n",
            " 50% 201/400 [01:20<01:21,  2.46it/s]\u001b[A\n",
            " 50% 202/400 [01:21<01:20,  2.46it/s]\u001b[A\n",
            " 51% 203/400 [01:21<01:20,  2.46it/s]\u001b[A\n",
            " 51% 204/400 [01:22<01:20,  2.45it/s]\u001b[A\n",
            " 51% 205/400 [01:22<01:19,  2.45it/s]\u001b[A\n",
            " 52% 206/400 [01:23<01:19,  2.45it/s]\u001b[A\n",
            " 52% 207/400 [01:23<01:19,  2.44it/s]\u001b[A\n",
            " 52% 208/400 [01:23<01:18,  2.44it/s]\u001b[A\n",
            " 52% 209/400 [01:24<01:17,  2.45it/s]\u001b[A\n",
            " 52% 210/400 [01:24<01:17,  2.45it/s]\u001b[A\n",
            " 53% 211/400 [01:25<01:17,  2.44it/s]\u001b[A\n",
            " 53% 212/400 [01:25<01:16,  2.44it/s]\u001b[A\n",
            " 53% 213/400 [01:25<01:16,  2.44it/s]\u001b[A\n",
            " 54% 214/400 [01:26<01:16,  2.43it/s]\u001b[A\n",
            " 54% 215/400 [01:26<01:16,  2.43it/s]\u001b[A\n",
            " 54% 216/400 [01:27<01:15,  2.44it/s]\u001b[A\n",
            " 54% 217/400 [01:27<01:15,  2.44it/s]\u001b[A\n",
            " 55% 218/400 [01:27<01:14,  2.44it/s]\u001b[A\n",
            " 55% 219/400 [01:28<01:14,  2.44it/s]\u001b[A\n",
            " 55% 220/400 [01:28<01:13,  2.44it/s]\u001b[A\n",
            " 55% 221/400 [01:29<01:12,  2.46it/s]\u001b[A\n",
            " 56% 222/400 [01:29<01:12,  2.47it/s]\u001b[A\n",
            " 56% 223/400 [01:29<01:11,  2.48it/s]\u001b[A\n",
            " 56% 224/400 [01:30<01:10,  2.50it/s]\u001b[A\n",
            " 56% 225/400 [01:30<01:10,  2.50it/s]\u001b[A\n",
            " 56% 226/400 [01:31<01:09,  2.49it/s]\u001b[A\n",
            " 57% 227/400 [01:31<01:09,  2.48it/s]\u001b[A\n",
            " 57% 228/400 [01:31<01:09,  2.47it/s]\u001b[A\n",
            " 57% 229/400 [01:32<01:09,  2.47it/s]\u001b[A\n",
            " 57% 230/400 [01:32<01:09,  2.46it/s]\u001b[A\n",
            " 58% 231/400 [01:33<01:08,  2.46it/s]\u001b[A\n",
            " 58% 232/400 [01:33<01:08,  2.47it/s]\u001b[A\n",
            " 58% 233/400 [01:33<01:07,  2.46it/s]\u001b[A\n",
            " 58% 234/400 [01:34<01:07,  2.47it/s]\u001b[A\n",
            " 59% 235/400 [01:34<01:06,  2.47it/s]\u001b[A\n",
            " 59% 236/400 [01:35<01:06,  2.46it/s]\u001b[A\n",
            " 59% 237/400 [01:35<01:05,  2.47it/s]\u001b[A\n",
            " 60% 238/400 [01:36<01:05,  2.48it/s]\u001b[A\n",
            " 60% 239/400 [01:36<01:04,  2.48it/s]\u001b[A\n",
            " 60% 240/400 [01:36<01:04,  2.47it/s]\u001b[A\n",
            " 60% 241/400 [01:37<01:04,  2.46it/s]\u001b[A\n",
            " 60% 242/400 [01:37<01:04,  2.45it/s]\u001b[A\n",
            " 61% 243/400 [01:38<01:04,  2.45it/s]\u001b[A\n",
            " 61% 244/400 [01:38<01:03,  2.44it/s]\u001b[A\n",
            " 61% 245/400 [01:38<01:03,  2.44it/s]\u001b[A\n",
            " 62% 246/400 [01:39<01:03,  2.44it/s]\u001b[A\n",
            " 62% 247/400 [01:39<01:02,  2.45it/s]\u001b[A\n",
            " 62% 248/400 [01:40<01:01,  2.46it/s]\u001b[A\n",
            " 62% 249/400 [01:40<01:01,  2.46it/s]\u001b[A\n",
            " 62% 250/400 [01:40<01:00,  2.46it/s]\u001b[A\n",
            " 63% 251/400 [01:41<01:00,  2.46it/s]\u001b[A\n",
            " 63% 252/400 [01:41<01:00,  2.46it/s]\u001b[A\n",
            " 63% 253/400 [01:42<00:59,  2.47it/s]\u001b[A\n",
            " 64% 254/400 [01:42<00:58,  2.48it/s]\u001b[A\n",
            " 64% 255/400 [01:42<00:58,  2.49it/s]\u001b[A\n",
            " 64% 256/400 [01:43<00:57,  2.48it/s]\u001b[A\n",
            " 64% 257/400 [01:43<00:57,  2.48it/s]\u001b[A\n",
            " 64% 258/400 [01:44<00:57,  2.47it/s]\u001b[A\n",
            " 65% 259/400 [01:44<00:57,  2.46it/s]\u001b[A\n",
            " 65% 260/400 [01:44<00:56,  2.47it/s]\u001b[A\n",
            " 65% 261/400 [01:45<00:56,  2.47it/s]\u001b[A\n",
            " 66% 262/400 [01:45<00:55,  2.47it/s]\u001b[A\n",
            " 66% 263/400 [01:46<00:55,  2.47it/s]\u001b[A\n",
            " 66% 264/400 [01:46<00:54,  2.47it/s]\u001b[A\n",
            " 66% 265/400 [01:46<00:54,  2.47it/s]\u001b[A\n",
            " 66% 266/400 [01:47<00:54,  2.46it/s]\u001b[A\n",
            " 67% 267/400 [01:47<00:53,  2.47it/s]\u001b[A\n",
            " 67% 268/400 [01:48<00:53,  2.46it/s]\u001b[A\n",
            " 67% 269/400 [01:48<00:53,  2.47it/s]\u001b[A\n",
            " 68% 270/400 [01:48<00:52,  2.47it/s]\u001b[A\n",
            " 68% 271/400 [01:49<00:52,  2.46it/s]\u001b[A\n",
            " 68% 272/400 [01:49<00:52,  2.46it/s]\u001b[A\n",
            " 68% 273/400 [01:50<00:51,  2.46it/s]\u001b[A\n",
            " 68% 274/400 [01:50<00:51,  2.46it/s]\u001b[A\n",
            " 69% 275/400 [01:51<00:50,  2.47it/s]\u001b[A\n",
            " 69% 276/400 [01:51<00:50,  2.46it/s]\u001b[A\n",
            " 69% 277/400 [01:51<00:50,  2.45it/s]\u001b[A\n",
            " 70% 278/400 [01:52<00:50,  2.44it/s]\u001b[A\n",
            " 70% 279/400 [01:52<00:49,  2.43it/s]\u001b[A\n",
            " 70% 280/400 [01:53<00:48,  2.47it/s]\u001b[A\n",
            " 70% 281/400 [01:53<00:48,  2.47it/s]\u001b[A\n",
            " 70% 282/400 [01:53<00:47,  2.46it/s]\u001b[A\n",
            " 71% 283/400 [01:54<00:47,  2.44it/s]\u001b[A\n",
            " 71% 284/400 [01:54<00:47,  2.43it/s]\u001b[A\n",
            " 71% 285/400 [01:55<00:47,  2.43it/s]\u001b[A\n",
            " 72% 286/400 [01:55<00:47,  2.42it/s]\u001b[A\n",
            " 72% 287/400 [01:55<00:46,  2.43it/s]\u001b[A\n",
            " 72% 288/400 [01:56<00:46,  2.43it/s]\u001b[A\n",
            " 72% 289/400 [01:56<00:45,  2.44it/s]\u001b[A\n",
            " 72% 290/400 [01:57<00:44,  2.45it/s]\u001b[A\n",
            " 73% 291/400 [01:57<00:44,  2.46it/s]\u001b[A\n",
            " 73% 292/400 [01:57<00:43,  2.46it/s]\u001b[A\n",
            " 73% 293/400 [01:58<00:43,  2.45it/s]\u001b[A\n",
            " 74% 294/400 [01:58<00:43,  2.44it/s]\u001b[A\n",
            " 74% 295/400 [01:59<00:42,  2.44it/s]\u001b[A\n",
            " 74% 296/400 [01:59<00:42,  2.45it/s]\u001b[A\n",
            " 74% 297/400 [02:00<00:41,  2.46it/s]\u001b[A\n",
            " 74% 298/400 [02:00<00:41,  2.46it/s]\u001b[A\n",
            " 75% 299/400 [02:00<00:40,  2.46it/s]\u001b[A\n",
            " 75% 300/400 [02:01<00:40,  2.47it/s]\u001b[A\n",
            " 75% 301/400 [02:01<00:40,  2.47it/s]\u001b[A\n",
            " 76% 302/400 [02:02<00:39,  2.47it/s]\u001b[A\n",
            " 76% 303/400 [02:02<00:39,  2.48it/s]\u001b[A\n",
            " 76% 304/400 [02:02<00:38,  2.47it/s]\u001b[A\n",
            " 76% 305/400 [02:03<00:38,  2.46it/s]\u001b[A\n",
            " 76% 306/400 [02:03<00:38,  2.46it/s]\u001b[A\n",
            " 77% 307/400 [02:04<00:37,  2.46it/s]\u001b[A\n",
            " 77% 308/400 [02:04<00:37,  2.45it/s]\u001b[A\n",
            " 77% 309/400 [02:04<00:36,  2.46it/s]\u001b[A\n",
            " 78% 310/400 [02:05<00:36,  2.46it/s]\u001b[A\n",
            " 78% 311/400 [02:05<00:36,  2.46it/s]\u001b[A\n",
            " 78% 312/400 [02:06<00:35,  2.47it/s]\u001b[A\n",
            " 78% 313/400 [02:06<00:35,  2.45it/s]\u001b[A\n",
            " 78% 314/400 [02:06<00:34,  2.46it/s]\u001b[A\n",
            " 79% 315/400 [02:07<00:34,  2.45it/s]\u001b[A\n",
            " 79% 316/400 [02:07<00:34,  2.42it/s]\u001b[A\n",
            " 79% 317/400 [02:08<00:35,  2.31it/s]\u001b[A\n",
            " 80% 318/400 [02:08<00:34,  2.35it/s]\u001b[A\n",
            " 80% 319/400 [02:09<00:34,  2.37it/s]\u001b[A\n",
            " 80% 320/400 [02:09<00:33,  2.39it/s]\u001b[A\n",
            " 80% 321/400 [02:09<00:32,  2.43it/s]\u001b[A\n",
            " 80% 322/400 [02:10<00:31,  2.45it/s]\u001b[A\n",
            " 81% 323/400 [02:10<00:32,  2.38it/s]\u001b[A\n",
            " 81% 324/400 [02:11<00:31,  2.41it/s]\u001b[A\n",
            " 81% 325/400 [02:11<00:30,  2.44it/s]\u001b[A\n",
            " 82% 326/400 [02:11<00:30,  2.45it/s]\u001b[A\n",
            " 82% 327/400 [02:12<00:29,  2.45it/s]\u001b[A\n",
            " 82% 328/400 [02:12<00:29,  2.46it/s]\u001b[A\n",
            " 82% 329/400 [02:13<00:28,  2.47it/s]\u001b[A\n",
            " 82% 330/400 [02:13<00:28,  2.46it/s]\u001b[A\n",
            " 83% 331/400 [02:13<00:28,  2.44it/s]\u001b[A\n",
            " 83% 332/400 [02:14<00:27,  2.43it/s]\u001b[A\n",
            " 83% 333/400 [02:14<00:27,  2.43it/s]\u001b[A\n",
            " 84% 334/400 [02:15<00:27,  2.42it/s]\u001b[A\n",
            " 84% 335/400 [02:15<00:26,  2.41it/s]\u001b[A\n",
            " 84% 336/400 [02:16<00:26,  2.42it/s]\u001b[A\n",
            " 84% 337/400 [02:16<00:25,  2.44it/s]\u001b[A\n",
            " 84% 338/400 [02:16<00:25,  2.44it/s]\u001b[A\n",
            " 85% 339/400 [02:17<00:24,  2.46it/s]\u001b[A\n",
            " 85% 340/400 [02:17<00:24,  2.46it/s]\u001b[A\n",
            " 85% 341/400 [02:18<00:24,  2.46it/s]\u001b[A\n",
            " 86% 342/400 [02:18<00:23,  2.46it/s]\u001b[A\n",
            " 86% 343/400 [02:18<00:23,  2.47it/s]\u001b[A\n",
            " 86% 344/400 [02:19<00:22,  2.46it/s]\u001b[A\n",
            " 86% 345/400 [02:19<00:22,  2.46it/s]\u001b[A\n",
            " 86% 346/400 [02:20<00:21,  2.46it/s]\u001b[A\n",
            " 87% 347/400 [02:20<00:21,  2.47it/s]\u001b[A\n",
            " 87% 348/400 [02:20<00:21,  2.47it/s]\u001b[A\n",
            " 87% 349/400 [02:21<00:20,  2.45it/s]\u001b[A\n",
            " 88% 350/400 [02:21<00:20,  2.45it/s]\u001b[A\n",
            " 88% 351/400 [02:22<00:19,  2.46it/s]\u001b[A\n",
            " 88% 352/400 [02:22<00:19,  2.44it/s]\u001b[A\n",
            " 88% 353/400 [02:22<00:19,  2.44it/s]\u001b[A\n",
            " 88% 354/400 [02:23<00:19,  2.41it/s]\u001b[A\n",
            " 89% 355/400 [02:23<00:18,  2.41it/s]\u001b[A\n",
            " 89% 356/400 [02:24<00:18,  2.41it/s]\u001b[A\n",
            " 89% 357/400 [02:24<00:17,  2.43it/s]\u001b[A\n",
            " 90% 358/400 [02:25<00:17,  2.43it/s]\u001b[A\n",
            " 90% 359/400 [02:25<00:16,  2.43it/s]\u001b[A\n",
            " 90% 360/400 [02:25<00:16,  2.43it/s]\u001b[A\n",
            " 90% 361/400 [02:26<00:15,  2.44it/s]\u001b[A\n",
            " 90% 362/400 [02:26<00:15,  2.45it/s]\u001b[A\n",
            " 91% 363/400 [02:27<00:15,  2.45it/s]\u001b[A\n",
            " 91% 364/400 [02:27<00:14,  2.47it/s]\u001b[A\n",
            " 91% 365/400 [02:27<00:14,  2.48it/s]\u001b[A\n",
            " 92% 366/400 [02:28<00:13,  2.49it/s]\u001b[A\n",
            " 92% 367/400 [02:28<00:13,  2.48it/s]\u001b[A\n",
            " 92% 368/400 [02:29<00:12,  2.47it/s]\u001b[A\n",
            " 92% 369/400 [02:29<00:12,  2.46it/s]\u001b[A\n",
            " 92% 370/400 [02:29<00:12,  2.47it/s]\u001b[A\n",
            " 93% 371/400 [02:30<00:11,  2.48it/s]\u001b[A\n",
            " 93% 372/400 [02:30<00:11,  2.47it/s]\u001b[A\n",
            " 93% 373/400 [02:31<00:10,  2.47it/s]\u001b[A\n",
            " 94% 374/400 [02:31<00:10,  2.46it/s]\u001b[A\n",
            " 94% 375/400 [02:31<00:10,  2.46it/s]\u001b[A\n",
            " 94% 376/400 [02:32<00:09,  2.45it/s]\u001b[A\n",
            " 94% 377/400 [02:32<00:09,  2.46it/s]\u001b[A\n",
            " 94% 378/400 [02:33<00:08,  2.46it/s]\u001b[A\n",
            " 95% 379/400 [02:33<00:08,  2.45it/s]\u001b[A\n",
            " 95% 380/400 [02:33<00:08,  2.46it/s]\u001b[A\n",
            " 95% 381/400 [02:34<00:07,  2.47it/s]\u001b[A\n",
            " 96% 382/400 [02:34<00:07,  2.47it/s]\u001b[A\n",
            " 96% 383/400 [02:35<00:06,  2.46it/s]\u001b[A\n",
            " 96% 384/400 [02:35<00:06,  2.46it/s]\u001b[A\n",
            " 96% 385/400 [02:35<00:06,  2.45it/s]\u001b[A\n",
            " 96% 386/400 [02:36<00:05,  2.44it/s]\u001b[A\n",
            " 97% 387/400 [02:36<00:05,  2.46it/s]\u001b[A\n",
            " 97% 388/400 [02:37<00:04,  2.47it/s]\u001b[A\n",
            " 97% 389/400 [02:37<00:04,  2.46it/s]\u001b[A\n",
            " 98% 390/400 [02:38<00:04,  2.46it/s]\u001b[A\n",
            " 98% 391/400 [02:38<00:03,  2.44it/s]\u001b[A\n",
            " 98% 392/400 [02:38<00:03,  2.41it/s]\u001b[A\n",
            " 98% 393/400 [02:39<00:02,  2.42it/s]\u001b[A\n",
            " 98% 394/400 [02:39<00:02,  2.43it/s]\u001b[A\n",
            " 99% 395/400 [02:40<00:02,  2.43it/s]\u001b[A\n",
            " 99% 396/400 [02:40<00:01,  2.43it/s]\u001b[A\n",
            " 99% 397/400 [02:40<00:01,  2.44it/s]\u001b[A\n",
            "100% 398/400 [02:41<00:00,  2.44it/s]\u001b[A\n",
            "100% 399/400 [02:41<00:00,  2.45it/s]\u001b[A\n",
            "                                       \n",
            "\u001b[A{'eval_loss': 1.0042539834976196, 'eval_rouge1': 28.3309, 'eval_rouge2': 17.6735, 'eval_rougeL': 28.0658, 'eval_rougeLsum': 28.1011, 'eval_bleu': 8.978, 'eval_gen_len': 18.0731, 'eval_runtime': 187.4679, 'eval_samples_per_second': 8.535, 'eval_steps_per_second': 2.134, 'epoch': 4.0}\n",
            " 80% 1200/1500 [32:04<02:31,  1.98it/s]\n",
            "100% 400/400 [03:07<00:00,  2.46it/s]\u001b[A\n",
            "                                     \u001b[ASaving model checkpoint to mT5_model_full/checkpoint-1200\n",
            "Configuration saved in mT5_model_full/checkpoint-1200/config.json\n",
            "Configuration saved in mT5_model_full/checkpoint-1200/generation_config.json\n",
            "Model weights saved in mT5_model_full/checkpoint-1200/pytorch_model.bin\n",
            "tokenizer config file saved in mT5_model_full/checkpoint-1200/tokenizer_config.json\n",
            "Special tokens file saved in mT5_model_full/checkpoint-1200/special_tokens_map.json\n",
            "Copy vocab file to mT5_model_full/checkpoint-1200/spiece.model\n",
            "{'loss': 1.4031, 'learning_rate': 4.9999999999999996e-06, 'epoch': 4.17}\n",
            "{'loss': 1.4163, 'learning_rate': 4e-06, 'epoch': 4.33}\n",
            " 87% 1300/1500 [33:12<01:38,  2.02it/s]Saving model checkpoint to mT5_model_full/checkpoint-1300\n",
            "Configuration saved in mT5_model_full/checkpoint-1300/config.json\n",
            "Configuration saved in mT5_model_full/checkpoint-1300/generation_config.json\n",
            "Model weights saved in mT5_model_full/checkpoint-1300/pytorch_model.bin\n",
            "tokenizer config file saved in mT5_model_full/checkpoint-1300/tokenizer_config.json\n",
            "Special tokens file saved in mT5_model_full/checkpoint-1300/special_tokens_map.json\n",
            "Copy vocab file to mT5_model_full/checkpoint-1300/spiece.model\n",
            "{'loss': 1.4031, 'learning_rate': 3e-06, 'epoch': 4.5}\n",
            "{'loss': 1.319, 'learning_rate': 2e-06, 'epoch': 4.67}\n",
            " 93% 1400/1500 [34:21<00:50,  1.96it/s]***** Running Evaluation *****\n",
            "  Num examples = 1600\n",
            "  Batch size = 4\n",
            "\n",
            "  0% 0/400 [00:00<?, ?it/s]\u001b[A\n",
            "  0% 2/400 [00:00<01:20,  4.92it/s]\u001b[A\n",
            "  1% 3/400 [00:00<01:53,  3.49it/s]\u001b[A\n",
            "  1% 4/400 [00:01<02:12,  2.99it/s]\u001b[A\n",
            "  1% 5/400 [00:01<02:22,  2.78it/s]\u001b[A\n",
            "  2% 6/400 [00:02<02:27,  2.67it/s]\u001b[A\n",
            "  2% 7/400 [00:02<02:31,  2.60it/s]\u001b[A\n",
            "  2% 8/400 [00:02<02:33,  2.55it/s]\u001b[A\n",
            "  2% 9/400 [00:03<02:35,  2.52it/s]\u001b[A\n",
            "  2% 10/400 [00:03<02:35,  2.50it/s]\u001b[A\n",
            "  3% 11/400 [00:04<02:36,  2.48it/s]\u001b[A\n",
            "  3% 12/400 [00:04<02:37,  2.47it/s]\u001b[A\n",
            "  3% 13/400 [00:04<02:37,  2.46it/s]\u001b[A\n",
            "  4% 14/400 [00:05<02:36,  2.47it/s]\u001b[A\n",
            "  4% 15/400 [00:05<02:36,  2.46it/s]\u001b[A\n",
            "  4% 16/400 [00:06<02:36,  2.46it/s]\u001b[A\n",
            "  4% 17/400 [00:06<02:35,  2.46it/s]\u001b[A\n",
            "  4% 18/400 [00:06<02:35,  2.46it/s]\u001b[A\n",
            "  5% 19/400 [00:07<02:34,  2.46it/s]\u001b[A\n",
            "  5% 20/400 [00:07<02:34,  2.46it/s]\u001b[A\n",
            "  5% 21/400 [00:08<02:33,  2.47it/s]\u001b[A\n",
            "  6% 22/400 [00:08<02:33,  2.47it/s]\u001b[A\n",
            "  6% 23/400 [00:08<02:32,  2.47it/s]\u001b[A\n",
            "  6% 24/400 [00:09<02:33,  2.45it/s]\u001b[A\n",
            "  6% 25/400 [00:09<02:33,  2.45it/s]\u001b[A\n",
            "  6% 26/400 [00:10<02:32,  2.45it/s]\u001b[A\n",
            "  7% 27/400 [00:10<02:32,  2.45it/s]\u001b[A\n",
            "  7% 28/400 [00:11<02:32,  2.45it/s]\u001b[A\n",
            "  7% 29/400 [00:11<02:32,  2.43it/s]\u001b[A\n",
            "  8% 30/400 [00:11<02:31,  2.44it/s]\u001b[A\n",
            "  8% 31/400 [00:12<02:30,  2.45it/s]\u001b[A\n",
            "  8% 32/400 [00:12<02:31,  2.43it/s]\u001b[A\n",
            "  8% 33/400 [00:13<02:31,  2.43it/s]\u001b[A\n",
            "  8% 34/400 [00:13<02:31,  2.42it/s]\u001b[A\n",
            "  9% 35/400 [00:13<02:30,  2.42it/s]\u001b[A\n",
            "  9% 36/400 [00:14<02:30,  2.42it/s]\u001b[A\n",
            "  9% 37/400 [00:14<02:28,  2.44it/s]\u001b[A\n",
            " 10% 38/400 [00:15<02:27,  2.45it/s]\u001b[A\n",
            " 10% 39/400 [00:15<02:27,  2.45it/s]\u001b[A\n",
            " 10% 40/400 [00:15<02:26,  2.46it/s]\u001b[A\n",
            " 10% 41/400 [00:16<02:25,  2.46it/s]\u001b[A\n",
            " 10% 42/400 [00:16<02:25,  2.46it/s]\u001b[A\n",
            " 11% 43/400 [00:17<02:24,  2.47it/s]\u001b[A\n",
            " 11% 44/400 [00:17<02:23,  2.48it/s]\u001b[A\n",
            " 11% 45/400 [00:17<02:23,  2.47it/s]\u001b[A\n",
            " 12% 46/400 [00:18<02:23,  2.47it/s]\u001b[A\n",
            " 12% 47/400 [00:18<02:22,  2.48it/s]\u001b[A\n",
            " 12% 48/400 [00:19<02:21,  2.48it/s]\u001b[A\n",
            " 12% 49/400 [00:19<02:21,  2.48it/s]\u001b[A\n",
            " 12% 50/400 [00:19<02:20,  2.48it/s]\u001b[A\n",
            " 13% 51/400 [00:20<02:20,  2.48it/s]\u001b[A\n",
            " 13% 52/400 [00:20<02:20,  2.47it/s]\u001b[A\n",
            " 13% 53/400 [00:21<02:20,  2.47it/s]\u001b[A\n",
            " 14% 54/400 [00:21<02:20,  2.47it/s]\u001b[A\n",
            " 14% 55/400 [00:21<02:19,  2.47it/s]\u001b[A\n",
            " 14% 56/400 [00:22<02:20,  2.46it/s]\u001b[A\n",
            " 14% 57/400 [00:22<02:20,  2.45it/s]\u001b[A\n",
            " 14% 58/400 [00:23<02:19,  2.45it/s]\u001b[A\n",
            " 15% 59/400 [00:23<02:19,  2.44it/s]\u001b[A\n",
            " 15% 60/400 [00:24<02:18,  2.45it/s]\u001b[A\n",
            " 15% 61/400 [00:24<02:18,  2.45it/s]\u001b[A\n",
            " 16% 62/400 [00:24<02:18,  2.45it/s]\u001b[A\n",
            " 16% 63/400 [00:25<02:18,  2.44it/s]\u001b[A\n",
            " 16% 64/400 [00:25<02:17,  2.44it/s]\u001b[A\n",
            " 16% 65/400 [00:26<02:17,  2.43it/s]\u001b[A\n",
            " 16% 66/400 [00:26<02:17,  2.43it/s]\u001b[A\n",
            " 17% 67/400 [00:26<02:18,  2.41it/s]\u001b[A\n",
            " 17% 68/400 [00:27<02:17,  2.42it/s]\u001b[A\n",
            " 17% 69/400 [00:27<02:16,  2.42it/s]\u001b[A\n",
            " 18% 70/400 [00:28<02:15,  2.44it/s]\u001b[A\n",
            " 18% 71/400 [00:28<02:14,  2.45it/s]\u001b[A\n",
            " 18% 72/400 [00:28<02:13,  2.46it/s]\u001b[A\n",
            " 18% 73/400 [00:29<02:13,  2.45it/s]\u001b[A\n",
            " 18% 74/400 [00:29<02:12,  2.46it/s]\u001b[A\n",
            " 19% 75/400 [00:30<02:12,  2.46it/s]\u001b[A\n",
            " 19% 76/400 [00:30<02:11,  2.46it/s]\u001b[A\n",
            " 19% 77/400 [00:30<02:11,  2.46it/s]\u001b[A\n",
            " 20% 78/400 [00:31<02:10,  2.46it/s]\u001b[A\n",
            " 20% 79/400 [00:31<02:10,  2.45it/s]\u001b[A\n",
            " 20% 80/400 [00:32<02:09,  2.46it/s]\u001b[A\n",
            " 20% 81/400 [00:32<02:09,  2.46it/s]\u001b[A\n",
            " 20% 82/400 [00:33<02:09,  2.46it/s]\u001b[A\n",
            " 21% 83/400 [00:33<02:09,  2.46it/s]\u001b[A\n",
            " 21% 84/400 [00:33<02:08,  2.45it/s]\u001b[A\n",
            " 21% 85/400 [00:34<02:08,  2.46it/s]\u001b[A\n",
            " 22% 86/400 [00:34<02:08,  2.44it/s]\u001b[A\n",
            " 22% 87/400 [00:35<02:08,  2.43it/s]\u001b[A\n",
            " 22% 88/400 [00:35<02:08,  2.43it/s]\u001b[A\n",
            " 22% 89/400 [00:35<02:06,  2.45it/s]\u001b[A\n",
            " 22% 90/400 [00:36<02:06,  2.45it/s]\u001b[A\n",
            " 23% 91/400 [00:36<02:06,  2.45it/s]\u001b[A\n",
            " 23% 92/400 [00:37<02:05,  2.45it/s]\u001b[A\n",
            " 23% 93/400 [00:37<02:04,  2.46it/s]\u001b[A\n",
            " 24% 94/400 [00:37<02:04,  2.45it/s]\u001b[A\n",
            " 24% 95/400 [00:38<02:03,  2.46it/s]\u001b[A\n",
            " 24% 97/400 [00:38<01:40,  3.00it/s]\u001b[A\n",
            " 24% 98/400 [00:39<01:46,  2.84it/s]\u001b[A\n",
            " 25% 99/400 [00:39<01:50,  2.73it/s]\u001b[A\n",
            " 25% 100/400 [00:40<01:52,  2.66it/s]\u001b[A\n",
            " 25% 101/400 [00:40<01:54,  2.60it/s]\u001b[A\n",
            " 26% 102/400 [00:40<01:56,  2.57it/s]\u001b[A\n",
            " 26% 103/400 [00:41<01:56,  2.55it/s]\u001b[A\n",
            " 26% 104/400 [00:41<01:57,  2.51it/s]\u001b[A\n",
            " 26% 105/400 [00:42<01:58,  2.50it/s]\u001b[A\n",
            " 26% 106/400 [00:42<01:58,  2.48it/s]\u001b[A\n",
            " 27% 107/400 [00:42<01:58,  2.48it/s]\u001b[A\n",
            " 27% 108/400 [00:43<01:58,  2.47it/s]\u001b[A\n",
            " 27% 109/400 [00:43<01:57,  2.47it/s]\u001b[A\n",
            " 28% 110/400 [00:44<01:57,  2.47it/s]\u001b[A\n",
            " 28% 111/400 [00:44<01:57,  2.47it/s]\u001b[A\n",
            " 28% 112/400 [00:44<01:56,  2.48it/s]\u001b[A\n",
            " 28% 113/400 [00:45<01:55,  2.48it/s]\u001b[A\n",
            " 28% 114/400 [00:45<01:55,  2.48it/s]\u001b[A\n",
            " 29% 115/400 [00:46<01:54,  2.49it/s]\u001b[A\n",
            " 29% 116/400 [00:46<01:54,  2.48it/s]\u001b[A\n",
            " 29% 117/400 [00:46<01:54,  2.48it/s]\u001b[A\n",
            " 30% 118/400 [00:47<01:54,  2.47it/s]\u001b[A\n",
            " 30% 119/400 [00:47<01:53,  2.47it/s]\u001b[A\n",
            " 30% 120/400 [00:48<01:53,  2.48it/s]\u001b[A\n",
            " 30% 121/400 [00:48<01:52,  2.48it/s]\u001b[A\n",
            " 30% 122/400 [00:48<01:51,  2.48it/s]\u001b[A\n",
            " 31% 123/400 [00:49<01:51,  2.49it/s]\u001b[A\n",
            " 31% 124/400 [00:49<01:51,  2.47it/s]\u001b[A\n",
            " 31% 125/400 [00:50<01:51,  2.47it/s]\u001b[A\n",
            " 32% 126/400 [00:50<01:51,  2.45it/s]\u001b[A\n",
            " 32% 127/400 [00:50<01:52,  2.43it/s]\u001b[A\n",
            " 32% 128/400 [00:51<01:52,  2.42it/s]\u001b[A\n",
            " 32% 129/400 [00:51<01:52,  2.42it/s]\u001b[A\n",
            " 32% 130/400 [00:52<01:51,  2.43it/s]\u001b[A\n",
            " 33% 131/400 [00:52<01:50,  2.43it/s]\u001b[A\n",
            " 33% 132/400 [00:53<01:49,  2.45it/s]\u001b[A\n",
            " 33% 133/400 [00:53<01:48,  2.46it/s]\u001b[A\n",
            " 34% 134/400 [00:53<01:48,  2.46it/s]\u001b[A\n",
            " 34% 135/400 [00:54<01:48,  2.45it/s]\u001b[A\n",
            " 34% 136/400 [00:54<01:47,  2.46it/s]\u001b[A\n",
            " 34% 137/400 [00:55<01:47,  2.45it/s]\u001b[A\n",
            " 34% 138/400 [00:55<01:47,  2.43it/s]\u001b[A\n",
            " 35% 139/400 [00:55<01:46,  2.45it/s]\u001b[A\n",
            " 35% 140/400 [00:56<01:45,  2.46it/s]\u001b[A\n",
            " 35% 141/400 [00:56<01:45,  2.45it/s]\u001b[A\n",
            " 36% 142/400 [00:57<01:45,  2.45it/s]\u001b[A\n",
            " 36% 143/400 [00:57<01:44,  2.45it/s]\u001b[A\n",
            " 36% 144/400 [00:57<01:44,  2.46it/s]\u001b[A\n",
            " 36% 145/400 [00:58<01:43,  2.46it/s]\u001b[A\n",
            " 36% 146/400 [00:58<01:42,  2.47it/s]\u001b[A\n",
            " 37% 147/400 [00:59<01:41,  2.48it/s]\u001b[A\n",
            " 37% 148/400 [00:59<01:41,  2.49it/s]\u001b[A\n",
            " 37% 149/400 [00:59<01:41,  2.48it/s]\u001b[A\n",
            " 38% 150/400 [01:00<01:40,  2.48it/s]\u001b[A\n",
            " 38% 151/400 [01:00<01:40,  2.49it/s]\u001b[A\n",
            " 38% 152/400 [01:01<01:39,  2.49it/s]\u001b[A\n",
            " 38% 153/400 [01:01<01:39,  2.48it/s]\u001b[A\n",
            " 38% 154/400 [01:01<01:39,  2.47it/s]\u001b[A\n",
            " 39% 155/400 [01:02<01:39,  2.47it/s]\u001b[A\n",
            " 39% 156/400 [01:02<01:38,  2.47it/s]\u001b[A\n",
            " 39% 157/400 [01:03<01:38,  2.48it/s]\u001b[A\n",
            " 40% 158/400 [01:03<01:37,  2.47it/s]\u001b[A\n",
            " 40% 159/400 [01:03<01:37,  2.47it/s]\u001b[A\n",
            " 40% 160/400 [01:04<01:36,  2.48it/s]\u001b[A\n",
            " 40% 161/400 [01:04<01:36,  2.49it/s]\u001b[A\n",
            " 40% 162/400 [01:05<01:35,  2.50it/s]\u001b[A\n",
            " 41% 163/400 [01:05<01:35,  2.49it/s]\u001b[A\n",
            " 41% 164/400 [01:05<01:35,  2.48it/s]\u001b[A\n",
            " 41% 165/400 [01:06<01:35,  2.47it/s]\u001b[A\n",
            " 42% 166/400 [01:06<01:34,  2.47it/s]\u001b[A\n",
            " 42% 167/400 [01:07<01:34,  2.48it/s]\u001b[A\n",
            " 42% 168/400 [01:07<01:34,  2.46it/s]\u001b[A\n",
            " 42% 169/400 [01:08<01:33,  2.46it/s]\u001b[A\n",
            " 42% 170/400 [01:08<01:33,  2.46it/s]\u001b[A\n",
            " 43% 171/400 [01:08<01:33,  2.46it/s]\u001b[A\n",
            " 43% 172/400 [01:09<01:32,  2.46it/s]\u001b[A\n",
            " 43% 173/400 [01:09<01:32,  2.45it/s]\u001b[A\n",
            " 44% 174/400 [01:10<01:31,  2.46it/s]\u001b[A\n",
            " 44% 175/400 [01:10<01:31,  2.45it/s]\u001b[A\n",
            " 44% 176/400 [01:10<01:31,  2.45it/s]\u001b[A\n",
            " 44% 177/400 [01:11<01:30,  2.45it/s]\u001b[A\n",
            " 44% 178/400 [01:11<01:30,  2.46it/s]\u001b[A\n",
            " 45% 179/400 [01:12<01:30,  2.45it/s]\u001b[A\n",
            " 45% 180/400 [01:12<01:29,  2.46it/s]\u001b[A\n",
            " 45% 181/400 [01:12<01:29,  2.44it/s]\u001b[A\n",
            " 46% 182/400 [01:13<01:29,  2.45it/s]\u001b[A\n",
            " 46% 183/400 [01:13<01:28,  2.45it/s]\u001b[A\n",
            " 46% 184/400 [01:14<01:27,  2.46it/s]\u001b[A\n",
            " 46% 185/400 [01:14<01:27,  2.46it/s]\u001b[A\n",
            " 46% 186/400 [01:14<01:26,  2.46it/s]\u001b[A\n",
            " 47% 187/400 [01:15<01:26,  2.47it/s]\u001b[A\n",
            " 47% 188/400 [01:15<01:25,  2.47it/s]\u001b[A\n",
            " 47% 189/400 [01:16<01:25,  2.48it/s]\u001b[A\n",
            " 48% 190/400 [01:16<01:24,  2.48it/s]\u001b[A\n",
            " 48% 191/400 [01:16<01:24,  2.48it/s]\u001b[A\n",
            " 48% 192/400 [01:17<01:23,  2.48it/s]\u001b[A\n",
            " 48% 193/400 [01:17<01:23,  2.48it/s]\u001b[A\n",
            " 48% 194/400 [01:18<01:23,  2.48it/s]\u001b[A\n",
            " 49% 195/400 [01:18<01:22,  2.49it/s]\u001b[A\n",
            " 49% 196/400 [01:18<01:22,  2.48it/s]\u001b[A\n",
            " 49% 197/400 [01:19<01:21,  2.49it/s]\u001b[A\n",
            " 50% 198/400 [01:19<01:21,  2.49it/s]\u001b[A\n",
            " 50% 199/400 [01:20<01:20,  2.49it/s]\u001b[A\n",
            " 50% 200/400 [01:20<01:20,  2.49it/s]\u001b[A\n",
            " 50% 201/400 [01:20<01:20,  2.47it/s]\u001b[A\n",
            " 50% 202/400 [01:21<01:20,  2.47it/s]\u001b[A\n",
            " 51% 203/400 [01:21<01:19,  2.47it/s]\u001b[A\n",
            " 51% 204/400 [01:22<01:19,  2.47it/s]\u001b[A\n",
            " 51% 205/400 [01:22<01:18,  2.47it/s]\u001b[A\n",
            " 52% 206/400 [01:23<01:18,  2.46it/s]\u001b[A\n",
            " 52% 207/400 [01:23<01:18,  2.45it/s]\u001b[A\n",
            " 52% 208/400 [01:23<01:18,  2.45it/s]\u001b[A\n",
            " 52% 209/400 [01:24<01:18,  2.45it/s]\u001b[A\n",
            " 52% 210/400 [01:24<01:17,  2.45it/s]\u001b[A\n",
            " 53% 211/400 [01:25<01:17,  2.44it/s]\u001b[A\n",
            " 53% 212/400 [01:25<01:17,  2.43it/s]\u001b[A\n",
            " 53% 213/400 [01:25<01:16,  2.44it/s]\u001b[A\n",
            " 54% 214/400 [01:26<01:15,  2.45it/s]\u001b[A\n",
            " 54% 215/400 [01:26<01:15,  2.45it/s]\u001b[A\n",
            " 54% 216/400 [01:27<01:15,  2.43it/s]\u001b[A\n",
            " 54% 217/400 [01:27<01:15,  2.42it/s]\u001b[A\n",
            " 55% 218/400 [01:27<01:14,  2.44it/s]\u001b[A\n",
            " 55% 219/400 [01:28<01:14,  2.44it/s]\u001b[A\n",
            " 55% 220/400 [01:28<01:13,  2.45it/s]\u001b[A\n",
            " 55% 221/400 [01:29<01:12,  2.47it/s]\u001b[A\n",
            " 56% 222/400 [01:29<01:12,  2.47it/s]\u001b[A\n",
            " 56% 223/400 [01:29<01:11,  2.48it/s]\u001b[A\n",
            " 56% 224/400 [01:30<01:10,  2.48it/s]\u001b[A\n",
            " 56% 225/400 [01:30<01:10,  2.48it/s]\u001b[A\n",
            " 56% 226/400 [01:31<01:10,  2.48it/s]\u001b[A\n",
            " 57% 227/400 [01:31<01:10,  2.45it/s]\u001b[A\n",
            " 57% 228/400 [01:31<01:09,  2.46it/s]\u001b[A\n",
            " 57% 229/400 [01:32<01:09,  2.46it/s]\u001b[A\n",
            " 57% 230/400 [01:32<01:09,  2.46it/s]\u001b[A\n",
            " 58% 231/400 [01:33<01:08,  2.46it/s]\u001b[A\n",
            " 58% 232/400 [01:33<01:08,  2.47it/s]\u001b[A\n",
            " 58% 233/400 [01:34<01:07,  2.47it/s]\u001b[A\n",
            " 58% 234/400 [01:34<01:07,  2.47it/s]\u001b[A\n",
            " 59% 235/400 [01:34<01:06,  2.48it/s]\u001b[A\n",
            " 59% 236/400 [01:35<01:06,  2.47it/s]\u001b[A\n",
            " 59% 237/400 [01:35<01:06,  2.47it/s]\u001b[A\n",
            " 60% 238/400 [01:36<01:05,  2.47it/s]\u001b[A\n",
            " 60% 239/400 [01:36<01:05,  2.46it/s]\u001b[A\n",
            " 60% 240/400 [01:36<01:04,  2.47it/s]\u001b[A\n",
            " 60% 241/400 [01:37<01:04,  2.47it/s]\u001b[A\n",
            " 60% 242/400 [01:37<01:04,  2.46it/s]\u001b[A\n",
            " 61% 243/400 [01:38<01:03,  2.46it/s]\u001b[A\n",
            " 61% 244/400 [01:38<01:03,  2.45it/s]\u001b[A\n",
            " 61% 245/400 [01:38<01:03,  2.46it/s]\u001b[A\n",
            " 62% 246/400 [01:39<01:02,  2.45it/s]\u001b[A\n",
            " 62% 247/400 [01:39<01:02,  2.45it/s]\u001b[A\n",
            " 62% 248/400 [01:40<01:01,  2.46it/s]\u001b[A\n",
            " 62% 249/400 [01:40<01:01,  2.45it/s]\u001b[A\n",
            " 62% 250/400 [01:40<01:01,  2.45it/s]\u001b[A\n",
            " 63% 251/400 [01:41<01:00,  2.45it/s]\u001b[A\n",
            " 63% 252/400 [01:41<01:00,  2.44it/s]\u001b[A\n",
            " 63% 253/400 [01:42<01:00,  2.43it/s]\u001b[A\n",
            " 64% 254/400 [01:42<00:59,  2.43it/s]\u001b[A\n",
            " 64% 255/400 [01:42<00:59,  2.44it/s]\u001b[A\n",
            " 64% 256/400 [01:43<00:58,  2.45it/s]\u001b[A\n",
            " 64% 257/400 [01:43<00:58,  2.45it/s]\u001b[A\n",
            " 64% 258/400 [01:44<00:58,  2.45it/s]\u001b[A\n",
            " 65% 259/400 [01:44<00:57,  2.45it/s]\u001b[A\n",
            " 65% 260/400 [01:45<00:57,  2.45it/s]\u001b[A\n",
            " 65% 261/400 [01:45<00:56,  2.46it/s]\u001b[A\n",
            " 66% 262/400 [01:45<00:56,  2.46it/s]\u001b[A\n",
            " 66% 263/400 [01:46<00:55,  2.46it/s]\u001b[A\n",
            " 66% 264/400 [01:46<00:55,  2.46it/s]\u001b[A\n",
            " 66% 265/400 [01:47<00:54,  2.47it/s]\u001b[A\n",
            " 66% 266/400 [01:47<00:54,  2.46it/s]\u001b[A\n",
            " 67% 267/400 [01:47<00:54,  2.46it/s]\u001b[A\n",
            " 67% 268/400 [01:48<00:53,  2.45it/s]\u001b[A\n",
            " 67% 269/400 [01:48<00:53,  2.45it/s]\u001b[A\n",
            " 68% 270/400 [01:49<00:53,  2.44it/s]\u001b[A\n",
            " 68% 271/400 [01:49<00:52,  2.43it/s]\u001b[A\n",
            " 68% 272/400 [01:49<00:52,  2.42it/s]\u001b[A\n",
            " 68% 273/400 [01:50<00:52,  2.41it/s]\u001b[A\n",
            " 68% 274/400 [01:50<00:52,  2.40it/s]\u001b[A\n",
            " 69% 275/400 [01:51<00:51,  2.41it/s]\u001b[A\n",
            " 69% 276/400 [01:51<00:51,  2.42it/s]\u001b[A\n",
            " 69% 277/400 [01:52<00:51,  2.41it/s]\u001b[A\n",
            " 70% 278/400 [01:52<00:50,  2.41it/s]\u001b[A\n",
            " 70% 279/400 [01:52<00:49,  2.42it/s]\u001b[A\n",
            " 70% 280/400 [01:53<00:48,  2.47it/s]\u001b[A\n",
            " 70% 281/400 [01:53<00:47,  2.48it/s]\u001b[A\n",
            " 70% 282/400 [01:54<00:47,  2.48it/s]\u001b[A\n",
            " 71% 283/400 [01:54<00:47,  2.47it/s]\u001b[A\n",
            " 71% 284/400 [01:54<00:46,  2.48it/s]\u001b[A\n",
            " 71% 285/400 [01:55<00:46,  2.47it/s]\u001b[A\n",
            " 72% 286/400 [01:55<00:46,  2.46it/s]\u001b[A\n",
            " 72% 287/400 [01:56<00:46,  2.44it/s]\u001b[A\n",
            " 72% 288/400 [01:56<00:46,  2.43it/s]\u001b[A\n",
            " 72% 289/400 [01:56<00:45,  2.43it/s]\u001b[A\n",
            " 72% 290/400 [01:57<00:45,  2.42it/s]\u001b[A\n",
            " 73% 291/400 [01:57<00:45,  2.42it/s]\u001b[A\n",
            " 73% 292/400 [01:58<00:44,  2.42it/s]\u001b[A\n",
            " 73% 293/400 [01:58<00:43,  2.44it/s]\u001b[A\n",
            " 74% 294/400 [01:58<00:43,  2.43it/s]\u001b[A\n",
            " 74% 295/400 [01:59<00:43,  2.43it/s]\u001b[A\n",
            " 74% 296/400 [01:59<00:42,  2.43it/s]\u001b[A\n",
            " 74% 297/400 [02:00<00:42,  2.44it/s]\u001b[A\n",
            " 74% 298/400 [02:00<00:41,  2.44it/s]\u001b[A\n",
            " 75% 299/400 [02:00<00:41,  2.45it/s]\u001b[A\n",
            " 75% 300/400 [02:01<00:40,  2.46it/s]\u001b[A\n",
            " 75% 301/400 [02:01<00:40,  2.45it/s]\u001b[A\n",
            " 76% 302/400 [02:02<00:39,  2.46it/s]\u001b[A\n",
            " 76% 303/400 [02:02<00:39,  2.46it/s]\u001b[A\n",
            " 76% 304/400 [02:03<00:39,  2.46it/s]\u001b[A\n",
            " 76% 305/400 [02:03<00:38,  2.47it/s]\u001b[A\n",
            " 76% 306/400 [02:03<00:38,  2.46it/s]\u001b[A\n",
            " 77% 307/400 [02:04<00:37,  2.46it/s]\u001b[A\n",
            " 77% 308/400 [02:04<00:37,  2.46it/s]\u001b[A\n",
            " 77% 309/400 [02:05<00:36,  2.47it/s]\u001b[A\n",
            " 78% 310/400 [02:05<00:36,  2.47it/s]\u001b[A\n",
            " 78% 311/400 [02:05<00:36,  2.47it/s]\u001b[A\n",
            " 78% 312/400 [02:06<00:35,  2.47it/s]\u001b[A\n",
            " 78% 313/400 [02:06<00:35,  2.46it/s]\u001b[A\n",
            " 78% 314/400 [02:07<00:34,  2.47it/s]\u001b[A\n",
            " 79% 315/400 [02:07<00:34,  2.47it/s]\u001b[A\n",
            " 79% 316/400 [02:07<00:34,  2.46it/s]\u001b[A\n",
            " 79% 317/400 [02:08<00:33,  2.45it/s]\u001b[A\n",
            " 80% 318/400 [02:08<00:33,  2.44it/s]\u001b[A\n",
            " 80% 319/400 [02:09<00:33,  2.44it/s]\u001b[A\n",
            " 80% 320/400 [02:09<00:32,  2.45it/s]\u001b[A\n",
            " 80% 321/400 [02:09<00:32,  2.46it/s]\u001b[A\n",
            " 80% 322/400 [02:10<00:31,  2.45it/s]\u001b[A\n",
            " 81% 323/400 [02:10<00:31,  2.46it/s]\u001b[A\n",
            " 81% 324/400 [02:11<00:30,  2.47it/s]\u001b[A\n",
            " 81% 325/400 [02:11<00:30,  2.47it/s]\u001b[A\n",
            " 82% 326/400 [02:11<00:29,  2.47it/s]\u001b[A\n",
            " 82% 327/400 [02:12<00:29,  2.47it/s]\u001b[A\n",
            " 82% 328/400 [02:12<00:29,  2.48it/s]\u001b[A\n",
            " 82% 329/400 [02:13<00:28,  2.48it/s]\u001b[A\n",
            " 82% 330/400 [02:13<00:28,  2.47it/s]\u001b[A\n",
            " 83% 331/400 [02:13<00:27,  2.47it/s]\u001b[A\n",
            " 83% 332/400 [02:14<00:27,  2.45it/s]\u001b[A\n",
            " 83% 333/400 [02:14<00:27,  2.46it/s]\u001b[A\n",
            " 84% 334/400 [02:15<00:26,  2.48it/s]\u001b[A\n",
            " 84% 335/400 [02:15<00:26,  2.48it/s]\u001b[A\n",
            " 84% 336/400 [02:16<00:25,  2.47it/s]\u001b[A\n",
            " 84% 337/400 [02:16<00:25,  2.48it/s]\u001b[A\n",
            " 84% 338/400 [02:16<00:24,  2.49it/s]\u001b[A\n",
            " 85% 339/400 [02:17<00:24,  2.49it/s]\u001b[A\n",
            " 85% 340/400 [02:17<00:24,  2.49it/s]\u001b[A\n",
            " 85% 341/400 [02:18<00:23,  2.48it/s]\u001b[A\n",
            " 86% 342/400 [02:18<00:23,  2.47it/s]\u001b[A\n",
            " 86% 343/400 [02:18<00:22,  2.48it/s]\u001b[A\n",
            " 86% 344/400 [02:19<00:22,  2.48it/s]\u001b[A\n",
            " 86% 345/400 [02:19<00:22,  2.48it/s]\u001b[A\n",
            " 86% 346/400 [02:20<00:21,  2.48it/s]\u001b[A\n",
            " 87% 347/400 [02:20<00:21,  2.47it/s]\u001b[A\n",
            " 87% 348/400 [02:20<00:20,  2.48it/s]\u001b[A\n",
            " 87% 349/400 [02:21<00:20,  2.47it/s]\u001b[A\n",
            " 88% 350/400 [02:21<00:20,  2.48it/s]\u001b[A\n",
            " 88% 351/400 [02:22<00:19,  2.48it/s]\u001b[A\n",
            " 88% 352/400 [02:22<00:19,  2.46it/s]\u001b[A\n",
            " 88% 353/400 [02:22<00:19,  2.46it/s]\u001b[A\n",
            " 88% 354/400 [02:23<00:18,  2.45it/s]\u001b[A\n",
            " 89% 355/400 [02:23<00:18,  2.45it/s]\u001b[A\n",
            " 89% 356/400 [02:24<00:17,  2.46it/s]\u001b[A\n",
            " 89% 357/400 [02:24<00:17,  2.43it/s]\u001b[A\n",
            " 90% 358/400 [02:24<00:17,  2.44it/s]\u001b[A\n",
            " 90% 359/400 [02:25<00:16,  2.44it/s]\u001b[A\n",
            " 90% 360/400 [02:25<00:16,  2.45it/s]\u001b[A\n",
            " 90% 361/400 [02:26<00:16,  2.41it/s]\u001b[A\n",
            " 90% 362/400 [02:26<00:15,  2.40it/s]\u001b[A\n",
            " 91% 363/400 [02:26<00:15,  2.41it/s]\u001b[A\n",
            " 91% 364/400 [02:27<00:14,  2.43it/s]\u001b[A\n",
            " 91% 365/400 [02:27<00:14,  2.43it/s]\u001b[A\n",
            " 92% 366/400 [02:28<00:14,  2.43it/s]\u001b[A\n",
            " 92% 367/400 [02:28<00:13,  2.44it/s]\u001b[A\n",
            " 92% 368/400 [02:29<00:13,  2.44it/s]\u001b[A\n",
            " 92% 369/400 [02:29<00:12,  2.44it/s]\u001b[A\n",
            " 92% 370/400 [02:29<00:12,  2.46it/s]\u001b[A\n",
            " 93% 371/400 [02:30<00:11,  2.47it/s]\u001b[A\n",
            " 93% 372/400 [02:30<00:11,  2.47it/s]\u001b[A\n",
            " 93% 373/400 [02:31<00:10,  2.47it/s]\u001b[A\n",
            " 94% 374/400 [02:31<00:10,  2.46it/s]\u001b[A\n",
            " 94% 375/400 [02:31<00:10,  2.47it/s]\u001b[A\n",
            " 94% 376/400 [02:32<00:09,  2.47it/s]\u001b[A\n",
            " 94% 377/400 [02:32<00:09,  2.47it/s]\u001b[A\n",
            " 94% 378/400 [02:33<00:08,  2.47it/s]\u001b[A\n",
            " 95% 379/400 [02:33<00:08,  2.46it/s]\u001b[A\n",
            " 95% 380/400 [02:33<00:08,  2.46it/s]\u001b[A\n",
            " 95% 381/400 [02:34<00:07,  2.46it/s]\u001b[A\n",
            " 96% 382/400 [02:34<00:07,  2.46it/s]\u001b[A\n",
            " 96% 383/400 [02:35<00:06,  2.45it/s]\u001b[A\n",
            " 96% 384/400 [02:35<00:06,  2.46it/s]\u001b[A\n",
            " 96% 385/400 [02:35<00:06,  2.46it/s]\u001b[A\n",
            " 96% 386/400 [02:36<00:05,  2.46it/s]\u001b[A\n",
            " 97% 387/400 [02:36<00:05,  2.46it/s]\u001b[A\n",
            " 97% 388/400 [02:37<00:04,  2.46it/s]\u001b[A\n",
            " 97% 389/400 [02:37<00:04,  2.46it/s]\u001b[A\n",
            " 98% 390/400 [02:37<00:04,  2.45it/s]\u001b[A\n",
            " 98% 391/400 [02:38<00:03,  2.45it/s]\u001b[A\n",
            " 98% 392/400 [02:38<00:03,  2.45it/s]\u001b[A\n",
            " 98% 393/400 [02:39<00:02,  2.45it/s]\u001b[A\n",
            " 98% 394/400 [02:39<00:02,  2.44it/s]\u001b[A\n",
            " 99% 395/400 [02:40<00:02,  2.44it/s]\u001b[A\n",
            " 99% 396/400 [02:40<00:01,  2.45it/s]\u001b[A\n",
            " 99% 397/400 [02:40<00:01,  2.45it/s]\u001b[A\n",
            "100% 398/400 [02:41<00:00,  2.45it/s]\u001b[A\n",
            "100% 399/400 [02:41<00:00,  2.45it/s]\u001b[A\n",
            "                                       \n",
            "\u001b[A{'eval_loss': 1.0000256299972534, 'eval_rouge1': 28.2988, 'eval_rouge2': 17.6175, 'eval_rougeL': 28.0132, 'eval_rougeLsum': 28.0524, 'eval_bleu': 9.0301, 'eval_gen_len': 18.0969, 'eval_runtime': 187.4741, 'eval_samples_per_second': 8.535, 'eval_steps_per_second': 2.134, 'epoch': 4.67}\n",
            " 93% 1400/1500 [37:28<00:50,  1.96it/s]\n",
            "100% 400/400 [03:07<00:00,  2.46it/s]\u001b[A\n",
            "                                     \u001b[ASaving model checkpoint to mT5_model_full/checkpoint-1400\n",
            "Configuration saved in mT5_model_full/checkpoint-1400/config.json\n",
            "Configuration saved in mT5_model_full/checkpoint-1400/generation_config.json\n",
            "Model weights saved in mT5_model_full/checkpoint-1400/pytorch_model.bin\n",
            "tokenizer config file saved in mT5_model_full/checkpoint-1400/tokenizer_config.json\n",
            "Special tokens file saved in mT5_model_full/checkpoint-1400/special_tokens_map.json\n",
            "Copy vocab file to mT5_model_full/checkpoint-1400/spiece.model\n",
            "{'loss': 1.3009, 'learning_rate': 1e-06, 'epoch': 4.83}\n",
            "{'loss': 1.4052, 'learning_rate': 0.0, 'epoch': 5.0}\n",
            "100% 1500/1500 [38:36<00:00,  1.94it/s]Saving model checkpoint to mT5_model_full/checkpoint-1500\n",
            "Configuration saved in mT5_model_full/checkpoint-1500/config.json\n",
            "Configuration saved in mT5_model_full/checkpoint-1500/generation_config.json\n",
            "Model weights saved in mT5_model_full/checkpoint-1500/pytorch_model.bin\n",
            "tokenizer config file saved in mT5_model_full/checkpoint-1500/tokenizer_config.json\n",
            "Special tokens file saved in mT5_model_full/checkpoint-1500/special_tokens_map.json\n",
            "Copy vocab file to mT5_model_full/checkpoint-1500/spiece.model\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "{'train_runtime': 2336.0416, 'train_samples_per_second': 10.274, 'train_steps_per_second': 0.642, 'train_loss': 2.2826637166341146, 'epoch': 5.0}\n",
            "100% 1500/1500 [38:54<00:00,  1.56s/it]\n",
            "Saving model checkpoint to mT5_model_full/\n",
            "Configuration saved in mT5_model_full/config.json\n",
            "Configuration saved in mT5_model_full/generation_config.json\n",
            "Model weights saved in mT5_model_full/pytorch_model.bin\n",
            "tokenizer config file saved in mT5_model_full/tokenizer_config.json\n",
            "Special tokens file saved in mT5_model_full/special_tokens_map.json\n",
            "Copy vocab file to mT5_model_full/spiece.model\n",
            "***** train metrics *****\n",
            "  epoch                    =        5.0\n",
            "  train_loss               =     2.2827\n",
            "  train_runtime            = 0:38:56.04\n",
            "  train_samples            =       4800\n",
            "  train_samples_per_second =     10.274\n",
            "  train_steps_per_second   =      0.642\n",
            "05/07/2023 03:45:52 - INFO - __main__ -   *** Evaluate ***\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1600\n",
            "  Batch size = 4\n",
            "100% 400/400 [07:52<00:00,  1.06s/it]Traceback (most recent call last):\n",
            "  File \"/content/iterater/code/IteraTeR_ACL2022/model/generation/./transformers/examples/pytorch/summarization/run_summarization.py\", line 633, in <module>\n",
            "    main()\n",
            "  File \"/content/iterater/code/IteraTeR_ACL2022/model/generation/./transformers/examples/pytorch/summarization/run_summarization.py\", line 575, in main\n",
            "    metrics = trainer.evaluate(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/transformers/trainer_seq2seq.py\", line 159, in evaluate\n",
            "    return super().evaluate(eval_dataset, ignore_keys=ignore_keys, metric_key_prefix=metric_key_prefix)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\", line 2993, in evaluate\n",
            "    output = eval_loop(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\", line 3281, in evaluation_loop\n",
            "    metrics = self.compute_metrics(EvalPrediction(predictions=all_preds, label_ids=all_labels))\n",
            "  File \"/content/iterater/code/IteraTeR_ACL2022/model/generation/./transformers/examples/pytorch/summarization/run_summarization.py\", line 510, in compute_metrics\n",
            "    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py\", line 3446, in batch_decode\n",
            "    return [\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py\", line 3447, in <listcomp>\n",
            "    self.decode(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py\", line 3486, in decode\n",
            "    return self._decode(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_fast.py\", line 549, in _decode\n",
            "    text = self._tokenizer.decode(token_ids, skip_special_tokens=skip_special_tokens)\n",
            "OverflowError: out of range integral type conversion attempted\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/iterater/code/IteraTeR_ACL2022/model/generation/./transformers/examples/pytorch/summarization/run_summarization.py\", line 633, in <module>\n",
            "    main()\n",
            "  File \"/content/iterater/code/IteraTeR_ACL2022/model/generation/./transformers/examples/pytorch/summarization/run_summarization.py\", line 575, in main\n",
            "    metrics = trainer.evaluate(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/transformers/trainer_seq2seq.py\", line 159, in evaluate\n",
            "    return super().evaluate(eval_dataset, ignore_keys=ignore_keys, metric_key_prefix=metric_key_prefix)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\", line 2993, in evaluate\n",
            "    output = eval_loop(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\", line 3281, in evaluation_loop\n",
            "    metrics = self.compute_metrics(EvalPrediction(predictions=all_preds, label_ids=all_labels))\n",
            "  File \"/content/iterater/code/IteraTeR_ACL2022/model/generation/./transformers/examples/pytorch/summarization/run_summarization.py\", line 510, in compute_metrics\n",
            "    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py\", line 3446, in batch_decode\n",
            "    return [\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py\", line 3447, in <listcomp>\n",
            "    self.decode(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py\", line 3486, in decode\n",
            "    return self._decode(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_fast.py\", line 549, in _decode\n",
            "    text = self._tokenizer.decode(token_ids, skip_special_tokens=skip_special_tokens)\n",
            "OverflowError: out of range integral type conversion attempted\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[31m(failed 1).\u001b[0m Press Control-C to abort syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                      eval/bleu ▁█▄▃▃▃▃\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                   eval/gen_len ▁████▇▇\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                      eval/loss █▄▂▂▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                    eval/rouge1 ▁▅█████\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                    eval/rouge2 ▁▆█████\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                    eval/rougeL ▁▅█████\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                 eval/rougeLsum ▁▅█████\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                   eval/runtime ▁█▅▆▆▅▅\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        eval/samples_per_second █▁▃▃▃▄▄\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/steps_per_second █▁▃▂▃▄▄\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                    train/epoch ▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇█████\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:              train/global_step ▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇█████\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            train/learning_rate ███▇▇▇▇▆▆▆▆▅▅▅▅▄▄▄▄▃▃▃▃▂▂▂▂▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                     train/loss █▅▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               train/total_flos ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               train/train_loss ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            train/train_runtime ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: train/train_samples_per_second ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   train/train_steps_per_second ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                      eval/bleu 9.0301\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                   eval/gen_len 18.0969\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                      eval/loss 1.00003\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                    eval/rouge1 28.2988\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                    eval/rouge2 17.6175\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                    eval/rougeL 28.0132\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                 eval/rougeLsum 28.0524\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                   eval/runtime 187.4741\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        eval/samples_per_second 8.535\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/steps_per_second 2.134\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                    train/epoch 5.0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:              train/global_step 1500\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            train/learning_rate 0.0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                     train/loss 1.4052\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               train/total_flos 4506327996088320.0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               train/train_loss 2.28266\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            train/train_runtime 2336.0416\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: train/train_samples_per_second 10.274\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   train/train_steps_per_second 0.642\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33msmooth-valley-17\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/cs678/huggingface/runs/8s6yf44b\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20230507_030650-8s6yf44b/logs\u001b[0m\n",
            "CPU times: user 17.1 s, sys: 2.96 s, total: 20.1 s\n",
            "Wall time: 47min 33s\n"
          ]
        }
      ],
      "source": [
        "#training model\n",
        "%%time\n",
        "%cd /content/iterater/code/IteraTeR_ACL2022/model/generation\n",
        "!sh mT5_fullysup_multilingual_train.sh"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "753d2a28-8a21-40ca-b7dc-89febed3efd8",
        "id": "8_02Km32ofg5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Errno 2] No such file or directory: '/content/iterater/code/model/generation'\n",
            "/content/iterater/code/IteraTeR_ACL2022/model/generation\n",
            "2023-05-07 03:54:04.387317: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2023-05-07 03:54:04.444749: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-05-07 03:54:06.013445: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "  0% 0/1440 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1313: UserWarning: Using `max_length`'s default (20) to control the generation length. This behaviour is deprecated and will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "100% 1440/1440 [07:58<00:00,  3.01it/s]\n",
            "100% 1440/1440 [00:10<00:00, 138.66it/s]\n",
            "100% 1440/1440 [00:12<00:00, 113.97it/s]\n",
            "BLEU     : 0.13402236930544706\n",
            "ROUGE     : {'rouge1': 22.06655299014657, 'rouge2': 14.23723118683722, 'rougeL': 21.836828000211607, 'rougeLsum': 21.82532109588471}\n",
            "SARI: 20.33575886466732, KEEP: 0.3157255297027471, ADD: 0.0011374863399074018, DELETE: 0.29320974989736526\n",
            "CPU times: user 3.71 s, sys: 668 ms, total: 4.38 s\n",
            "Wall time: 8min 52s\n"
          ]
        }
      ],
      "source": [
        "#printing metrics\n",
        "%%time\n",
        "%cd /content/iterater/code/IteraTeR_ACL2022/model/generation\n",
        "!python3 mT5_inference_and_metrics.py --checkpoint mT5_model_full --reference /content/cs678-cp1-cp2/multi_data/fully_multi/test.json --output mt5full_sent_output"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Result Graphs"
      ],
      "metadata": {
        "id": "wWitTahvVDYj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Multilingual Intent Classification Result"
      ],
      "metadata": {
        "id": "yCWzZ_JKVJcP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Define the data for each model's performance\n",
        "model_data = [\n",
        "    {\n",
        "        'model': 'RoBERTa ZeroShot',\n",
        "        'Clarity': [0.71, 0.73, 0.72],\n",
        "        'Fluency': [0.77, 0.84, 0.80],\n",
        "        'Coherance': [0.54, 0.41, 0.47],\n",
        "        'Style': [0, 0, 0],\n",
        "        'Meaning Changed': [0.68, 0.78, 0.72],\n",
        "        'Metric': ['Precision','Recall','F1']\n",
        "    },\n",
        "    {\n",
        "        'model': 'RoBERTa Multilingual',\n",
        "        'Clarity': [0.50, 0.57, 0.53],\n",
        "        'Fluency': [0.54, 0.54, 0.54],\n",
        "        'Coherance': [0.40, 0.21, 0.27],\n",
        "        'Style': [0, 0, 0],\n",
        "        'Meaning Changed': [0.33, 0.42, 0.37],\n",
        "        'Metric': ['Precision','Recall','F1']\n",
        "    },\n",
        "    {\n",
        "        'model': 'XLM-RoBERTa ZeroShot',\n",
        "        'Clarity': [0.71, 0.78, 0.75],\n",
        "        'Fluency': [0.83, 0.83, 0.83],\n",
        "        'Coherance': [0.59, 0.48, 0.53],\n",
        "        'Style': [0, 0, 0],\n",
        "        'Meaning Changed': [0.64, 0.72, 0.68],\n",
        "        'Metric': ['Precision','Recall','F1']\n",
        "    },\n",
        "    {\n",
        "        'model': 'XLM-RoBERTa Multilingual',\n",
        "        'Clarity': [0.52, 0.48, 0.50],\n",
        "        'Fluency': [0.45, 0.59, 0.50],\n",
        "        'Coherance': [0.38, 0.10, 0.16],\n",
        "        'Style': [0, 0, 0],\n",
        "        'Meaning Changed': [0.32, 0.46, 0.38],\n",
        "        'Metric': ['Precision','Recall','F1']\n",
        "    }\n",
        "]\n",
        "\n",
        "# Convert the data to a pandas DataFrame\n",
        "df = pd.DataFrame(model_data)\n",
        "df = df.set_index('model')\n",
        "\n",
        "# Create a figure with 5 subplots, one for each intent\n",
        "fig, axs = plt.subplots(nrows=5, ncols=1, figsize=(10, 20), sharex=True)\n",
        "\n",
        "# Plot each intent as a separate bar chart\n",
        "for i, intent in enumerate(['Clarity', 'Fluency', 'Coherance', 'Style', 'Meaning Changed']):\n",
        "    # Get the data for the current intent and reshape it\n",
        "    intent_data = df[intent].values.tolist()\n",
        "    intent_data = [list(x) for x in zip(*intent_data)]\n",
        "\n",
        "    # Create a pandas DataFrame for the current intent's data\n",
        "    intent_df = pd.DataFrame(intent_data, columns=df.index)\n",
        "\n",
        "    # Update column names\n",
        "    new_cols = {\n",
        "        'model': 'metric',\n",
        "        0: 'Precision',\n",
        "        1: 'Recall',\n",
        "        2: 'F1'\n",
        "    }\n",
        "    intent_df = intent_df.rename(index=new_cols)\n",
        "\n",
        "    # Plot the data as a bar chart\n",
        "    intent_df.plot(kind='bar', ax=axs[i], rot=0)\n",
        "\n",
        "    # Set the chart title and axis labels\n",
        "    axs[i].set_title(intent)\n",
        "    axs[i].set_ylabel('Score')\n",
        "\n",
        "    # Get the x-axis tick labels\n",
        "    labels = intent_df.index.tolist()\n",
        "\n",
        "    # Set the x-axis tick labels for the current axis\n",
        "    axs[i].set_xticklabels(labels, rotation=0)\n",
        "\n",
        "    # Add the x-axis label for the current axis\n",
        "    axs[i].set_xlabel('Metric')\n",
        "\n",
        "    # Slant the x-axis labels by 45 degrees\n",
        "    axs[i].set_xticklabels(axs[i].get_xticklabels(), rotation=45, ha='right')\n",
        "\n",
        "# Slant the x-axis labels by 45 degrees\n",
        "ax.set_xticklabels(ax.get_xticklabels(), rotation=45, ha='right')\n",
        "\n",
        "# Set the overall chart title and axis labels\n",
        "fig.suptitle('Intent Classification Model Comparison', fontsize=16, y=0.92)\n",
        "\n",
        "# Display the chart\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "sonig1fIYH64",
        "outputId": "9300add6-7c8e-49a7-8a97-2bc3dffbb2a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x2000 with 5 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Multilingual Iterative Text Generation Result"
      ],
      "metadata": {
        "id": "39NNnp9VgKcn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "# Define the data\n",
        "data = {\n",
        "    'Model': ['Pegasus Zeroshot', 'Pegasus Multilingual', 'MT5 Zeroshot', 'MT5 Multilingual'],\n",
        "    'BLEU': [24.1, 24.2, 13.1, 13.2],\n",
        "    'RougeL': [27.67, 27.46, 21.51, 21.83],\n",
        "    'SARI': [18.08, 18.08, 19.73, 20.33]\n",
        "}\n",
        "\n",
        "# Convert the data to a pandas DataFrame\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Set the 'Model' column as the index\n",
        "df = df.set_index('Model')\n",
        "\n",
        "# Plot the data as a grouped bar chart\n",
        "ax = df.plot(kind='bar', rot=0)\n",
        "\n",
        "# Set the chart title and axis labels\n",
        "ax.set_title('Multilingual Model Performance Comparison for Edit Generation')\n",
        "ax.set_xlabel('Model')\n",
        "ax.set_ylabel('Score')\n",
        "\n",
        "# Slant the x-axis labels by 45 degrees\n",
        "ax.set_xticklabels(ax.get_xticklabels(), rotation=45, ha='right')\n",
        "\n",
        "# Display the chart\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 568
        },
        "id": "cXq6EzE3bSP7",
        "outputId": "d2adda77-199f-42c4-fe56-2379ce8a6cb3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "QHFd0qWA1ILy",
        "cHeKfc6g1WzL",
        "-D7ak9Ip10kP",
        "3Cc3hr3VnVLf",
        "Tm6aVcu6bHhd",
        "3c7LyW2yc7FX",
        "k4PBJrvcleVA",
        "Ehl3go_9jTiU",
        "1GTtAqsujwM1",
        "EN9zfkTEkInP",
        "0AgpC342kwsl"
      ],
      "machine_shape": "hm",
      "provenance": [],
      "gpuType": "T4",
      "toc_visible": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0b0b1dfaf8d6409fb46ff879593d939d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2f1ed22774fe471dab11ec6230ed4d99",
            "placeholder": "​",
            "style": "IPY_MODEL_a5e3b4d38e884b50804cd46af7a01e37",
            "value": "Downloading (…)lve/main/config.json: 100%"
          }
        },
        "0e70110beb2e4d97b0304e6d129d2ab1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_85295745d4f84dd6a18508b55afd7839",
            "placeholder": "​",
            "style": "IPY_MODEL_ec9df7f736174bed9d144a7f1e16fb21",
            "value": "Downloading (…)olve/main/vocab.json: 100%"
          }
        },
        "0f354d1326104642bb13f857639dafc2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7e6008d278de4bb7bf25401b4c69778d",
            "max": 501200538,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6cda7705f34641cd80e92af87742e555",
            "value": 501200538
          }
        },
        "1635b1aac34148759856d748ca4b228a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "23a77decbb454962ba7cfb38bc621394": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "24d52bcd0364477f80b96ddbdc4c5413": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "26975757cbc0431bab72b5b13e65b5c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2885fcfaf6e641fcb1630ef870cda141": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2c9951ab4b87430fa29cf3ce8f5b199e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ae9664db0c8b4d74b7a7c8c442e1c272",
            "placeholder": "​",
            "style": "IPY_MODEL_c8af097b721c4870b1b7436342e56e72",
            "value": "Downloading (…)olve/main/merges.txt: 100%"
          }
        },
        "2f1ed22774fe471dab11ec6230ed4d99": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "31d1bd51aded40b7a923e4ad7a1482e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_24d52bcd0364477f80b96ddbdc4c5413",
            "max": 898823,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e39f665eae444b078180cec12c983f9b",
            "value": 898823
          }
        },
        "4b41cbcc6b7f4dd487068ef982959e3c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4da3f72e742a4f62bd8c211c6406841b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "542bc26609f44040b2dbcafaaac6891c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5792bfc1a1b740578335e717c413fbc3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "66014c512c5b4dcd8c6cb7c81a061b32": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0e70110beb2e4d97b0304e6d129d2ab1",
              "IPY_MODEL_31d1bd51aded40b7a923e4ad7a1482e8",
              "IPY_MODEL_9edd3f1765514c058b1782fc02d4c6db"
            ],
            "layout": "IPY_MODEL_e9f2eef57c1e46fab74b07b6bd20695e"
          }
        },
        "6691fc2e31e24a12b63b6b78c7331dad": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6cda7705f34641cd80e92af87742e555": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "71b517cae9304d629857cc4a2edc8b62": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b14c5873d3a94193a1b29962a26a8ef2",
            "placeholder": "​",
            "style": "IPY_MODEL_e30fe1a315b743c9907dbaf068c320c5",
            "value": " 1.36M/1.36M [00:00&lt;00:00, 1.59MB/s]"
          }
        },
        "779d908a6fb3466db707f31fd479dbb6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7dafdbc7acb14490add81f4e23aae744": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7e6008d278de4bb7bf25401b4c69778d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "85295745d4f84dd6a18508b55afd7839": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8829a3508767430784c5e6e9f520b171": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "89292e82c5eb4101a48c1be2698fc232": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0b0b1dfaf8d6409fb46ff879593d939d",
              "IPY_MODEL_98f1a00eb6f7419a8d783315a608517f",
              "IPY_MODEL_cd122485192847598f7bd960063985bc"
            ],
            "layout": "IPY_MODEL_23a77decbb454962ba7cfb38bc621394"
          }
        },
        "8e42c7909a1c43268049dee9d35a6770": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "90fee9af1d9945abb2b622713e3ae262": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "98f1a00eb6f7419a8d783315a608517f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e703a6953b4644aa9adecc07ac2fc6ad",
            "max": 481,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2885fcfaf6e641fcb1630ef870cda141",
            "value": 481
          }
        },
        "9edd3f1765514c058b1782fc02d4c6db": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_542bc26609f44040b2dbcafaaac6891c",
            "placeholder": "​",
            "style": "IPY_MODEL_ecd209b0dd5d400bbb651e8f16e26f26",
            "value": " 899k/899k [00:00&lt;00:00, 17.1MB/s]"
          }
        },
        "9f1d4f779f2c45f9bed86941339c21ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_779d908a6fb3466db707f31fd479dbb6",
            "max": 456318,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f40514e63d1e4959a7cbcfac70dc784e",
            "value": 456318
          }
        },
        "a4da6cb97eea4110bb6c739965fb641e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4da3f72e742a4f62bd8c211c6406841b",
            "placeholder": "​",
            "style": "IPY_MODEL_c7e7e80c59ce499da47672585d383c8b",
            "value": "Downloading pytorch_model.bin: 100%"
          }
        },
        "a5d1611b270949a397c3a6e7316722f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cd2dd45d36d744309c53a6e1e93a7a45",
              "IPY_MODEL_d2860eb1ad024fa9b35de9e256825166",
              "IPY_MODEL_71b517cae9304d629857cc4a2edc8b62"
            ],
            "layout": "IPY_MODEL_db86c1b6a8bc46949fb54d577cfdf81c"
          }
        },
        "a5e3b4d38e884b50804cd46af7a01e37": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ae9664db0c8b4d74b7a7c8c442e1c272": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b0d08b981b044ce083501049bae9921a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a4da6cb97eea4110bb6c739965fb641e",
              "IPY_MODEL_0f354d1326104642bb13f857639dafc2",
              "IPY_MODEL_c656f7d20b624664b70d6a5406a413ce"
            ],
            "layout": "IPY_MODEL_d2d86a62c3c6486fab5a44efb20e229b"
          }
        },
        "b14c5873d3a94193a1b29962a26a8ef2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b593d756d7644f8a9de3de24a7b00556": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "be38747e0c5a4219872a133c893eab3b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c656f7d20b624664b70d6a5406a413ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5792bfc1a1b740578335e717c413fbc3",
            "placeholder": "​",
            "style": "IPY_MODEL_7dafdbc7acb14490add81f4e23aae744",
            "value": " 501M/501M [00:02&lt;00:00, 254MB/s]"
          }
        },
        "c7e7e80c59ce499da47672585d383c8b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c8af097b721c4870b1b7436342e56e72": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cd122485192847598f7bd960063985bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1635b1aac34148759856d748ca4b228a",
            "placeholder": "​",
            "style": "IPY_MODEL_4b41cbcc6b7f4dd487068ef982959e3c",
            "value": " 481/481 [00:00&lt;00:00, 27.6kB/s]"
          }
        },
        "cd2dd45d36d744309c53a6e1e93a7a45": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_be38747e0c5a4219872a133c893eab3b",
            "placeholder": "​",
            "style": "IPY_MODEL_b593d756d7644f8a9de3de24a7b00556",
            "value": "Downloading (…)/main/tokenizer.json: 100%"
          }
        },
        "d2860eb1ad024fa9b35de9e256825166": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8e42c7909a1c43268049dee9d35a6770",
            "max": 1355863,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8829a3508767430784c5e6e9f520b171",
            "value": 1355863
          }
        },
        "d2d86a62c3c6486fab5a44efb20e229b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "db86c1b6a8bc46949fb54d577cfdf81c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e30fe1a315b743c9907dbaf068c320c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e39f665eae444b078180cec12c983f9b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e681b04b211e4d8594d074e10568870e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2c9951ab4b87430fa29cf3ce8f5b199e",
              "IPY_MODEL_9f1d4f779f2c45f9bed86941339c21ef",
              "IPY_MODEL_f1428e0451a448f9aa4d8a4c5761589c"
            ],
            "layout": "IPY_MODEL_90fee9af1d9945abb2b622713e3ae262"
          }
        },
        "e703a6953b4644aa9adecc07ac2fc6ad": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e9f2eef57c1e46fab74b07b6bd20695e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ec9df7f736174bed9d144a7f1e16fb21": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ecd209b0dd5d400bbb651e8f16e26f26": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f1428e0451a448f9aa4d8a4c5761589c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6691fc2e31e24a12b63b6b78c7331dad",
            "placeholder": "​",
            "style": "IPY_MODEL_26975757cbc0431bab72b5b13e65b5c9",
            "value": " 456k/456k [00:00&lt;00:00, 18.0MB/s]"
          }
        },
        "f40514e63d1e4959a7cbcfac70dc784e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
